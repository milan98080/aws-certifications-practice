"use strict";(self.webpackChunkaws_practice_app=self.webpackChunkaws_practice_app||[]).push([[570],{570(e){e.exports=JSON.parse('{"exam_id":25,"total_pages_attempted":112,"successful_pages":111,"failed_pages":1,"total_questions":555,"extraction_date":"2025-12-24T09:15:23.814Z","extraction_method":"console_scraper_api_v1","questions":[{"question_id":"mqmIUzeiWNAWdRdYv7NU","question_number":1,"page":1,"question_text":"A company is implementing an application on Amazon EC2 instances. The application needs to process incoming transactions. When the application detects a transaction that is not valid, the application must send a chat message to the company\'s support team. To send the message, the application needs to retrieve the access token to authenticate by using the chat API.\\nA developer needs to implement a solution to store the access token. The access token must be encrypted at rest and in transit. The access token must also be accessible from other AWS accounts.\\nWhich solution will meet these requirements with the LEAST management overhead?","choices":{"D":"Encrypt the access token by using an AWS Key Management Service (AWS KMS) AWS managed key. Store the access token in an Amazon S3 bucket. Add a bucket policy to the S3 bucket to allow access from other accounts. Update the IAM role of the EC2 instances with permissions to access Amazon S3 and AWS KMS. Retrieve the token from the S3 bucket. Decrypt the token by using AWS KMS on the EC2 instances. Use the decrypted access token to send the massage to the chat.","C":"Use AWS Secrets Manager with an AWS Key Management Service (AWS KMS) customer managed key to store the access token. Add a resource-based policy to the secret to allow access from other accounts. Update the IAM role of the EC2 instances with permissions to access Secrets Manager. Retrieve the token from Secrets Manager. Use the decrypted access token to send the message to the chat.","B":"Encrypt the access token by using an AWS Key Management Service (AWS KMS) customer managed key. Store the access token in an Amazon DynamoDB table. Update the IAM role of the EC2 instances with permissions to access DynamoDB and AWS KMS. Retrieve the token from DynamoDDecrypt the token by using AWS KMS on the EC2 instances. Use the decrypted access token to send the message to the chat.","A":"Use an AWS Systems Manager Parameter Store SecureString parameter that uses an AWS Key Management Service (AWS KMS) AWS managed key to store the access token. Add a resource-based policy to the parameter to allow access from other accounts. Update the IAM role of the EC2 instances with permissions to access Parameter Store. Retrieve the token from Parameter Store with the decrypt flag enabled. Use the decrypted access token to send the message to the chat."},"correct_answer":"C","answer_ET":"C","answers_community":["C (88%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102778-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 09:21:00","unix_timestamp":1678954860,"discussion_count":45,"discussion":[{"upvote_count":"31","poster":"Untamables","comments":[{"content":"Based on this AWS managed keys can be used for cross account accessing. https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html","poster":"CyberBaby803","comments":[{"content":"I am not sure if the documentation you provided specifically say that AWS managed keys can be used for cross account accessing. \\n\\nHowever, @Untamables explanation is on point. Please see this Stack Overflow thread - https://stackoverflow.com/questions/63420732/sharing-an-aws-managed-kms-key-with-another-account","comment_id":"926129","poster":"AgboolaKun","upvote_count":"1","timestamp":"1687019700.0"}],"timestamp":"1679691600.0","comment_id":"849613","upvote_count":"2"},{"poster":"jipark","upvote_count":"2","timestamp":"1691112300.0","content":"cross account, rotate is key for \'Security Manager\'","comment_id":"971594"}],"timestamp":"1679355600.0","comment_id":"845354","content":"Selected Answer: C\\nThe correct answer is C.\\nhttps://aws.amazon.com/premiumsupport/knowledge-center/secrets-manager-share-between-accounts/\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/auth-and-access_examples_cross.html\\nOption A is wrong. It seems to be a good solution. However, AWS managed keys cannot be used for cross account accessing."},{"upvote_count":"7","content":"Selected Answer: C\\nC is the Correct Option\\nI\u2019ve tried a few mock test platforms, but SkillCertExams stood out. Their content is top-notch and very similar to what you see on the actual exam.","poster":"jake99","comment_id":"1585503","timestamp":"1752224040.0"},{"upvote_count":"1","comment_id":"1590850","content":"Selected Answer: C\\nQuestion: is this the 2025 updated AWS Certified Developer Associate question bank? Only asking because there\'s another one on this website ( does not have the DVA-C02 code or the \\"popular\\" sticker )","poster":"AlexChacon99","timestamp":"1753650720.0"},{"comment_id":"1581688","content":"Selected Answer: C\\nhttps://aws.amazon.com/premiumsupport/knowledge-center/secrets-manager-share-between-accounts","upvote_count":"1","timestamp":"1751221380.0","poster":"hamidze"},{"poster":"thinei","comment_id":"1578211","content":"Selected Answer: C\\nAnswer is C.\\nSecrets Manager automatically encrypts secrets at rest with KMS and uses TLS for encryption in transit. We can add a resource-based policy to a Secrets Manager secret to allow access from other AWS accounts.","timestamp":"1750136220.0","upvote_count":"1"},{"content":"Selected Answer: C\\nresource based policy works with secrets manger not with SSM","upvote_count":"1","comment_id":"1561183","poster":"anandkg","timestamp":"1744822560.0"},{"timestamp":"1734698460.0","comments":[{"content":"B) Eliminated - Creating and managing the DynamoDB table create overhead","upvote_count":"1","timestamp":"1734700920.0","comments":[{"comment_id":"1329461","poster":"sumanshu","upvote_count":"1","timestamp":"1734700980.0","content":"D) Eliminated - Complexity and overhead for Managing an S3 bucket with access policies for cross-account access"}],"comment_id":"1329459","poster":"sumanshu"}],"content":"Selected Answer: C\\nFor cross-account access, the AWS managed key (Option A) will be difficult to manage because it doesn\'t allow you to directly manage cross-account access. Therefore, Option C (AWS Secrets Manager with a customer-managed KMS key) is the recommended solution for cross-account access and security.","poster":"sumanshu","upvote_count":"1","comment_id":"1329440"},{"comments":[{"timestamp":"1733914020.0","content":"D: ==> C: ... sr for inconsistent","comment_id":"1324986","poster":"trieudo","upvote_count":"1"}],"poster":"trieudo","comment_id":"1324985","timestamp":"1733913960.0","content":"Selected Answer: C\\nkeywords: LEAST management overhead\\n\\n==> Discard B, D: you must do many steps to config with Storage, DB with KMS, IAM Role\\n==> Discard A: Pretty correct, but in use, you may write some script. It can work but requires additional configuration and doesn\'t offer some of the benefits tailored for secrets management like automatic rotation.\\n\\n\\nD: The solution with AWS Secrets Manager (option C) provides the least management overhead because:\\n\\nSecrets Manager is specifically designed for storing and managing sensitive information like access tokens.\\nIt natively integrates with AWS KMS for encryption and decryption.\\nIt simplifies access control and auditing.\\nBy adding a resource-based policy, cross-account access is easily managed without the need for additional configurations like DynamoDB tables or S3 bucket policies.","upvote_count":"1"},{"comment_id":"926935","timestamp":"1727237640.0","upvote_count":"1","content":"Selected Answer: A\\nUse an AWS Systems Manager Parameter Store SecureString parameter that uses an AWS Key Management Service (AWS KMS) AWS managed key to store the access token. This option allows you to securely store the access token in the Parameter Store, which automatically encrypts the data at rest and in transit. By adding a resource-based policy, you can also grant access to the access token from other AWS accounts. The IAM role of the EC2 instances can be updated to allow permissions to access the Parameter Store, and the access token can be retrieved with the decrypt flag enabled for use in sending the chat message. This option requires minimal setup and management compared to the other choices.","poster":"Tee400"},{"comment_id":"1058635","content":"Selected Answer: A\\nBy default, AWS Systems Manager Parameter Store does not natively support cross-account access for SecureString parameters. However, you can configure cross-account access to SecureString parameters by sharing the KMS key with the target AWS accounts. To do this, you need to create a resource-based KMS key policy that allows access to the key by the external AWS account(s). After configuring the KMS key policy to allow the necessary cross-account access, you can grant IAM roles in the target accounts permission to access the SecureString parameters that are encrypted using that KMS key.","timestamp":"1727237640.0","poster":"cgpt","upvote_count":"2"},{"content":"AWS Secrets Manager (Option C) is designed for exactly this kind of use case, providing built-in functionality for secure storage and retrieval of secrets with minimal management overhead, especially for managing access tokens and cross-account access.\\nAmazon S3 with KMS (Option D), while familiar and powerful, requires more manual work to set up and manage the security aspects, which can lead to increased overhead in comparison to Secrets Manager.\\nGiven that the goal is to have the least management overhead, Option C is the best fit because it is purpose-built for managing secrets and automates much of the complexity involved in secure storage and retrieval.","upvote_count":"1","poster":"tomchandler077","timestamp":"1727237580.0","comment_id":"1243772"},{"comment_id":"1248734","upvote_count":"2","timestamp":"1721113800.0","poster":"Anandesh","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/data-protection.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/auth-and-access_resource-policies.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/security-encryption.html"},{"poster":"nkroker","timestamp":"1720099920.0","comment_id":"1242107","content":"C is the correct answer as the Secrets Manager supports resource-based policies, allowing you to grant access to other AWS accounts easily.","upvote_count":"1"},{"comment_id":"1222762","timestamp":"1717257300.0","content":"Selected Answer: C\\nC is correct answer.","upvote_count":"1","poster":"NagaoShingo"},{"poster":"65703c1","upvote_count":"1","timestamp":"1716295140.0","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1214934"},{"content":"Selected Answer: C\\nThis is the correct answer for lease overhead to manage the secret key","poster":"shabeebcoder","comment_id":"1189913","timestamp":"1712319540.0","upvote_count":"1"},{"content":"Selected Answer: C\\nIt is C","poster":"ibratoev","timestamp":"1711370520.0","upvote_count":"1","comment_id":"1182463"},{"content":"- Option A involves using AWS Systems Manager Parameter Store, which can work but requires additional configuration and doesn\'t offer some of the benefits tailored for secrets management like automatic rotation.\\n- Option B involves storing the access token in DynamoDB, which is not specifically designed for secrets management, and managing encryption and decryption manually using AWS KMS.\\n- Option D involves using S3, which again is not designed for secrets management, and adds complexity in managing access policies and permissions. Additionally, accessing the token would involve reading from S3, decrypting it, and then using it, which is less straightforward compared to using a service like Secrets Manager.","timestamp":"1710303300.0","upvote_count":"2","poster":"certplan","comment_id":"1172225"},{"poster":"SD_CS","comment_id":"1149720","content":"Selected Answer: A\\nI think this would be A as this is cheaper than C. Any reason why A can not be the answer?","comments":[{"comment_id":"1165589","poster":"TheFivePips","upvote_count":"2","timestamp":"1709558100.0","content":"From what I can find, You can apply resource-based policies at the Parameter Store level to control access to the entire Parameter Store service. However, you cannot apply resource-based policies directly to individual parameters within the Parameter Store.\\nThat is seemingly the only reason I would choose C over A.\\nBut were also not looking for whats cheapest, were looking for whats easiest to manage"}],"timestamp":"1707872460.0","upvote_count":"2"},{"comment_id":"1132924","timestamp":"1706305860.0","poster":"tsdsmth","upvote_count":"2","content":"The answer would be C if an AWS-managed key was used, as Secrets Manager and KMS are good for situations like this. However, the use of a customer-managed key increases management overhead. So the best answer is D, not C."},{"upvote_count":"1","content":"You cannot use a resource-based policy with a parameter in the Parameter Store. The stephen answser Option C is correct Practise paper3","timestamp":"1705292460.0","comment_id":"1123049","poster":"gilleep_17"},{"timestamp":"1705291380.0","poster":"gilleep_17","content":"customer managed key , its an extra work. So I am confused with option A and C","comment_id":"1123037","upvote_count":"1"},{"content":"ahhhhhh","upvote_count":"1","timestamp":"1703450880.0","comment_id":"1104833","poster":"marcosbude"},{"comment_id":"1061906","timestamp":"1699074120.0","content":"Selected Answer: D\\nI think using S3 to store and KMS to decrypt is the solution for this requirement","upvote_count":"1","poster":"dongocanh272"},{"upvote_count":"1","timestamp":"1696703580.0","poster":"Digo30sp","comment_id":"1027585","content":"Selected Answer: C\\nAnswer C is correct"},{"upvote_count":"1","content":"Selected Answer: C\\ni think c is correct","comment_id":"1025592","timestamp":"1696506420.0","poster":"huyhq"},{"comment_id":"1021362","upvote_count":"1","content":"Since the question says LEAST Management Overhead. The answer cannot be B or C because they suggest to use \\"AWS Key Management Service (AWS KMS) customer managed key \\". Answer should be A.","timestamp":"1696065480.0","poster":"NinjaCloud"},{"poster":"Nav16011991","timestamp":"1695752520.0","content":"Selected Answer: C\\nThe correct answer is C.","upvote_count":"1","comment_id":"1018096"},{"upvote_count":"1","timestamp":"1694861460.0","poster":"Shreya_aspire","comment_id":"1009085","content":"Selected Answer: C\\nhttps://aws.amazon.com/blogs/security/how-to-access-secrets-across-aws-accounts-by-attaching-resource-based-policies/"},{"upvote_count":"1","poster":"hsinchang","timestamp":"1694209320.0","content":"Selected Answer: C\\nCross Account + Rotation = Secrets Manager","comment_id":"1002723"},{"poster":"Kashan6109","timestamp":"1693792020.0","content":"Selected Answer: C\\nSecret Manager allows you to share secret cross account","comment_id":"998081","upvote_count":"1"},{"comment_id":"962512","upvote_count":"3","content":"Selected Answer: C\\nCorrect Answer is C. Stephen Marek practice test on udemy has this question.","timestamp":"1690273740.0","poster":"Zeus_"},{"comment_id":"957076","upvote_count":"1","timestamp":"1689822420.0","poster":"backfringe","content":"vote for C."},{"timestamp":"1689145260.0","content":"C. Not A because resource based access policy is not allowed for parameter store in KMS. Only supports Identity Based. Whereas secret manager supports both","comment_id":"949544","upvote_count":"4","poster":"monkeyjuthu"},{"comment_id":"944306","poster":"eberhe900","content":"Selected Answer: D\\nAccess from Other AWS Accounts:\\n\\nCreate a cross-account IAM role in the AWS account where the access token is stored.\\nDefine the necessary permissions for the IAM role to allow access to the encrypted token.\\nShare the encrypted token with the other AWS accounts by granting the IAM role access to those accounts.\\nThe receiving accounts can then assume the IAM role to access the encrypted token securely.","timestamp":"1688616600.0","upvote_count":"2"},{"content":"Selected Answer: C\\nThe argument should be between A and C. However, the AWS owned keys in option A disqualifies it. \\n\\nThis is because AWS owned keys cannot be used fro cross-accounts accessing. Therefore, correct answer is C. Please read the following Stack Overflow thread - https://stackoverflow.com/questions/63420732/sharing-an-aws-managed-kms-key-with-another-account","poster":"AgboolaKun","timestamp":"1687031400.0","comment_id":"926223","upvote_count":"1"},{"comment_id":"910289","upvote_count":"1","poster":"ScherbakovMike","content":"Definitely, it\'s not A, because the AWS Systems manager parameter store doesn\'t support cross account access. \\nI guess, C is not correct, because there will be many saved tokens.\\nD, yes, why not, S3 access is possible from different accounts.","timestamp":"1685454480.0"},{"content":"Selected Answer: C\\nThe question is tricky, I thought it was A but you can\'t use the AWS KMS default key for the account. The AWS KMS default key is created, managed, and used on your behalf by an AWS service that runs on AWS Key Management Service. The AWS KMS default key is unique to your AWS account and AWS Region. Only the service that created the AWS managed key can use it. So the answer should be C","upvote_count":"1","comment_id":"910105","poster":"ezredame","timestamp":"1685438820.0"},{"comment_id":"890659","timestamp":"1683366900.0","poster":"Bibay","upvote_count":"1","content":"Selected Answer: C\\nC. The Lambda function does not have IAM permissions to write to DynamoDB is the most likely cause of this issue.\\n\\nWhen a Lambda function is unable to write to a DynamoDB table, it is usually because it lacks the necessary IAM permissions to perform the action. To resolve this issue, the developer needs to grant the Lambda function\'s execution role permissions to write to the DynamoDB table. The execution role should have the necessary policies attached to it. The developer can use the AWS Identity and Access Management (IAM) console to add the necessary policies to the execution role.\\n\\nThe other options may cause issues in different scenarios, but they are not the most likely causes in this specific situation."},{"comment_id":"883785","content":"Selected Answer: C\\nA is wrong, you can\'t share a parameter-store secureString to an external AWS Account.\\nThis is only possible with Secrets Manager : https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html","poster":"ihebchorfi","timestamp":"1682703360.0","upvote_count":"4"},{"content":"Selected Answer: C\\nOption A is wrong becuase you cant use AWS managed keys for cross-account access","comment_id":"874093","poster":"Duponator","upvote_count":"3","timestamp":"1681850760.0"},{"timestamp":"1681619820.0","comment_id":"871459","poster":"Syre","upvote_count":"2","content":"Selected Answer: A\\nAnswer here is A people.\\nOption C uses AWS Secrets Manager to store the access token, which is similar to Parameter Store but designed specifically for secrets. However, Secrets Manager has a higher cost and is better suited for complex secrets that require rotation or integration with AWS services. Parameter Store is a better fit for a simple access token. Additionally, retrieving the token from Secrets Manager requires more code and maintenance than retrieving the token directly from Parameter Store.\\n\\nOption D stores the access token in an Amazon S3 bucket, which requires more setup and management overhead than Parameter Store. Although S3 provides robust storage and access control features, it is not the best choice for a simple access token","comments":[{"comment_id":"888779","poster":"rlnd2000","content":"with option A how you make possible => ...The access token must also be accessible from other AWS accounts.","timestamp":"1683134160.0","upvote_count":"4"}]},{"content":"Selected Answer: C\\nShould be C.\\n\\nOption A is a valid solution that meets the requirements of encrypting the access token at rest and in transit, as well as allowing access from other AWS accounts. However, it requires an additional step of retrieving the token with the decrypt flag enabled, which adds some management overhead when compared to other options.\\n\\nOption C uses AWS Secrets Manager, which eliminates the need for explicitly enabling the decryption flag. It also has more granular permissions for accessing the secrets, making it slightly more secure. DynamoDB in Option B and S3 in Option D are also options for storing the access token, but they require additional steps for encryption and decryption, adding more management overhead. Overall, Option A is a valid solution, but the other options have less management overhead while still meeting the requirements.","timestamp":"1679098620.0","comment_id":"842373","upvote_count":"3","poster":"clarksu"},{"comment_id":"840723","poster":"haaris786","upvote_count":"2","content":"As per this doc it should be A:\\n\\nhttps://aws.amazon.com/blogs/mt/use-parameter-store-to-securely-access-secrets-and-config-data-in-aws-codedeploy/","timestamp":"1678957200.0"},{"comment_id":"840685","content":"What\'s the answer? Isn\'t it A?","poster":"good_","upvote_count":"3","timestamp":"1678954860.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:03.381Z","extraction_method":"api_direct_v1"},{"question_id":"to6q6rK96nvKH3vEdBwo","question_number":2,"page":1,"question_text":"A developer is deploying a new application to Amazon Elastic Container Service (Amazon ECS). The developer needs to securely store and retrieve different types of variables. These variables include authentication information for a remote API, the URL for the API, and credentials. The authentication information and API URL must be available to all current and future deployed versions of the application across development, testing, and production environments.\\nHow should the developer retrieve the variables with the FEWEST application changes?","choices":{"C":"Update the application to retrieve the variables from an encrypted file that is stored with the application. Store the API URL and credentials in unique files for each environment.","B":"Update the application to retrieve the variables from AWS Key Management Service (AWS KMS). Store the API URL and credentials as unique keys for each environment.","D":"Update the application to retrieve the variables from each of the deployed environments. Define the authentication information and API URL in the ECS task definition as unique names during the deployment process.","A":"Update the application to retrieve the variables from AWS Systems Manager Parameter Store. Use unique paths in Parameter Store for each variable in each environment. Store the credentials in AWS Secrets Manager in each environment."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103335-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-20 07:24:00","unix_timestamp":1679293440,"discussion_count":18,"discussion":[{"timestamp":"1683390360.0","content":"Correct answer is A.","upvote_count":"18","poster":"geekdamsel","comment_id":"890870"},{"upvote_count":"9","content":"Selected Answer: A\\nThe application has credentials and URL, so it\u2019s convenient to store them in ssm parameter store restive them.","poster":"Warlord_92","timestamp":"1679293440.0","comment_id":"844587"},{"comments":[{"timestamp":"1734709140.0","content":"C) Eliminated - Storing variables in encrypted files adds operational overhead. Managing separate files for each environment can quickly become cumbersome.","upvote_count":"1","poster":"sumanshu","comment_id":"1329544"}],"poster":"sumanshu","content":"Selected Answer: A\\nB) Eliminated - It cannot directly store variables such as the API URL or credentials\\nD) Eliminated - Storing sensitive information like credentials directly in ECS task definitions is not secure","timestamp":"1734709080.0","upvote_count":"1","comment_id":"1329543"},{"poster":"trieudo","timestamp":"1733962740.0","comment_id":"1325304","content":"Selected Answer: A\\nkeyword: FEWEST application changes\\n\\n==> A: This minimizes code changes as the retrieval method remains consistent across environments; only the Parameter Store paths need updating. Secrets Manager securely stores sensitive credentials.","upvote_count":"1"},{"comment_id":"927600","upvote_count":"2","timestamp":"1727238240.0","poster":"Tee400","content":"Selected Answer: A\\nAWS Systems Manager Parameter Store is a service that allows you to securely store configuration data such as API URLs, credentials, and other variables. By updating the application to retrieve the variables from Parameter Store, you can separate the configuration from the application code, making it easier to manage and update the variables without modifying the application itself. Storing the credentials in AWS Secrets Manager provides an additional layer of security for sensitive information."},{"timestamp":"1727238240.0","upvote_count":"2","comment_id":"1188851","poster":"badsati","content":"Answer is A\\n\\nAWS Systems Manager Parameter Store and AWS Secrets Manager are designed for securely storing and managing sensitive information such as credentials, API URLs, and configuration variables.\\nUsing AWS Systems Manager Parameter Store allows the developer to centrally manage configuration variables across different environments (development, testing, production) without requiring application code changes. Each variable can have a unique path in Parameter Store, ensuring separation and organization."},{"timestamp":"1727238240.0","comment_id":"1096678","poster":"ez_24","upvote_count":"5","content":"Correct Answer is A \\n\\nOption B, using AWS Key Management Service (AWS KMS), is not ideal for this scenario primarily because AWS KMS is designed for creating and controlling encryption keys, not for storing configuration data or credentials. KMS keys are used to encrypt and decrypt data, rather than directly storing or managing it. For securely managing and retrieving application configuration data and sensitive information like API credentials, Systems Manager Parameter Store and AWS Secrets Manager are more appropriate, offering direct support for these use cases with better integration for applications."},{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716297420.0","upvote_count":"1","comment_id":"1214967","poster":"65703c1"},{"timestamp":"1715032020.0","content":"Selected Answer: A\\nSSM parameter store with proper posh is the answer.","comment_id":"1207586","poster":"Prosen2522","upvote_count":"1"},{"comment_id":"1072021","timestamp":"1700092440.0","upvote_count":"2","poster":"leonardoliveros","content":"Selected Answer: A\\nYou put the different variables for each environment, is the best solution because it\'s isolated between environment"},{"upvote_count":"2","content":"i think corrent is A, but why is B ?","comment_id":"1058469","timestamp":"1698731580.0","poster":"vmintam"},{"comment_id":"1009048","content":"I think the wording of option A has a typo first it mentioned \\" Update the application to retrieve the variables from AWS Systems Manager Parameter Store\\" then it says \\"Store the credentials in AWS Secrets Manager in each environment.\\"","poster":"alihaider907","upvote_count":"1","timestamp":"1694856480.0"},{"content":"A is correct","timestamp":"1693389900.0","comment_id":"993933","upvote_count":"1","poster":"meetparag81"},{"poster":"jayvarma","content":"Option A is correct. The AWS Systems Manager Paramter Store\'s primary purpose is to secure sensitive information such as API URLs, credentials and the variables that we store in it.","comment_id":"976264","upvote_count":"2","timestamp":"1691558100.0"},{"timestamp":"1682381640.0","content":"Selected Answer: A\\nhis solution allows the developer to securely store and retrieve different types of variables, including authentication information for a remote API, the URL for the API, and credentials.","poster":"MrTee","comment_id":"879787","upvote_count":"2"},{"content":"Definitely A","timestamp":"1681364820.0","comment_id":"869122","poster":"qsergii","upvote_count":"1"},{"content":"it should be a, kms is used for encryption: https://aws.amazon.com/kms/","upvote_count":"3","comment_id":"866892","timestamp":"1681184460.0","poster":"fqmark"},{"poster":"prabhay786","comment_id":"844769","upvote_count":"2","timestamp":"1679308860.0","content":"It should be option A"}],"answer_description":"","extracted_at":"2025-12-24T08:55:03.381Z","extraction_method":"api_direct_v1"},{"question_id":"6fzK3DHFUDh4Do0fxh17","question_number":3,"page":1,"question_text":"A company uses AWS Lambda functions and an Amazon S3 trigger to process images into an S3 bucket. A development team set up multiple environments in a single AWS account.\\n\\nAfter a recent production deployment, the development team observed that the development S3 buckets invoked the production environment Lambda functions. These invocations caused unwanted execution of development S3 files by using production Lambda functions. The development team must prevent these invocations. The team must follow security best practices.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Update the Lambda execution role for the production Lambda function to add a policy that allows the execution role to read from only the production environment S3 bucket.","B":"Move the development and production environments into separate AWS accounts. Add a resource policy to each Lambda function to allow only S3 buckets that are within the same account to invoke the function.","C":"Add a resource policy to the production Lambda function to allow only the production environment S3 bucket to invoke the function.","D":"Move the development and production environments into separate AWS accounts. Update the Lambda execution role for each function to add a policy that allows the execution role to read from the S3 bucket that is within the same account."},"correct_answer":"B","answer_ET":"B","answers_community":["B (51%)","C (45%)","2%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109246-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-15 01:06:00","unix_timestamp":1684105560,"discussion_count":32,"discussion":[{"content":"Selected Answer: C\\nB is a wrong answer because I do not understand the need to move the environments to separate AWS accounts. The resource policy in the production environment can be used to control which S3 bucket invokes the function. \\n\\nIn my understanding, the answer choice C fulfills the security best practices requirement in the question.","comment_id":"900510","upvote_count":"29","poster":"AgboolaKun","comments":[{"content":"It\'s a best practice: Best Practices:\\nSeparate workloads using accounts: Establish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access. https://wa.aws.amazon.com/wat.question.SEC_1.en.html","poster":"MrPie","comments":[{"upvote_count":"1","poster":"maurice2005","content":"There is nowhere mentioned in the question that workload is the problem!","timestamp":"1710966900.0","comment_id":"1178683"}],"timestamp":"1688645760.0","comment_id":"944627","upvote_count":"15"},{"comment_id":"1269353","upvote_count":"3","poster":"wh1t4k3r","timestamp":"1724149920.0","content":"\\"The team must follow security best practices\\"\\nSecurity best practices state that prod should be separated from non prod environments."},{"comment_id":"970808","timestamp":"1691044260.0","content":"resource policy totally fulfill requirement","poster":"jipark","upvote_count":"3"}],"timestamp":"1684358400.0"},{"timestamp":"1686082560.0","comment_id":"916617","poster":"csG13","upvote_count":"23","content":"Selected Answer: B\\nI choose B because it says that the team should follow the best security practices. AWS well-architected framework suggests separation. For reference see the link below: https://wa.aws.amazon.com/wat.question.SEC_1.en.html"},{"content":"Selected Answer: C\\nAmazon S3 can invoke a Lambda function only if the Lambda function\'s resource-based policy allows it.\\n\\nIn this case, development S3 buckets are incorrectly configured to invoke the production Lambda function. This implies that the resource policy on the production Lambda function is too permissive.\\n\\nTo fix this, you should restrict the Lambda function\u2019s resource policy so that only the production S3 bucket has permission to invoke it.","timestamp":"1743913080.0","comment_id":"1557201","poster":"wmv__","upvote_count":"1"},{"poster":"mooncake1","comment_id":"1346187","upvote_count":"1","timestamp":"1737736560.0","content":"Selected Answer: C\\nSeparating account can be more secure and easy but maintenance will be more hard. \\nIt is developer\'s role and ability to distinguish and maintain between two environments, not just splitting them because it\'s easy. \\nWhat AWS wants as a DVA Certificate Member is not a person who splits the accounts because its easy , but is able to use IAM properly."},{"timestamp":"1737493380.0","poster":"rkotit","content":"Selected Answer: C\\nWhen securing AWS Lambda functions, you must ensure that only authorized resources (like an S3 bucket) can trigger or invoke the function. In this scenario, the simplest and most effective solution is to use resource-based policies on the Lambda function to restrict access.","comment_id":"1344369","upvote_count":"1"},{"comment_id":"1332374","poster":"sumanshu","upvote_count":"1","comments":[{"timestamp":"1739039280.0","poster":"sumanshu","comment_id":"1353574","upvote_count":"1","content":"B) can be correct\\n\\nWhile this does restrict invocation to the production S3 bucket, keeping both environments in the same account is not a best security practice.\\nA single-account setup increases the risk of misconfigurations, accidental access, and security breaches."}],"timestamp":"1735298220.0","content":"Selected Answer: C\\nA) Eliminated - This approach focuses on the Lambda function\'s ability to read from S3, not on which S3 buckets can invoke it.\\n\\nB) Eliminated - Moving environments to separate AWS accounts might improve isolation but is not necessary to solve the stated problem\\n\\nC) Correct - The resource policy in Option C restricts Lambda function invocations to only the intended production S3 bucket. This is a direct implementation of AWS\'s least privilege security model"},{"timestamp":"1734777120.0","poster":"Dimix3","comment_id":"1329926","content":"Selected Answer: C\\nOption C focuses on securing the production Lambda function by adding a resource policy to restrict invocations. This policy would specify that only the production S3 bucket can trigger the production Lambda function. This prevents accidental invocations from development S3 buckets.","upvote_count":"1"},{"content":"Selected Answer: B\\nPls pay attention to keywords when you do aws quizzes.\\nThe best security practice: option B\\nThe lowest operational cost: option C.\\nSo B is definitely the answer.","upvote_count":"2","timestamp":"1730542620.0","poster":"nbxyzd","comment_id":"1306134"},{"timestamp":"1728738360.0","upvote_count":"1","content":"Selected Answer: C\\nBecause-\\nB. Move the development and production environments into separate AWS accounts:\\n\\nWhile moving to separate accounts is a good practice for environment isolation, it\'s a more complex and potentially costly solution. Also, it isn\'t strictly necessary to achieve the goal of preventing unauthorized invocations, which can be accomplished via resource policies. It adds overhead without directly addressing the root cause.","poster":"AmitRanchi","comment_id":"1296513"},{"timestamp":"1726204860.0","upvote_count":"1","content":"Selected Answer: B\\nBest practices is the key Word","poster":"Saudis","comment_id":"1283021"},{"poster":"Saurabh04","content":"Option D is correct. This approach ensures isolation while maintaining manageability","timestamp":"1722907680.0","comment_id":"1261326","upvote_count":"1"},{"comments":[{"content":"Read carefully. The questions asks for \'the best\' not the \'the simplest\' security practice.","comment_id":"1306129","timestamp":"1730542380.0","upvote_count":"1","poster":"nbxyzd"}],"content":"Selected Answer: C\\nOption C is the simplest way to achieve this requirement.","upvote_count":"1","poster":"queekao","timestamp":"1721790180.0","comment_id":"1254071"},{"comment_id":"1253377","upvote_count":"1","poster":"Anandesh","timestamp":"1721703600.0","content":"Selected Answer: B\\nEstablish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access"},{"comment_id":"1250148","timestamp":"1721280780.0","poster":"Aws_aspr","content":"Asked 18 July 24 WIthout security best practices word. So C is correct answer for this.","upvote_count":"1"},{"upvote_count":"1","comment_id":"1215999","content":"Selected Answer: B\\nB is the correct amswer.","timestamp":"1716408780.0","poster":"65703c1"},{"poster":"SerialiDr","timestamp":"1709121960.0","comment_id":"1161590","content":"Selected Answer: C\\nThis approach involves configuring a resource-based policy (also known as a Lambda function policy) that explicitly defines which resources (in this case, S3 buckets) can invoke the Lambda function. By specifying only the production S3 bucket in the resource policy of the production Lambda function, you ensure that only events from the designated production S3 bucket can trigger the production Lambda function. This prevents development or other non-production buckets from inadvertently invoking production Lambda functions, thus maintaining environment integrity and security best practices.","upvote_count":"1"},{"poster":"KarBiswa","timestamp":"1708848240.0","upvote_count":"2","comment_id":"1158469","content":"Selected Answer: D\\nI feel it is D as there is no doubt we need to separately create two accounts for DEV & PROD. After that there must lambda execution roles where we can the specific policies. Resource based policies more of a Cross Account access.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html\\nhttps://repost.aws/knowledge-center/lambda-execution-role-s3-bucket\\nAs the question demands the best practices scenario so option D fulfils that."},{"comment_id":"1150669","content":"Selected Answer: B\\nI initially thought C, but after going through the below, I dont think there is any scope for doubt. \\n\\nstablish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access\\n\\nhttps://docs.aws.amazon.com/en_us/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html","timestamp":"1707958920.0","poster":"SD_CS","upvote_count":"4"},{"comment_id":"1112806","upvote_count":"1","poster":"rrshah83","content":"Selected Answer: C\\nnew accounts not necessary...","timestamp":"1704289920.0"},{"poster":"Certified101","content":"Selected Answer: B\\nB - following best practices","upvote_count":"2","comment_id":"1099183","timestamp":"1702841940.0"},{"content":"OMG this questions can be very wordy... be careful and read carefully - Answer is C","poster":"[Removed]","comments":[{"upvote_count":"1","poster":"[Removed]","comment_id":"1092180","content":"after reading this link --\x3e https://wa.aws.amazon.com/wat.question.SEC_1.en.html changing answer to B","timestamp":"1702166880.0"}],"timestamp":"1702166640.0","upvote_count":"1","comment_id":"1092176"},{"poster":"Mimi666","comment_id":"1086971","upvote_count":"1","content":"Selected Answer: B\\nKeeping the security best-practices.","timestamp":"1701624660.0"},{"comment_id":"1086397","upvote_count":"1","content":"Selected Answer: B\\nChatGPT: B","comments":[],"timestamp":"1701547980.0","poster":"tqiu654"},{"comment_id":"1046341","poster":"Rameez1","upvote_count":"4","timestamp":"1697573520.0","content":"Selected Answer: B\\nMoving the Dev and Prod environments to separate Accounts will make them totally isolated with cross account Lambda invocations. Whereas in Option C though Prod Lambda won\'t trigger with Dev S3 bucket Event, Dev Lambda may still get mistakenly invoked by Prod S3 Bucket event and perform unwanted actions."},{"poster":"Nagasoracle","upvote_count":"1","comments":[{"timestamp":"1698349500.0","upvote_count":"1","content":"COMO CHINGAS","poster":"Chicote","comment_id":"1054879"}],"comment_id":"1046218","content":"Selected Answer: B\\nSorry it is B\\nAs it mentions to follow security practice","timestamp":"1697561700.0"},{"upvote_count":"1","comment_id":"1046217","timestamp":"1697561640.0","content":"Selected Answer: A\\nAnswer : A\\nAs it mentions to follow best security practice","poster":"Nagasoracle"},{"comment_id":"1010523","content":"B seems to be the correct one\\nhttps://docs.aws.amazon.com/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html\\nEstablish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access.","timestamp":"1695037440.0","upvote_count":"1","poster":"Millie024"},{"comment_id":"993621","upvote_count":"1","poster":"fossil123","timestamp":"1693357380.0","content":"Selected Answer: C\\nC meets the contextual security requirements."},{"timestamp":"1692891120.0","poster":"stilloneway","upvote_count":"1","comment_id":"989302","content":"Selected Answer: B\\nSee the question, in terms of \\"Security best practices\\", Answer is B. It could be C for 2nd option if separate AWS account is not possible."},{"content":"C. Add a resource policy to the production Lambda function to allow only the production environment S3 bucket to invoke the function.\\n\\nExplanation:\\n\\nIn this scenario, the goal is to prevent unwanted invocations of production Lambda functions by development S3 buckets. Adding a resource policy directly to the production Lambda function that restricts invocations to only the production S3 bucket ensures that the function is only invoked by the intended bucket.\\n\\nChatGPT","comment_id":"988469","upvote_count":"2","timestamp":"1692808020.0","poster":"love777","comments":[{"content":"ChatGPT is usually wrong. Do not base your answers on ChatGPT","poster":"[Removed]","comment_id":"1080425","upvote_count":"2","timestamp":"1700962080.0"}]},{"content":"Selected Answer: B\\nchatgpt said","poster":"loctong","comment_id":"899791","upvote_count":"1","timestamp":"1684306560.0"},{"content":"Selected Answer: B\\nAnswer is B","comment_id":"897918","timestamp":"1684105560.0","poster":"junrun3","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T08:55:03.381Z","extraction_method":"api_direct_v1"},{"question_id":"xYAai7Yo6KdGrrSayGZD","question_number":4,"page":1,"question_text":"A developer is creating an application. New users of the application must be able to create an account and register by using their own social media accounts.\\n\\nWhich AWS service or resource should the developer use to meet these requirements?","choices":{"D":"AWS Directory Service","C":"Amazon Cognito user pools","A":"IAM role","B":"Amazon Cognito identity pools"},"correct_answer":"C","answer_ET":"C","answers_community":["C (73%)","B (27%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106980-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 15:06:00","unix_timestamp":1682168760,"discussion_count":17,"discussion":[{"comment_id":"915484","poster":"HuiHsin","upvote_count":"10","timestamp":"1685974620.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html"},{"comment_id":"1017257","comments":[{"timestamp":"1702177500.0","upvote_count":"3","poster":"[Removed]","comment_id":"1092263","content":"The big difference being users authenticates to applications (web and mobile) vs identity authenticates to AWS resources."}],"upvote_count":"9","poster":"Bhatfield","timestamp":"1695685620.0","content":"Amazon Cognito user pools provide user identity management and authentication for your application. They allow you to create and maintain a user directory, and you can enable social identity providers like Facebook, Google, or Amazon to allow users to register and log in using their social media accounts. This service is specifically designed for user management and authentication scenarios like the one described.\\n\\nOption B, \\"Amazon Cognito identity pools,\\" is more focused on providing temporary AWS credentials for users to access AWS services securely after they have been authenticated through a user pool."},{"timestamp":"1743913200.0","content":"Selected Answer: C\\nAmazon Cognito identity pools \u2013 Used for authorization and temporary AWS credentials, not for user sign-up. They often work with user pools after authentication.","comment_id":"1557235","upvote_count":"1","poster":"wmv__"},{"comments":[{"comment_id":"1332377","content":"Sorry - C\\n\\n\\nA) Eliminated - Eliminated because it does not support user account registration or social sign-in directly.\\n\\nC) Correct - Manages user registration and authentication.\\n\\nB) Eliminated - Provides temporary AWS credentials to authenticated users so they can access AWS resources like S3, DynamoDB, etc.","poster":"sumanshu","timestamp":"1735298520.0","upvote_count":"1"}],"comment_id":"1332376","upvote_count":"1","content":"Selected Answer: B\\nA) Eliminated - Eliminated because it does not support user account registration or social sign-in directly.\\n\\nB) Correct - Manages user registration and authentication.\\n\\nC) Eliminated - Provides temporary AWS credentials to authenticated users so they can access AWS resources like S3, DynamoDB, etc.","poster":"sumanshu","timestamp":"1735298520.0"},{"poster":"nbxyzd","upvote_count":"1","content":"Selected Answer: C\\nB is wrong. While identity pools also support federated identities, they are primarily used for granting AWS credentials to authenticated users. They are less focused on user management within the application itself.","comment_id":"1306391","timestamp":"1730597160.0"},{"comments":[{"poster":"ogogundare","timestamp":"1730502600.0","upvote_count":"1","comment_id":"1306021","content":"I think C is the right answer on further check\\nAmazon Cognito user pool can use social idps"}],"content":"The best answer is B Amazon Cognito Identity Pool","upvote_count":"1","comment_id":"1306020","timestamp":"1730502120.0","poster":"ogogundare"},{"comment_id":"1280141","content":"Does emamtopic have exact replicas of actual exam questions","timestamp":"1725746820.0","upvote_count":"1","poster":"gdm83"},{"upvote_count":"1","timestamp":"1716409200.0","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1216004"},{"content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","timestamp":"1716409080.0","upvote_count":"1","comment_id":"1216003"},{"timestamp":"1709122320.0","upvote_count":"2","poster":"SerialiDr","comment_id":"1161599","content":"Selected Answer: B\\nOption B: Amazon Cognito identity pools\\n\\nAmazon Cognito identity pools (also known as federated identities) enable you to create unique identities for your users and authenticate them with identity providers. With identity pools, your users can obtain temporary AWS credentials to access AWS services. This service supports authentication through social identity providers such as Amazon, Facebook, Google, and also supports unauthenticated identities."},{"upvote_count":"1","timestamp":"1708381740.0","content":"c \\nAmazon Cognito user pools provide user identity management and authentication for your application.","comment_id":"1154324","poster":"rrharris"},{"poster":"SerialiDr","upvote_count":"1","content":"Selected Answer: B\\nB. Amazon Cognito identity pools: Amazon Cognito identity pools (also known as Federated Identities) enable you to create unique identities for your users and authenticate them with identity providers, including social media platforms like Facebook, Google, Amazon, and Apple. With identity pools, you can grant your users access to other AWS services. They are designed to handle scenarios where users can sign in through a third-party identity provider or use guest access.","comment_id":"1123399","timestamp":"1705324980.0"},{"content":"Selected Answer: C\\nFor creating an application where new users can create accounts and register using their social media accounts, Amazon Cognito is the most suitable service. Specifically, you\'d want to use Amazon Cognito User Pools.\\n\\nAmazon Cognito User Pools support sign-ins using social identity providers like Facebook, Google, and Amazon, as well as enterprise identity providers via SAML 2.0. With a user pool, you can create a fully managed user directory to enable user sign-up and sign-in, as well as handle password recovery, user verification, and other user management tasks.","poster":"Dushank","upvote_count":"2","timestamp":"1694287800.0","comment_id":"1003459"},{"poster":"Dushank","upvote_count":"1","timestamp":"1694205960.0","comment_id":"1002713","content":"The answer is (B).\\n\\nAmazon Cognito identity pools is a managed service that provides user sign-in and identity management for your web and mobile applications. It supports social sign-in with a variety of providers, including Amazon, Facebook, Google, and Twitter."},{"timestamp":"1682648940.0","poster":"hanJR","content":"Selected Answer: C\\nYou can\'t register using Identity Pool. It lets you authenticate with provided identification pools.","upvote_count":"4","comment_id":"883179"},{"comment_id":"878569","timestamp":"1682265180.0","content":"Selected Answer: C\\nhttps://medium.com/wolox/integrating-social-media-to-your-app-with-aws-cognito-8943329aa89b","upvote_count":"5","poster":"Cloud_Cloud"},{"comments":[{"comment_id":"893110","timestamp":"1683637860.0","content":"B is incorrect. https://www.youtube.com/watch?v=9pvygKIuCpI","poster":"awsdummie","upvote_count":"1"},{"timestamp":"1684153740.0","comment_id":"898270","content":"Using Cognito identity pools you can get the token and access AWS using social media accounts, BUT you can\'t create an account, in this case we need Cognito user pools.","upvote_count":"1","poster":"rlnd2000"}],"timestamp":"1682168760.0","comment_id":"877282","content":"Selected Answer: B\\nKey word is registration using their social media accounts","poster":"MrTee","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:55:03.381Z","extraction_method":"api_direct_v1"},{"question_id":"ZBMEoBPenZ0Uiry7cMv0","question_number":5,"page":1,"question_text":"A social media application uses the AWS SDK for JavaScript on the frontend to get user credentials from AWS Security Token Service (AWS STS). The application stores its assets in an Amazon S3 bucket. The application serves its content by using an Amazon CloudFront distribution with the origin set to the S3 bucket.\\n\\nThe credentials for the role that the application assumes to make the SDK calls are stored in plaintext in a JSON file within the application code. The developer needs to implement a solution that will allow the application to get user credentials without having any credentials hardcoded in the application code.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Move the credentials from the JSON file into the function. Move all SDK calls from the frontend into the function.","A":"Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Add permissions to the function\'s execution role to allow the function to access AWS STS. Move all SDK calls from the frontend into the function.","B":"Add a CloudFront function to the distribution. Invoke the function on viewer request. Add permissions to the function\'s execution role to allow the function to access AWS STS. Move all SDK calls from the frontend into the function.","D":"Add a CloudFront function to the distribution. Invoke the function on viewer request. Move the credentials from the JSON file into the function. Move all SDK calls from the frontend into the function."},"correct_answer":"A","answer_ET":"A","answers_community":["A (85%)","B (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106981-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 15:30:00","unix_timestamp":1682170200,"discussion_count":12,"discussion":[{"poster":"csG13","comment_id":"918175","content":"Selected Answer: A\\nThe answer is A. Here is a reference directly from AWS docs:\\n\\n\\"If you need some of the capabilities of Lambda@Edge that are not available with CloudFront Functions, such as network access or a longer execution time, you can still use Lambda@Edge before and after content is cached by CloudFront.\\"\\n\\nSince the requirement is to access the STS service, network access is required. Therefore, it can\'t be Cloudfront functions. Also, as a side note it\'s worth to mention that Cloudfront functions can only execute for up to 1ms. Apparently this isn\'t enough to fetch user creds (tokens) from STS. \\n\\nThe table in the following link summarises the differences between Cloudfront functions and Lambda@edge\\n\\nhttps://aws.amazon.com/blogs/aws/introducing-cloudfront-functions-run-your-code-at-the-edge-with-low-latency-at-any-scale/","timestamp":"1702041360.0","upvote_count":"14"},{"comment_id":"877303","timestamp":"1697981400.0","upvote_count":"5","poster":"MrTee","comments":[{"content":"Now one problem is lambda function can not perform AWS STS command","timestamp":"1698076620.0","comments":[{"content":"After rereading the last part of the question. It doesnt mention that it must remain written in Javascript, but does seem using AWS STS is a requirement so I think I would stick with A being the answer","timestamp":"1702792800.0","poster":"eboehm","comment_id":"925745","upvote_count":"1"}],"upvote_count":"1","comment_id":"878577","poster":"Cloud_Cloud"}],"content":"Selected Answer: B\\nThe difference between A and B is the SDK for Javascript in use here; Lambda@Edge functions can be written in a variety of programming languages, including Node.js, Python, and Java, while CloudFront functions are written in JavaScript."},{"timestamp":"1735304160.0","upvote_count":"1","comment_id":"1332408","poster":"sumanshu","content":"Selected Answer: A\\nB) Eliminated - CloudFront functions are lightweight JavaScript functions designed for simple HTTP request and response manipulations (e.g., header rewrites, URL rewrites). They cannot access AWS services like STS or assume roles\\n\\nC/D) Eliminated - Moving the credentials from the JSON file to the Lambda@Edge function does not eliminate the core issue of hardcoding credentials"},{"upvote_count":"1","poster":"65703c1","comment_id":"1216008","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732314300.0"},{"timestamp":"1724099580.0","content":"Selected Answer: A\\nWhy A is Correct:\\nLambda@Edge for Secure Credential Management: Lambda@Edge allows you to run Lambda functions in response to CloudFront events. By using Lambda@Edge, the developer can securely manage credentials by keeping them out of the client-side code.\\n\\nInvoking on Viewer Request: Invoking the Lambda@Edge function on viewer requests ensures that the credential generation happens in real-time, securely, and as needed, without exposing any sensitive information.\\n\\nExecution Role with STS Access: Assigning the Lambda function an execution role with permissions to access AWS STS (Security Token Service) enables the function to securely request temporary, limited-privilege credentials on behalf of the client.\\n\\nMoving SDK Calls to Lambda@Edge: Transferring all AWS SDK calls from the frontend to the Lambda@Edge function prevents exposing any credentials in the frontend code, enhancing security.","upvote_count":"3","comment_id":"1154327","poster":"rrharris"},{"comment_id":"1123404","content":"Selected Answer: A\\nA. Lambda@Edge allows you to run Lambda functions in response to CloudFront events. By using a Lambda@Edge function, you can securely handle the process of obtaining credentials from AWS STS without exposing them in the client-side application code. The function\'s execution role can be granted the necessary permissions to interact with AWS STS, and SDK calls can be made from within this server-side environment. This approach centralizes credential management and AWS interactions in a more secure, server-side context.","poster":"SerialiDr","timestamp":"1721043180.0","upvote_count":"4"},{"comment_id":"1086929","timestamp":"1717424460.0","poster":"LR2023","upvote_count":"2","content":"I think i will also go with A as cloudfront functions can only read authorization headers from the viewer request if it sees the authorization header request. And Clouf front functions has no access to internet."},{"timestamp":"1709833440.0","comment_id":"1001702","upvote_count":"1","poster":"Baba_Eni","content":"Selected Answer: A\\nI will go for A, check the link below, Cloudfront functions are just within Cloudfront, hence, they DONT HAVE NETWORK ACCESS. Network access is required to make a call to AWS STS.\\n\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/edge-functions.html"},{"upvote_count":"1","poster":"MG1407","comment_id":"978625","timestamp":"1707663420.0","content":"The answer is B. I was in agreement with csG13 until a further research into the JavaScript SDK and STS. Found the following: https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/clients/client-cloudfront/classes/stsclient.html.\\nSince the question states Js SDK and STS the answer is B."},{"content":"Selected Answer: A\\nOption A.","poster":"FunkyFresco","upvote_count":"1","comment_id":"909642","timestamp":"1701290580.0"},{"content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/89838-exam-aws-certified-developer-associate-topic-1-question-361/","timestamp":"1699475280.0","comment_id":"892432","upvote_count":"2","poster":"zodraz"},{"timestamp":"1698519000.0","upvote_count":"2","comment_id":"883830","content":"Selected Answer: A\\nCloud front function doesn\'t have network access, it has to be lambda @ edge\\n\\n I l","poster":"vic614"}],"answer_description":"","extracted_at":"2025-12-24T08:55:03.381Z","extraction_method":"api_direct_v1"},{"question_id":"vTo65VBl6GMTzdcUUqf7","question_number":6,"page":2,"question_text":"An ecommerce website uses an AWS Lambda function and an Amazon RDS for MySQL database for an order fulfillment service. The service needs to return order confirmation immediately.\\n\\nDuring a marketing campaign that caused an increase in the number of orders, the website\'s operations team noticed errors for \u201ctoo many connections\u201d from Amazon RDS. However, the RDS DB cluster metrics are healthy. CPU and memory capacity are still available.\\n\\nWhat should a developer do to resolve the errors?","choices":{"D":"Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function\'s concurrency to a value that is less than the number of available database connections.","B":"Initialize the database connection outside the handler function. Use RDS Proxy instead of connecting directly to the DB cluster.","C":"Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function\'s concurrency to a value that equals the number of available database connections.","A":"Initialize the database connection outside the handler function. Increase the max_user_connections value on the parameter group of the DB cluster. Restart the DB cluster."},"correct_answer":"B","answer_ET":"B","answers_community":["B (93%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106984-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 15:39:00","unix_timestamp":1682170740,"discussion_count":10,"discussion":[{"poster":"MrTee","content":"Selected Answer: B\\nUse an RDS Proxy instead of connecting directly to the DB cluster.","comment_id":"877312","timestamp":"1682170740.0","upvote_count":"13"},{"poster":"hanJR","comment_id":"883187","content":"B \\n\\nhttps://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/","timestamp":"1682649660.0","upvote_count":"7"},{"timestamp":"1735304460.0","comment_id":"1332409","poster":"sumanshu","upvote_count":"3","content":"Selected Answer: B\\nThe \\"too many connections\\" error occurs because Lambda functions create separate database connections for each invocation.\\nRDS Proxy is designed to manage database connections efficiently by pooling and reusing connections, reducing the load on the database.\\nLambda functions can share connections from the proxy pool, avoiding the \\"too many connections\\" issue.\\n\\nA) Eliminated - Increasing max_user_connections temporarily alleviates the issue but does not address the root cause"},{"timestamp":"1726207980.0","content":"Selected Answer: B\\nThe key word is increase in the number of orders, so the proxy can help in this stuation","poster":"Saudis","comment_id":"1283031","upvote_count":"1"},{"timestamp":"1716410220.0","poster":"65703c1","comment_id":"1216012","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1"},{"comments":[{"content":"Read carefully: \\"the service needs to return order confirmation *immediately*.\\"\\nThis means that asynchronous solutions like SQS does NOT meet the requirement.","poster":"nbxyzd","comment_id":"1306405","timestamp":"1730599500.0","upvote_count":"2"}],"upvote_count":"2","timestamp":"1710704400.0","content":"Selected Answer: C\\nOption B only improve the execution time of lambda and decrease the delay from request to database. It might even worsen the situation because database can get more concurrent connection. RDS Proxy also doesn\'t limit the number of connections, even if so it will generate errors for lambda.\\n\\nThe only way is to throttle the requests using SQS until a connection gets released.\\nWhy everyone thinks ChatGPT has the ultimate answer????!!!!","poster":"maurice2005","comment_id":"1176039"},{"content":"Selected Answer: B\\nAWS RDS Proxy is designed to manage and pool database connections, which makes it ideal for environments with highly variable and potentially high-volume database access patterns, such as those driven by Lambda functions. It helps to reduce the number of direct connections to the database and can efficiently manage the connections from the pool.","timestamp":"1705326000.0","poster":"SerialiDr","comment_id":"1123410","upvote_count":"3"},{"comment_id":"988541","content":"Selected Answer: B\\nWe can use an RDS proxy to handle a lot of connections. We are choosing this option because the load on the RDS is normal. If the RDS was unable to handle loads, we would\'ve checked other options like queues or transactions.","poster":"hmdev","upvote_count":"2","timestamp":"1692813240.0"},{"comment_id":"946011","content":"Selected Answer: B\\nhttps://repost.aws/questions/QULXSqEPGbQx6qiyBa1D1Udg/lambda-to-db-connectivity-best-practices","upvote_count":"1","poster":"eberhe900","timestamp":"1688765160.0"},{"upvote_count":"2","content":"Selected Answer: B\\nUsing an RDS Proxy can manage connections to the RDS instance, reducing the overhead of establishing new connections and thereby preventing the \\"too many connections\\" error.","poster":"loctong","comment_id":"904044","timestamp":"1684759560.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:13.801Z","extraction_method":"api_direct_v1"},{"question_id":"Yw6s5Zx9Fu1W1GNxAqdy","question_number":7,"page":2,"question_text":"A company stores its data in data tables in a series of Amazon S3 buckets. The company received an alert that customer credit card information might have been exposed in a data table on one of the company\'s public applications. A developer needs to identify all potential exposures within the application environment.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.","D":"Use Amazon Athena to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.","C":"Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Personal finding type.","A":"Use Amazon Athena to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Personal finding type."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106987-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 16:09:00","unix_timestamp":1682172540,"discussion_count":9,"discussion":[{"timestamp":"1682172540.0","upvote_count":"24","comment_id":"877330","content":"Selected Answer: B\\nUse Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.\\nOption A and D suggest using Amazon Athena, which is an interactive query service that can be used to analyze data stored in S3 using standard SQL queries. While Athena can help identify data in S3 buckets, it does not provide the same level of automated scanning and pattern matching that Amazon Macie does.\\n\\nOption C is incorrect because the SensitiveData:S3Object/Personal finding type is designed to identify personally identifiable information (PII), such as names and addresses, but not credit card information.","poster":"MrTee"},{"comment_id":"1332410","content":"Selected Answer: B\\nMacie is a fully managed data security and privacy service that uses machine learning and pattern matching to discover and protect sensitive data stored in Amazon S3.\\n\\nC) Eliminated - SensitiveData:S3Object/Personal finding type is irrelevant because credit card information is not classified as \\"personal\\" in this context but as \\"financial.\\"\\n\\nA/D) Eliminated - Athena does not support sensitive data detection","timestamp":"1735304640.0","poster":"sumanshu","upvote_count":"1"},{"content":"Selected Answer: B\\nThe Ans is B because the credit card is a sensitive Data and also it is a financial Data","comment_id":"1283034","timestamp":"1726208400.0","poster":"Saudis","upvote_count":"1"},{"upvote_count":"1","timestamp":"1716410340.0","comment_id":"1216014","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer."},{"content":"Selected Answer: B\\nSensitiveData:S3Object/Financial only works with Macie?? so how can it be D?","poster":"SD_CS","timestamp":"1707032100.0","upvote_count":"1","comment_id":"1139870"},{"upvote_count":"3","content":"Selected Answer: B\\nB. Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type: Amazon Macie is a security service that uses machine learning and pattern matching to discover and protect sensitive data in AWS. Macie is designed to identify various types of sensitive data, including financial data, which would cover credit card information. This option is suitable for the requirement as it leverages Macie\'s capability to specifically identify and report on exposures of sensitive financial data.","comment_id":"1123415","poster":"SerialiDr","timestamp":"1705326360.0"},{"upvote_count":"4","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/macie/latest/user/findings-types.html","poster":"Baba_Eni","comment_id":"924224","timestamp":"1686835200.0"},{"poster":"HuiHsin","comment_id":"915503","upvote_count":"1","timestamp":"1685976660.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/zh_tw/macie/latest/user/findings-types.html"},{"comment_id":"897833","content":"Selected Answer: B\\nThe best solution to identify all potential exposures within the application environment after receiving an alert that customer credit card information might have been exposed in a data table on one of the company\'s public applications is to use Amazon Macie. Amazon Macie is a fully managed data security and privacy service that uses machine learning and pattern matching to discover and protect sensitive data in AWS.","upvote_count":"1","poster":"Prem28","timestamp":"1684088880.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:13.801Z","extraction_method":"api_direct_v1"},{"question_id":"pPa1F7szOb194xsXb0Wx","question_number":8,"page":2,"question_text":"A software company is launching a multimedia application. The application will allow guest users to access sample content before the users decide if they want to create an account to gain full access. The company wants to implement an authentication process that can identify users who have already created an account. The company also needs to keep track of the number of guest users who eventually create an account.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"A":"Create an Amazon Cognito user pool. Configure the user pool to allow unauthenticated users. Exchange user tokens for temporary credentials that allow authenticated users to assume a role.","D":"Create a role for authenticated users that allows access to all content. Create a role for unauthenticated users that allows access to only the sample content.","C":"Create an Amazon CloudFront distribution. Configure the distribution to allow unauthenticated users. Exchange user tokens for temporary credentials that allow all users to assume a role.","E":"Allow all users to access the sample content by default. Create a role for authenticated users that allows access to the other content.","B":"Create an Amazon Cognito identity pool. Configure the identity pool to allow unauthenticated users. Exchange unique identity for temporary credentials that allow all users to assume a role."},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106989-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 16:21:00","unix_timestamp":1682173260,"discussion_count":6,"discussion":[{"poster":"MrTee","content":"Selected Answer: BD\\noption B because by configuring the identity pool to allow unauthenticated users, you can enable guest users to access the sample content. When users create an account, they can be authenticated, and then given access to the full content by assuming a role that allows them access.\\nOption D is correct because creating roles for authenticated and unauthenticated users with different levels of access is an appropriate way to meet the requirement of identifying users who have created an account and keeping track of the number of guest users who eventually create an account.","timestamp":"1697984460.0","upvote_count":"25","comment_id":"877334"},{"comment_id":"1332411","timestamp":"1735304880.0","poster":"sumanshu","content":"Selected Answer: BD\\nA) Eliminated - User pools are primarily for managing authenticated users. They do not natively support unauthenticated (guest) users.\\n\\nB) Identity pools support both unauthenticated (guest) and authenticated users\\n\\nC) Eliminated - CloudFront is a content delivery service, not an authentication or identity management service.\\n\\nD) This allows proper segregation of access, where guest users can only access sample content while authenticated users gain full access.\\n\\nE) Eliminated - Proper identity management requires differentiating between roles for guest and authenticated users.","upvote_count":"3"},{"upvote_count":"1","comment_id":"1216015","poster":"65703c1","timestamp":"1732315260.0","content":"Selected Answer: BD\\nBD is the correct answer."},{"poster":"a_win","content":"Selected Answer: BD\\nE won\'t be a choice because \\"The company also needs to keep track of the number of guest users who eventually create an account.\\"","comment_id":"1105080","timestamp":"1719292800.0","upvote_count":"4"},{"poster":"KarBiswa","comment_id":"1100339","upvote_count":"1","timestamp":"1718768340.0","content":"Selected Answer: BD\\nCovers Unauthenticated and authenticated users scenario"},{"content":"Selected Answer: BD\\n\\"who alreaady created account\\" means User Pool not required. - NOT A","poster":"jipark","timestamp":"1706952000.0","upvote_count":"4","comment_id":"970853"}],"answer_description":"","extracted_at":"2025-12-24T08:55:13.801Z","extraction_method":"api_direct_v1"},{"question_id":"L6aNByB3dNecEmzMIugo","question_number":9,"page":2,"question_text":"A company is updating an application to move the backend of the application from Amazon EC2 instances to a serverless model. The application uses an Amazon RDS for MySQL DB instance and runs in a single VPC on AWS. The application and the DB instance are deployed in a private subnet in the VPC.\\n\\nThe company needs to connect AWS Lambda functions to the DB instance.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create Lambda functions inside the VPC with the AWSLambdaBasicExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group.","C":"Create Lambda functions with the AWSLambdaBasicExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunclion action for each Lambda function\'s Amazon Resource Name (ARN).","B":"Create Lambda functions inside the VPC with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group.","D":"Create Lambda functions with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunction action for each Lambda function\'s Amazon Resource Name (ARN)."},"correct_answer":"B","answer_ET":"B","answers_community":["B (81%)","D (19%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106992-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 16:40:00","unix_timestamp":1682174400,"discussion_count":10,"discussion":[{"poster":"MrTee","comment_id":"877345","content":"Selected Answer: B\\nThe AWSLambdaVPCAccessExecutionRole policy allows the Lambda function to create elastic network interfaces (ENIs) in the VPC and use the security groups attached to those ENIs for controlling inbound and outbound traffic.","upvote_count":"14","timestamp":"1697985600.0"},{"timestamp":"1735692960.0","content":"Selected Answer: B\\nB: This option ensures that the Lambda functions have the necessary permissions to access resources within the VPC and that the RDS security group is configured to allow inbound access from the Lambda functions.\\nD: Reason for eliminating this is creating an interface VPC endpoint and configuring the endpoint policy is unnecessary for this scenario as it complicates the setup without addressing the VPC access requirements directly.","upvote_count":"1","poster":"Khaja2k","comment_id":"1335085"},{"comment_id":"1332412","content":"Selected Answer: B\\nLambda functions need to run inside the VPC to access resources like the RDS instance, which is located within the private subnet. \\n\\nThe AWSLambdaVPCAccessExecutionRole policy is required for Lambda functions to connect to resources inside a VPC. This policy allows Lambda functions to use Elastic Network Interfaces (ENIs) to connect to the VPC.\\n\\nThe security group associated with the RDS instance must allow inbound connections from the Lambda function\'s security group.","upvote_count":"2","poster":"sumanshu","timestamp":"1735305120.0","comments":[{"content":"A) Eliminated - AWSLambdaBasicExecutionRole provides basic permissions to write logs to Amazon CloudWatch but does not grant the necessary permissions for Lambda to connect to resources in a VPC","comment_id":"1332413","timestamp":"1735305180.0","upvote_count":"1","poster":"sumanshu","comments":[{"poster":"sumanshu","content":"D) Eliminated - lambda:InvokeFunction permissions relate to calling Lambda functions, not connecting to a database.","timestamp":"1739052300.0","comment_id":"1353658","upvote_count":"1"}]}]},{"upvote_count":"1","poster":"65703c1","timestamp":"1732316460.0","comment_id":"1216028","content":"Selected Answer: B\\nB is the correct answer."},{"upvote_count":"3","timestamp":"1721048040.0","poster":"SerialiDr","comment_id":"1123462","content":"Selected Answer: B\\nThis is the correct solution. The AWSLambdaVPCAccessExecutionRole policy includes permissions that allow the Lambda function to access resources within a VPC, such as an RDS instance. Additionally, modifying the RDS security group to allow inbound access from the Lambda security group is necessary to enable network connectivity between the Lambda functions and the RDS instance."},{"comment_id":"1100342","timestamp":"1718768940.0","poster":"KarBiswa","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html","upvote_count":"1"},{"timestamp":"1713379920.0","upvote_count":"2","poster":"Nagasoracle","comment_id":"1046284","content":"Selected Answer: D\\nAnswer : D"},{"comment_id":"992580","poster":"love777","content":"Selected Answer: D\\nWhile Lambda functions cannot run directly in private subnets, they can be configured to access resources within a VPC by creating a VPC endpoint for Lambda.\\nAWS Lambda supports VPC Endpoints for Lambda, which allow Lambda functions to securely access resources within a VPC without needing to traverse the public internet.\\nYou should attach the AWSLambdaVPCAccessExecutionRole policy to your Lambda execution role to enable it to create network interfaces in your VPC for accessing resources.\\nBy configuring an interface VPC endpoint for Lambda, you can enable the Lambda function to communicate with resources within the private subnet and the RDS instance.","timestamp":"1709154540.0","upvote_count":"4"},{"upvote_count":"3","timestamp":"1702662660.0","poster":"Baba_Eni","comment_id":"924334","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaVPCAccessExecutionRole.html\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html"},{"content":"ans- opt d\\n\\nOption A does not allow Lambda functions to access resources in the VPC.\\nOption B does not create an interface VPC endpoint, which means that Lambda functions will be exposed to the public internet.\\nOption C does not configure the interface endpoint policy to allow the lambda:InvokeFunction action, which means that Lambda functions will not be able to invoke each other.","upvote_count":"3","timestamp":"1701726540.0","comment_id":"914903","comments":[{"timestamp":"1706958300.0","upvote_count":"1","comment_id":"970925","content":"I definitely agree.\\nLambda cannot be installed inside VPC, instead, AWSLambdaVPCAccessExectutionRole allow to connect via ENI.","poster":"jipark"}],"poster":"Prem28"}],"answer_description":"","extracted_at":"2025-12-24T08:55:13.801Z","extraction_method":"api_direct_v1"},{"question_id":"hZBjKGdegybCY6uL7mnb","question_number":10,"page":2,"question_text":"A company has a web application that runs on Amazon EC2 instances with a custom Amazon Machine Image (AMI). The company uses AWS CloudFormation to provision the application. The application runs in the us-east-1 Region, and the company needs to deploy the application to the us-west-1 Region.\\n\\nAn attempt to create the AWS CloudFormation stack in us-west-1 fails. An error message states that the AMI ID does not exist. A developer must resolve this error with a solution that uses the least amount of operational overhead.\\n\\nWhich solution meets these requirements?","choices":{"D":"Manually deploy the application outside AWS CloudFormation in us-west-1.","B":"Copy the custom AMI from us-east-1 to us-west-1. Update the AWS CloudFormation template for us-west-1 to refer to AMI ID for the copied AMI. Relaunch the stack.","C":"Build the custom AMI in us-west-1. Create a new AWS CloudFormation template to launch the stack in us-west-1 with the new AMI ID.","A":"Change the AWS CloudFormation templates for us-east-1 and us-west-1 to use an AWS AMI. Relaunch the stack for both Regions."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107007-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 18:05:00","unix_timestamp":1682179500,"discussion_count":5,"discussion":[{"comment_id":"877428","poster":"MrTee","upvote_count":"12","content":"Selected Answer: B\\nThis will allow the company to deploy the application to the us-west-1 Region using the same custom AMI that is used in the us-east-1 Region.","timestamp":"1682179500.0"},{"upvote_count":"1","timestamp":"1735305600.0","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - The goal is to deploy the custom AMI, not AWS-provided AMI\\n\\nC) Eliminated - Building the custom AMI from scratch in us-west-1 is unnecessary and adds extra operational overhead\\n\\nD) Eliminated - it bypasses CloudFormation\'s infrastructure-as-code benefits and increases operational overhead.","comment_id":"1332416"},{"poster":"Saudis","content":"The Ans is B the keyword is operational overhead so from the choice the last overhead is copy","timestamp":"1726209600.0","upvote_count":"1","comment_id":"1283040"},{"comment_id":"1216031","upvote_count":"1","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716411780.0"},{"poster":"gomurali","timestamp":"1688060640.0","upvote_count":"2","content":"https://www.examtopics.com/discussions/amazon/view/78848-exam-aws-certified-developer-associate-topic-1-question-118/","comment_id":"938417"}],"answer_description":"","extracted_at":"2025-12-24T08:55:13.801Z","extraction_method":"api_direct_v1"},{"question_id":"yYHofggIELAOJ0rX0lQw","question_number":11,"page":3,"question_text":"A developer is updating several AWS Lambda functions and notices that all the Lambda functions share the same custom libraries. The developer wants to centralize all the libraries, update the libraries in a convenient way, and keep the libraries versioned.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"B":"Create a custom container image for the Lambda functions to save all the custom libraries.","A":"Create an AWS CodeArtifact repository that contains all the custom libraries.","C":"Create a Lambda layer that contains all the custom libraries.","D":"Create an Amazon Elastic File System (Amazon EFS) file system to store all the custom libraries."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107010-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 18:17:00","unix_timestamp":1682180220,"discussion_count":7,"discussion":[{"poster":"MrTee","content":"Selected Answer: C\\nthe most efficient solution is to use a Lambda layer to store the common libraries, update them in one place, and reference them from each Lambda function that requires them.","timestamp":"1682180220.0","comment_id":"877439","upvote_count":"18"},{"upvote_count":"1","timestamp":"1735305660.0","content":"Selected Answer: C\\nLambda layers allow you to manage your shared libraries separately from the function code\\n\\nA) Eliminated - it would require additional steps for Lambda functions to access these libraries. The Lambda functions would need to fetch the libraries at runtime, adding more complexity to your setup.\\n\\nB/D) Additional overhead","comment_id":"1332418","poster":"sumanshu"},{"comment_id":"1216032","timestamp":"1716411840.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer."},{"poster":"HuiHsin","comment_id":"917262","content":"Selected Answer: C\\nThe Lambda layer of option C provides a simpler solution without the need to introduce an additional CodeArtifact service.","timestamp":"1686145620.0","upvote_count":"3"},{"timestamp":"1684310820.0","comment_id":"899840","upvote_count":"2","poster":"loctong","content":"Selected Answer: C\\nLambda layers are a distribution mechanism for libraries, custom runtimes, and other function dependencies in AWS Lambda. By creating a Lambda layer, you can package and centrally manage the shared custom libraries for the Lambda functions."},{"poster":"loctong","timestamp":"1684114560.0","comment_id":"897978","upvote_count":"1","content":"Selected Answer: C\\nIt should be Create a Lambda layer."},{"comment_id":"891280","comments":[{"content":"\\"LEAST development effort\\"\\nWhile CodeArtifact can be integrated with Lambda, it typically involves additional steps such as setting up credentials and configuring the Lambda functions to access the repository. This can require more development effort compared to Lambda Layer which is specifically designed for Lambda.","upvote_count":"1","comment_id":"1306499","poster":"nbxyzd","timestamp":"1730634420.0"},{"content":"\\"LEAST development effort\\"","poster":"jipark","comment_id":"970929","timestamp":"1691054040.0","upvote_count":"3"},{"upvote_count":"1","poster":"[Removed]","comment_id":"1092282","content":"We are updating a Lambda function. Lambda layers are specifically used for situations mentioned in this question","timestamp":"1702185420.0"}],"upvote_count":"2","timestamp":"1683453120.0","poster":"Ryan1002","content":"Why not CodeArtifact?\\n\\n\\"CodeArtifact allows you to store artifacts using popular package managers and build tools like Maven, Gradle, npm, Yarn, Twine, pip, and NuGet. CodeArtifact can automatically fetch software packages on demand from public package repositories so you can access the latest versions of application dependencies.\\""}],"answer_description":"","extracted_at":"2025-12-24T08:55:25.554Z","extraction_method":"api_direct_v1"},{"question_id":"eQLNcrT6FXh2W8fwLdJG","question_number":12,"page":3,"question_text":"A developer wants to use AWS Elastic Beanstalk to test a new version of an application in a test environment.\\n\\nWhich deployment method offers the FASTEST deployment?","choices":{"D":"All at once","C":"Rolling with additional batch","B":"Rolling","A":"Immutable"},"correct_answer":"D","answer_ET":"D","answers_community":["D (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109399-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-16 13:52:00","unix_timestamp":1684237920,"discussion_count":5,"discussion":[{"comment_id":"899147","timestamp":"1700142720.0","content":"Selected Answer: D\\nThe answer is D.\\n\\n\\"All at once \u2013 The quickest deployment method.\\" https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html","poster":"yeacuz","upvote_count":"8"},{"comment_id":"899842","upvote_count":"6","timestamp":"1700215620.0","content":"Selected Answer: D\\nThe \\"All at once\\" deployment method deploys the new version of the application to all instances simultaneously. It updates all instances of the environment in a short period of time, resulting in the fastest overall deployment.","poster":"loctong"},{"upvote_count":"1","poster":"thalasi","timestamp":"1746931500.0","comment_id":"1568029","content":"Selected Answer: B\\nA developer wants to deploy a new version of an AWS Elastic Beanstalk application. During\\ndeployment the application must maintain full capacity and avoid service interruption. Additionally,\\nthe developer must minimize the cost of additional resources that support the deployment.\\nWhich deployment method should the developer use to meet these requirements?\\nA. All at once\\nB. Rolling with additional batch\\nC. Bluegreen\\nD. Immutable"},{"upvote_count":"1","content":"Selected Answer: D\\nThis deployment method deploys the new version of the application to all instances in the environment simultaneously\\n\\nA) Eliminated - In an immutable deployment, Elastic Beanstalk creates a new environment with the new version of the application and swaps it with the old one once it\'s ready. This method ensures that there is no impact on the current environment during the deployment, but it takes longer due to the creation of a new environment and the time needed for verification.\\n\\nB) Eliminated - In a rolling deployment, Elastic Beanstalk updates a batch of instances one at a time while keeping the others running. This method minimizes downtime but takes longer than \\"all at once\\" since it updates instances in batches.\\n\\nC) Eliminated -","timestamp":"1735305780.0","poster":"sumanshu","comment_id":"1332419"},{"timestamp":"1732316700.0","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","comment_id":"1216033","poster":"65703c1"}],"answer_description":"","extracted_at":"2025-12-24T08:55:25.554Z","extraction_method":"api_direct_v1"},{"question_id":"oydsYPHLYcyTXEZLxYT0","question_number":13,"page":3,"question_text":"A company is migrating legacy internal applications to AWS. Leadership wants to rewrite the internal employee directory to use native AWS services. A developer needs to create a solution for storing employee contact details and high-resolution photos for use with the new application.\\nWhich solution will enable the search and retrieval of each employee\'s individual details and high-resolution photos using AWS APIs?","choices":{"A":"Encode each employee\'s contact information and photos using Base64. Store the information in an Amazon DynamoDB table using a sort key.","D":"Store employee contact information in an Amazon RDS DB instance with the photos stored in Amazon Elastic File System (Amazon EFS).","C":"Use Amazon Cognito user pools to implement the employee directory in a fully managed software-as-a-service (SaaS) method.","B":"Store each employee\'s contact information in an Amazon DynamoDB table along with the object keys for the photos stored in Amazon S3."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102787-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 10:01:00","unix_timestamp":1678957260,"discussion_count":14,"discussion":[{"upvote_count":"9","poster":"Bibay","content":"Selected Answer: B\\nB. Store each employee\'s contact information in an Amazon DynamoDB table along with the object keys for the photos stored in Amazon S3.\\n\\nStoring each employee\'s contact information in an Amazon DynamoDB table along with the object keys for the photos stored in Amazon S3 provides a scalable and efficient solution for storing and retrieving employee details and high-resolution photos using AWS APIs. The developer can use the DynamoDB table to query and retrieve employee details, while the S3 bucket can be used to store the high-resolution photos. By using S3, the solution can support large amounts of data while enabling fast retrieval times. The combination of DynamoDB and S3 can provide a cost-effective and scalable solution for storing employee data and photos.","comment_id":"890709","timestamp":"1683373020.0"},{"timestamp":"1747951500.0","upvote_count":"1","comment_id":"1571421","content":"Selected Answer: B\\nThis is the best solution because it uses AWS-native services that are scalable, serverless, and fully managed","poster":"alemaricame"},{"comment_id":"1329564","timestamp":"1734713340.0","upvote_count":"3","content":"Selected Answer: B\\nA) Eliminated - DynamoDB is not cost-effective for storing large binary data and also increases query latency\\n\\nC) Eliminated - Cognito user pools are intended for user authentication and authorization, not as a storage solution","poster":"sumanshu"},{"comment_id":"1325317","upvote_count":"1","timestamp":"1733964720.0","content":"Selected Answer: B\\n==> discard A: store image in db, will enhance time query \\n==> discard C: cognito for idetifying not querying info\\n==> discard D: EFS vs S3, I choose s3, its storage is global, best popular to store image than EFS, with EFS you must use EC2, how you can link image in EC2 with db\\n\\n==> B is best choice","poster":"trieudo"},{"timestamp":"1722291780.0","comment_id":"1257727","poster":"ACurryDeveloper","content":"A: Base 64 is a distraction. You can use encryption at rest using KMS for most things. Would you store photos in DynamoDB? Would be silly\\nC. Cognito has nothing to do with the question. Question is asking about searching for employee details\\nD. Could work, but seems convoluted. Relational DBs are easily searchable, but how would you link the db to the image in EC2? \\n\\nB is the simplest and correct answer here.","upvote_count":"1"},{"comment_id":"1214973","poster":"65703c1","upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716298200.0"},{"poster":"badsati","comment_id":"1191717","content":"Selected Answer: B\\nAnswer is B","timestamp":"1712597220.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\\nI agree, B is correct, DynamoDB to store user\'s data along the Key for S3 objects knowing that S3 is a good solution to store large amount of data or \\"high quality\\" images","poster":"Baalhammun","comment_id":"1144706","timestamp":"1707409500.0"},{"comment_id":"1072026","timestamp":"1700092560.0","upvote_count":"1","content":"Selected Answer: B\\nDynamoDb + S3 is the best option for those scenaries","poster":"leonardoliveros"},{"comment_id":"992319","upvote_count":"2","content":"Selected Answer: B\\nDynamoDB is very fast, secure, and scalable. The S3 is very in-expensive, virtually limitless, and can handle large files. So B is the correct answer.","poster":"hmdev","timestamp":"1693234740.0"},{"content":"Selected Answer: B\\nA. is not really clear to me, however encoding all info in base64 would make search a bit complex\\nC. does not provide a solution for high resolution image\\nD. EFS does not provide API access to content","timestamp":"1692276600.0","poster":"ninomfr64","upvote_count":"3","comment_id":"983631"},{"comment_id":"976269","upvote_count":"2","content":"Option B. As the question says that we have to store high-resolution photos, the solution is to use the S3 here. Because, DynamoDb cannot be used to store anything that is above 400 KB for each object.\\n\\nIn this case, we can use DynamoDb to store the contact information of each of the employees and reference the object keys in the table to retrieve the high-resolution images.","timestamp":"1691558460.0","poster":"jayvarma"},{"poster":"ihta_2031","upvote_count":"4","timestamp":"1680356640.0","comment_id":"857967","content":"Selected Answer: B\\nAgreed with B"},{"comment_id":"840725","upvote_count":"4","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/88823-exam-aws-certified-developer-associate-topic-1-question-240/","timestamp":"1678957260.0","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T08:55:25.554Z","extraction_method":"api_direct_v1"},{"question_id":"avplNrYJk8u20KU6AYHg","question_number":14,"page":3,"question_text":"A company is providing read access to objects in an Amazon S3 bucket for different customers. The company uses IAM permissions to restrict access to the S3 bucket. The customers can access only their own files.\\n\\nDue to a regulation requirement, the company needs to enforce encryption in transit for interactions with Amazon S3.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Add an IAM policy to the IAM users to enforce the usage of the AWS SDK.","A":"Add a bucket policy to the S3 bucket to deny S3 actions when the aws:SecureTransport condition is equal to false.","B":"Add a bucket policy to the S3 bucket to deny S3 actions when the s3:x-amz-acl condition is equal to public-read.","D":"Add an IAM policy to the IAM users that allows S3 actions when the s3:x-amz-acl condition is equal to bucket-owner-read."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107013-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 18:23:00","unix_timestamp":1682180580,"discussion_count":5,"discussion":[{"comment_id":"877447","upvote_count":"19","timestamp":"1697991780.0","poster":"MrTee","comments":[{"poster":"jipark","timestamp":"1706959920.0","upvote_count":"2","content":"\'in transit\' = SSL Secure Transport","comment_id":"970953"}],"content":"Selected Answer: A\\nThis solution enforces encryption in transit for interactions with Amazon S3 by denying access to the S3 bucket if the request is not made over an HTTPS connection. This condition can be enforced by using the \\"aws:SecureTransport\\" condition key in a bucket policy."},{"poster":"sumanshu","upvote_count":"1","comment_id":"1332420","timestamp":"1735306080.0","content":"Selected Answer: A\\nBy adding a bucket policy that denies S3 actions when the aws:SecureTransport condition is false, you ensure that only requests made over HTTPS are allowed. The condition aws:SecureTransport checks if the request was made using a secure transport (HTTPS).\\n\\nB) Eliminated - s3:x-amz-acl condition relates to access control lists (ACLs) for the objects\\n\\nC) Enforcing the usage of the AWS SDK does not guarantee encryption in transit.\\n\\nD) Eliminated - The bucket-owner-read ACL allows the bucket owner to read the objects, but it does not enforce secure communication"},{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732316880.0","poster":"65703c1","upvote_count":"1","comment_id":"1216036"},{"content":"Selected Answer: A\\nTo enforce encryption in transit for interactions with Amazon S3, you can add a bucket policy to the S3 bucket that denies S3 actions when the aws:SecureTransport condition is equal to false. This condition checks whether the requests to S3 are made over a secure (HTTPS) connection.","timestamp":"1700215740.0","poster":"loctong","upvote_count":"3","comment_id":"899843"},{"timestamp":"1700074620.0","poster":"rlnd2000","content":"Selected Answer: A\\nhttps://repost.aws/knowledge-center/s3-bucket-policy-for-config-rule","upvote_count":"3","comment_id":"898531"}],"answer_description":"","extracted_at":"2025-12-24T08:55:25.554Z","extraction_method":"api_direct_v1"},{"question_id":"tSHrb12bGuk0ByFjQn9Q","question_number":15,"page":3,"question_text":"A company has an image storage web application that runs on AWS. The company hosts the application on Amazon EC2 instances in an Auto Scaling group. The Auto Scaling group acts as the target group for an Application Load Balancer (ALB) and uses an Amazon S3 bucket to store the images for sale.\\n\\nThe company wants to develop a feature to test system requests. The feature will direct requests to a separate target group that hosts a new beta version of the application.\\n\\nWhich solution will meet this requirement with the LEAST effort?","choices":{"C":"Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Use Amazon CloudFront with Lambda@Edge to determine which specific request will go to the new ALB. Use the CloudFront endpoint to send the test system requests to test the beta version of the application.","B":"Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Configure an alternate Amazon Route 53 record for the new ALB endpoint. Use the alternate Route 53 endpoint in the test system requests to test the beta version of the application.","D":"Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Use Amazon CloudFront with Lambda@Edge to update the test system requests to add the required cookie when the requests go to the ALB.","A":"Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Update the test system code to use this cookie to test the beta version of the application."},"correct_answer":"A","answer_ET":"A","answers_community":["A (53%)","B (36%)","11%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107028-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 20:49:00","unix_timestamp":1682189340,"discussion_count":21,"discussion":[{"timestamp":"1682189340.0","upvote_count":"26","content":"Selected Answer: A\\nThis solution will allow the company to direct requests to a separate target group that hosts the new beta version of the application without having to create a new ALB or use additional services such as Amazon Route 53 or Amazon CloudFront. \\nOption D adds additional complexity and effort compared to option A, which simply involves updating the ALB routing rule with a condition that looks for a cookie named version that has a value of beta and updating the test system code to use this cookie to test the beta version of the application.","poster":"MrTee","comment_id":"877550"},{"timestamp":"1690767540.0","comment_id":"967645","content":"Selected Answer: B\\nOption B provides the simplest and least effort solution to test the beta version of the application. By creating a new ALB, Auto Scaling group, and target group for the beta version, the company can deploy the new version of the application separately from the production version. Configuring an alternate Amazon Route 53 record for the new ALB endpoint allows the test system requests to be directed to the beta version.","upvote_count":"8","comments":[{"poster":"wh1t4k3r","content":"I will say that it is way simpler to create an ALB rule to a new tg and alter the beta app then create a new tg, a new alb and configure route 53 and then deploy the app","timestamp":"1724153520.0","upvote_count":"1","comment_id":"1269412"}],"poster":"backfringe"},{"comment_id":"1332455","comments":[{"timestamp":"1735312440.0","upvote_count":"1","poster":"sumanshu","comment_id":"1332456","content":"A )\\n\\nNew Beta Group:\\nYou create a new \\"group of servers\\" (Auto Scaling group + target group) for the beta version of your app. These servers will run the updated beta code.\\n\\nRouting with Cookies:\\nThe existing load balancer is updated to check incoming requests for a specific cookie in the browser.\\n\\nIf the cookie says something like version=beta, the load balancer will route the request to the beta servers.\\nIf there\u2019s no cookie, the load balancer routes the request to the normal servers (current version).\\nTest System\u2019s Role:\\nThe test system (used by testers) adds the special cookie (version=beta) to its requests. This ensures only the testers access the beta version. Regular users don\u2019t have this cookie, so they continue to see the normal version."}],"timestamp":"1735312440.0","upvote_count":"2","content":"Selected Answer: A\\nB) Eliminated - You need a second load balancer, which increases both costs and maintenance overhead.\\nTesters must switch between different URLs to test the beta version, which is less seamless.\\n\\nC/D) Eliminated - Lambda@Edge increases complexity unnecessarily","poster":"sumanshu"},{"content":"Selected Answer: A\\nhttps://aws.amazon.com/blogs/aws/new-advanced-request-routing-for-aws-application-load-balancers/","upvote_count":"1","poster":"Anandesh","comment_id":"1244091","timestamp":"1720414320.0"},{"poster":"65703c1","comment_id":"1216039","timestamp":"1716412440.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1"},{"poster":"IvRa","upvote_count":"1","timestamp":"1712724900.0","comment_id":"1192708","content":"ChatGPT goes for D."},{"timestamp":"1710693180.0","upvote_count":"1","comment_id":"1175944","poster":"41eb566","content":"Selected Answer: B\\nThe solution that will meet the requirement with the least effort is:\\n\\nB. Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Configure an alternate Amazon Route 53 record for the new ALB endpoint. Use the alternate Route 53 endpoint in the test system requests to test the beta version of the application."},{"poster":"SerialiDr","comment_id":"1162241","content":"Selected Answer: A\\nThis approach allows for the least amount of effort in setting up a beta environment where test system requests can be directed to a new version of the application for testing purposes. It leverages ALB\'s ability to conditionally route traffic based on request attributes, such as cookies, allowing for flexible and efficient testing of new application versions alongside existing production workloads.","timestamp":"1709184960.0","upvote_count":"1"},{"content":"Selected Answer: A\\nA. Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Update the test system code to use this cookie to test the beta version of the application: This is a straightforward and effective solution. By creating a new Auto Scaling group and target group for the beta version and updating the ALB to route based on a specific cookie, the company can easily direct test traffic to the beta version without needing additional infrastructure or complex configurations. The test system would simply include the specified cookie in its requests to access the beta version.","poster":"SerialiDr","comment_id":"1123560","upvote_count":"1","timestamp":"1705343880.0"},{"poster":"JohnPl","comment_id":"1122599","timestamp":"1705242540.0","content":"Selected Answer: D\\nA is modifying the code for testing, not a good practice. D is the least effort compared to B and C","upvote_count":"2"},{"timestamp":"1704156480.0","poster":"gqs3119","comment_id":"1111528","content":"Selected Answer: D\\nModifying ALB (A/D) is less effort than modifying route 53 and adding ALB (B/C), 1 action vs 2.\\n\\nSo it\'s A or D, let\'s think about effort in both cases.\\nIn case of A you will need to:\\n1.Add a new temporary code to set cookies\\n2.Test app with new temporary code, to make sure it won\'t break the production\\n3.Deploy it to the production\\nAfter tests are finished:\\n4.Remove temporary code\\n5.Deploy to production\\n\\nIn case of D you will need: \\n1.Create lambda\\n2.Do a simple testing to make sure it won\'t affect production\\nAfter tests are finished:\\n3.Remove lambda\\n\\nI\'d say D is the least effort.","upvote_count":"3"},{"comment_id":"1105085","timestamp":"1703489700.0","poster":"a_win","upvote_count":"1","content":"Selected Answer: A\\nrequirement with the LEAST effort"},{"comment_id":"1087758","upvote_count":"3","poster":"LR2023","timestamp":"1701705900.0","content":"Selected Answer: D\\njust using voting...explanation in a different thread"},{"upvote_count":"3","content":"I am going with D.....\\n\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html\\n\\nA Lambda function can inspect cookies and rewrite URLs so that users see different versions of a site for A/B testing.\\n\\nOption B & C requires to create new ALB - which is not least effort. And option A requires to update code.","comment_id":"1087751","poster":"LR2023","timestamp":"1701705420.0"},{"upvote_count":"3","content":"Selected Answer: B\\nConsidering Least effort","poster":"Nagasoracle","comment_id":"1046388","timestamp":"1697580540.0"},{"poster":"LemonGremlin","timestamp":"1697575020.0","content":"Selected Answer: A\\nAgree that this is A","comment_id":"1046349","upvote_count":"1"},{"poster":"Rameez1","content":"Selected Answer: A\\nOption A serves the requirement with least efforts.","timestamp":"1697298660.0","upvote_count":"1","comment_id":"1043576"},{"content":"Selected Answer: B\\nWhich solution will meet this requirement with the LEAST effort? Updating code will be more effort, hence B is the correct answer.","upvote_count":"4","poster":"nnecode","comment_id":"1020822","timestamp":"1695994320.0"},{"poster":"eboehm","timestamp":"1686975120.0","upvote_count":"6","content":"Selected Answer: B\\nim going to go with B as well since updating code is way more labor intensive than creating a new route entry","comment_id":"925754"},{"upvote_count":"3","content":"Selected Answer: A\\nOption A is the least effort. With option B, you have to additionally create a new ALB *and* also a new route 53 record. With option A, you can create a new listener based on HTTP header: https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-rules.html and it will fulfill the requirements. You will also need a new auto scaling group and target group with option A - but you also need this with option B as well, so option A is the least effort.","poster":"yeacuz","comment_id":"899303","timestamp":"1684250220.0"},{"poster":"junrun3","comment_id":"897907","upvote_count":"4","timestamp":"1684103400.0","content":"Selected Answer: B\\nThe question is: \\"Which solution meets this requirement with the least amount of effort?\\" The question is: Which solution meets this requirement with the least amount of effort?\\n\\n\\n\\nThe answer is B.\\n\\nA is more labor intensive to implement because it requires updating the ALB routing rules and the test system code needs to be updated."}],"answer_description":"","extracted_at":"2025-12-24T08:55:25.554Z","extraction_method":"api_direct_v1"},{"question_id":"7M6v7HvJn5bXdCxbRrak","question_number":16,"page":4,"question_text":"A team is developing an application that is deployed on Amazon EC2 instances. During testing, the team receives an error. The EC2 instances are unable to access an Amazon S3 bucket.\\n\\nWhich steps should the team take to troubleshoot this issue? (Choose two.)","choices":{"A":"Check whether the policy that is assigned to the IAM role that is attached to the EC2 instances grants access to Amazon S3.","B":"Check the S3 bucket policy to validate the access permissions for the S3 bucket.","C":"Check whether the policy that is assigned to the IAM user that is attached to the EC2 instances grants access to Amazon S3.","E":"Check the security groups that are assigned to the EC2 instances. Make sure that a rule is not blocking the access to Amazon S3.","D":"Check the S3 Lifecycle policy to validate the permissions that are assigned to the S3 bucket."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (91%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107037-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 21:40:00","unix_timestamp":1682192400,"discussion_count":13,"discussion":[{"upvote_count":"17","comment_id":"877591","poster":"MrTee","content":"Selected Answer: AB\\nOption A is correct because IAM roles are used to grant permissions to AWS services, such as EC2 instances, to access other AWS services, such as S3 buckets. The policy assigned to the IAM role attached to the EC2 instances should be checked to ensure that it grants access to the S3 bucket.\\n\\nOption B is also correct because the S3 bucket policy controls access to the S3 bucket. The S3 bucket policy should be checked to ensure that the access permissions are correctly configured.","timestamp":"1698003600.0"},{"poster":"sumanshu","upvote_count":"1","timestamp":"1735313100.0","comment_id":"1332467","content":"Selected Answer: AB\\nEC2 instances typically assume an IAM role to interact with AWS services like S3. If the attached IAM role does not have the correct permissions, the EC2 instance will not be able to access the S3 bucket.\\n\\nEven if the IAM role grants S3 permissions, the bucket policy might explicitly deny access or restrict access to certain principals (users or roles).\\n\\nC) Eliminated - EC2 instances do not use IAM users to access AWS services.\\n\\nD) Eliminated - An S3 Lifecycle policy is used for managing object lifecycles (e.g., moving objects to Glacier or deleting old versions). It does not control access permissions.\\n\\nE) Eliminated - Security groups control inbound and outbound traffic at the network level"},{"content":"Selected Answer: AB\\nAB is the correct answer.","poster":"65703c1","comment_id":"1216059","timestamp":"1732324080.0","upvote_count":"1"},{"comment_id":"1216058","upvote_count":"1","timestamp":"1732324020.0","poster":"65703c1","content":"AB is the correct answer."},{"timestamp":"1722526740.0","upvote_count":"1","comment_id":"1137797","content":"Selected Answer: AB\\nIncorrectly stated question. Its not mentioned how does the application us IAM, that is wether its STS or user credentials. AC is as well perfectly correct answer.","poster":"konieczny69"},{"poster":"SerialiDr","upvote_count":"2","timestamp":"1721061900.0","comment_id":"1123566","content":"Selected Answer: AB\\nThe two steps most relevant to troubleshooting the issue are:\\n\\nA. Check whether the policy that is assigned to the IAM role that is attached to the EC2 instances grants access to Amazon S3.\\nB. Check the S3 bucket policy to validate the access permissions for the S3 bucket."},{"poster":"Nagasoracle","timestamp":"1713393120.0","comment_id":"1046399","upvote_count":"4","content":"Selected Answer: AB\\nhttps://repost.aws/knowledge-center/ec2-instance-access-s3-bucket"},{"poster":"love777","comment_id":"988530","upvote_count":"3","timestamp":"1708717320.0","content":"Selected Answer: AE\\nExplanation:\\n\\nA. IAM Role Policy: EC2 instances are typically associated with IAM roles. These roles have policies attached to them that define the permissions the instances have. If the instances are unable to access an S3 bucket, it\'s essential to verify that the IAM role assigned to the EC2 instances has the necessary permissions to interact with S3.\\n\\nE. Security Groups: Security groups act as virtual firewalls for EC2 instances. They control inbound and outbound traffic. If the EC2 instances are unable to access S3, it\'s possible that the associated security group is blocking outbound traffic to the S3 service. Make sure the security group rules allow outbound traffic to the S3 service."},{"poster":"love777","timestamp":"1708717260.0","comment_id":"988528","upvote_count":"2","content":"The correct steps to troubleshoot the issue are:\\n\\nA. Check whether the policy that is assigned to the IAM role that is attached to the EC2 instances grants access to Amazon S3.\\nE. Check the security groups that are assigned to the EC2 instances. Make sure that a rule is not blocking the access to Amazon S3.\\n\\nExplanation:\\n\\nE. Security Groups: Security groups act as virtual firewalls for EC2 instances. They control inbound and outbound traffic. If the EC2 instances are unable to access S3, it\'s possible that the associated security group is blocking outbound traffic to the S3 service. Make sure the security group rules allow outbound traffic to the S3 service."},{"upvote_count":"2","comment_id":"946231","content":"Why not E ?","poster":"awsazedevsh","comments":[{"upvote_count":"3","comment_id":"981352","poster":"remynick","content":"access to S3 is controlled by IAM, not security groups.","timestamp":"1707985740.0","comments":[{"timestamp":"1726506900.0","poster":"maurice2005","upvote_count":"1","content":"Security group is like a firewall, can block any inbound/outbound traffic.","comment_id":"1175212"}]}],"timestamp":"1704702900.0"},{"poster":"indirasubbaraj","upvote_count":"1","comment_id":"924429","timestamp":"1702668300.0","content":"AB\\nhttps://repost.aws/knowledge-center/ec2-instance-access-s3-bucket"},{"poster":"Prem28","upvote_count":"2","comment_id":"915713","content":"AE\\n\\nB. Check the S3 bucket policy to validate the access permissions for the S3 bucket. The S3 bucket policy controls who has access to the bucket, but it does not control how they can access it. The IAM role or user that is attached to the EC2 instances must have the appropriate permissions to access the bucket, regardless of what the S3 bucket policy says.\\nC. Check whether the policy that is assigned to the IAM user that is attached to the EC2 instances grants access to Amazon S3. This is unlikely to be the cause of the issue, as the IAM role is what is typically used to control access to AWS resources.\\nD. Check the S3 Lifecycle policy to validate the permissions that are assigned to the S3 bucket. The S3 Lifecycle policy controls how objects are stored and moved in Amazon S3. It does not control who has access to the bucket.","timestamp":"1701813540.0"},{"comment_id":"883520","timestamp":"1698500220.0","upvote_count":"4","content":"Selected Answer: AB\\nA: Make sure EC2 instance profile has permission to access s3\\nB: Make sure S3 resource policy allows the access from instance","poster":"vic614"}],"answer_description":"","extracted_at":"2025-12-24T08:55:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"ULv0KV2YzbRWHecsF7uN","question_number":17,"page":4,"question_text":"A developer is working on an ecommerce website. The developer wants to review server logs without logging in to each of the application servers individually. The website runs on multiple Amazon EC2 instances, is written in Python, and needs to be highly available.\\n\\nHow can the developer update the application to meet these requirements with MINIMUM changes?","choices":{"C":"Scale down the application to one larger EC2 instance where only one instance is recording logs.","A":"Rewrite the application to be cloud native and to run on AWS Lambda, where the logs can be reviewed in Amazon CloudWatch.","D":"Install the unified Amazon CloudWatch agent on the EC2 instances. Configure the agent to push the application logs to CloudWatch.","B":"Set up centralized logging by using Amazon OpenSearch Service, Logstash, and OpenSearch Dashboards."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107038-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 21:46:00","unix_timestamp":1682192760,"discussion_count":5,"discussion":[{"timestamp":"1698003960.0","content":"Selected Answer: D\\nOption D is the best option because it requires minimum changes and leverages the existing infrastructure.","poster":"MrTee","upvote_count":"12","comment_id":"877594"},{"poster":"sumanshu","upvote_count":"1","timestamp":"1735313160.0","content":"Selected Answer: D\\nBy installing the unified Amazon CloudWatch agent on all EC2 instances, the application logs will automatically be pushed to Amazon CloudWatch Logs, a centralized logging service.","comment_id":"1332468"},{"timestamp":"1732324200.0","comment_id":"1216060","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","poster":"65703c1"},{"upvote_count":"3","comment_id":"1123568","content":"Selected Answer: D\\nD. Install the unified Amazon CloudWatch agent on the EC2 instances. Configure the agent to push the application logs to CloudWatch: This is the most appropriate solution. The unified CloudWatch agent can be easily installed and configured on each EC2 instance to push logs to Amazon CloudWatch. This allows for centralized log storage and access without a significant change to the application architecture or its high availability setup. It provides a straightforward way to aggregate logs from multiple instances in one place.","poster":"SerialiDr","timestamp":"1721062200.0"},{"comment_id":"899850","upvote_count":"3","timestamp":"1700216100.0","poster":"loctong","content":"Selected Answer: D\\nBy installing the Amazon CloudWatch agent on the EC2 instances, the developer can easily collect and send logs from each instance to Amazon CloudWatch. The CloudWatch agent provides a unified way to collect logs, system-level metrics, and custom metrics from the EC2 instances."}],"answer_description":"","extracted_at":"2025-12-24T08:55:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"QXK7RLz2IZIcoHn2h2b8","question_number":18,"page":4,"question_text":"A company is creating an application that processes .csv files from Amazon S3. A developer has created an S3 bucket. The developer has also created an AWS Lambda function to process the .csv files from the S3 bucket.\\n\\nWhich combination of steps will invoke the Lambda function when a .csv file is uploaded to Amazon S3? (Choose two.)","choices":{"C":"Add a trigger to the existing Lambda function. Set the trigger type to EventBridge. Select the Amazon EventBridge rule.","A":"Create an Amazon EventBridge rule. Configure the rule with a pattern to match the S3 object created event.","D":"Create a new Lambda function to scan the S3 bucket for recently added S3 objects.","E":"Add S3 Lifecycle rules to invoke the existing Lambda function.","B":"Schedule an Amazon EventBridge rule to run a new Lambda function to scan the S3 bucket."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (93%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107039-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 21:52:00","unix_timestamp":1682193120,"discussion_count":9,"discussion":[{"content":"Selected Answer: AC\\nOption A is correct because an Amazon EventBridge rule can be created to detect when an object is created in an S3 bucket. The rule should be configured with a pattern to match the S3 object created event.\\nOption C is correct because the existing Lambda function can be updated with an EventBridge trigger. The trigger type should be set to EventBridge, and the Amazon EventBridge rule created in step A should be selected.","poster":"MrTee","comment_id":"877596","timestamp":"1682193120.0","upvote_count":"17"},{"upvote_count":"1","content":"Selected Answer: AC\\nEventBridge allows you to trigger actions (like Lambda functions) based on specific events (like S3 object uploads).","timestamp":"1735313340.0","poster":"sumanshu","comment_id":"1332472"},{"poster":"wh1t4k3r","timestamp":"1724154060.0","upvote_count":"2","content":"Selected Answer: AC\\nFor the options given as answers, A and C is the viable option. But its a stupid solution... you can use s3 events to trigger it directly.","comment_id":"1269419"},{"comment_id":"1216061","timestamp":"1716419580.0","upvote_count":"1","content":"Selected Answer: AC\\nAC is the correct answer.","poster":"65703c1"},{"poster":"tqiu654","comment_id":"1086429","content":"Selected Answer: AE\\nChatGPT:AE","comments":[{"timestamp":"1702563840.0","comment_id":"1096545","content":"ChatGPT: AC\\nA. Create an Amazon EventBridge rule. Configure the rule with a pattern to match the S3 object created event.\\n\\nThis sets up an EventBridge rule to respond to S3 object creation events.\\nC. Add a trigger to the existing Lambda function. Set the trigger type to EventBridge. Select the Amazon EventBridge rule.\\n\\nThis associates the Lambda function with the EventBridge rule, ensuring that the Lambda function is triggered when the specified event occurs.","upvote_count":"1","poster":"Hari4455"},{"timestamp":"1701554340.0","upvote_count":"1","comment_id":"1086430","poster":"tqiu654","content":"Lambda functions are not currently supported as triggers directly from EventBridge rules.Lambda can be used as the target of an EventBridge rule, but is not added to a Lambda function as a trigger."}],"upvote_count":"1","timestamp":"1701554280.0"},{"comment_id":"1046404","timestamp":"1697582280.0","content":"Selected Answer: AC\\nAC is combination of steps required","upvote_count":"2","poster":"Nagasoracle"},{"comments":[{"content":"I agree that in general this is a stupid question. But maybe company need\'s to use EB in application \ud83e\udd37\u200d\u2642\ufe0f","upvote_count":"1","poster":"ValeriiRadchenko","timestamp":"1699744080.0","comment_id":"1068191"}],"timestamp":"1696850880.0","comment_id":"1028827","content":"Why not just use the S3 event as the trigger directly.","poster":"Jing2023","upvote_count":"3"},{"upvote_count":"2","timestamp":"1689739560.0","poster":"Naj_64","comment_id":"956188","content":"Selected Answer: AC\\nA C for sure"},{"comment_id":"907843","timestamp":"1685175180.0","content":"Selected Answer: AB\\nA, B are correctly","upvote_count":"1","poster":"loctong"}],"answer_description":"","extracted_at":"2025-12-24T08:55:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"33KEQCpkdL7fLiFh34wU","question_number":19,"page":4,"question_text":"A developer needs to build an AWS CloudFormation template that self-populates the AWS Region variable that deploys the CloudFormation template.\\n\\nWhat is the MOST operationally efficient way to determine the Region in which the template is being deployed?","choices":{"D":"Dynamically import the Region by referencing the relevant parameter in AWS Systems Manager Parameter Store.","C":"Find the Region from the AWS::StackId pseudo parameter by using the Fn::Split intrinsic function.","A":"Use the AWS::Region pseudo parameter.","B":"Require the Region as a CloudFormation parameter."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107041-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 21:55:00","unix_timestamp":1682193300,"discussion_count":7,"discussion":[{"upvote_count":"10","poster":"MrTee","comment_id":"877599","timestamp":"1682193300.0","content":"Selected Answer: A\\nA. Use the AWS::Region pseudo parameter."},{"timestamp":"1735313520.0","poster":"sumanshu","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/mappings-section-structure.html\\n\\nAWS::Region is a pseudo parameter that automatically provides the Region where the stack is being deployed (e.g., us-east-1 if deploying in the US East Region).\\n\\nB) Eliminated - Adding a parameter for the Region means users would need to manually specify the Region every time they deploy the template\\n\\nC) Eliminated - While the stack ID contains the Region as part of its value (e.g., arn:aws:cloudformation:us-east-1:123456789012:stack/MyStack/...), extracting it with Fn::Split is a complicated workaround.\\n\\nD) Eliminated","comment_id":"1332475","upvote_count":"2"},{"content":"Selected Answer: A\\nResources:\\n MyS3Bucket:\\n Type: \\"AWS::S3::Bucket\\"\\n Properties:\\n BucketName: !Sub \\"my-bucket-${AWS::Region}\\"","timestamp":"1726983540.0","upvote_count":"1","poster":"albert_kuo","comment_id":"1287561"},{"comment_id":"1216062","timestamp":"1716419640.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","poster":"65703c1"},{"poster":"Baba_Eni","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html","timestamp":"1686920640.0","comment_id":"925186","upvote_count":"2"},{"poster":"Baba_Eni","comment_id":"925185","upvote_count":"1","timestamp":"1686920520.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.htmlhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html"},{"timestamp":"1684311480.0","comment_id":"899853","content":"Selected Answer: A\\nThe AWS::Region pseudo parameter is a built-in CloudFormation parameter that automatically resolves to the AWS Region where the CloudFormation stack is being created. By using this pseudo parameter, you can dynamically access the current Region without requiring any additional configuration or input.","poster":"loctong","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:55:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"PImXy2W5K0hyqbOSYNdS","question_number":20,"page":4,"question_text":"A company has hundreds of AWS Lambda functions that the company\'s QA team needs to test by using the Lambda function URLs. A developer needs to configure the authentication of the Lambda functions to allow access so that the QA IAM group can invoke the Lambda functions by using the public URLs.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to loop on the Lambda functions to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group\'s Amazon Resource Name (ARN).","C":"Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to loop on the Lambda functions to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group\'s Amazon Resource Name (ARN).","B":"Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group.","A":"Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group."},"correct_answer":"A","answer_ET":"A","answers_community":["A (75%)","C (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107050-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:08:00","unix_timestamp":1682197680,"discussion_count":10,"discussion":[{"poster":"MrTee","upvote_count":"16","comments":[{"upvote_count":"4","content":"https://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html","comment_id":"933211","poster":"ppardav","timestamp":"1687668480.0"},{"poster":"jipark","upvote_count":"5","comment_id":"971085","timestamp":"1691063640.0","content":"create \'AWS_IAM auth type\' -> Attach the policy to the QA IAM group"}],"content":"Selected Answer: A\\nOption A meets these requirements?","timestamp":"1682197680.0","comment_id":"877647"},{"comment_id":"1332798","upvote_count":"1","content":"Selected Answer: A\\nA) Correct - Setting the AWS_IAM authentication type ensures that only IAM users or roles with the right permissions can invoke the Lambda function URLs.\\n\\nC) Eliminated - While this approach is secure, creating individual resource-based policies for hundreds of Lambda functions is unnecessarily complex and hard to manage. An identity-based policy (used in Option A) is simpler because it applies to the entire QA IAM group at once.\\n\\n\\nB/D - Eliminated - Setting NONE as the auth type makes the Lambda function URLs publicly accessible without authentication.","timestamp":"1735363680.0","poster":"sumanshu"},{"upvote_count":"1","timestamp":"1720775820.0","comment_id":"1246617","content":"Selected Answer: A\\nApologies again, please refer to the youtube link I shared earlier..correct ans is A","poster":"Anandesh"},{"comment_id":"1240811","poster":"Anandesh","content":"I think the answer is B here, reason being the function should be invoked using public urls","timestamp":"1719925920.0","upvote_count":"1"},{"content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","timestamp":"1716420180.0","comment_id":"1216063","upvote_count":"1"},{"timestamp":"1709189940.0","poster":"SerialiDr","comment_id":"1162284","content":"Selected Answer: A\\nThis approach leverages AWS IAM authentication (AWS_IAM auth type) for Lambda function URLs, ensuring that only authenticated and authorized IAM entities can invoke the Lambda functions. By creating an IAM policy that specifies the lambda:InvokeFunctionUrl action and attaching it to the QA IAM group, you provide the necessary permissions for the QA team to invoke the Lambda functions securely. This method aligns with AWS best practices for security and access control, allowing for scalable and manageable access management across multiple Lambda functions.","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\\nI don\'t know why so much A, but ins\'t A giving the access to all the lambda?","poster":"CrescentShared","comment_id":"1156945","timestamp":"1708669560.0"},{"upvote_count":"1","timestamp":"1707966720.0","poster":"SD_CS","content":"Selected Answer: A\\nI have to go for A even though it appears both should suffice. I took this from AWS Documentation\\n\\nIf you choose the AWS_IAM auth type, users who need to invoke your Lambda function URL must have the lambda:InvokeFunctionUrl permission. Depending on who makes the invocation request, you may have to grant this permission using a resource-based policy.\\n\\nIf the principal making the request is in the same AWS account as the function URL, then the principal must either have lambda:InvokeFunctionUrl permissions in their identity-based policy, OR have permissions granted to them in the function\'s resource-based policy.\\n\\nAWS clearly states both should be good. The reason for selecting A is the wording is clear, loop on to lambda function to provide the permission was bit of confusing to me.","comment_id":"1150726"},{"timestamp":"1706809740.0","content":"Selected Answer: C\\nI don\'t get all A answers. This is typical resource based policy that allows invoking a function by concrete principal - in this case its the QA role.\\n\\nFor all those who vote for A - go ahead and create simple API Gateway with a lambda integration type. Then look at the resource based policy - lambda:InvokeFunction allowed by apigateway.amazonaws.com with ArnLike condition.\\n\\nChatGTP also says C.","comment_id":"1137804","upvote_count":"2","poster":"konieczny69"},{"upvote_count":"4","comment_id":"988559","content":"Selected Answer: C\\nExplanation:\\n\\nIn this scenario, the QA team needs to test AWS Lambda functions using Lambda function URLs while ensuring proper authentication and access control. Here\'s why option C is the appropriate solution:\\n\\nAuthentication Type: Using the AWS_IAM auth type for the Lambda function URLs ensures that the Lambda functions can be invoked only by users and roles that have the necessary IAM permissions.\\n\\nIdentity-Based Policy: By creating an IAM identity-based policy, you grant permissions directly to the QA IAM group to invoke the Lambda functions using the Lambda function URLs. This provides fine-grained control over which IAM entities can access the functions.\\n\\nOption A uses the AWS_IAM auth type and creates a policy for the QA IAM group, which is a good direction. However, the creation of a policy that allows lambda:InvokeFunctionUrl for all Lambda function ARNs might grant excessive permissions.","poster":"love777","comments":[{"upvote_count":"4","poster":"[Removed]","comments":[{"timestamp":"1703602080.0","comment_id":"1106108","poster":"Manel87","upvote_count":"1","content":"good thought!"}],"timestamp":"1702224960.0","content":"pay attention to the wording of the answers:\\nA - Run another script to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs).\\n*This option is very clear. You are creating an IAM identity based policy allowing access to invoke the function and then attaching this policy to the QA IAM group.\\n\\nC - Run another script to loop on the Lambda functions to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group\'s Amazon Resource Name (ARN).\\n*What does \\"Run another script to loop on the Lambda functions\\" What does this even mean?? are we doing some sort of while loop here? Wording for this option is very confusing and makes no sense to me. I go with A","comment_id":"1092628"},{"content":"Why A grant excessive permissions? The policy will contain only the Lambda\'s ARNs wich the QA group should have access to.","comment_id":"1043563","timestamp":"1697297520.0","poster":"dezoito","upvote_count":"2"}],"timestamp":"1692813540.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"HYJzFgj0TzNFxDweGFhj","question_number":21,"page":5,"question_text":"A developer maintains a critical business application that uses Amazon DynamoDB as the primary data store. The DynamoDB table contains millions of documents and receives 30-60 requests each minute. The developer needs to perform processing in near-real time on the documents when they are added or updated in the DynamoDB table.\\n\\nHow can the developer implement this feature with the LEAST amount of change to the existing application code?","choices":{"B":"Enable a DynamoDB stream on the table. Invoke an AWS Lambda function to process the documents.","C":"Update the application to send a PutEvents request to Amazon EventBridge. Create an EventBridge rule to invoke an AWS Lambda function to process the documents.","A":"Set up a cron job on an Amazon EC2 instance. Run a script every hour to query the table for changes and process the documents.","D":"Update the application to synchronously process the documents directly after the DynamoDB write."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107051-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:13:00","unix_timestamp":1682197980,"discussion_count":5,"discussion":[{"poster":"MrTee","upvote_count":"10","comment_id":"877648","timestamp":"1698009180.0","content":"Selected Answer: B\\nOption B is the best solution because it proposes enabling a DynamoDB stream on the table, which allows the developer to capture document-level changes in near-real time without modifying the application code. Then, the stream can be configured to invoke an AWS Lambda function to process the documents in near-real time. This solution requires minimal changes to the existing application code, and the Lambda function can be developed and deployed separately, enabling the developer to easily maintain and update it as needed."},{"poster":"loctong","comment_id":"899857","content":"Selected Answer: B\\nTo implement near-real-time processing on documents added or updated in a DynamoDB table with the least amount of change to the existing application code, the developer should:\\n\\nB. Enable a DynamoDB stream on the table and invoke an AWS Lambda function to process the documents.\\n\\nEnabling a DynamoDB stream on the table allows capturing and processing of the changes made to the table in near-real-time. The stream provides an ordered sequence of item-level modifications (inserts, updates, and deletes) that can be consumed by other AWS services, such as AWS Lambda.","timestamp":"1700216460.0","upvote_count":"5"},{"content":"Selected Answer: B\\nA DynamoDB stream is a feature that automatically tracks changes (inserts, updates, deletes) to items in a table.\\nWhenever a document is added or updated, the change is recorded in the stream.\\n\\nA) Eliminated - Querying the DynamoDB table every hour introduces a delay, so it\'s not near-real-time.\\n\\nC) Eliminated - To use EventBridge, you would need to modify the application code to explicitly send events (PutEvents) every time a change is made in DynamoDB.\\n\\nD) Eliminated - require significant changes to the existing application code.","poster":"sumanshu","comment_id":"1332837","upvote_count":"1","timestamp":"1735372260.0"},{"comment_id":"1216064","upvote_count":"1","timestamp":"1732325040.0","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer."},{"content":"Selected Answer: B\\nGPT\\nTo implement near-real-time processing of documents when they are added or updated in an Amazon DynamoDB table with the least amount of change to the existing application code, let\'s evaluate the options:\\n\\nA. Set up a cron job on an Amazon EC2 instance. Run a script every hour to query the table for changes and process the documents: This approach introduces additional complexity and is not near-real time. Running a script periodically to check for updates is inefficient and does not meet the requirement for immediate processing upon document addition or update.\\n\\nB. Enable a DynamoDB stream on the table. Invoke an AWS Lambda function to process the documents: This is the most efficient and least intrusive option. DynamoDB Streams capture changes to items in the DynamoDB table as they occur in near-real time and can trigger an AWS Lambda function automatically. This setup requires minimal changes to the existing application code, as the processing logic is moved to the Lambda function, which is triggered by the stream events.","timestamp":"1721111280.0","poster":"SerialiDr","upvote_count":"1","comment_id":"1124017"}],"answer_description":"","extracted_at":"2025-12-24T08:55:47.312Z","extraction_method":"api_direct_v1"},{"question_id":"tl9WgQYgrJLkbILc4CnW","question_number":22,"page":5,"question_text":"A developer is writing an application for a company. The application will be deployed on Amazon EC2 and will use an Amazon RDS for Microsoft SQL Server database. The company\'s security team requires that database credentials are rotated at least weekly.\\n\\nHow should the developer configure the database credentials for this application?","choices":{"C":"Create a database user. Store the user name and password in an AWS Secrets Manager secret that has daily rotation enabled.","D":"Use the EC2 user data to create a database user. Provide the user name and password in environment variables to the application.","A":"Create a database user. Store the user name and password in an AWS Systems Manager Parameter Store secure string parameter. Enable rotation of the AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter.","B":"Enable IAM authentication for the database. Create a database user for use with IAM authentication. Enable password rotation."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107052-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:16:00","unix_timestamp":1682198160,"discussion_count":8,"discussion":[{"timestamp":"1682198160.0","upvote_count":"14","poster":"MrTee","content":"Selected Answer: C\\noption C: Create a database user. Store the user name and password in an AWS Secrets Manager secret that has daily rotation enabled. This will allow the developer to securely store the database credentials and automatically rotate them at least weekly to meet the company\u2019s security requirements.","comment_id":"877651"},{"timestamp":"1735375140.0","comment_id":"1332873","content":"Selected Answer: C\\nIt can automatically rotate the credentials for supported databases\\n\\nA) Eliminated - it does not natively support automatic credential rotation for databases.","upvote_count":"1","poster":"sumanshu"},{"poster":"Saurabh04","content":"Correct Answer should be A: This approach centralizes credential management and provides secure storage. Rotation can be scheduled weekly as required by the security team1.","comment_id":"1261870","upvote_count":"1","timestamp":"1722988920.0"},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","poster":"65703c1","comment_id":"1216068","timestamp":"1716420420.0"},{"upvote_count":"2","comment_id":"1124032","poster":"SerialiDr","timestamp":"1705395180.0","content":"Selected Answer: C\\nC. Create a database user. Store the user name and password in an AWS Secrets Manager secret that has daily rotation enabled: This is the correct solution. AWS Secrets Manager is specifically designed to handle secrets like database credentials, including their rotation. You can configure Secrets Manager to automatically rotate the credentials as frequently as needed (e.g., daily or weekly), which aligns with the security team\'s requirements."},{"timestamp":"1691066580.0","poster":"jipark","comment_id":"971110","content":"Selected Answer: C\\nrotation key & cross account key is feature of Secret Manager\\nhttps://tutorialsdojo.com/aws-secrets-manager-vs-systems-manager-parameter-store/","upvote_count":"2"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\\n\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_turn-on-for-other.html\\n\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_schedule.html","timestamp":"1686931560.0","upvote_count":"3","poster":"Baba_Eni","comment_id":"925361"},{"poster":"loctong","content":"Selected Answer: C\\nthe keyword is \\"rotation\\"","timestamp":"1684318740.0","upvote_count":"4","comment_id":"899981"}],"answer_description":"","extracted_at":"2025-12-24T08:55:47.312Z","extraction_method":"api_direct_v1"},{"question_id":"nrARt34AwLFKLzDTn5gv","question_number":23,"page":5,"question_text":"A real-time messaging application uses Amazon API Gateway WebSocket APIs with backend HTTP service. A developer needs to build a feature in the application to identify a client that keeps connecting to and disconnecting from the WebSocket connection. The developer also needs the ability to remove the client.\\n\\nWhich combination of changes should the developer make to the application to meet these requirements? (Choose two.)","choices":{"D":"Add code to track the client status in Amazon ElastiCache in the backend service.","A":"Switch to HTTP APIs in the backend service.","C":"Use the callback URL to disconnect the client from the backend service.","B":"Switch to REST APIs in the backend service.","E":"Implement $connect and $disconnect routes in the backend service."},"correct_answer":"DE","answer_ET":"DE","answers_community":["DE (48%)","CE (47%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107053-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:24:00","unix_timestamp":1682198640,"discussion_count":24,"discussion":[{"content":"Selected Answer: DE\\nOption D because by storing the client status in the cache, the backend service can quickly access the client status data without the need to query the database or perform other time-consuming operations.\\nOption E. Implement $connect and $disconnect routes in the backend service: $connect and $disconnect are the reserved routes in WebSocket APIs, which are automatically called by API Gateway whenever a client connects or disconnects from the WebSocket. By implementing these routes in the backend service, the developer can track and manage the client status, including identifying and removing the client when needed.","poster":"MrTee","timestamp":"1682198640.0","comments":[{"content":"You guys need to stop pasting ChatGPT answers and specially upvoting them without any reference link","poster":"robotgeek","comment_id":"1574702","timestamp":"1749021420.0","upvote_count":"1"},{"timestamp":"1711577640.0","poster":"akmv2","content":"How is D viable when the question doesn\'t mention Elasticache? You\'re making an assumption that adding a service/configuration is what\'s being asked","comment_id":"1184426","upvote_count":"1"}],"upvote_count":"22","comment_id":"877652"},{"timestamp":"1685439840.0","comment_id":"910120","poster":"catcatpunch","upvote_count":"10","content":"Selected Answer: CE\\nC => https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html\\n\\nE => https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-websocket-api-route-keys-connect-disconnect.html"},{"timestamp":"1752479220.0","comment_id":"1586657","poster":"Wardove","content":"Selected Answer: CE\\nAlthough - option D is also correct, I would choose C and E \\n1) what we know 100% - we can disconnect uses using Callback url \\nreference: https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api.html\\n2) we definitely need to implement $connect and $disconnect routes (to identify during runtime)\\n3) we cannot technically track a user spamming connections if we don\'t pass this info logically to each invocation - and technically without persistence this is a mission impossible","upvote_count":"1"},{"comment_id":"1346303","content":"Selected Answer: CE\\nDE does not make the developer disconnect","upvote_count":"1","comments":[{"timestamp":"1737772860.0","content":"Can\'t believe DE is 50%.. this q is not even hard","upvote_count":"1","comment_id":"1346304","poster":"mooncake1"}],"poster":"mooncake1","timestamp":"1737772500.0"},{"upvote_count":"1","timestamp":"1736113260.0","poster":"Arad","content":"Selected Answer: CE\\nCE is correct.","comment_id":"1336885"},{"content":"Selected Answer: DE\\nA) Eliminated - Switching to HTTP APIs would eliminate the WebSocket capability entirely,\\nB) Eliminated - REST APIs are also unsuitable for WebSocket connections, as they are designed for request-response interactions rather than persistent, real-time communication.\\n\\nBoth C&E and D&E - seems correct\\n\\nC) - API Gateway provides a callback URL that your backend service can use to invoke the POST /connections/{connectionId} API with the disconnect command.\\n\\nD) \\n\\nE) Correct - The $connect route triggers when a client establishes a WebSocket connection. The $disconnect route triggers when a client disconnects from the WebSocket","timestamp":"1735384800.0","upvote_count":"1","comments":[{"upvote_count":"1","poster":"sumanshu","content":"C) Callback URL allows you to explicitly disconnect clients.","timestamp":"1735384980.0","comments":[{"poster":"sumanshu","comments":[{"timestamp":"1735385160.0","poster":"sumanshu","content":"D is critical for tracking client activity.\\nE is required to capture connection and disconnection events.\\nC provides the functionality to disconnect a client once identified.\\nThus, the correct combination is C, D, and E.","upvote_count":"1","comments":[{"comment_id":"1332925","timestamp":"1735385220.0","upvote_count":"1","content":"C. Use the callback URL to disconnect the client from the backend service\\n\\nThis is essential for removing the client. Without it, the backend has no way to forcibly disconnect a problematic client.\\n\u2705 Must-have.\\nD. Add code to track the client status in Amazon ElastiCache in the backend service\\n\\nTracking client connection/disconnection behavior is critical to identifying problematic clients. ElastiCache is a highly suitable tool for storing connection data efficiently.\\n\u2705 Must-have.\\nE. Implement $connect and $disconnect routes in the backend service\\n\\nWhile these routes are necessary for detecting client connections and disconnections, this could be seen as implicit in the implementation of D (since tracking client status assumes these routes are already used).\\n\u26a0\ufe0f Optional, depending on how the question is interpreted.","poster":"sumanshu"}],"comment_id":"1332924"}],"upvote_count":"1","timestamp":"1735385100.0","content":"The two requirements in the question are:\\n\\nIdentify a client that keeps connecting and disconnecting:\\n\\nThis requires tracking client connections and disconnections over time.\\nTo achieve this, the backend needs a mechanism to log or store connection events for each client, which can then be analyzed to identify repeated connection patterns.\\nRemove the client:\\n\\nOnce the client is identified as problematic (e.g., frequent connects/disconnects), the backend needs to remove the client. This is achieved using the WebSocket callback URL to explicitly disconnect the client.","comment_id":"1332923"}],"comment_id":"1332922"}],"poster":"sumanshu","comment_id":"1332920"},{"poster":"Saurabh04","timestamp":"1722989280.0","comments":[{"content":"What about \\"the ability to remove the client\\"? for that it needs to use the callback function","poster":"9d8dd9c","timestamp":"1729937460.0","comment_id":"1303224","upvote_count":"1"}],"content":"Option DE: Implement $connect and $disconnect Routes:\\nAdd $connect and $disconnect routes to your WebSocket API.\\nThese routes handle client connections and disconnections.\\nWhen a client connects ($connect), a Lambda function can add the connection ID to a data store (e.g., DynamoDB).\\nWhen a client disconnects ($disconnect), another Lambda function can remove the connection ID from the data store.\\nTrack Client Status:\\nUse Amazon ElastiCache (e.g., Redis) to track client status.\\nStore relevant information (e.g., client IDs, connection timestamps) in ElastiCache.\\nThis allows you to identify clients that connect and disconnect","upvote_count":"1","comment_id":"1261872"},{"timestamp":"1721239080.0","poster":"tomchandler077","comment_id":"1249868","content":"Option D ---\x3e CORRECT Because, tracking the client\'s connection status using ElastiCache could help in identifying clients with erratic connection patterns and managing stateful information in a distributed environment, which is useful for WebSocket applications.\\n\\nAlso Option E CORRECT. These routes handle connection and disconnection events.","upvote_count":"1"},{"comment_id":"1231696","poster":"tsangckl","content":"This appear at 17 Jun exam","timestamp":"1718596080.0","upvote_count":"2","comments":[{"poster":"frangesk","comment_id":"1272185","content":"Do you remember the answers?","timestamp":"1724597880.0","upvote_count":"1"}]},{"content":"Selected Answer: DE\\nDE is the correct answer.","comment_id":"1216072","poster":"65703c1","upvote_count":"1","timestamp":"1716420600.0"},{"upvote_count":"1","poster":"41eb566","content":"Selected Answer: DE\\nE. Implement $connect and $disconnect routes in the backend service.\\n\\nBy implementing $connect and $disconnect routes, the backend service can capture when clients connect and disconnect from the WebSocket connection. This allows the application to track client status effectively.\\nD. Add code to track the client status in Amazon ElastiCache in the backend service.","timestamp":"1710694740.0","comment_id":"1175960"},{"content":"Selected Answer: CE\\nYour backend service can use the following WebSocket connection HTTP requests to send a callback message to a connected client, get connection information, or disconnect the client\\n\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html","comment_id":"1173793","poster":"maurice2005","upvote_count":"1","timestamp":"1710456120.0"},{"timestamp":"1709190960.0","poster":"SerialiDr","content":"Selected Answer: DE\\nWhen a client connects to your WebSocket API, the $connect route is invoked, and when they disconnect, the $disconnect route is invoked. You can use these routes to track the state of each client. By maintaining a record of each client\'s connections and disconnections, possibly in a database or an in-memory data store like Amazon ElastiCache, you can identify clients that frequently connect and disconnect.\\n\\nHence, the combination of changes that should be made to the application to meet these requirements includes:\\n\\nImplement $connect and $disconnect routes in the backend service (Option E).\\nAdd code to track the client status in Amazon ElastiCache in the backend service (Option D).","upvote_count":"2","comment_id":"1162291"},{"upvote_count":"1","content":"Selected Answer: CE\\nC option - Supports https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html\\nE option supports - https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-route-keys-connect-disconnect.html","timestamp":"1708853640.0","poster":"KarBiswa","comment_id":"1158516"},{"timestamp":"1706687580.0","content":"Selected Answer: CD\\nC: https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html\\n\\nD: You need a way to track which user is continuously reconnecting. That is why option D is so important because without it you will just be disconnecting every user that tries to connect cause then how will you know which user is the \\"problem\\" user. Note that you don\'t need the $disconnect endpoint to disconnect a client if you use option C. So CD is the only combination to solve the problem.","poster":"Ashwinvdm22","upvote_count":"2","comment_id":"1136510"},{"timestamp":"1705862040.0","upvote_count":"1","poster":"Abdullah22","comment_id":"1128055","content":"going with DE"},{"upvote_count":"1","comment_id":"1124037","content":"Selected Answer: CD\\nC. Use the callback URL to disconnect the client from the backend service: The callback URL can be used to send messages to connected clients or to disconnect them from the WebSocket connection. This approach allows the backend service to programmatically disconnect a client, which is useful for managing clients that frequently connect and disconnect.\\n\\nD. Add code to track the client status in Amazon ElastiCache in the backend service: Implementing client status tracking in the backend service, possibly using a fast, in-memory data store like Amazon ElastiCache, allows the application to monitor and record the behavior of each client. This can be used to identify clients with frequent connect/disconnect patterns.","timestamp":"1705395900.0","poster":"SerialiDr"},{"upvote_count":"1","comment_id":"1105096","content":"Selected Answer: DE\\nD. Add code to track the client status in Amazon ElastiCache in the backend service. \\nE. Implement $connect and $disconnect routes in the backend service.","poster":"a_win","timestamp":"1703490960.0"},{"comment_id":"1087792","timestamp":"1701710100.0","poster":"LR2023","content":"Selected Answer: CE\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html","upvote_count":"1"},{"upvote_count":"2","timestamp":"1694556840.0","poster":"Balliache520505","comment_id":"1006057","content":"Selected Answer: CE\\nI go with C and E.\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-route-keys-connect-disconnect.html\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html"},{"comment_id":"988567","content":"Selected Answer: DE\\nD. Tracking Client Status: To identify and manage clients that connect and disconnect from the WebSocket connection, you need a way to persist this information. Amazon ElastiCache is a managed in-memory caching service that can be used to store this kind of data. By adding code to your backend service to track client status in ElastiCache, you can keep a record of client connections and disconnections.\\n\\nE.\\nconnectanddisconnect Routes: In API Gateway WebSocket APIs, the\\nconnectanddisconnect routes are special routes that are automatically triggered when a client connects and disconnects from the WebSocket connection. By implementing these routes in your backend service, you can capture the client information and update the client status in the ElastiCache, thus achieving the requirement of identifying clients and managing their connections.","timestamp":"1692814200.0","upvote_count":"3","poster":"love777"},{"upvote_count":"4","poster":"Phongsanth","content":"Selected Answer: CE\\nOption C and E is my preferable choice. \\nwhy do we have to use option D in case we apply $connect and $disconnect already in option E ?\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-route-keys-connect-disconnect.html","comment_id":"937385","timestamp":"1688005200.0"},{"poster":"delak","content":"Selected Answer: CE\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html","comment_id":"903562","timestamp":"1684708560.0","upvote_count":"4"},{"content":"Selected Answer: CE\\nImplementing a callback URL allows the backend service to initiate disconnection from the WebSocket connection.","comment_id":"899876","timestamp":"1684312680.0","upvote_count":"4","poster":"loctong"}],"answer_description":"","extracted_at":"2025-12-24T08:55:47.312Z","extraction_method":"api_direct_v1"},{"question_id":"irxRQmYfLdO83ULHXjsZ","question_number":24,"page":5,"question_text":"A developer is creating an application that will give users the ability to store photos from their cellphones in the cloud. The application needs to support tens of thousands of users. The application uses an Amazon API Gateway REST API that is integrated with AWS Lambda functions to process the photos. The application stores details about the photos in Amazon DynamoDB.\\nUsers need to create an account to access the application. In the application, users must be able to upload photos and retrieve previously uploaded photos. The photos will range in size from 300 KB to 5 MB.\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Create a users table in DynamoDB. Use the table to manage user accounts. Create a Lambda authorizer that validates user credentials against the users table. Integrate the Lambda authorizer with API Gateway to control access to the API. Use the Lambda function to store the photos in Amazon S3. Store the object\'s S3 key as par of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","C":"Create an IAM user for each user of the application during the sign-up process. Use IAM authentication to access the API Gateway API. Use the Lambda function to store the photos in Amazon S3. Store the object\'s S3 key as part of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","B":"Use Amazon Cognito user pools to manage user accounts. Create an Amazon Cognito user pool authorizer in API Gateway to control access to the API. Use the Lambda function to store the photos in Amazon S3. Store the object\'s S3 key as part of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","A":"Use Amazon Cognito user pools to manage user accounts. Create an Amazon Cognito user pool authorizer in API Gateway to control access to the API. Use the Lambda function to store the photos and details in the DynamoDB table. Retrieve previously uploaded photos directly from the DynamoDB table."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103439-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 06:35:00","unix_timestamp":1679376900,"discussion_count":11,"discussion":[{"timestamp":"1679376900.0","poster":"Untamables","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-integrate-with-cognito.html\\nhttps://aws.amazon.com/blogs/big-data/building-and-maintaining-an-amazon-s3-metadata-index-without-servers/","upvote_count":"12","comment_id":"845551"},{"poster":"jayvarma","upvote_count":"6","comment_id":"976284","timestamp":"1691559600.0","content":"As it is not a good practice to create a new IAM user for each user that signs up for the application, Option C is ruled out. Amazon Cognito user pools primary purpose is to authenticate and authorize web and mobile applications.\\n\\nAs the solution requires the application to store images that are between 300KB and 5MB in size, The idea of storing the images in the DynamoDB is ruled out because the object size in a dynamoDb table cannot exceed 400kb. The ideal solution for this problem would be to store the photos in S3 and store the object\'s key in the DynamoDB table.\\n\\nSo, Option B is the right answer"},{"timestamp":"1734714420.0","content":"Selected Answer: B\\nA) Eliminated - DynamoDB is not optimized for large binary objects\\nC) Eliminated - Creating IAM users for each application user is not scalable\\nD) Eliminated - Using a custom table and Lambda authorizer for user authentication increases operational complexity.","comment_id":"1329571","upvote_count":"1","poster":"sumanshu"},{"timestamp":"1733966160.0","comment_id":"1325328","content":"Selected Answer: B\\nkeyword: LEAST operational overhead, size from 300 KB to 5 MB.\\n\\n==> discard A: item limit upto 400kB only\\n==> discard C: each user per IAM user --\x3e really bad practice\\n==> discard D: violate \\"LEAST operational overhead\\", you must build a lot (wriete lambda function), result in manage it alot \\n\\nB is best choice to use services: s3, dynamoDB, Amazon Cognito with maximum automatic build-in feature and least effort for operation","poster":"trieudo","upvote_count":"1"},{"timestamp":"1730068980.0","poster":"Saudis","content":"The difference between B and C the key word create usr > cognito","upvote_count":"1","comment_id":"1303749"},{"upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716298380.0","comment_id":"1214977","poster":"65703c1"},{"poster":"badsati","content":"Selected Answer: B\\nNo question, Answer is B","timestamp":"1712597400.0","upvote_count":"1","comment_id":"1191721"},{"upvote_count":"2","content":"Selected Answer: B\\nDefinitly do not add all users manually, so that rules out C and D. \\nYou wouldnt use DynamoDB to store the photos because DynamoDB limits the size of each item that you store in a table to 400 KB. So that rules out A","comment_id":"1165605","poster":"TheFivePips","timestamp":"1709560380.0"},{"content":"Selected Answer: B\\nIt\'s easier if you leverage all pros of Amazon Cognito you don\'t need creating a IAM user by employeer","upvote_count":"1","poster":"leonardoliveros","timestamp":"1700092860.0","comment_id":"1072027"},{"content":"Selected Answer: B\\nCognito,\\nItem size in dynamodb is less than this scenario","timestamp":"1680357240.0","upvote_count":"4","poster":"ihta_2031","comment_id":"857980"},{"comment_id":"851736","upvote_count":"3","content":"Selected Answer: B\\nB is the most valid solution.\\nA nearest, but invalid, because you cannot store object in Dynamo.","poster":"pratchatcap","timestamp":"1679894460.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:47.312Z","extraction_method":"api_direct_v1"},{"question_id":"xg7CtAuBeV2aKjxgdHZg","question_number":25,"page":5,"question_text":"A developer has written code for an application and wants to share it with other developers on the team to receive feedback. The shared application code needs to be stored long-term with multiple versions and batch change tracking.\\n\\nWhich AWS service should the developer use?","choices":{"A":"AWS CodeBuild","B":"Amazon S3","C":"AWS CodeCommit","D":"AWS Cloud9"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107054-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:26:00","unix_timestamp":1682198760,"discussion_count":6,"discussion":[{"comment_id":"877654","timestamp":"1698009960.0","poster":"MrTee","upvote_count":"7","content":"Selected Answer: C\\noption C, AWS CodeCommit."},{"content":"Selected Answer: C\\nAWS CodeCommit is specifically built for managing source code.","poster":"sumanshu","timestamp":"1735385940.0","upvote_count":"1","comment_id":"1332927"},{"poster":"65703c1","comment_id":"1216074","upvote_count":"1","timestamp":"1732325460.0","content":"Selected Answer: C\\nC is the correct answer."},{"timestamp":"1717514160.0","comment_id":"1087794","poster":"LR2023","content":"Selected Answer: C\\nCode commit is a code source repository","upvote_count":"1"},{"comment_id":"899877","upvote_count":"3","content":"Selected Answer: C\\nmust be C","timestamp":"1700217540.0","poster":"loctong"},{"timestamp":"1700016780.0","poster":"delak","comment_id":"897965","content":"it\'s C","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T08:55:47.312Z","extraction_method":"api_direct_v1"},{"question_id":"yl2KYWVSZ7IugkoTIcpp","question_number":26,"page":6,"question_text":"A company\'s developer is building a static website to be deployed in Amazon S3 for a production environment. The website integrates with an Amazon Aurora PostgreSQL database by using an AWS Lambda function. The website that is deployed to production will use a Lambda alias that points to a specific version of the Lambda function.\\n\\nThe company must rotate the database credentials every 2 weeks. Lambda functions that the company deployed previously must be able to use the most recent credentials.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Systems Manager Parameter Store.","B":"Include the database credentials as part of the Lambda function code. Update the credentials periodically and deploy the new Lambda function.","C":"Use Lambda environment variables. Update the environment variables when new credentials are available.","A":"Store the database credentials in AWS Secrets Manager. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Secrets Manager."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107055-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:31:00","unix_timestamp":1682199060,"discussion_count":6,"discussion":[{"comment_id":"877655","upvote_count":"12","content":"Selected Answer: A\\nOption A is the correct solution; Option D is also a valid solution, but it is not the best option since Secrets Manager provides built-in rotation, which ensures that the latest credentials are automatically updated. Additionally, AWS Systems Manager Parameter Store does not provide the ability to rotate secrets automatically.","timestamp":"1698010260.0","poster":"MrTee"},{"timestamp":"1700223660.0","content":"Selected Answer: A\\nthe key word is \\"rotation\\"","upvote_count":"5","poster":"loctong","comment_id":"899982"},{"comment_id":"1332949","upvote_count":"1","content":"Selected Answer: A\\nAWS Secrets Manager provides a built-in feature for rotating credentials automatically\\n\\nD) Eliminated - it does not provide built-in rotation functionality","timestamp":"1735389960.0","poster":"sumanshu"},{"comment_id":"1216083","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732326000.0"},{"timestamp":"1721129940.0","poster":"SerialiDr","comment_id":"1124248","content":"Selected Answer: A\\nA. Store the database credentials in AWS Secrets Manager. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Secrets Manager: This is the most suitable solution. AWS Secrets Manager is designed to manage, retrieve, and rotate secrets such as database credentials. By storing the credentials in Secrets Manager and enabling rotation, the credentials will be automatically rotated every 2 weeks. The Lambda function can retrieve the latest credentials programmatically from Secrets Manager, ensuring it always has access to the current credentials.","upvote_count":"2"},{"content":"Selected Answer: A\\nSecrets manager for rotation","poster":"LR2023","comment_id":"1087795","upvote_count":"1","timestamp":"1717514280.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:58.124Z","extraction_method":"api_direct_v1"},{"question_id":"WtD15bgLcXY0lqyWSAoR","question_number":27,"page":6,"question_text":"A developer is developing an application that uses signed requests (Signature Version 4) to call other AWS services. The developer has created a canonical request, has created the string to sign, and has calculated signing information.\\n\\nWhich methods could the developer use to complete a signed request? (Choose two.)","choices":{"A":"Add the signature to an HTTP header that is named Authorization.","D":"Add the signature to a query string parameter that is named X-Amz-Signature.","B":"Add the signature to a session cookie.","E":"Add the signature to an HTTP header that is named WWW-Authenticate.","C":"Add the signature to an HTTP header that is named Authentication."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107057-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:33:00","unix_timestamp":1682199180,"discussion_count":7,"discussion":[{"comment_id":"944451","upvote_count":"10","poster":"vicvega","timestamp":"1704537420.0","content":"Header:\\n\\nAuthorization: AWS4-HMAC-SHA256\\nCredential=AKIAIOSFODNN7EXAMPLE/20220830/us-east-1/ec2/aws4_request,\\nSignedHeaders=host;x-amz-date,\\nSignature=calculated-signature\\n\\nQuery String:\\n\\nhttps://ec2.amazonaws.com/?\\nAction=DescribeInstances&\\nVersion=2016-11-15&\\nX-Amz-Signature=calculated-signature\\n\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/create-signed-request.html"},{"upvote_count":"9","content":"Selected Answer: AD\\nthe correct options are A and D.","comment_id":"877657","timestamp":"1698010380.0","poster":"MrTee"},{"poster":"sumanshu","content":"Selected Answer: AD\\nThe developer has already performed the necessary steps to generate the signature but needs to know where to place the signature in the request to ensure the request is valid and properly authenticated.\\n\\nA) Correct - SigV4 officially supports placing the signature in the Authorization header,\\n\\nC) Eliminated - AWS specifically requires the Authorization header for passing the signature in HTTP headers\\n\\nD) Correct - SigV4 allows for query string authentication as an alternative to using the Authorization header. This is especially useful for presigned URLs, where the signature and other necessary information are passed in the query string (e.g., X-Amz-Signature)","timestamp":"1735390380.0","comments":[{"comment_id":"1354038","timestamp":"1739122860.0","comments":[{"comment_id":"1354039","upvote_count":"1","content":"E) Eliminated - This is used for different types of authentication (like when a website asks for a username and password), not AWS Signature V4.","poster":"sumanshu","timestamp":"1739122860.0"}],"poster":"sumanshu","upvote_count":"1","content":"C) Eliminated - The correct header is Authorization, not Authentication"}],"comment_id":"1332954","upvote_count":"1"},{"timestamp":"1732326300.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: AD\\nAD is the correct answer.","comment_id":"1216085"},{"content":"Selected Answer: AD\\nA. Add the signature to an HTTP header that is named Authorization: This is a correct method. In Signature Version 4, the completed signature is typically added to the request\'s Authorization header. This header includes the signing information along with other necessary components such as the Credential Scope and the Signed Headers.\\n\\nD. Add the signature to a query string parameter that is named X-Amz-Signature: This is a correct method. In addition to including the signature in the Authorization header, Signature Version 4 also allows for presigned URLs where the signature is part of the query string parameters. The signature is included in the X-Amz-Signature query string parameter.","upvote_count":"3","comment_id":"1124261","timestamp":"1721130780.0","poster":"SerialiDr"},{"poster":"loctong","comment_id":"899858","timestamp":"1700216580.0","upvote_count":"1","content":"Selected Answer: AD\\nOption B,C And E are not correct;"},{"upvote_count":"2","comment_id":"891438","content":"Selected Answer: AD\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/create-signed-request.html","poster":"awsdummie","timestamp":"1699372740.0"}],"answer_description":"","extracted_at":"2025-12-24T08:55:58.124Z","extraction_method":"api_direct_v1"},{"question_id":"VDkV80E9KFymP6r6forc","question_number":28,"page":6,"question_text":"A company must deploy all its Amazon RDS DB instances by using AWS CloudFormation templates as part of AWS CodePipeline continuous integration and continuous delivery (CI/CD) automation. The primary password for the DB instance must be automatically generated as part of the deployment process.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"A":"Create an AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get the value of the secure string. Use the value to create the DB instance.","C":"Create an AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get a value of the secure string. Create secrets in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored in the secret to create the DB instance.","B":"Use the AWS CodeBuild action of CodePipeline to generate a secure string by using the following AWS CLI command: aws secretsmanager get-random-password. Pass the generated secure string as a CloudFormation parameter with the NoEcho attribute set to true. Use the parameter reference to create the DB instance.","D":"Use the AWS::SecretsManager::Secret resource to generate a secure string. Store the secure string as a secret in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored in the secret to create the DB instance."},"correct_answer":"D","answer_ET":"D","answers_community":["D (77%)","B (23%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107059-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:54:00","unix_timestamp":1682200440,"discussion_count":15,"discussion":[{"content":"Its a difficult choice between B and D\\nOption B leverages the existing AWS CLI command to generate a secure string, and then passes it as a parameter to CloudFormation, where it can be used to create the DB instance. But, if the use of Secrets Manager is already part of the organization\'s infrastructure, and the setup has already been completed, then option D may indeed be the simplest solution.","comment_id":"877660","timestamp":"1682200440.0","upvote_count":"7","poster":"MrTee"},{"comment_id":"1332957","upvote_count":"2","content":"Selected Answer: D\\nA) Eliminated - This approach requires writing and maintaining custom Lambda code, which adds development effort.\\n\\nB) Eliminated - This requires some setup in CodeBuild and manual handling of parameters, which adds complexity.\\n\\nC) Eliminated - Same as option A (Reason)\\n\\nD) Correct - Secrets Manager handles password generation and rotation automatically. This approach uses native CloudFormation functionality with no custom code.","timestamp":"1735390860.0","comments":[{"content":"D)\\n\\nResources:\\n MyDBPassword:\\n Type: AWS::SecretsManager::Secret\\n Properties:\\n Name: MyDBPasswordSecret\\n GenerateSecretString:\\n PasswordLength: 16\\n ExcludeCharacters: \'\\"@/\'\\n RequireEachIncludedType: true\\n IncludeSpace: false","upvote_count":"1","comments":[{"comment_id":"1354047","poster":"sumanshu","content":"B) Eliminated - In Option B, the password is generated but not stored securely in any service (like Secrets Manager), which means you\'d lose access to it after creation. This makes it problematic for future access to the database.","timestamp":"1739123460.0","upvote_count":"1"}],"timestamp":"1739123220.0","poster":"sumanshu","comment_id":"1354043"}],"poster":"sumanshu"},{"poster":"Saudis","upvote_count":"1","comment_id":"1283092","content":"Selected Answer: D\\nAns is B because the keyword is automatically generate passwords by secret manger by lest effort","timestamp":"1726220460.0"},{"comment_id":"1216089","timestamp":"1716421980.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"upvote_count":"2","timestamp":"1710370800.0","comment_id":"1172958","poster":"maurice2005","content":"Selected Answer: B\\nWhere is the automatic generating of the password in option D?"},{"poster":"SerialiDr","content":"Selected Answer: D\\nD. Use the AWS::SecretsManager::Secret resource to generate a secure string. Store the secure string as a secret in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored in the secret to create the DB instance: This solution efficiently uses AWS CloudFormation\'s native integration with AWS Secrets Manager. The AWS::SecretsManager::Secret resource type in CloudFormation can generate a secure string and store it as a secret. The secret value can then be used directly in the CloudFormation template to set the RDS instance password, using the secretsmanager dynamic reference. This approach minimizes development effort and leverages existing AWS services.","timestamp":"1705425000.0","comment_id":"1124375","upvote_count":"3"},{"comment_id":"1099679","content":"D: This option leverages a native CloudFormation resource specifically designed for secret management. It eliminates the need for custom code or external tools, making it the simplest and most effort-efficient solution.\\n\\nThis approach minimizes custom code and utilizes native CloudFormation features, reducing overall complexity and maintenance.","timestamp":"1702899720.0","upvote_count":"1","poster":"fagilom"},{"upvote_count":"2","content":"Selected Answer: D\\nyou can create secrets with AWS::SecretsManager::Secret so it is the correct answer.","poster":"chewasa","comment_id":"1091989","timestamp":"1702148820.0"},{"content":"Selected Answer: D\\nI was dilly dallying between B and D....but this helped me solidify my answer choice\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/cfn-example_reference-secret.html","comment_id":"1087822","timestamp":"1701712800.0","poster":"LR2023","upvote_count":"1"},{"timestamp":"1697298900.0","comment_id":"1043580","upvote_count":"2","poster":"dezoito","content":"Selected Answer: D\\nWith AWS CloudFormation, you can retrieve a secret to use in another AWS CloudFormation resource. A common scenario is to first create a secret with a password generated by Secrets Manager, and then retrieve the username and password from the secret to use as credentials for a new database. \\n\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/cfn-example_reference-secret.html"},{"comment_id":"988580","poster":"love777","timestamp":"1692814980.0","upvote_count":"4","content":"Selected Answer: B\\nOption B provides a straightforward approach to generating a secure string for the DB instance password and using it in CloudFormation with minimal development effort. Here\'s why this option is efficient:\\n\\nCodeBuild Action: Using the AWS CodeBuild action within CodePipeline to generate a secure string using the aws secretsmanager get-random-password command allows you to easily create a random password without writing custom Lambda code.\\n\\nCloudFormation Parameter: You can pass the generated secure string as a CloudFormation parameter with the NoEcho attribute set to true. This ensures that the parameter value won\'t be exposed in CloudFormation outputs or logs."},{"comment_id":"908538","poster":"FunkyFresco","upvote_count":"4","content":"Selected Answer: D\\nThe correct option is D. Create the password from secrets manager.","timestamp":"1685269920.0"},{"content":"Selected Answer: D\\nyes it\'s D","upvote_count":"2","poster":"delak","comment_id":"903552","timestamp":"1684706760.0"},{"upvote_count":"2","content":"Selected Answer: D\\nThe answer is D\\nThis is a secretsmanager dynamic reference sample in cloud formation","comment_id":"899320","timestamp":"1684252260.0","poster":"rlnd2000"},{"upvote_count":"2","poster":"chumji","timestamp":"1683946860.0","content":"I think answer is D \\nhttps://aws.amazon.com/about-aws/whats-new/2022/12/amazon-rds-integration-aws-secrets-manager/","comment_id":"896381"}],"answer_description":"","extracted_at":"2025-12-24T08:55:58.124Z","extraction_method":"api_direct_v1"},{"question_id":"iTID1trcKLQo7ubGVYQh","question_number":29,"page":6,"question_text":"An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata.\\n\\nWhat AWS service should be used to accomplish this?","choices":{"A":"Amazon DynamoDB","C":"AWS Lambda","D":"Amazon RDS","B":"Amazon EC2"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107060-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-22 23:57:00","unix_timestamp":1682200620,"discussion_count":7,"discussion":[{"timestamp":"1682200620.0","content":"Selected Answer: A\\nIn this scenario, the metadata about the files can be stored in a DynamoDB table with a primary key based on the metadata attributes. This would enable the organization to quickly query and retrieve metadata about the files in real-time, with single-digit millisecond latency.","upvote_count":"14","comment_id":"877662","poster":"MrTee"},{"content":"Selected Answer: A\\nDynamoDB is a fully managed NoSQL database service that provides single-digit millisecond latency for read and write operations.\\n\\nD) Eliminated - While RDS can store metadata and index it using relational queries, it does not guarantee single-digit millisecond latency like DynamoDB.","comment_id":"1332965","timestamp":"1735391820.0","upvote_count":"1","poster":"sumanshu"},{"poster":"Saudis","content":"Selected Answer: A\\nKeyword => single-digit millisecond latency retrieval for the metadata","upvote_count":"1","timestamp":"1730385660.0","comment_id":"1305483"},{"comment_id":"1231697","poster":"tsangckl","content":"This appear at 17 Jun exam","upvote_count":"1","timestamp":"1718596080.0"},{"timestamp":"1716422520.0","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","comment_id":"1216093"},{"content":"Selected Answer: A\\nA. Amazon DynamoDB: DynamoDB is a fast and flexible NoSQL database service that provides consistent single-digit millisecond latency for data retrieval. It is well-suited for applications that require high-performance data retrieval. The metadata of the files stored in S3 can be indexed and stored in a DynamoDB table, enabling efficient and quick access for the web application. This setup allows users to quickly browse metadata and select files for download.","comment_id":"1124266","upvote_count":"2","timestamp":"1705413540.0","poster":"SerialiDr"},{"comment_id":"899859","upvote_count":"3","timestamp":"1684311840.0","content":"Selected Answer: A\\nAmazon DynamoDB is a highly scalable and fully managed NoSQL database service that can provide fast and consistent performance at any scale. It is a suitable choice for indexing and storing metadata associated with files.","poster":"loctong"}],"answer_description":"","extracted_at":"2025-12-24T08:55:58.124Z","extraction_method":"api_direct_v1"},{"question_id":"SYiZdcbfkwGsc8419Qyz","question_number":30,"page":6,"question_text":"A developer is creating an AWS Serverless Application Model (AWS SAM) template. The AWS SAM template contains the definition of multiple AWS Lambda functions, an Amazon S3 bucket, and an Amazon CloudFront distribution. One of the Lambda functions runs on Lambda@Edge in the CloudFront distribution. The S3 bucket is configured as an origin for the CloudFront distribution.\\n\\nWhen the developer deploys the AWS SAM template in the eu-west-1 Region, the creation of the stack fails.\\n\\nWhich of the following could be the reason for this issue?","choices":{"B":"Lambda@Edge functions can be created only in the us-east-1 Region.","D":"The CloudFront distribution and the S3 bucket cannot be created in the same Region.","C":"A single AWS SAM template cannot contain multiple Lambda functions.","A":"CloudFront distributions can be created only in the us-east-1 Region."},"correct_answer":"B","answer_ET":"B","answers_community":["B (93%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107062-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-23 00:06:00","unix_timestamp":1682201160,"discussion_count":8,"discussion":[{"upvote_count":"12","comment_id":"877665","timestamp":"1698012360.0","poster":"MrTee","content":"Selected Answer: B\\nit must be deployed to a region where Lambda@Edge is supported, such as us-east-1."},{"upvote_count":"9","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/edge-functions-restrictions.html\\n\\nThe Lambda function must be in the US East (N. Virginia) Region.","comment_id":"893213","timestamp":"1699549380.0","poster":"zodraz"},{"poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - CloudFront is a global service that is not tied to a specific region.\\nWhen creating a CloudFront distribution, the deployment can originate from any AWS region (e.g., eu-west-1).\\n\\nB) Correct - Lambda@Edge functions must be deployed in the us-east-1 Region because they are globally replicated and integrated with CloudFront.","timestamp":"1735392360.0","upvote_count":"1","comment_id":"1332970"},{"content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1216095","upvote_count":"1","timestamp":"1732327500.0","poster":"65703c1"},{"poster":"SD_CS","timestamp":"1722759180.0","comment_id":"1139975","upvote_count":"1","content":"Selected Answer: B\\nB is the only answer that makes sense"},{"upvote_count":"1","timestamp":"1718772480.0","comment_id":"1100387","poster":"KarBiswa","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-edge-how-it-works-tutorial.html\\nclear mention"},{"timestamp":"1706926620.0","poster":"tinyflame","content":"Selected Answer: B\\nSAM can only specify one region\\nLangda@Edge only in us-east1 region\\n\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-edge-how-it-works-tutorial.html","upvote_count":"1","comment_id":"970619"},{"comment_id":"899862","timestamp":"1700216700.0","upvote_count":"2","poster":"loctong","content":"Selected Answer: C\\nOption A states that CloudFront distributions can only be created in the us-east-1 Region. This statement is incorrect because CloudFront distributions can be created in various AWS regions, including the eu-west-1 Region."}],"answer_description":"","extracted_at":"2025-12-24T08:55:58.124Z","extraction_method":"api_direct_v1"},{"question_id":"QSb5QAgw9UaleK90oT2Y","question_number":31,"page":7,"question_text":"A developer is integrating Amazon ElastiCache in an application. The cache will store data from a database. The cached data must populate real-time dashboards.\\n\\nWhich caching strategy will meet these requirements?","choices":{"C":"A lazy-loading cache","A":"A read-through cache","D":"A write-through cache","B":"A write-behind cache"},"correct_answer":"D","answer_ET":"D","answers_community":["D (96%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107063-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-23 00:25:00","unix_timestamp":1682202300,"discussion_count":10,"discussion":[{"poster":"MrTee","comment_id":"877667","timestamp":"1682202300.0","content":"Selected Answer: D\\nThe best caching strategy for populating real-time dashboards using Amazon ElastiCache would be a write-through caching strategy. In this strategy, when new data is written to the database, it is also written to the cache. This ensures that the most current data is always available in the cache for the real-time dashboards to access, reducing the latency of the data retrieval. Additionally, using a write-through cache ensures that data consistency is maintained between the database and the cache, as any changes to the data are written to both locations simultaneously.","upvote_count":"16"},{"timestamp":"1735392540.0","poster":"sumanshu","upvote_count":"2","comment_id":"1332971","comments":[{"content":"B) Eliminated\\n\\nIn a write-behind cache, data is written to the cache first, and the database is updated asynchronously (in the background).\\nThis caching strategy prioritizes write performance but risks data loss in the event of a failure because the cache may not yet have updated the database.\\nFor real-time dashboards, there is no guarantee that the cache is always up-to-date because the data is updated asynchronously.","timestamp":"1735392540.0","comment_id":"1332972","upvote_count":"1","comments":[{"content":"C) Eliminated\\n\\nIn a lazy-loading cache, the data is loaded into the cache only when requested.\\nIf the data is not in the cache (a \\"cache miss\\"), it is fetched from the database, loaded into the cache, and returned to the application.\\nWhile this reduces unnecessary caching, it does not proactively update the cache. Therefore, data in the cache may become stale, which is unsuitable for real-time dashboards.","comment_id":"1332973","comments":[{"upvote_count":"1","comment_id":"1332974","timestamp":"1735392600.0","content":"D) Correct\\nIn a write-through cache, every write operation to the database is immediately mirrored in the cache.\\nThis ensures that the cache always contains the most up-to-date data and is ideal for scenarios where real-time consistency is required, such as updating dashboards.","poster":"sumanshu"}],"upvote_count":"1","poster":"sumanshu","timestamp":"1735392600.0"}],"poster":"sumanshu"}],"content":"Selected Answer: D\\nA) Eliminated\\n\\nIn a read-through cache, when an application tries to retrieve data:\\nIf the data is not available in the cache, the cache retrieves it from the database, stores it in the cache, and returns it to the application.\\nIf the data is available in the cache, it is returned directly.\\nThe cache is updated only when data is requested, which could result in outdated data being served to real-time dashboards if no recent read request has occurred."},{"timestamp":"1730386080.0","content":"Selected Answer: D\\nthe keyword => real-time","upvote_count":"1","comment_id":"1305489","poster":"Saudis"},{"upvote_count":"1","content":"When using a write-through cache strategy, the cache is updated in real-time alongside the database. This ensures that the cached data remains consistent with the underlying database. According to AWS best practices, this approach pushes data into the cache at the time it is written to the database, reducing the risk of serving stale data.\\nIn contrast, option A (a read-through cache strategy) may result in stale data, particularly if the cache has a time-to-live (TTL) setting that allows data to remain in the cache longer than it remains accurate in the database. This can be problematic for real-time dashboards that require up-to-date information. For these reasons, I opted for option D.\\n\\nhttps://aws.amazon.com/caching/best-practices/#:~:text=Write%2Dthrough,also%20pushed%20into%20the%20cache.\\n\\nPlease correct me if my understanding is incorrect, as I am still learning.","poster":"tirthyakamaldasgupta","comment_id":"1263499","timestamp":"1723294860.0"},{"poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716422880.0","comment_id":"1216096"},{"timestamp":"1707216120.0","comment_id":"1142034","upvote_count":"1","poster":"Walker17","content":"B. Write Behind Cache."},{"content":"Selected Answer: D\\nD. A write-through cache: A write-through caching strategy immediately writes data to both the cache and the database at the same time. This approach ensures that the cache always contains the most recent data, making it highly suitable for applications that require up-to-date information, such as real-time dashboards.","comment_id":"1124455","timestamp":"1705432620.0","poster":"SerialiDr","upvote_count":"2"},{"poster":"tqiu654","comment_id":"1086456","upvote_count":"1","content":"Selected Answer: C\\nChatGPT:C","timestamp":"1701558180.0"},{"poster":"Prem28","upvote_count":"1","comment_id":"916174","content":"ans- A\\n\\nOption D, a write-through cache, is incorrect because it would not meet the requirement of populating real-time dashboards. A write-through cache writes data to the cache and the database at the same time. This means that the data in the cache would always be up-to-date, but it would also mean that the cache would always be lagging behind the database. This would cause a delay in populating real-time dashboards.","timestamp":"1686050280.0"},{"comment_id":"899864","content":"Selected Answer: D\\nA write-through cache strategy involves writing data to both the cache and the underlying database simultaneously. When data is updated or inserted into the database, it is also stored or updated in the cache to ensure that the cache remains up-to-date with the latest data.","upvote_count":"2","poster":"loctong","timestamp":"1684311960.0"}],"answer_description":"","extracted_at":"2025-12-24T08:56:09.188Z","extraction_method":"api_direct_v1"},{"question_id":"4QM3lDFe3y2c2ORFR2fj","question_number":32,"page":7,"question_text":"A developer is creating an AWS Lambda function. The Lambda function needs an external library to connect to a third-party solution. The external library is a collection of files with a total size of 100 MB. The developer needs to make the external library available to the Lambda execution environment and reduce the Lambda package space.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"B":"Create an Amazon S3 bucket. Upload the external library into the S3 bucket. Mount the S3 bucket folder in the Lambda function. Import the library by using the proper folder in the mount point.","A":"Create a Lambda layer to store the external library. Configure the Lambda function to use the layer.","D":"Create an Amazon Elastic File System (Amazon EFS) volume. Upload the external library to the EFS volume. Mount the EFS volume in the Lambda function. Import the library by using the proper folder in the mount point.","C":"Load the external library to the Lambda function\'s /tmp directory during deployment of the Lambda package. Import the library from the /tmp directory."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107064-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-23 00:31:00","unix_timestamp":1682202660,"discussion_count":10,"discussion":[{"upvote_count":"13","timestamp":"1682202660.0","comment_id":"877670","poster":"MrTee","content":"Selected Answer: A\\nCreate a Lambda layer to store the external library. Configure the Lambda function to use the layer. This will allow the developer to make the external library available to the Lambda execution environment without having to include it in the Lambda package, which will reduce the Lambda package space. Using a Lambda layer is a simple and straightforward solution that requires minimal operational overhead."},{"content":"Selected Answer: A\\nLayers are managed separately from the Lambda function.\\nThey reduce the size of the deployment package.\\nLayers are easy to use, and there is no need for complex infrastructure or manual management.","poster":"sumanshu","timestamp":"1735393200.0","upvote_count":"1","comment_id":"1332978"},{"timestamp":"1722991080.0","comment_id":"1261878","content":"Option B is correct because it is straightforward with lesser operation overhead than managing layers. Option A and C are incorrect. While Option A approach allows you to separate library from your function code, it introduces some operational overhead in managing layers.\\nOption C is simple but doesn\'t separate library from your function code.","poster":"Saurabh04","upvote_count":"1"},{"comments":[{"comment_id":"1270699","content":"Do you remember the answer?","poster":"frangesk","upvote_count":"1","timestamp":"1724333040.0"}],"timestamp":"1718596140.0","comment_id":"1231698","content":"This appear at 17 Jun exam","poster":"tsangckl","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","timestamp":"1716423180.0","comment_id":"1216100"},{"timestamp":"1708452840.0","content":"Selected Answer: A\\nYou can add up to five layers to a Lambda function. The total unzipped size of the function and all layers cannot exceed the unzipped deployment package size quota of 250 MB. For more information, see Lambda quotas.","upvote_count":"4","comment_id":"1154904","poster":"KillThemWithKindness"},{"content":"Selected Answer: A\\nA. Create a Lambda layer to store the external library. Configure the Lambda function to use the layer: This is the most suitable solution. Lambda layers allow you to include libraries and other dependencies without including them in the deployment package of your Lambda function. By creating a layer with the external library and configuring the Lambda function to use this layer, the developer can easily manage and update the library independently of the Lambda function code, reducing the package size and operational overhead.","poster":"SerialiDr","timestamp":"1705434960.0","comment_id":"1124478","upvote_count":"2"},{"poster":"CalvinL4","upvote_count":"1","content":"One lambda layer only allows 50 mb for storage. The file is 100 MB. So I will vote for D unless the library can break down into less than 5 layers.","comment_id":"1114236","timestamp":"1704426600.0"},{"content":"Selected Answer: A\\nBy creating a Lambda layer, you can separate the external library from the Lambda function code itself and make it available to multiple functions. This approach offers the following benefits:","comment_id":"899868","timestamp":"1684312140.0","upvote_count":"2","poster":"loctong"},{"timestamp":"1682777820.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","comment_id":"884386","upvote_count":"3","poster":"dan80"}],"answer_description":"","extracted_at":"2025-12-24T08:56:09.188Z","extraction_method":"api_direct_v1"},{"question_id":"oJFBj8jnUa37NlO1o3It","question_number":33,"page":7,"question_text":"A company has a front-end application that runs on four Amazon EC2 instances behind an Elastic Load Balancer (ELB) in a production environment that is provisioned by AWS Elastic Beanstalk. A developer needs to deploy and test new application code while updating the Elastic Beanstalk platform from the current version to a newer version of Node.js. The solution must result in zero downtime for the application.\\n\\nWhich solution meets these requirements?","choices":{"A":"Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.","C":"Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks.","D":"Use a rolling deployment for the new application code. Apply the code to a subset of EC2 instances until the tests pass. Redeploy the previous code if the tests fail.","B":"Deploy the new application code in an all-at-once deployment to the existing EC2 instances. Test the code. Redeploy the previous code if verification fails."},"correct_answer":"C","answer_ET":"C","answers_community":["C (48%)","A (39%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107066-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-23 00:45:00","unix_timestamp":1682203500,"discussion_count":26,"discussion":[{"upvote_count":"23","poster":"MrTee","comment_id":"877673","comments":[{"comment_id":"889629","poster":"awsdummie","content":"C is incorrect, after passing health checks the elastic Beanstalk transfers them to the original Auto Scaling group. No testing or platform update is done.","upvote_count":"5","timestamp":"1683230880.0"},{"upvote_count":"3","timestamp":"1684450260.0","poster":"yeacuz","comment_id":"901542","content":"I would agree that option A can affect the cost, but cost is not the issue. The question is asking for zero downtime. I believe the answer is option A"}],"content":"Selected Answer: C\\nOption C is the correct solution that meets the requirements. Performing an immutable update to deploy the new application code to new EC2 instances and serving traffic to the new instances after they pass health checks will ensure zero downtime for the application.\\n\\nOption A would work but cloning the production environment to a different platform version will result in a longer deployment time and can impact the cost of the environment.","timestamp":"1682203500.0"},{"poster":"gagol14","comment_id":"928145","timestamp":"1687235580.0","upvote_count":"10","content":"Selected Answer: A\\nNot C: While an immutable update can ensure zero downtime during the deployment process, it doesn\'t account for updating the Elastic Beanstalk platform version."},{"upvote_count":"1","poster":"Artemiy","comment_id":"1395548","timestamp":"1741940160.0","content":"Selected Answer: A\\nOption A creates a completely separate environment with the newer Node.js version, deploys the new code there, and allows for testing without affecting the production environment. Once verified, you simply swap the URLs"},{"poster":"sumanshu","upvote_count":"1","timestamp":"1735393740.0","comment_id":"1332980","content":"Selected Answer: C\\nA) Eliminated - This solution meets the requirement of zero downtime but may have additional resource and cost overhead.\\n\\nB) Eliminated - All-at-once deployment means that all instances are updated at the same time, which would result in downtime during the deployment.\\n\\nC) Correct - Immutable updates ensure that new EC2 instances are created, and only healthy instances will serve traffic. The old EC2 instances are not affected until the new instances are confirmed to be healthy and live.\\n\\nD) Eliminated - Rolling deployments help ensure that some EC2 instances are always running the old code and serving traffic while others are being updated."},{"comment_id":"1292109","poster":"MasoudK","content":"Option A is Correct not C: By cloning the production environment to a different platform version, you create a separate environment where you can safely deploy and test the new application code and platform version without affecting the live production environment.\u2022 Option C (Immutable update): While immutable updates ensure zero downtime by deploying to new instances, they do not address the need to update the Elastic Beanstalk platform version. Additionally, this approach can be more resource-intensive and costly.","timestamp":"1727814780.0","upvote_count":"1"},{"comment_id":"1283101","timestamp":"1726222560.0","upvote_count":"1","content":"Selected Answer: C\\nAns is c","poster":"Saudis"},{"upvote_count":"1","timestamp":"1716423300.0","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","comment_id":"1216105"},{"upvote_count":"3","poster":"ibratoev","comment_id":"1184160","content":"It is A: https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","timestamp":"1711548960.0"},{"poster":"KarBiswa","timestamp":"1710652860.0","content":"This question must be true for 2 options because C & D are both correct","comment_id":"1175595","upvote_count":"1"},{"poster":"KarBiswa","content":"Selected Answer: D\\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","upvote_count":"1","timestamp":"1710079620.0","comment_id":"1170366"},{"content":"Selected Answer: C\\nThe solutions that best meet the requirements for zero downtime are:\\n\\nA. Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.\\nC. Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks.\\nBoth options A and C provide robust strategies for deploying updates with zero downtime, allowing for thorough testing in an isolated environment before directing production traffic to the new setup.","poster":"SerialiDr","comment_id":"1124816","timestamp":"1705482660.0","upvote_count":"3"},{"content":"Selected Answer: A\\nNot C: tt doesn\'t account for updating the Elastic Beanstalk platform version. This would affect both the live and test environments.\\n\\nIts also best practise to have 2 seperate environments for production and test and there is no mention of cost optimisation here.","timestamp":"1702411440.0","upvote_count":"3","comment_id":"1094916","poster":"Certified101"},{"comment_id":"1086466","content":"Selected Answer: A\\nChatGPT:A","timestamp":"1701559440.0","upvote_count":"2","poster":"tqiu654"},{"content":"Selected Answer: C\\nA & C both works for given scenario but C does it more feasibly for Elastic Beanstalk with zero downtime.","poster":"Rameez1","timestamp":"1697302380.0","upvote_count":"1","comment_id":"1043623"},{"upvote_count":"2","timestamp":"1692972780.0","comments":[{"timestamp":"1705386240.0","poster":"CrescentShared","comment_id":"1123913","content":"It\'s a downtime if test fails and rollback.","upvote_count":"1"}],"content":"Selected Answer: C\\nKey terminology in question is \\"Test\\". So it should be immutable for quick rollback in case of test not working.","poster":"stilloneway","comment_id":"990144"},{"timestamp":"1692816000.0","upvote_count":"4","content":"Selected Answer: C\\nExplanation:\\n\\nImmutable Update with Elastic Beanstalk:\\nWith an immutable update, Elastic Beanstalk provisions new instances with the updated code while keeping the existing instances running. The traffic is shifted gradually to the new instances after they pass health checks, ensuring that there is no downtime during the deployment. If any issue arises during the deployment, traffic is still being served by the existing instances.","poster":"love777","comment_id":"988597"},{"timestamp":"1692537720.0","upvote_count":"2","poster":"Naj_64","comment_id":"985802","content":"Selected Answer: D\\nScreenshot of Step 4 of Method 1 in the link:\\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config\\n\\n\\"...your application is unavailable during the update. To keep at least one instance in service during the update, enable rolling updates\\"","comments":[{"upvote_count":"1","comment_id":"985812","poster":"Naj_64","timestamp":"1692538140.0","content":"I take this back. I\'m going with A\\n\\n\\"However, you can avoid this downtime by deploying the new version to a separate environment. The existing environment\u2019s configuration is copied and used to launch the green environment with the new version of the application. The new green environment will have its own URL. When it\u2019s time to promote the green environment to serve production traffic, you can use Elastic Beanstalk\'s Swap Environment URLs feature.\\"\\n\\nhttps://docs.aws.amazon.com/whitepapers/latest/blue-green-deployments/swap-the-environment-of-an-elastic-beanstalk-application.html"}]},{"upvote_count":"4","poster":"MG1407","comment_id":"983902","content":"Selected Answer: A\\nA is the answer. Sorry about the double post ...\\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","timestamp":"1692295920.0"},{"comment_id":"983901","content":"Selected Answer: D\\nCan\'t be clearer than this ... https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","upvote_count":"2","timestamp":"1692295800.0","poster":"MG1407"},{"content":"Selected Answer: A\\nA is the correct solution here. From https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html, \\"A blue/green deployment is also required if you want to update an environment to an incompatible platform version.\\". An immutable deployment would ensure zero downtime, but the new instances launched would have the same platform version as before.","comment_id":"964359","timestamp":"1690434600.0","upvote_count":"2","poster":"redfivedog"},{"comment_id":"962983","content":"Selected Answer: A\\nA developer also needs to update to a new platform version and it\'s more likely a new major version of node.js. To update to the new major version there is only one method and it is a blue/green deployment by creating (cloning) a new environment with the latest platform version. Then deploy a new app version to it. Test it, then swap the env URL without downtime.","timestamp":"1690308060.0","upvote_count":"3","poster":"bobo777"},{"upvote_count":"3","poster":"Phongsanth","comment_id":"938021","comments":[{"comment_id":"985798","upvote_count":"1","timestamp":"1692537600.0","content":"+1\\n\\n\\"...your application is unavailable during the update. To keep at least one instance in service during the update, enable rolling updates\\"","poster":"Naj_64"}],"timestamp":"1688039580.0","content":"Selected Answer: D\\nOn the step 4 of Method 1 in the link. you will see it clearly that rolling update is perfect fit with this question. Of course with zero downtime.\\n\\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config"},{"content":"Selected Answer: A\\nOption A is referring to Blue/Green deployments and will fulfill the requirements of the question (https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html)","poster":"yeacuz","upvote_count":"4","comment_id":"901543","timestamp":"1684450320.0"},{"timestamp":"1684312080.0","upvote_count":"2","content":"Selected Answer: D\\nPerforming an immutable update involves creating new EC2 instances with the updated code and the newer version of Node.js, and then swapping the traffic to the new instances once they pass health checks. This approach ensures zero downtime as the existing instances continue to serve traffic until the new instances are ready.","comment_id":"899867","poster":"loctong"},{"comment_id":"889631","upvote_count":"5","content":"Option A","timestamp":"1683230940.0","poster":"awsdummie"},{"poster":"MrTee","timestamp":"1682203680.0","content":"Option B and D both involve deploying the new application code to the existing EC2 instances, which can result in downtime if the deployment fails. Redeploying the previous code after a failed deployment can also result in downtime.","upvote_count":"2","comment_id":"877675","comments":[{"poster":"qwan","timestamp":"1688506440.0","comment_id":"943168","upvote_count":"1","content":"Option D states \\" Apply the code to a subset of EC2 instances until the tests pass\\". Subset, not all EC2 instances. So, if deployment fails, you still have some EC2 instances running the old application code. So, no downtime."}]}],"answer_description":"","extracted_at":"2025-12-24T08:56:09.188Z","extraction_method":"api_direct_v1"},{"question_id":"AfJmBYpfOJQs7UPFpBrB","question_number":34,"page":7,"question_text":"A developer is creating an AWS Lambda function. The Lambda function will consume messages from an Amazon Simple Queue Service (Amazon SQS) queue. The developer wants to integrate unit testing as part of the function\'s continuous integration and continuous delivery (CI/CD) process.\\n\\nHow can the developer unit test the function?","choices":{"C":"Create an SQS queue for tests. Use this SQS queue in the application\'s unit test. Run the unit tests during the CI/CD process.","A":"Create an AWS CloudFormation template that creates an SQS queue and deploys the Lambda function. Create a stack from the template during the CI/CD process. Invoke the deployed function. Verify the output.","B":"Create an SQS event for tests. Use a test that consumes messages from the SQS queue during the function\'s Cl/CD process.","D":"Use the aws lambda invoke command with a test event during the CIICD process."},"correct_answer":"D","answer_ET":"D","answers_community":["D (45%)","C (38%)","B (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/112424-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-06-17 06:32:00","unix_timestamp":1686976320,"discussion_count":25,"discussion":[{"content":"Selected Answer: C\\nUnit testing is a type of testing that verifies the correctness of individual units of source code, typically functions or methods. When unit testing a Lambda function that interacts with Amazon SQS, you can create a separate test SQS queue that the Lambda function interacts with during testing. You would then validate the behavior of the function based on its interactions with the test queue. This approach isolates the function\'s behavior from the rest of the system, which is a key principle of unit testing.\\n\\nOption A is incorrect because AWS CloudFormation is typically used for infrastructure deployment, not for unit testing.\\n\\nOption B is incorrect because it does not actually test the function; it only creates an event.\\n\\nOption D is incorrect because the \'aws lambda invoke\' command is used to manually trigger a Lambda function, but doesn\'t necessarily facilitate testing the function\'s behavior when consuming messages from an SQS queue.","poster":"gagol14","comment_id":"928148","upvote_count":"16","timestamp":"1687235700.0"},{"timestamp":"1690435320.0","upvote_count":"13","poster":"redfivedog","content":"Selected Answer: D\\nD is correct here. Both B and C are integration tests as they are using an actual SQS queue in the tests and not mocking it out.","comment_id":"964367"},{"upvote_count":"1","content":"Selected Answer: D\\nThose who select C and still think they are right - Should study more about unit test & integrate testing before AWS","poster":"mooncake1","comment_id":"1346315","timestamp":"1737776280.0"},{"content":"Selected Answer: D\\nA) Eliminated - This approach involves creating and destroying AWS resources (SQS, Lambda) for each test, which increases the time, complexity, and potential costs associated with running tests.\\n\\n\\nB) Eliminated - t involves real AWS resources (SQS)\\n\\nC) Eliminated - Even though it\'s meant for testing, you\'re still using an actual AWS service (SQS) to conduct the test, making it less of a unit test and more of an integration test.\\n\\nD) Correct - You use the aws lambda invoke command to invoke the Lambda function directly during the test process, without needing to rely on actual resources like an SQS queue.","comment_id":"1332982","upvote_count":"1","poster":"sumanshu","timestamp":"1735394040.0"},{"content":"Selected Answer: C\\nUnit testing is a type of testing that verifies the correctness of individual units of source code, typically functions or methods","comment_id":"1325287","timestamp":"1733955300.0","upvote_count":"1","poster":"ShakthiGCP"},{"comment_id":"1324003","content":"Selected Answer: C\\noption C seems more appropriate. As there is a clear isolation of test stage environment and it is staged prior to the deployment. \\nOption D triggered manually and consuming from the same queue that was meant for the Production environment","timestamp":"1733742360.0","poster":"f271c23","upvote_count":"1"},{"timestamp":"1731339900.0","upvote_count":"1","poster":"CloudChingon","comment_id":"1310177","content":"Selected Answer: D\\nIt\'s testing so option D seems more logic. The other options would put a message in SQS."},{"poster":"Anandesh","upvote_count":"1","comment_id":"1252784","timestamp":"1721615760.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-guide.html"},{"upvote_count":"1","timestamp":"1716424440.0","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1216114"},{"timestamp":"1712820480.0","upvote_count":"1","poster":"Moralles","comment_id":"1193526","content":"Selected Answer: D\\nIn the case of unit tests, whose objective is to isolate the tested unit, option D is the one that most isolates the unit."},{"upvote_count":"1","comment_id":"1175977","poster":"41eb566","timestamp":"1710696480.0","content":"Selected Answer: C\\nTo unit test the AWS Lambda function that consumes messages from an Amazon SQS queue as part of the CI/CD process, the developer can follow option C:\\n\\nC. Create an SQS queue for tests. Use this SQS queue in the application\'s unit test. Run the unit tests during the CI/CD process."},{"content":"Selected Answer: D\\nIn production, our Lambda function code will directly access the AWS resources we defined in our function handler; however, in our unit tests we want to isolate our code and replace the AWS resources with simulations. This isolation facilitates running unit tests in an isolated environment to prevent accidental access to actual cloud resources.\\n\\nhttps://aws.amazon.com/blogs/devops/unit-testing-aws-lambda-with-python-and-mock-aws-services/","timestamp":"1708454160.0","poster":"KillThemWithKindness","comment_id":"1154919","upvote_count":"1"},{"comment_id":"1124828","upvote_count":"3","content":"Selected Answer: D\\nD. Use the aws lambda invoke command with a test event during the CI/CD process: This option is closer to what unit testing entails. The aws lambda invoke command can be used to invoke the Lambda function with a simulated event payload that mimics an SQS message. This allows the developer to test the function\'s logic and handling of SQS messages without needing an actual SQS queue. The test can focus on how the function processes the input and generates output, which is the essence of unit testing.","timestamp":"1705483260.0","poster":"SerialiDr"},{"content":"Anybody find this question in the exam, please? The question itself looks so wrong to me, the action of testing the lambda function does not seem like a \'unit test\' already... Isn\'t the unit test testing all the Classes inside the lambda function?","comment_id":"1123915","timestamp":"1705386780.0","poster":"CrescentShared","upvote_count":"2"},{"content":"Selected Answer: C\\nC there should be a seperate isolated test enviroment \\nD will only invoke the lambda and not test SQS polling.","timestamp":"1702411620.0","poster":"Certified101","upvote_count":"2","comment_id":"1094922"},{"comment_id":"1086465","upvote_count":"1","content":"Selected Answer: D\\nChatGPT:D","timestamp":"1701559380.0","poster":"tqiu654"},{"comment_id":"1074557","content":"B.\\nOption A (CloudFormation template for SQS queue and Lambda function) involves more of an integration test rather than a unit test. It\'s typically preferable to keep unit tests isolated and focused on the specific functionality of the function.\\n\\nOption C (Create an SQS queue for tests) might involve additional setup and cleanup steps, and it could introduce dependencies that impact the isolation of unit tests.\\n\\nOption D (aws lambda invoke command with a test event) is similar to Option B, but creating a test event is generally more flexible and allows for a clearer representation of the expected input to the Lambda function.","upvote_count":"3","poster":"ShawnWon","timestamp":"1700387640.0"},{"comment_id":"1042354","timestamp":"1697177940.0","upvote_count":"3","content":"Selected Answer: D\\nOption D is the only true unit test.","poster":"dilleman"},{"comment_id":"988602","poster":"love777","upvote_count":"7","content":"Selected Answer: B\\nExplanation:\\n\\nOption B involves simulating the SQS event trigger for testing purposes. This is a common practice in AWS Lambda unit testing. Here\'s how it works:\\n\\nSQS Event for Tests: In your unit test code, you can create an SQS event object that simulates the event structure that Lambda receives when an SQS message is consumed. This event object will contain the necessary information, such as the message content, message attributes, etc.\\n\\nTesting Logic: You can then pass this event object to your Lambda function\'s handler function as if it were an actual SQS event. This allows you to test your Lambda function\'s logic as it would work in response to an SQS message.\\n\\nMocking Dependencies: During unit testing, you might want to mock any AWS service calls, such as SQS, to isolate your Lambda function\'s logic from external services.","timestamp":"1692816240.0"},{"poster":"r3mo","content":"Option B!\\nOffers a practical and efficient way to unit test an AWS Lambda function consuming messages from an SQS queue. It provides an accurate representation of the actual event source, simplifies the testing process, integrates well with CI/CD pipelines, isolates production resources, and is cost-effective.","timestamp":"1690314600.0","upvote_count":"2","comment_id":"963080"},{"upvote_count":"2","timestamp":"1689686280.0","comment_id":"955457","poster":"nguyenta","content":"Selected Answer: D\\nD, from Google Bard"},{"timestamp":"1688634360.0","comment_id":"944482","upvote_count":"3","content":"The idea of creating permanent, persistent AWS resources for a test that might take 3 seconds is an anti-pattern. During a CI/CD pipeline, resources should be spun up, used, and then torn down. Nothing should hang around after a CI/CD pipeline runs.\\n\\nDoes that not negate B and C?","poster":"vicvega"},{"poster":"Phongsanth","comment_id":"938198","timestamp":"1688046600.0","content":"Selected Answer: C\\nI vote C.\\nUnit test should be isolated. Check out in this link.\\nhttps://aws.amazon.com/blogs/devops/unit-testing-aws-lambda-with-python-and-mock-aws-services/","upvote_count":"3"},{"timestamp":"1687869480.0","poster":"hexie","comment_id":"935355","upvote_count":"4","content":"Selected Answer: B\\nB. And before explaining it I would like to ask you guys to use ChatGPT if you want, but don\'t take it as a source of truth and either use it\'s answers here, where people usually come to read USEFUL stuff and understand correctly what it\'s all about. Moderators should review those votes before approving it lol\\n\\nB option is ONE approach for unit testing AWS Lambda functions, since it involves creating a mock SQS event and passing it to the function to be tested. This will allow the function behavior to be tested in isolation, which is the aim of unit testing. :)\\n\\nC option is more like a integration test, not a unit test. That\'s all. :)"},{"poster":"patrick889","upvote_count":"3","content":"chatGPT said C is correct","timestamp":"1686976320.0","comment_id":"925766"}],"answer_description":"","extracted_at":"2025-12-24T08:56:09.188Z","extraction_method":"api_direct_v1"},{"question_id":"Dh6SlHhCeBglkXV32Vbj","question_number":35,"page":7,"question_text":"A company receives food orders from multiple partners. The company has a microservices application that uses Amazon API Gateway APIs with AWS Lambda integration. Each partner sends orders by calling a customized API that is exposed through API Gateway. The API call invokes a shared Lambda function to process the orders.\\nPartners need to be notified after the Lambda function processes the orders. Each partner must receive updates for only the partner\'s own orders. The company wants to add new partners in the future with the fewest code changes possible.\\nWhich solution will meet these requirements in the MOST scalable way?","choices":{"B":"Create a different Lambda function for each partner. Configure the Lambda function to notify each partner\'s service endpoint directly.","C":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure the Lambda function to publish messages with specific attributes to the SNS topic. Subscribe each partner to the SNS topic. Apply the appropriate filter policy to the topic subscriptions.","A":"Create a different Amazon Simple Notification Service (Amazon SNS) topic for each partner. Configure the Lambda function to publish messages for each partner to the partner\'s SNS topic.","D":"Create one Amazon Simple Notification Service (Amazon SNS) topic. Subscribe all partners to the SNS topic."},"correct_answer":"C","answer_ET":"C","answers_community":["C (80%)","A (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103442-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 06:45:00","unix_timestamp":1679377500,"discussion_count":23,"discussion":[{"comment_id":"845559","timestamp":"1679377500.0","poster":"Untamables","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html","upvote_count":"12"},{"timestamp":"1727238300.0","upvote_count":"7","poster":"Bibay","comment_id":"890718","content":"Selected Answer: C\\nOption C is the most scalable way to meet the requirements. This solution allows for a single SNS topic to be used for all partners, which minimizes the need for code changes when adding new partners. By publishing messages with specific attributes to the SNS topic and applying the appropriate filter policy to the topic subscriptions, partners will only receive notifications for their own orders. This approach allows for a more flexible and scalable solution, where new partners can be added to the system with minimal changes to the existing codebase. Option A and D may not be scalable when there are a large number of partners, as creating a separate SNS topic for each partner or subscribing all partners to a single topic may not be feasible. Option B may result in a large number of Lambda functions that need to be managed separately."},{"comment_id":"1574148","poster":"sudmat","timestamp":"1748864700.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html","upvote_count":"1"},{"poster":"sumanshu","content":"Selected Answer: C\\nA) Eliminated - Every time a new partner is added, a new SNS topic needs to be created. This requires manual configuration and updates to the infrastructure.","comments":[{"comment_id":"1329785","content":"B) Eliminated - Adding a new partner means creating a new Lambda function, increasing operational overhead.","comments":[{"comments":[{"timestamp":"1734749580.0","content":"D) Eliminated - All partners would receive updates for all orders because there is no filtering mechanism to ensure partner-specific messages.","comment_id":"1329787","upvote_count":"1","poster":"sumanshu"}],"poster":"sumanshu","timestamp":"1734749520.0","content":"C) Correct - A single SNS topic is used. The Lambda function publishes messages with attributes (e.g., partner ID). Each partner subscribes to the SNS topic and uses a filter policy to only receive messages relevant to their partner ID","comment_id":"1329786","upvote_count":"1"}],"timestamp":"1734749460.0","poster":"sumanshu","upvote_count":"1"}],"comment_id":"1329784","upvote_count":"1","timestamp":"1734749460.0"},{"comment_id":"1325598","poster":"trieudo","content":"Selected Answer: C\\nkeyword: MOST scalable way, only the partner\'s own orders\\n\\n==> Discard A: you must update lambda for new topic added, but it simple for case having few partners, and little change\\n==> Discard B: You must create duplicate lambda function and maintain it. But best case for customized comlexity requirements\\n==> Discard D: it is easy to scalable, but violate rule \'only the partner\'s own orders\', when a partner can see msg of all anothers\\n\\nC: best choice, match with 2 keywords above","timestamp":"1734007020.0","upvote_count":"1"},{"timestamp":"1724326560.0","comments":[{"content":"With C, if it\'s more that 200 partners, we could create another SNS for the next 200 partners. so it couls support up to 2000000 partners.","poster":"AnthonyTL","comment_id":"1282072","upvote_count":"2","timestamp":"1726056000.0"}],"poster":"wail1997","comment_id":"1270652","content":"Selected Answer: A\\nbecause of the fact that By default, you can have up to 200 filter policies per topic, the C option can\'t be the wright answer, but it\'s the A choice. since we can go up to 100 00 topics per SNS","upvote_count":"1"},{"comment_id":"1257729","upvote_count":"1","poster":"ACurryDeveloper","timestamp":"1722292200.0","content":"A works, but C is better, benchods. More efficient. Have to remember good curry cannot be had in a hurry"},{"comment_id":"1248793","upvote_count":"1","poster":"Anandesh","timestamp":"1721122080.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/sns/latest/dg/example-filter-policies.html"},{"comment_id":"1214981","upvote_count":"1","poster":"65703c1","timestamp":"1716298500.0","content":"Selected Answer: C\\nC is the correct answer."},{"content":"Selected Answer: C\\nFunny understand why some people want to create separate SNS for each partner. You have got the option to filter and send notifications to the appropriate partner.","comment_id":"1207594","timestamp":"1715033100.0","poster":"Prosen2522","upvote_count":"1"},{"comment_id":"1191723","timestamp":"1712597880.0","poster":"badsati","upvote_count":"1","content":"Selected Answer: C\\nAnswer is C ... No Question"},{"timestamp":"1703148900.0","poster":"xdkonorek2","content":"Selected Answer: A\\nyou can create up to \\n 10.000 filter policies per AWS account\\n 200 filter policies per topic (not subscription!) limits option C to 200 partners\\n 100 000 topics per AWS account, limits option A to 100 000 partners\\n\\nA and C works but A has better scalability with ability to add 100 000 partners","upvote_count":"5","comment_id":"1102285","comments":[{"poster":"drycleansing","comment_id":"1193344","upvote_count":"1","content":"the best answer","timestamp":"1712791980.0"}]},{"upvote_count":"1","content":"Selected Answer: C\\nYou can using a filter policy to just sent the info by partner","poster":"leonardoliveros","comment_id":"1072030","timestamp":"1700093100.0"},{"upvote_count":"1","poster":"ninomfr64","content":"Selected Answer: C\\nC. adding a new partner would only require to create a new subscription with the right filter","timestamp":"1692277020.0","comment_id":"983637"},{"content":"Selected Answer: C\\nC seems the most efficient way. when you add more partners, you can just assign new codes for each partner. with the codes, you can send notifications to specific paters","comment_id":"951328","poster":"tttamtttam","upvote_count":"1","timestamp":"1689319800.0"},{"upvote_count":"1","content":"Selected Answer: A\\nThe answer is A since this question has two crucial requirements: \\na) ... with the fewest code changes possible. \\n\\nb) ...in the MOST scalable way\\n\\nChatGPT initially gives an incorrect answer and then adjusts its response when requirements are asked.","poster":"rlnd2000","timestamp":"1689072480.0","comment_id":"948896","comments":[{"comment_id":"948898","poster":"rlnd2000","content":"OOH another important requirement: Each partner must receive updates for only the partner\'s own orders, that is not achievable with option C","upvote_count":"1","timestamp":"1689072660.0","comments":[{"upvote_count":"5","poster":"Jeremy11","timestamp":"1690762320.0","content":"This part of C seems to meet that requirement: Apply the appropriate filter policy to the topic subscriptions.","comment_id":"967607"}]},{"poster":"Skywalker23","upvote_count":"2","content":"Cannot be A. It requires change of lambda function code to send notifications to new SNS topics for new partners. Not a scalable solution.","timestamp":"1695548760.0","comment_id":"1015646"}]},{"timestamp":"1683390420.0","upvote_count":"4","poster":"geekdamsel","comment_id":"890871","content":"Got this question in exam. Correct answer is C."},{"content":"Selected Answer: C\\nC is the answer","poster":"Rpod","upvote_count":"2","comment_id":"875496","timestamp":"1681988460.0"},{"comments":[{"poster":"Baalhammun","upvote_count":"1","timestamp":"1707410340.0","content":"You apply message filtering on the SNS so they recieve only their messages, think C is the correct answer","comment_id":"1144719"}],"content":"Selected Answer: A\\nThe subscription depends on how the subscriber subcribes to the topic. It would be unsecure to allow customers to notify to whatever they want, they would get messages from other partners. This is more like a traditional queue scenario.","comment_id":"866440","poster":"robotgeek","timestamp":"1681144260.0","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: C\\nC is the best answer. A would work but is less scalable as you have to create new topics for each new partner.","poster":"grimsdev","comment_id":"861072","timestamp":"1680614340.0"},{"content":"Selected Answer: C\\nC is the answer\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html","poster":"TungNNS","upvote_count":"3","timestamp":"1680498900.0","comments":[{"comment_id":"869432","timestamp":"1681391700.0","content":"So you are allowing Customer A to subscribe to orders from Customer B? sounds like a security fiasco IMHO. Is there any way you as a publisher can limit what Customers can subscribe to which messages with only 1 topic?","upvote_count":"1","poster":"robotgeek"}],"comment_id":"859549"},{"timestamp":"1680358380.0","content":"Selected Answer: C\\nC is the answer.\\nTo receive only a subset of the messages, a subscriber must assign a filter policy to the topic subscription.","upvote_count":"4","comment_id":"858002","poster":"ihta_2031"},{"content":"Selected Answer: A\\nI think Option A should be the answer where for each partner we should have an SNS topic","poster":"shahs10","timestamp":"1680007920.0","upvote_count":"1","comment_id":"853248"}],"answer_description":"","extracted_at":"2025-12-24T08:56:09.188Z","extraction_method":"api_direct_v1"},{"question_id":"LSqaxKcgIVODaVwzxIR2","question_number":36,"page":8,"question_text":"A developer is working on a web application that uses Amazon DynamoDB as its data store. The application has two DynamoDB tables: one table that is named artists and one table that is named songs. The artists table has artistName as the partition key. The songs table has songName as the partition key and artistName as the sort key.\\n\\nThe table usage patterns include the retrieval of multiple songs and artists in a single database operation from the webpage. The developer needs a way to retrieve this information with minimal network traffic and optimal application performance.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Perform a Scan operation on each table that filters by the list of songName/artistName for the songs table and the list of artistName in the artists table.","C":"Perform a BatchGetitem operation on the songs table that uses the songName/artistName keys. Perform a BatchGetltem operation on the artists table that uses artistName as the key.","B":"Create a local secondary index (LSI) on the songs table that uses artistName as the partition key. Perform a query operation for each artistName on the songs table that filters by the list of songName. Perform a query operation for each artistName on the artists table.","A":"Perform a BatchGetltem operation that returns items from the two tables. Use the list of songName/artistName keys for the songs table and the list of artistName key for the artists table."},"correct_answer":"A","answer_ET":"A","answers_community":["A (91%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/111831-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-06-10 14:49:00","unix_timestamp":1686401340,"discussion_count":9,"discussion":[{"poster":"csG13","timestamp":"1686401340.0","content":"Selected Answer: A\\nThe correct answer is A. BatchGetItem can return one or multiple items from one or more tables. For reference check the link below\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","comment_id":"920063","upvote_count":"8"},{"content":"Selected Answer: A\\nBatchGetItem allows fetching multiple items from one or more DynamoDB tables in a single call, which reduces network traffic.\\n\\nC) Eliminated - While each operation is efficient within its table, two separate BatchGetItem calls still result in more round trips to DynamoDB than a single batch operation for both tables\\n\\nD) Eliminated - Scan operations are very inefficient because they read every item in the table, even if only a subset of data is needed.","upvote_count":"2","poster":"sumanshu","timestamp":"1735394340.0","comment_id":"1332984"},{"upvote_count":"1","timestamp":"1716424740.0","poster":"65703c1","comment_id":"1216117","content":"Selected Answer: A\\nA is the correct answer."},{"content":"Selected Answer: C\\nI would go for it because typically we are taking the advantage of key selection","comments":[{"content":"(C) performs BatchGetItem operation twice; that\'s NOT optimal and above the minimal network traffic necessary. \\nAmazon DynamoDB BatchGetItem - returns the attributes of one or more items from one or more tables. You identify requested items by primary key.","timestamp":"1726377180.0","upvote_count":"1","comment_id":"1283916","poster":"NSA_Poker"},{"upvote_count":"1","timestamp":"1708857840.0","poster":"KarBiswa","content":"Sorry its Option A saying multiple songs so list will be right option","comment_id":"1158569"}],"poster":"KarBiswa","comment_id":"1158565","timestamp":"1708857720.0","upvote_count":"1"},{"timestamp":"1705484820.0","comment_id":"1124860","content":"Selected Answer: A\\nThe BatchGetItem API allows you to get up to 100 items from one or more DynamoDB tables in a single operation, which can reduce the number of network requests. This is efficient for retrieving a specific list of items when you know the primary keys (partition key and sort key, if applicable) of the items you want to retrieve.","upvote_count":"4","poster":"SerialiDr"},{"comment_id":"1016121","timestamp":"1695582540.0","poster":"norris81","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","upvote_count":"2"},{"poster":"rlnd2000","content":"Selected Answer: B\\nAgree 100% with Caiyi.","comment_id":"961705","upvote_count":"1","timestamp":"1690208700.0"},{"comments":[{"timestamp":"1692460500.0","comment_id":"985308","upvote_count":"6","poster":"GripZA","content":"You can\'t create a LSI on an existing DDB table"},{"upvote_count":"2","poster":"remynick","comment_id":"981435","content":"I dont agree, we need to creat a global secondary index to use artistName as the partition ke","timestamp":"1692089040.0"}],"comment_id":"942372","timestamp":"1688441340.0","content":"B.\\nBy creating a local secondary index (LSI) on the songs table with artistName as the partition key, you can efficiently query the songs table for each artistName in the list of artists. This approach allows you to retrieve the desired songs for multiple artists with minimal network traffic.","upvote_count":"3","poster":"caiyi"},{"poster":"Baba_Eni","comment_id":"926567","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","timestamp":"1687078500.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:56:20.193Z","extraction_method":"api_direct_v1"},{"question_id":"SRU5tft4FsfV9Qrxj8fL","question_number":37,"page":8,"question_text":"A company is developing an ecommerce application that uses Amazon API Gateway APIs. The application uses AWS Lambda as a backend. The company needs to test the code in a dedicated, monitored test environment before the company releases the code to the production environment.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Use a single stage in API Gateway. Configure API clients to send a query parameter that indicates the environment. Add different code blocks for different environments in the Lambda function to match the value of the query parameter.","C":"Use multiple stages in API Gateway. Create a Lambda function for each environment. Configure API Gateway stage variables to route traffic to the Lambda function in different environments.","B":"Use multiple stages in API Gateway. Create a single Lambda function for all environments. Add different code blocks for different environments in the Lambda function based on Lambda environment variables.","A":"Use a single stage in API Gateway. Create a Lambda function for each environment. Configure API clients to send a query parameter that indicates the environment and the specific Lambda function."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/111832-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-06-10 14:52:00","unix_timestamp":1686401520,"discussion_count":6,"discussion":[{"upvote_count":"14","timestamp":"1686401520.0","comment_id":"920065","poster":"csG13","content":"Selected Answer: C\\nThe answer is C - we should create multiple stages and different Lambdas that will be utilised based on API Gateway stages variables.\\n\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/amazon-api-gateway-using-stage-variables.html"},{"upvote_count":"1","poster":"thalasi","comment_id":"1570131","timestamp":"1747640820.0","content":"Selected Answer: C\\nB. Elimnated : Wont support automatic rotation"},{"poster":"e886835","timestamp":"1738748520.0","content":"Selected Answer: C\\nLambda functions for each environment: Creating separate Lambda functions for each environment helps to ensure that the code for testing in the test environment is isolated from the production code.","comment_id":"1351786","upvote_count":"1"},{"upvote_count":"1","comment_id":"1231699","timestamp":"1718596200.0","poster":"tsangckl","content":"This appear at 17 Jun exam"},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","timestamp":"1716424860.0","poster":"65703c1","comment_id":"1216119"},{"comment_id":"1124948","upvote_count":"3","poster":"SerialiDr","timestamp":"1705494540.0","content":"Selected Answer: C\\nC. Use multiple stages in API Gateway. Create a Lambda function for each environment. Configure API Gateway stage variables to route traffic to the Lambda function in different environments: This is the recommended approach. Using multiple stages in API Gateway (one for testing and one for production) allows for clear separation of environments. Having a dedicated Lambda function for each environment ensures isolation and reduces the risk of accidental changes impacting the production environment. API Gateway stage variables can be used to manage configurations specific to each stage, such as function names or other parameters."}],"answer_description":"","extracted_at":"2025-12-24T08:56:20.193Z","extraction_method":"api_direct_v1"},{"question_id":"ks7ACLM9ke65koEm3kar","question_number":38,"page":8,"question_text":"A developer creates an AWS Lambda function that retrieves and groups data from several public API endpoints. The Lambda function has been updated and configured to connect to the private subnet of a VPC. An internet gateway is attached to the VPC. The VPC uses the default network ACL and security group configurations.\\n\\nThe developer finds that the Lambda function can no longer access the public API. The developer has ensured that the public API is accessible, but the Lambda function cannot connect to the API\\n\\nHow should the developer fix the connection issue?","choices":{"D":"Ensure that outbound traffic from the private subnet is routed to a new internet gateway.","C":"Ensure that outbound traffic from the private subnet is routed to a public NAT gateway.","A":"Ensure that the network ACL allows outbound traffic to the public internet.","B":"Ensure that the security group allows outbound traffic to the public internet."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117336-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:51:00","unix_timestamp":1691149860,"discussion_count":7,"discussion":[{"comment_id":"1003487","timestamp":"1710022980.0","upvote_count":"7","poster":"Dushank","content":"Selected Answer: C\\nWhen a Lambda function is configured to connect to a VPC, it loses its default internet access. To allow the Lambda function to access the public internet, it must be connected to a private subnet in the VPC that is configured to route its traffic through a NAT Gateway (Network Address Translation Gateway).\\n\\nThe Internet Gateway is usually used to provide internet access to resources in the public subnet, but for resources in the private subnet, a NAT Gateway is required."},{"comment_id":"1216123","poster":"65703c1","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1732329900.0"},{"upvote_count":"2","content":"Selected Answer: C\\nC. Ensure that outbound traffic from the private subnet is routed to a public NAT gateway: This is the most likely solution. Lambda functions in a private subnet require a NAT (Network Address Translation) gateway or NAT instance in a public subnet to access the public internet, as private subnets do not have direct internet access. The VPC route table associated with the private subnet needs to have a route that directs internet-bound traffic to the NAT gateway.","timestamp":"1721213460.0","comment_id":"1124972","poster":"SerialiDr"},{"poster":"Naj_64","upvote_count":"1","comment_id":"986260","content":"Selected Answer: C\\nNAT Gateway from a public subnet is required.","timestamp":"1708504740.0"},{"content":"Selected Answer: C\\nThe Lambda function is running in a private subnet of the VPC, it needs to send outbound traffic to the internet to reach the API endpoints. To enable this, a NAT gateway is required.","upvote_count":"1","poster":"cmonthatsme","comment_id":"973831","timestamp":"1707230640.0"},{"timestamp":"1707083160.0","poster":"Parsons","upvote_count":"1","comment_id":"972447","content":"Selected Answer: C\\nC is correct.\\nwith Lambda, You need an IP of NAT GW to be able to access public internet."},{"poster":"cloudenthusiast","upvote_count":"2","comment_id":"972111","timestamp":"1707054660.0","content":"Selected Answer: C\\nit leverages a NAT gateway, which is a service that enables instances in a private subnet to connect to the internet or other AWS services, but prevents the internet from initiating a connection with those instances."}],"answer_description":"","extracted_at":"2025-12-24T08:56:20.193Z","extraction_method":"api_direct_v1"},{"question_id":"0RKW9dC5m1fgd2OxiJaZ","question_number":39,"page":8,"question_text":"A developer needs to store configuration variables for an application. The developer needs to set an expiration date and time for the configuration. The developer wants to receive notifications before the configuration expires.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Create a standard parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.","D":"Create an advanced parameter in AWS Systems Manager Parameter Store. Create an Amazon EC2 instance with a cron job to expire the configuration and to send notifications.","C":"Create an advanced parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.","B":"Create a standard parameter in AWS Systems Manager Parameter Store. Create an AWS Lambda function to expire the configuration and to send Amazon Simple Notification Service (Amazon SNS) notifications."},"correct_answer":"C","answer_ET":"C","answers_community":["C (81%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117335-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:46:00","unix_timestamp":1691149560,"discussion_count":11,"discussion":[{"poster":"Parsons","comment_id":"972445","timestamp":"1691178300.0","upvote_count":"11","content":"Selected Answer: C\\nC is correct.\\nYou have to use \\"advanced parameter in AWS Systems Manager Parameter Store\\" to be able to Set Expiration and ExpirationNotification policy types."},{"timestamp":"1721214180.0","poster":"Anandesh","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-policies.html","comment_id":"1249541","upvote_count":"1"},{"timestamp":"1716426060.0","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","comment_id":"1216130"},{"timestamp":"1708858860.0","upvote_count":"1","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-policies.html","comment_id":"1158606","poster":"KarBiswa"},{"upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1741476540.0","comment_id":"1366711","poster":"Shamalka","content":"You cannot have expiration policies for standard parameters. It is only allowed for Advanced parameters in AWS SSM Parameter Store"}],"timestamp":"1708799400.0","poster":"Trung125122","comment_id":"1158096","content":"Selected Answer: A\\nA is sufficient. C is abundant"},{"timestamp":"1701273960.0","upvote_count":"1","content":"Advanced Parameters: These offer more capabilities, such as adding policies for expiration and triggering notifications","poster":"NijeshT","comment_id":"1083632"},{"comment_id":"1048747","upvote_count":"2","content":"Selected Answer: B\\nUsing Lambda function and SNS will address the requirement with least operational overhead.","timestamp":"1697803440.0","poster":"Rameez1","comments":[{"content":"Changing my mind option A is correct here.","poster":"Rameez1","timestamp":"1697969280.0","upvote_count":"2","comment_id":"1050432","comments":[{"comment_id":"1090644","upvote_count":"1","timestamp":"1701988320.0","poster":"Fizbo","content":"It is C. standard tier does not have those features"}]}]},{"content":"A is the right Answer","comment_id":"1041756","poster":"Gold07","timestamp":"1697116260.0","upvote_count":"2"},{"poster":"worseforwear","comment_id":"975189","content":"Selected Answer: C\\nYou can\'t set expiration policy on standard parameter","timestamp":"1691469300.0","upvote_count":"4"},{"upvote_count":"2","timestamp":"1691325960.0","comments":[{"comment_id":"1575607","timestamp":"1749337980.0","content":"no, Standard Parameters: These are the default tier for Parameter Store. They have a content size limit of 4 KB and a maximum of 10,000 parameters per Region. They are free of charge.\\nAdvanced Parameters: These offer additional features for a cost, including:\\nLarger content size limit (8 KB).\\nIncreased parameter quota (100,000 per Region).\\nSupport for parameter policies, such as Expiration, ExpirationNotification, and NoChangeNotification.","poster":"USR","upvote_count":"1"}],"comment_id":"973833","content":"Selected Answer: A\\nBy creating a standard parameter, you can set an expiration date for the parameter","poster":"cmonthatsme"},{"poster":"cloudenthusiast","timestamp":"1691149560.0","content":"Selected Answer: C\\nit leverages the advanced parameter tier and the parameter policies feature of Parameter Store, which meet the requirements with the least operational overhead.","upvote_count":"4","comment_id":"972107"}],"answer_description":"","extracted_at":"2025-12-24T08:56:20.193Z","extraction_method":"api_direct_v1"},{"question_id":"sUuEyP6yeDDBZ0NA6reI","question_number":40,"page":8,"question_text":"A company is developing a serverless application that consists of various AWS Lambda functions behind Amazon API Gateway APIs. A developer needs to automate the deployment of Lambda function code. The developer will deploy updated Lambda functions with AWS CodeDeploy. The deployment must minimize the exposure of potential errors to end users. When the application is in production, the application cannot experience downtime outside the specified maintenance window.\\n\\nWhich deployment configuration will meet these requirements with the LEAST deployment time?","choices":{"B":"Use the AWS CodeDeploy linear deployment configuration to shift 10% of the traffic every minute.","D":"Use the AWS CodeDeploy predefined canary deployment configuration to shift 10% of the traffic immediately and shift the remaining traffic after 5 minutes.","C":"Use the AWS CodeDeploy all-at-once deployment configuration to shift all traffic to the updated versions immediately.","A":"Use the AWS CodeDeploy in-place deployment configuration for the Lambda functions. Shift all traffic immediately after deployment."},"correct_answer":"D","answer_ET":"D","answers_community":["D (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117334-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:45:00","unix_timestamp":1691149500,"discussion_count":14,"discussion":[{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","comment_id":"1216132","timestamp":"1732331160.0","poster":"65703c1"},{"upvote_count":"2","comment_id":"1158614","timestamp":"1724576940.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/whitepapers/latest/practicing-continuous-integration-continuous-delivery/deployment-methods.html#:~:text=A%20variation%20of,is%20gradually%20increased.","poster":"KarBiswa"},{"poster":"rimaSamir","timestamp":"1722428760.0","upvote_count":"1","content":"Selected answer is A.\\nTo them who have choosen D, you have forgotton also about \\"When the application is in production, the application cannot experience downtime outside the specified maintenance window.\\"","comment_id":"1136840"},{"comment_id":"1124986","content":"Selected Answer: D\\nD. Use the AWS CodeDeploy predefined canary deployment configuration to shift 10% of the traffic immediately and shift the remaining traffic after 5 minutes: The canary deployment strategy first shifts a small percentage of traffic to the new version (e.g., 10%) and, after a specified period (e.g., 5 minutes), shifts the remaining traffic. This approach allows for initial validation of the new version with minimal user exposure before full rollout, balancing speed and risk mitigation.","timestamp":"1721215020.0","poster":"SerialiDr","upvote_count":"2"},{"content":"Selected Answer: D\\nLambda deploy supports just Linear or Canary. So answer is D. Linear or All","upvote_count":"2","timestamp":"1718728320.0","poster":"c9ebec2","comment_id":"1099954"},{"comment_id":"1084870","poster":"aravindpti","content":"Answer A.\\nhttps://aws.amazon.com/blogs/containers/aws-codedeploy-now-supports-linear-and-canary-deployments-for-amazon-ecs/","timestamp":"1717200480.0","upvote_count":"1"},{"poster":"jingle4944","timestamp":"1714019520.0","content":"Canary deployment is supported: https://aws.amazon.com/blogs/compute/implementing-safe-aws-lambda-deployments-with-aws-codedeploy/","comment_id":"1053446","upvote_count":"1"},{"poster":"passhojaun","comments":[{"content":"https://aws.amazon.com/es/blogs/containers/aws-codedeploy-now-supports-linear-and-canary-deployments-for-amazon-ecs/","comment_id":"1053285","poster":"Jaimoo","timestamp":"1714000860.0","upvote_count":"2"}],"upvote_count":"1","timestamp":"1713438540.0","comment_id":"1046843","content":"Selected Answer: A\\nCanary is not supported in AWS CodeDeploy."},{"upvote_count":"2","comments":[{"content":"Canary is supported by code deploy\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html","upvote_count":"1","comment_id":"1115854","timestamp":"1720351020.0","poster":"Monivs"}],"comment_id":"1046842","timestamp":"1713438480.0","content":"Canary is not supported in AWS CodeDeploy.","poster":"passhojaun"},{"upvote_count":"2","content":"Selected Answer: D\\nCanary is faster than linear in this case.","timestamp":"1709175660.0","poster":"Yuxing_Li","comment_id":"993619"},{"poster":"love777","comments":[{"upvote_count":"1","timestamp":"1720351080.0","poster":"Monivs","comment_id":"1115855","content":"Inplace deployment is not supported by ECS and Lambda"}],"upvote_count":"1","timestamp":"1708797000.0","content":"Selected Answer: A\\nExplanation:\\n\\nIn an AWS Lambda context, using the in-place deployment configuration minimizes deployment time and provides fast updates to the function\'s code. In this case, the application consists of AWS Lambda functions behind Amazon API Gateway APIs. With the in-place deployment configuration, all traffic is shifted to the updated versions of the Lambda functions immediately after deployment.\\n\\nOption B suggests a linear deployment configuration that shifts 10% of the traffic every minute. While this provides controlled deployment and gradual rollout, it might not be the fastest approach if you want to minimize deployment time.\\n\\nOption C suggests an all-at-once deployment configuration. While this configuration might be fast, it poses a higher risk of exposing potential errors to end users all at once.","comment_id":"989314"},{"content":"Selected Answer: D\\nCanary deployment","timestamp":"1707108720.0","poster":"RaidenKurosaki","upvote_count":"2","comment_id":"972638"},{"content":"Selected Answer: D\\nD is correct.\\nKeyword:\\n-\\"must minimize the exposure of potential errors to end users\\", you just have to trade-off 10% of traffic\\n- \\"cannot experience downtime \\", eliminate C. \\n- \\"LEAST deployment time\\", with B, You have to take 10 mins other than D just 5 min.","poster":"Parsons","timestamp":"1707083040.0","comment_id":"972443","upvote_count":"4"},{"content":"Selected Answer: D\\nthe predefined canary deployment configuration, which shifts a small percentage of traffic to the updated versions immediately, and then shifts the remaining traffic after a specified period","timestamp":"1707054300.0","poster":"cloudenthusiast","upvote_count":"2","comment_id":"972106"}],"answer_description":"","extracted_at":"2025-12-24T08:56:20.193Z","extraction_method":"api_direct_v1"},{"question_id":"5dezEzIvkbWFLvRKOKoZ","question_number":41,"page":9,"question_text":"A company created four AWS Lambda functions that connect to a relational database server that runs on an Amazon RDS instance. A security team requires the company to automatically change the database password every 30 days.\\n\\nWhich solution will meet these requirements MOST securely?","choices":{"C":"Store the database credentials in AWS Systems Manager Parameter Store secure strings. Configure a 30-day schedule for the secure strings.","D":"Store the database credentials in an Amazon S3 bucket that uses server-side encryption with customer-provided encryption keys (SSE-C). Configure a 30-day key rotation schedule for the customer key.","B":"Store the database credentials in AWS Secrets Manager. Configure a 30-day rotation schedule for the credentials.","A":"Store the database credentials in the environment variables of the Lambda function. Deploy the Lambda function with the new credentials every 30 days."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117333-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:41:00","unix_timestamp":1691149260,"discussion_count":6,"discussion":[{"poster":"Dushank","upvote_count":"6","content":"Selected Answer: B\\nThe most secure and automated way to handle database credential rotation is to use AWS Secrets Manager. Secrets Manager can automatically rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. You can configure Secrets Manager to automatically rotate the secrets for you according to a schedule you specify, making it easier to adhere to best practices for security.","comment_id":"1003492","timestamp":"1694291220.0"},{"content":"This appear at 17 Jun exam","timestamp":"1718596260.0","poster":"tsangckl","upvote_count":"1","comment_id":"1231700"},{"timestamp":"1716426540.0","upvote_count":"1","comment_id":"1216135","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"upvote_count":"4","content":"Selected Answer: B\\nSecrets Manager supports auto rotation. Systems Manager does not do that.","timestamp":"1691203980.0","poster":"RaidenKurosaki","comment_id":"972639"},{"poster":"Parsons","upvote_count":"2","comment_id":"972438","content":"Selected Answer: B\\nB is correct.\\nKeyword: \\"automatically change the database password every 30 days\\"","timestamp":"1691178000.0"},{"content":"Selected Answer: B\\nSecrets Manager supports automatic rotation of secrets by using either built-in or custom Lambda functions","timestamp":"1691149260.0","poster":"cloudenthusiast","comments":[{"poster":"niks1221","timestamp":"1691250420.0","content":"DId you give your exam recently?\\nIf yes, how many questions were from here?","upvote_count":"1","comment_id":"973146"}],"upvote_count":"3","comment_id":"972103"}],"answer_description":"","extracted_at":"2025-12-24T08:56:31.151Z","extraction_method":"api_direct_v1"},{"question_id":"aBcc2DENNmeMdsPV5W8w","question_number":42,"page":9,"question_text":"A developer is setting up a deployment pipeline. The pipeline includes an AWS CodeBuild build stage that requires access to a database to run integration tests. The developer is using a buildspec.yml file to configure the database connection. Company policy requires automatic rotation of all database credentials.\\n\\nWhich solution will handle the database credentials MOST securely?","choices":{"B":"Retrieve the credentials from an environment variable that is linked to a SecureString parameter in AWS Systems Manager Parameter Store. Configure Parameter Store for automatic rotation.","A":"Retrieve the credentials from variables that are hardcoded in the buildspec.yml file. Configure an AWS Lambda function to rotate the credentials.","C":"Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.","D":"Retrieve the credentials from an environment variable that contains the connection string in plaintext. Configure an Amazon EventBridge event to rotate the credentials."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117332-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:39:00","unix_timestamp":1691149140,"discussion_count":7,"discussion":[{"comment_id":"1570132","upvote_count":"1","timestamp":"1747640880.0","content":"Selected Answer: C\\nSecureString parameter in AWS Systems Manager Parameter Store wont support auto rotation","poster":"thalasi"},{"upvote_count":"2","comment_id":"1216137","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1732331700.0","poster":"65703c1"},{"comment_id":"1136846","upvote_count":"2","poster":"rimaSamir","timestamp":"1722429120.0","content":"Answer is C as CodeBuild already supports Secret Manager"},{"upvote_count":"4","poster":"Gold07","comment_id":"1019838","timestamp":"1711635900.0","content":"c is the correct answer"},{"content":"Selected Answer: C\\nSecure + Rotation are key words for Secrets Manager","comment_id":"973841","timestamp":"1707231240.0","upvote_count":"4","poster":"cmonthatsme"},{"timestamp":"1707082740.0","content":"Selected Answer: C\\nC is correct.\\nExplanation: \\"requires automatic rotation of all database credentials\\" => \\"Secrets Manager for automatic rotation.\\"\\nWith the Systems Manager Parameter Store, you have to do that manually.","comment_id":"972436","upvote_count":"4","poster":"Parsons"},{"comment_id":"972101","content":"Selected Answer: C\\nBecause configure Secrets Manager for automatic rotation","upvote_count":"2","timestamp":"1707053940.0","poster":"cloudenthusiast"}],"answer_description":"","extracted_at":"2025-12-24T08:56:31.151Z","extraction_method":"api_direct_v1"},{"question_id":"TPx95TtXWtLPgncwWFEt","question_number":43,"page":9,"question_text":"A company is developing a serverless multi-tier application on AWS. The company will build the serverless logic tier by using Amazon API Gateway and AWS Lambda.\\nWhile the company builds the logic tier, a developer who works on the frontend of the application must develop integration tests. The tests must cover both positive and negative scenarios, depending on success and error HTTP status codes.\\n\\nWhich solution will meet these requirements with the LEAST effort?","choices":{"A":"Set up a mock integration for API methods in API Gateway. In the integration request from Method Execution, add simple logic to return either a success or error based on HTTP status code. In the integration response, add messages that correspond to the HTTP status codes.","B":"Create two mock integration resources for API methods in API Gateway. In the integration request, return a success HTTP status code for one resource and an error HTTP status code for the other resource. In the integration response, add messages that correspond to the HTTP status codes.","D":"Create a Lambda function to perform tests. Add simple logic to return either success or error-based HTTP status codes. Create a mock integration in API Gateway. Select the Lambda function that corresponds to the HTTP status codes.","C":"Create Lambda functions to perform tests. Add simple logic to return either success or error, based on the HTTP status codes. Build an API Gateway Lambda integration. Select appropriate Lambda functions that correspond to the HTTP status codes."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117331-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-04 13:38:00","unix_timestamp":1691149080,"discussion_count":5,"discussion":[{"content":"Selected Answer: A\\nA is correct (with the LEAST effort)\\n\\n\\"API Gateway supports mock integrations for API methods\\"\\n\\"As an API developer, you decide how API Gateway responds to a mock integration request. For this, you configure the method\'s integration request and integration response to associate a response with a given status code. \\"\\n\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html","timestamp":"1707083640.0","comment_id":"972463","poster":"Parsons","upvote_count":"10"},{"timestamp":"1737784380.0","comment_id":"1346341","content":"Selected Answer: A\\nB - resource should not be used as such.. \\nOne Request should fulfill both success and fail scenario. Another resource means it\'s not the same request","upvote_count":"1","poster":"mooncake1"},{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216138","timestamp":"1732331820.0","upvote_count":"1","poster":"65703c1"},{"content":"Selected Answer: A\\nThis is an efficient solution. Mock integrations in API Gateway allow you to simulate backend logic directly within API Gateway, without the need for an actual backend like Lambda. You can define the behavior and response (including HTTP status codes and messages) directly in API Gateway, making it ideal for quickly developing and testing various scenarios.","poster":"SerialiDr","timestamp":"1721237640.0","upvote_count":"2","comment_id":"1125257"},{"timestamp":"1707053880.0","upvote_count":"3","content":"Selected Answer: A\\nA because set up a mock integration for API methods in API Gateway with the least effort.","poster":"cloudenthusiast","comment_id":"972098"}],"answer_description":"","extracted_at":"2025-12-24T08:56:31.151Z","extraction_method":"api_direct_v1"},{"question_id":"izHZQASEjvskra1pL1Ri","question_number":44,"page":9,"question_text":"Users are reporting errors in an application. The application consists of several microservices that are deployed on Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.\\n\\nWhich combination of steps should a developer take to fix the errors? (Choose two.)","choices":{"B":"Deploy AWS X-Ray as a daemonset to the Fargate cluster. Update the service role policy to allow access to the X-Ray API.","D":"Instrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X-Ray daemon.","A":"Deploy AWS X-Ray as a sidecar container to the microservices. Update the task role policy to allow access to the X-Ray API.","C":"Instrument the application by using the AWS X-Ray SDK. Update the application to use the PutXrayTrace API call to communicate with the X-Ray API.","E":"Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action."},"correct_answer":"A","answer_ET":"A","answers_community":["A (43%)","D (36%)","14%","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117795-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-10 14:07:00","unix_timestamp":1691669220,"discussion_count":14,"discussion":[{"content":"AD\\nA. You can only use X-ray with Fargate as a side car because there is not EC2 image.\\nD. https://github.com/aws-samples/aws-xray-fargate","upvote_count":"14","poster":"MG1407","comment_id":"979440","timestamp":"1691854560.0","comments":[{"upvote_count":"2","timestamp":"1694360100.0","content":"With AWS Fargate, there are no EC2 instances to install the X-Ray daemon onto.\\n\\nHowever, the X-Ray daemon is actually provided automatically with Fargate - it runs as an additional container alongside the application containers in the task. So there is no need to deploy it as a sidecar.\\n\\nWhen using X-Ray with Fargate, you just need to:\\n\\nInstrument the application code with the X-Ray SDK\\nThe SDK will communicate with the daemon container provided by Fargate\\nSo you\'re right that there are no EC2 hosts to install daemons on directly. But Fargate handles running the X-Ray daemon automatically as part of the task, eliminating the need for a sidecar. The SDK can communicate with the daemon container transparently.","comment_id":"1004090","poster":"Iamtany"},{"content":"I agree - AD\\nhttps://github.com/aws-samples/aws-xray-fargate","comment_id":"1046981","upvote_count":"1","poster":"Nagasoracle","timestamp":"1697638140.0"}]},{"timestamp":"1738750140.0","poster":"e886835","comment_id":"1351800","content":"Selected Answer: D\\nAD- The X-Ray SDK is used to enable the application code to send trace data. By integrating the SDK, the application will automatically collect traces of the requests and responses, helping you understand where errors occur within the microservices.","upvote_count":"1"},{"timestamp":"1718213220.0","poster":"vkovilam","content":"A. Deploy AWS X-Ray as a sidecar container to the microservices. Update the task role policy to allow access to the X-Ray API.\\n\\nD. Instrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X-Ray daemon.","comment_id":"1229376","upvote_count":"1"},{"timestamp":"1716427320.0","poster":"65703c1","comment_id":"1216141","content":"Selected Answer: A\\nAD is the correct answer.","upvote_count":"1"},{"content":"Selected Answer: AE\\nChatGPT\uff1aAE","timestamp":"1711303860.0","comment_id":"1181909","upvote_count":"1","poster":"Single"},{"comment_id":"1175992","poster":"41eb566","upvote_count":"1","content":"Selected Answer: C\\nCE\\nC. Instrument the application by using the AWS X-Ray SDK. Update the application to use the PutXrayTrace API call to communicate with the X-Ray API.\\n\\nThis step involves instrumenting the application code using the AWS X-Ray SDK to generate trace data and communicate it to the X-Ray service for analysis.\\nE. Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action.","timestamp":"1710698100.0"},{"comment_id":"1111159","upvote_count":"1","content":"Selected Answer: A\\nAC\\n\\nFargate cannot have daemon. This rules out B and C. D is distractor.","poster":"rrshah83","timestamp":"1704113100.0"},{"poster":"tqiu654","timestamp":"1701565680.0","content":"Selected Answer: A\\nCHatGpt: AD","comment_id":"1086507","upvote_count":"1"},{"upvote_count":"3","comment_id":"1074556","content":"DE\\nOption A is incorrect because deploying AWS X-Ray as a sidecar container to the microservices is not the common practice for Fargate deployments. Fargate tasks usually run as a single container, and the application is instrumented to communicate with the X-Ray daemon.\\n\\nOption B is not applicable because deploying AWS X-Ray as a daemonset is a concept related to Kubernetes, not AWS Fargate.\\n\\nOption C is incorrect because using the AWS X-Ray SDK involves instrumenting the application, but the suggested approach is to communicate with the X-Ray daemon rather than directly calling the X-Ray API.","poster":"ShawnWon","timestamp":"1700387280.0"},{"upvote_count":"1","comment_id":"1043281","poster":"Passexam4sure_com","content":"Selected Answer: D\\nInstrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X-Ray daemon","timestamp":"1697274720.0"},{"content":"D. Instrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X-Ray daemon.\\n\\nE. Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action.","timestamp":"1697250540.0","upvote_count":"1","comment_id":"1043097","poster":"Claire_KMT"},{"upvote_count":"3","timestamp":"1693951500.0","content":"Selected Answer: A\\nAD is correct.\\nA - X-Ray container as a \\"Side car\\" in ECS/Fargate cluster\\nD - Instrument the application using the AWS X-Ray SDK to collect telemetry data.","poster":"fossil123","comment_id":"999959"},{"poster":"love777","timestamp":"1692894000.0","upvote_count":"3","comment_id":"989332","content":"Selected Answer: D\\nD and E\\nOption D: \\n\\nInstrumenting the application using the AWS X-Ray SDK is essential for collecting traces and telemetry data. The X-Ray SDK helps you identify bottlenecks, errors, and other issues within your microservices.\\n\\nCommunicating with the X-Ray daemon allows your microservices to send trace data to X-Ray for analysis and visualization. This requires minimal configuration and is efficient for capturing and analyzing traces.\\n\\nOption E: \\n\\nInstrumenting the ECS task to send the application\'s standard output (stdout) and standard error (stderr) logs to Amazon CloudWatch Logs provides visibility into the application\'s behavior, errors, and issues.\\n\\nUpdating the task role policy to allow the cloudwatch:PullLogs action ensures that the ECS task has the necessary permissions to access and send logs to CloudWatch Logs."},{"upvote_count":"1","poster":"AWSdeveloper08","content":"Selected Answer: C\\nAnswer is CE\\n\\nTo diagnose and fix errors in an application deployed on Amazon ECS with AWS Fargate using AWS X-Ray, you should take the following steps:\\n\\nC. Instrument the application by using the AWS X-Ray SDK. Update the application to use the PutXrayTrace API call to communicate with the X-Ray API.\\n\\nInstrumenting the application using the AWS X-Ray SDK allows you to capture traces and data about requests as they flow through your application\'s components.\\nE. Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action.\\n\\nThis step will help you capture logs from your microservices, which can provide additional insights into the errors and issues occurring within the application.","comment_id":"977618","timestamp":"1691669220.0"}],"answer_description":"","extracted_at":"2025-12-24T08:56:31.151Z","extraction_method":"api_direct_v1"},{"question_id":"5nHv0liHNVU0PyCsavwX","question_number":45,"page":9,"question_text":"A developer is creating an application for a company. The application needs to read the file doc.txt that is placed in the root folder of an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET. The company\u2019s security team requires the principle of least privilege to be applied to the application\u2019s IAM policy.\\n\\nWhich IAM policy statement will meet these security requirements?","choices":{"B":"","D":"","A":"","C":""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117476-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-06 15:04:00","unix_timestamp":1691327040,"discussion_count":3,"discussion":[{"content":"Selected Answer: A\\nOnly read permission for the file","timestamp":"1707254520.0","upvote_count":"7","comment_id":"974169","poster":"Gadu"},{"upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732332180.0","comment_id":"1216142","poster":"65703c1"},{"timestamp":"1707231840.0","comment_id":"973852","poster":"cmonthatsme","upvote_count":"4","content":"Selected Answer: A\\nOnly allow to get this one file. A"}],"answer_description":"","extracted_at":"2025-12-24T08:56:31.151Z","extraction_method":"api_direct_v1"},{"question_id":"tpGs17ASShypB66kUsJs","question_number":46,"page":10,"question_text":"A financial company must store original customer records for 10 years for legal reasons. A complete record contains personally identifiable information (PII). According to local regulations, PII is available to only certain people in the company and must not be shared with third parties. The company needs to make the records available to third-party organizations for statistical analysis without sharing the PII.\\nA developer wants to store the original immutable record in Amazon S3. Depending on who accesses the S3 document, the document should be returned as is or with all the PII removed. The developer has written an AWS Lambda function to remove the PII from the document. The function is named removePii.\\nWhat should the developer do so that the company can meet the PII requirements while maintaining only one copy of the document?","choices":{"D":"Create an S3 access point from the S3 console. Use the access point name to call the GetObjectLegalHold S3 API function. Pass in the removePii function name to access the object without PII.","B":"Set up an S3 event notification that invokes the removePii function when an S3 PUT request is made. Call Amazon S3 by using a PUT request to access the object without PII.","C":"Create an S3 Object Lambda access point from the S3 console. Select the removePii function. Use S3 Access Points to access the object without PII.","A":"Set up an S3 event notification that invokes the removePii function when an S3 GET request is made. Call Amazon S3 by using a GET request to access the object without PII."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102741-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-15 23:34:00","unix_timestamp":1678919640,"discussion_count":13,"discussion":[{"poster":"gcmrjbr","upvote_count":"21","comments":[{"timestamp":"1719125460.0","upvote_count":"2","poster":"Skip","comment_id":"1235711","content":"Thanks for the info. Great heads up!"}],"content":"An S3 Object Lambda access point is a new type of access point that you can create to invoke your own AWS Lambda function to modify the content of an S3 object. You can use S3 Object Lambda access points to transform data as it is being retrieved from an S3 bucket, without modifying the original data stored in the bucket","comment_id":"1071735","timestamp":"1700070120.0"},{"content":"Selected Answer: C\\nC\\nhttps://aws.amazon.com/s3/features/object-lambda/","upvote_count":"13","poster":"Untamables","timestamp":"1679378820.0","comment_id":"845567"},{"comment_id":"1329811","timestamp":"1734755400.0","content":"Selected Answer: C\\nA) Eliminated - function cannot be invoked when a GET request is made.\\nB) Eliminated - It will either create two copies or overwrite existing copy\\nD) Eliminated - GetObjectLegalHold this API is used to check if an object is under a legal hold. It has nothing to do with dynamically modifying or removing PII from documents.","upvote_count":"3","poster":"sumanshu"},{"upvote_count":"1","timestamp":"1734048660.0","comment_id":"1325911","content":"Selected Answer: C\\n=> Discard A: S3 event notification not support GET\\n=> Discard B: violate this rule \'keyword: only one copy of the document\'. S3 event notification with PUT, make a copy (without PII) beside original record\\n\\n=> Dsiscard D: API GetObjectLegelHold is s3 GET API to know s3 object is editable, it can\'t update/ edit s3 object. Lambda can\'t auto be called by this API\\n\\nC: Lambda access point is intermediary s3 object and end-user, it modifies a copy of data (delete PII) then return user, then delete this data from local lambda memory","poster":"trieudo"},{"timestamp":"1721166900.0","poster":"ahadh7621","upvote_count":"2","comment_id":"1249274","content":"Selected Answer: C\\nhttps://aws.amazon.com/s3/features/object-lambda/\\nWith S3 Object Lambda, you can add your own code to S3 GET, HEAD, and LIST requests to modify and process data as it is returned to an application. You can use custom code to modify the data returned by S3 GET requests to filter rows, dynamically resize images, redact confidential data, and much more."},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html","comment_id":"1248796","timestamp":"1721122680.0","upvote_count":"1","poster":"Anandesh"},{"poster":"65703c1","upvote_count":"1","timestamp":"1716299460.0","comment_id":"1214989","content":"Selected Answer: C\\nC is the correct answer."},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-create.html","timestamp":"1710054900.0","poster":"KarBiswa","comment_id":"1170091","upvote_count":"1"},{"timestamp":"1683820740.0","upvote_count":"3","content":"Why is it C?","poster":"pagyabeng","comment_id":"895204"},{"upvote_count":"2","content":"Correct answer is C.","comment_id":"890872","poster":"geekdamsel","timestamp":"1683390420.0"},{"poster":"Rpod","timestamp":"1681988760.0","upvote_count":"1","content":"Selected Answer: C\\nC answer","comment_id":"875501"},{"poster":"ihta_2031","comment_id":"858005","content":"Selected Answer: C\\nIt is C","timestamp":"1680358620.0","upvote_count":"3"},{"content":"C\\nhttps://www.examtopics.com/discussions/amazon/view/88229-exam-aws-certified-developer-associate-topic-1-question-174/","timestamp":"1678919640.0","comment_id":"840374","poster":"aragon_saa","upvote_count":"7"}],"answer_description":"","extracted_at":"2025-12-24T08:56:42.160Z","extraction_method":"api_direct_v1"},{"question_id":"4NQFkgy1O5LO9Cnul23J","question_number":47,"page":10,"question_text":"A company has an application that uses AWS CodePipeline to automate its continuous integration and continuous delivery (CI/CD) workflow. The application uses AWS CodeCommit for version control. A developer who was working on one of the tasks did not pull the most recent changes from the main branch. A week later, the developer noticed merge conflicts.\\n\\nHow can the developer resolve the merge conflicts in the developer\'s branch with the LEAST development effort?","choices":{"B":"Create a new branch. Apply the changes from the previous branch.","D":"Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","C":"Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts.","A":"Clone the repository. Create a new branch. Update the branch with the changes."},"correct_answer":"D","answer_ET":"D","answers_community":["D (70%)","C (30%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117574-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-08 06:27:00","unix_timestamp":1691468820,"discussion_count":11,"discussion":[{"content":"Selected Answer: D\\nOption D is the best approach for resolving the merge conflicts with minimal development effort. Here\'s how it works:\\n\\nStop Pull from Main: By stopping the pull from the main branch to the feature branch, the developer can prevent the introduction of new conflicts while they are resolving the existing ones.\\n\\nRebase the Feature Branch: After stopping the pull, the developer can rebase the feature branch onto the main branch. This essentially replays the feature branch\'s changes on top of the main branch\'s latest changes. This allows the developer to resolve conflicts one commit at a time, addressing any conflicts that arise from the difference between the feature branch and the main branch.","timestamp":"1692895440.0","comment_id":"989340","poster":"love777","upvote_count":"10"},{"timestamp":"1730024580.0","upvote_count":"1","content":"Most people say D, but option D does not cover the fixing of conflict, but option C at lease says \\"fix the conflicts\\" so this is a complete answer, no?","poster":"9d8dd9c","comment_id":"1303546"},{"timestamp":"1716427620.0","poster":"65703c1","comment_id":"1216143","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"comment_id":"1164359","poster":"maurice2005","content":"Selected Answer: C\\nHow on earth non-visualize way is easier? And I\'ve never seen a rebase that happened commit-by-commit! Resolving the merge should happened in one go, merge or rebase. just rebase appear(!) more isolated. (which in practice it\'s not!). Also rebase is cleaner but the effort is even more since there is a level of isolation! \\nThe only point here is visualizing which makes it easier.","upvote_count":"2","timestamp":"1709411040.0"},{"poster":"SerialiDr","content":"Selected Answer: D\\nD. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch: Rebasing the feature branch from the main branch is an effective way to resolve merge conflicts. This approach involves updating the feature branch with the latest changes from the main branch and then applying the feature branch\'s changes on top of it. Rebasing can simplify the process of resolving conflicts and is generally less effort-intensive compared to creating new branches and transferring changes.\\n\\nC. Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts: Using tools like Commit Visualizer to understand the changes and conflicts can be helpful. However, this step alone doesn\u2019t resolve the conflicts. The developer still needs to manually resolve the conflicts in the code.","comment_id":"1125265","timestamp":"1705520880.0","upvote_count":"1"},{"timestamp":"1697274720.0","content":"D\\nD. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","poster":"Passexam4sure_com","upvote_count":"1","comment_id":"1043280"},{"content":"D. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","comment_id":"1043098","poster":"Claire_KMT","upvote_count":"1","timestamp":"1697250780.0"},{"content":"Selected Answer: D\\nRebasing the feature branch from the main branch would apply the changes from the main branch directly onto the feature branch, effectively bringing it up to date. This would resolve the conflicts in a way that minimizes manual effort.","upvote_count":"3","timestamp":"1694468040.0","comment_id":"1005172","poster":"Iamtany"},{"content":"Selected Answer: D\\nUsing the git rebase command to rebase a repository changes the history of a repository, which might cause commits to appear out of order.\\n\\nhttps://docs.aws.amazon.com/codecommit/latest/userguide/how-to-view-commit-details.html","poster":"[Removed]","comment_id":"977999","timestamp":"1691692740.0","upvote_count":"1"},{"poster":"AWSdeveloper08","upvote_count":"4","content":"Selected Answer: C\\nComparing commits in the Commit Visualizer view can provide a clear overview of the changes made over time and aid in understanding the context of the conflicts. This approach can help you pinpoint where conflicts arose and assist you in making informed decisions about how to resolve them.","timestamp":"1691669520.0","comment_id":"977625"},{"upvote_count":"1","timestamp":"1691468820.0","comment_id":"975176","comments":[{"comments":[{"poster":"maurice2005","comment_id":"1164358","upvote_count":"1","content":"because visualizing make it harder? You have to fix the conflict anyway! rebase or merge. in both resolve the conflict will happened in one go (unlike the comments I see which they say rebase is commit by commit). I don\'t think those who pick rebase ever used it before in practice!","timestamp":"1709410800.0"}],"timestamp":"1697077560.0","content":"I think C would take huge development effort","poster":"Cerakoted","upvote_count":"1","comment_id":"1041294"}],"content":"Selected Answer: C\\nAnswer D won\'t fix the problem","poster":"worseforwear"}],"answer_description":"","extracted_at":"2025-12-24T08:56:42.160Z","extraction_method":"api_direct_v1"},{"question_id":"Y302N0jp771uJclqhUWF","question_number":48,"page":10,"question_text":"A developer wants to add request validation to a production environment Amazon API Gateway API. The developer needs to test the changes before the API is deployed to the production environment. For the test, the developer will send test requests to the API through a testing tool.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Export the existing API to an OpenAPI file. Create a new API. Import the OpenAPI file. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.","C":"Create a new API. Add the necessary resources and methods, including new request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production","B":"Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage.","D":"Clone the existing API. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117797-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-10 14:13:00","unix_timestamp":1691669580,"discussion_count":4,"discussion":[{"timestamp":"1707574380.0","comment_id":"977628","content":"Selected Answer: B\\nIn this option, you are making changes directly to the existing API, adding request validation. Then, you deploy the updated API to a new API Gateway stage, which allows you to test the changes without affecting the production environment. After performing the tests and ensuring everything works as expected, you can then deploy the updated API to the production stage, thus minimizing operational overhead.","poster":"AWSdeveloper08","upvote_count":"12"},{"content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732332600.0","poster":"65703c1","comment_id":"1216145","upvote_count":"1"},{"comment_id":"1125659","upvote_count":"2","poster":"SerialiDr","content":"Selected Answer: B\\nB. Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage: This is a more streamlined approach. By deploying the updated API to a new stage, the developer can test the changes in an environment that closely mirrors production without affecting the current production traffic. Once testing is complete, the changes can be deployed to the production stage. This approach minimizes operational overhead.","timestamp":"1721288040.0"},{"comment_id":"1008558","content":"Selected Answer: B\\nIt looks Correct","upvote_count":"2","timestamp":"1710523860.0","poster":"imyashkale"}],"answer_description":"","extracted_at":"2025-12-24T08:56:42.160Z","extraction_method":"api_direct_v1"},{"question_id":"sJcukgHtrgHXdMMg10R7","question_number":49,"page":10,"question_text":"An online food company provides an Amazon API Gateway HTTP API to receive orders for partners. The API is integrated with an AWS Lambda function. The Lambda function stores the orders in an Amazon DynamoDB table.\\n\\nThe company expects to onboard additional partners. Some of the partners require additional Lambda functions to receive orders. The company has created an Amazon S3 bucket. The company needs to store all orders and updates in the S3 bucket for future analysis.\\n\\nHow can the developer ensure that all orders and updates are stored to Amazon S3 with the LEAST development effort?","choices":{"C":"Enable DynamoDB Streams on the DynamoDB table. Create a new Lambda function. Associate the stream\u2019s Amazon Resource Name (ARN) with the Lambda function. Configure the Lambda function to write to the S3 bucket as records appear in the table\'s stream.","D":"Modify the Lambda function to publish to a new Amazon Simple Notification Service (Amazon SNS) topic as the Lambda function receives orders. Subscribe a new Lambda function to the topic. Configure the new Lambda function to write to the S3 bucket as updates come through the topic.","A":"Create a new Lambda function and a new API Gateway API endpoint. Configure the new Lambda function to write to the S3 bucket. Modify the original Lambda function to post updates to the new API endpoint.","B":"Use Amazon Kinesis Data Streams to create a new data stream. Modify the Lambda function to publish orders to the data stream. Configure the data stream to write to the S3 bucket."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/117798-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-08-10 14:15:00","unix_timestamp":1691669700,"discussion_count":4,"discussion":[{"upvote_count":"9","comment_id":"977629","poster":"AWSdeveloper08","content":"Selected Answer: C\\nBy enabling DynamoDB Streams on the DynamoDB table, you can capture changes (orders and updates) to the table. Whenever a new order or an update is made to the table, a stream record is generated. You can then create a new Lambda function, associate the stream\'s ARN with this Lambda function, and configure it to write the stream records (orders and updates) to the S3 bucket. This approach leverages built-in features of DynamoDB and Lambda, minimizing the development effort required to achieve the desired outcome.","timestamp":"1707574500.0"},{"comment_id":"1216146","poster":"65703c1","upvote_count":"1","timestamp":"1732332660.0","content":"Selected Answer: C\\nC is the correct answer."},{"timestamp":"1721289780.0","content":"Selected Answer: C\\nThis is a streamlined and effective approach. Enabling DynamoDB Streams captures modifications to the DynamoDB table (such as new orders) and triggers a new Lambda function. This function can then write these changes to the S3 bucket. This approach requires minimal changes to the existing setup and leverages the integration between DynamoDB Streams and Lambda.","poster":"SerialiDr","upvote_count":"2","comment_id":"1125701"},{"comment_id":"1003495","poster":"Dushank","timestamp":"1710023760.0","content":"Selected Answer: C\\nEnabling DynamoDB Streams on the existing DynamoDB table and associating a new Lambda function to it would be a straightforward way to capture all changes (new orders and updates) in the DynamoDB table. The new Lambda function would automatically be triggered when a new record appears in the table\'s stream and could be configured to write this data to the S3 bucket. This is likely the least effort-intensive approach for meeting the requirement.","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:56:42.160Z","extraction_method":"api_direct_v1"},{"question_id":"vIFHpc2LA62XSD8ERSV2","question_number":50,"page":10,"question_text":"A company\u2019s website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours.\\n\\nWhich combination of steps will resolve the latency issue? (Choose two.)","choices":{"B":"Host the application code on AWS Lambda.","C":"Scale vertically by resizing the EC2 instances.","E":"Store the application\u2019s static content in Amazon S3.","D":"Create an Amazon CloudFront distribution to cache the static content.","A":"Double the Auto Scaling group\u2019s maximum number of servers."},"correct_answer":"DE","answer_ET":"DE","answers_community":["DE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122655-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 12:24:00","unix_timestamp":1696587840,"discussion_count":3,"discussion":[{"comment_id":"1216147","upvote_count":"2","timestamp":"1732332720.0","poster":"65703c1","content":"Selected Answer: DE\\nDE is the correct answer."},{"upvote_count":"3","content":"Selected Answer: DE\\nD. Create an Amazon CloudFront distribution to cache the static content: This is an effective solution. Amazon CloudFront is a content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency and high transfer speeds. Using CloudFront to cache static content closer to users can significantly reduce latency.\\n\\nE. Store the application\u2019s static content in Amazon S3: This is another effective solution. Amazon S3 can serve as a highly durable and scalable storage solution for static content. When combined with Amazon CloudFront, it provides an efficient way to manage and deliver static content with reduced latency.\\n\\nThe combination of steps that will best resolve the latency issue is:\\n\\nD. Create an Amazon CloudFront distribution to cache the static content.\\nE. Store the application\u2019s static content in Amazon S3.","poster":"SerialiDr","comment_id":"1125709","timestamp":"1721290140.0"},{"upvote_count":"4","timestamp":"1712399040.0","content":"Selected Answer: DE\\nOption (D), creating an Amazon CloudFront distribution to cache static content, is the most recommended solution. CloudFront is a global content delivery network (CDN) that can cache static content on servers distributed around the world. This can help significantly reduce latency for users around the world. Option (E), storing your application\'s static content in Amazon S3, can also help reduce latency. S3 is a high-performance object storage service that can be used to store static content.","comment_id":"1026423","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:56:42.160Z","extraction_method":"api_direct_v1"},{"question_id":"4oCpFFcjb3ZrH0L8wgtf","question_number":51,"page":11,"question_text":"A company has an Amazon S3 bucket containing premier content that it intends to make available to only paid subscribers of its website. The S3 bucket currently has default permissions of all objects being private to prevent inadvertent exposure of the premier content to non-paying website visitors.\\n\\nHow can the company limit the ability to download a premier content file in the S3 bucket to paid subscribers only?","choices":{"C":"Add a bucket policy that requires multi-factor authentication for requests to access the S3 bucket objects.","B":"Generate a pre-signed object URL for the premier content file when a paid subscriber requests a download.","D":"Enable server-side encryption on the S3 bucket for data protection against the non-paying website visitors.","A":"Apply a bucket policy that allows anonymous users to download the content from the S3 bucket."},"correct_answer":"B","answer_ET":"B","answers_community":["B (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122562-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:33:00","unix_timestamp":1696548780,"discussion_count":4,"discussion":[{"timestamp":"1721723580.0","poster":"BrainFried","upvote_count":"1","comment_id":"1253521","content":"Selected Answer: C\\nThe answer is NOT B.\\n\\nThe question states \\"limit the ABILITY TO DOWNLOAD a file in the S3 bucket to PAID SUBS ONLY\\"\\n\\nIf you choose B, it means that a paid sub can request the URL and then SHARE IT with non-paying customers. This will mean non-paying customers can DOWNLOAD the file using the URL.\\n\\nThe answer should be C - this enforces the user who downloads the file is a paying customer."},{"timestamp":"1716428040.0","upvote_count":"2","poster":"65703c1","comment_id":"1216148","content":"Selected Answer: B\\nB is the correct answer."},{"upvote_count":"3","poster":"SerialiDr","timestamp":"1705572720.0","comment_id":"1125716","content":"Selected Answer: B\\nB. Generate a pre-signed object URL for the premier content file when a paid subscriber requests a download: This is the most appropriate solution. A pre-signed URL grants temporary access to a private object stored in S3. The URL can be generated programmatically, and its validity can be limited to a short duration. This approach allows only those who have been provided with the URL (paid subscribers, in this case) to download the specific content."},{"timestamp":"1696587900.0","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nBy generating a pre-signed object URL for the main content file when a paid subscriber requests a download, the company can control who can download the file. The pre-signed object URL will be valid for a limited period of time and can only be used by the paid subscriber who requested the download.","comment_id":"1026426","upvote_count":"4","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:56:53.176Z","extraction_method":"api_direct_v1"},{"question_id":"ZgPtqn4iWBoXblzq451q","question_number":52,"page":11,"question_text":"A developer is creating an AWS Lambda function that searches for items from an Amazon DynamoDB table that contains customer contact information. The DynamoDB table items have the customer\u2019s email_address as the partition key and additional properties such as customer_type, name and job_title.\\n\\nThe Lambda function runs whenever a user types a new character into the customer_type text input. The developer wants the search to return partial matches of all the email_address property of a particular customer_type. The developer does not want to recreate the DynamoDB table.\\n\\nWhat should the developer do to meet these requirements?","choices":{"D":"Add a local secondary index (LSI) to the DynamoDB table with job_title as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property.","B":"Add a global secondary index (GSI) to the DynamoDB table with email_address as the partition key and customer_type as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.","A":"Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.","C":"Add a local secondary index (LSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122563-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:36:00","unix_timestamp":1696548960,"discussion_count":8,"discussion":[{"content":"Option B (Global Secondary Index with email_address as Partition Key):\\nAdd a global secondary index (GSI) to the DynamoDB table.\\nSet email_address as the partition key and customer_type as the sort key for the GSI.\\nPerform a query operation on the GSI using the begins_with key condition expression with the email_address property.","poster":"Saurabh04","upvote_count":"1","comment_id":"1262248","timestamp":"1723074360.0"},{"timestamp":"1716428160.0","poster":"65703c1","upvote_count":"3","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216149"},{"poster":"Examenee","comment_id":"1144482","upvote_count":"3","content":"Selected Answer: A\\nOnly global secondary indices can be added after a table has been created.","timestamp":"1707399240.0"},{"timestamp":"1705578480.0","poster":"SerialiDr","content":"Selected Answer: A\\nA. Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property: This approach is correct. By creating a GSI with customer_type as the partition key and email_address as the sort key, the developer can efficiently query items based on customer_type. The begins_with condition can be applied to the sort key (email_address) in the GSI, allowing for searches that return partial matches.","comment_id":"1125792","upvote_count":"1"},{"timestamp":"1704828120.0","comment_id":"1117780","content":"Selected Answer: A\\nA is correct","upvote_count":"1","poster":"RamyaMunipala"},{"upvote_count":"1","timestamp":"1697084100.0","comment_id":"1041347","content":"A is correct","poster":"Jing2023"},{"poster":"Patel_ajay745","comment_id":"1026548","upvote_count":"2","timestamp":"1696592040.0","content":"A\\n\\nAdd a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property."},{"comment_id":"1026427","upvote_count":"4","poster":"Digo30sp","timestamp":"1696588020.0","content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nBy adding a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key, the developer can perform a query operation on the GSI using the Begins_with key condition expression with the email_address property. This will return partial matches of all email_address properties of a specific customer_type."}],"answer_description":"","extracted_at":"2025-12-24T08:56:53.176Z","extraction_method":"api_direct_v1"},{"question_id":"XDcoV8EQ8acN9tc2Nu8E","question_number":53,"page":11,"question_text":"A developer is building an application that uses AWS API Gateway APIs, AWS Lambda functions, and AWS DynamoDB tables. The developer uses the AWS Serverless Application Model (AWS SAM) to build and run serverless applications on AWS. Each time the developer pushes changes for only to the Lambda functions, all the artifacts in the application are rebuilt.\\n\\nThe developer wants to implement AWS SAM Accelerate by running a command to only redeploy the Lambda functions that have changed.\\n\\nWhich command will meet these requirements?","choices":{"D":"sam sync --watch","A":"sam deploy --force-upload","C":"sam package","B":"sam deploy --no-execute-changeset"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122564-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:37:00","unix_timestamp":1696549020,"discussion_count":5,"discussion":[{"upvote_count":"8","poster":"Digo30sp","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nThe sam sync --watch command will only deploy the Lambda functions that have changed. This command uses AWS SAM Accelerate to compare the local versions of your Lambda functions to the versions deployed in AWS. If there are differences, the command deploys only the changed Lambda functions.","timestamp":"1712399280.0","comment_id":"1026429"},{"timestamp":"1732333080.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1216150"},{"content":"Correct answer is B.\\nTo deploy only the Lambda functions that have changed using AWS SAM Accelerate, the developer can use the sam deploy --no-execute-changeset command. This command will create an AWS CloudFormation change set without executing it, allowing the developer to preview the changes before deploying.","poster":"hayjaykay","timestamp":"1723938240.0","comment_id":"1152984","upvote_count":"1"},{"poster":"SerialiDr","content":"Selected Answer: D\\nD. sam sync --watch: This command is a part of SAM Accelerate and is used for rapid iterative development. When run, it watches for changes in the source files of your Lambda functions and APIs and deploys only those changes, rather than redeploying the entire stack. This greatly speeds up the deployment process during development.\\n\\nTherefore, to implement AWS SAM Accelerate and only redeploy the Lambda functions that have changed, the developer should use sam sync --watch. This command aligns with the goal of deploying changes rapidly and efficiently, focusing only on the components that have been modified.","comment_id":"1125801","upvote_count":"1","timestamp":"1721296800.0"},{"comment_id":"1040250","content":"Selected Answer: D\\nD is correct","timestamp":"1712817360.0","upvote_count":"1","poster":"dilleman"}],"answer_description":"","extracted_at":"2025-12-24T08:56:53.176Z","extraction_method":"api_direct_v1"},{"question_id":"WGjAzsI5qjlDQkQjnu81","question_number":54,"page":11,"question_text":"A developer is building an application that gives users the ability to view bank accounts from multiple sources in a single dashboard. The developer has automated the process to retrieve API credentials for these sources. The process invokes an AWS Lambda function that is associated with an AWS CloudFormation custom resource.\\n\\nThe developer wants a solution that will store the API credentials with minimal operational overhead.\\n\\nWhich solution will meet these requirements in the MOST secure way?","choices":{"A":"Add an AWS Secrets Manager GenerateSecretString resource to the CloudFormation template. Set the value to reference new credentials for the CloudFormation resource.","D":"Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter NoEcho attribute to true.","C":"Add an AWS Systems Manager Parameter Store resource to the CloudFormation template. Set the CloudFormation resource value to reference the new credentials. Set the resource NoEcho attribute to true.","B":"Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter type to SecureString."},"correct_answer":"B","answer_ET":"B","answers_community":["B (52%)","D (38%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122565-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:37:00","unix_timestamp":1696549020,"discussion_count":19,"discussion":[{"content":"Answer is B\\nA is not correct as the requirement asked to store API credentials, GenerateSecretString will create a random string as password. \\nC the API credential will be retrieved by the Lambda function, it is un-available to the template.\\nD no echo is a attribute of cloud formation template.","poster":"Jing2023","upvote_count":"17","timestamp":"1697088540.0","comment_id":"1041388"},{"content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nSolution (D) is the most secure because it stores the API credentials in AWS Secrets Manager, which is a managed service that provides secure, policy-controlled storage for secrets. The parameter\'s NoEcho attribute prevents the parameter value from being displayed in the console or request history.","timestamp":"1696588140.0","comment_id":"1026430","upvote_count":"7","poster":"Digo30sp"},{"comment_id":"1306892","content":"Selected Answer: B\\nSecureString parameters are encrypted both when stored in the Parameter Store (at rest) and while being transmitted (in transit) using AWS KMS (Key Management Service). This means that even if someone were to gain unauthorized access to the Parameter Store\'s underlying storage, they wouldn\'t be able to easily read the parameter\'s value.","upvote_count":"1","poster":"ShakthiGCP","timestamp":"1730716680.0"},{"poster":"Anandesh","timestamp":"1721217600.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/systems-manager/latest/APIReference/API_PutParameter.html","upvote_count":"1","comment_id":"1249570"},{"content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1216151","timestamp":"1716428520.0","upvote_count":"1","poster":"65703c1"},{"poster":"Melisa202401","comment_id":"1190801","upvote_count":"2","timestamp":"1712472240.0","content":"Selected Answer: C\\nI choose C, not choose A due to minimal cost\\nI dont understand why most of you choose B","comments":[{"upvote_count":"1","poster":"ShakthiGCP","content":"NoEcho is not very secure compared to SecureString which encrypts the sensitive data at rest and transit.","timestamp":"1730716860.0","comment_id":"1306893"}]},{"upvote_count":"2","timestamp":"1710648780.0","poster":"KarBiswa","content":"its B only\\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html#:~:text=You%20can%20also%20use%20SecureString%20parameters%20with%20other%20AWS%20services.%20In%20the%20following%20example%2C%20the%20Lambda%20function%20retrieves%20a%20SecureString%20parameter%20by%20using%20the%20GetParameters%20API.","comment_id":"1175578"},{"timestamp":"1708864920.0","poster":"KarBiswa","upvote_count":"1","comments":[{"poster":"KarBiswa","content":"Reverting the Option to B","upvote_count":"1","comment_id":"1175569","timestamp":"1710647760.0"}],"content":"Selected Answer: A\\nI will got with A.\\nBecausehttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html nullifying the B&D. Justifying A https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html","comment_id":"1158705"},{"content":"Selected Answer: B\\nThe solution that will meet the requirements is to use the AWS SDK ssm PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter type to SecureString. This way, the developer can store the API credentials with minimal operational overhead, as AWS Systems Manager Parameter Store provides secure and scalable storage for configuration data. The SecureString parameter type encrypts the parameter value with AWS Key Management Service (AWS KMS). The other options either involve adding additional resources to the CloudFormation template, which increases complexity and cost, or do not encrypt the parameter value, which reduces security.","poster":"KillThemWithKindness","upvote_count":"2","timestamp":"1708363260.0","comment_id":"1154146"},{"timestamp":"1705579500.0","poster":"SerialiDr","comment_id":"1125807","upvote_count":"1","content":"Selected Answer: B\\nB. Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter type to SecureString: This is a secure and operationally efficient solution. AWS Systems Manager Parameter Store can securely store parameters as SecureString, which encrypts the parameter value. The ssm:PutParameter operation can be used within the Lambda function to store the credentials directly after retrieval, minimizing operational overhead."},{"timestamp":"1704652440.0","comment_id":"1116089","upvote_count":"1","content":"Selected Answer: B\\nAnswer is B","poster":"Snape"},{"poster":"rrshah83","content":"Selected Answer: B\\nnoecho is CF feature, not ssm param store","upvote_count":"1","comment_id":"1111185","timestamp":"1704115080.0"},{"content":"Selected Answer: B\\nAgree with B - D will be stored in plain text, this is credentials so should be secure string","upvote_count":"2","poster":"Certified101","timestamp":"1702412760.0","comment_id":"1094934"},{"poster":"kaes","comment_id":"1080000","content":"Selected Answer: D\\nANS: D \\nNoEcho https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/82#issuecomment-517704282","timestamp":"1700915400.0","upvote_count":"3"},{"poster":"kaes","upvote_count":"1","comment_id":"1079999","content":"ANS: D \\nNoEcho https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/82#issuecomment-517704282","timestamp":"1700915340.0"},{"comment_id":"1053202","poster":"ut18","upvote_count":"2","timestamp":"1698186960.0","content":"Is B the correct answer?\\nSecureString isn\'t currently supported for AWS CloudFormation templates.\\nhttps://docs.aws.amazon.com/systems-manager/latest/APIReference/API_PutParameter.html"},{"poster":"Bolu_Jay","timestamp":"1698055020.0","content":"Answer is A\\nAWS Secrets Manager is specifically designed for securely storing sensitive information like API credentials, database passwords, and other secrets","comment_id":"1051693","upvote_count":"5"},{"comment_id":"1047066","content":"Selected Answer: B\\nI agree with Jing2023 answer","poster":"Nagasoracle","timestamp":"1697646300.0","upvote_count":"2"},{"timestamp":"1696933380.0","comment_id":"1039366","upvote_count":"4","poster":"dilleman","content":"Selected Answer: B\\nB should be correct since the type SecureString encrypts the value i think?"}],"answer_description":"","extracted_at":"2025-12-24T08:56:53.176Z","extraction_method":"api_direct_v1"},{"question_id":"rTp4NWwEzaFamTAI1ylB","question_number":55,"page":11,"question_text":"A developer is trying to get data from an Amazon DynamoDB table called demoman-table. The developer configured the AWS CLI to use a specific IAM user\u2019s credentials and ran the following command:\\n\\naws dynamodb get-item --table-name demoman-table --key \'{\\"id\\": {\\"N\\":\\"1993\\"}}\'\\n\\nThe command returned errors and no rows were returned.\\n\\nWhat is the MOST likely cause of these issues?","choices":{"A":"The command is incorrect; it should be rewritten to use put-item with a string argument.","B":"The developer needs to log a ticket with AWS Support to enable access to the demoman-table.","C":"Amazon DynamoDB cannot be accessed from the AWS CLI and needs to be called via the REST API.","D":"The IAM user needs an associated policy with read access to demoman-table."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122566-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:41:00","unix_timestamp":1696549260,"discussion_count":5,"discussion":[{"poster":"albert_kuo","timestamp":"1727315040.0","content":"Selected Answer: D\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": \\"dynamodb:GetItem\\",\\n \\"Resource\\": \\"arn:aws:dynamodb:us-east-1:123456789012:table/demoman-table\\"\\n }\\n ]\\n}","comment_id":"1289246","upvote_count":"1"},{"content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716428640.0","poster":"65703c1","upvote_count":"1","comment_id":"1216153"},{"upvote_count":"3","content":"Selected Answer: D\\nD is correct","poster":"Jing2023","comment_id":"1041358","timestamp":"1697084820.0"},{"comment_id":"1040251","upvote_count":"1","poster":"dilleman","timestamp":"1697006340.0","content":"Selected Answer: D\\nD is correct"},{"upvote_count":"4","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nThe command is correct and the demoman table exists. The most likely issue is that the IAM user does not have a policy associated with read access to the demoman table.\\n\\nTo resolve the issue, the developer must add a policy to the IAM user that grants read access to the demoman table.","poster":"Digo30sp","comment_id":"1026431","timestamp":"1696588200.0"}],"answer_description":"","extracted_at":"2025-12-24T08:56:53.176Z","extraction_method":"api_direct_v1"},{"question_id":"kEJ7IgYw2sZu7tG73CNy","question_number":56,"page":12,"question_text":"An organization is using Amazon CloudFront to ensure that its users experience low-latency access to its web application. The organization has identified a need to encrypt all traffic between users and CloudFront, and all traffic between CloudFront and the web application.\\n\\nHow can these requirements be met? (Choose two.)","choices":{"B":"Set the Origin Protocol Policy to \u201cHTTPS Only\u201d.","E":"Enable the CloudFront option Restrict Viewer Access.","D":"Set the Viewer Protocol Policy to \u201cHTTPS Only\u201d or \u201cRedirect HTTP to HTTPS\u201d.","C":"Set the Origin\u2019s HTTP Port to 443.","A":"Use AWS KMS to encrypt traffic between CloudFront and the web application."},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122567-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:42:00","unix_timestamp":1696549320,"discussion_count":5,"discussion":[{"poster":"SerialiDr","upvote_count":"5","comment_id":"1125831","content":"Selected Answer: BD\\nB. Set the Origin Protocol Policy to \u201cHTTPS Only\u201d: This setting ensures that all traffic between CloudFront and the web application (origin) is encrypted. By setting the Origin Protocol Policy to \\"HTTPS Only,\\" CloudFront will only connect to the origin over HTTPS, ensuring encryption of data in transit.\\nD. Set the Viewer Protocol Policy to \u201cHTTPS Only\u201d or \u201cRedirect HTTP to HTTPS\u201d: This setting is crucial for ensuring that all traffic between the users (viewers) and CloudFront is encrypted. By setting the Viewer Protocol Policy to \\"HTTPS Only\\" or \\"Redirect HTTP to HTTPS,\\" CloudFront ensures that user requests are either only served over HTTPS or automatically redirected from HTTP to HTTPS.","timestamp":"1721298960.0"},{"upvote_count":"1","timestamp":"1732333500.0","comment_id":"1216154","poster":"65703c1","content":"Selected Answer: BD\\nBD is the correct answer."},{"upvote_count":"2","content":"Selected Answer: BD\\nBD: Protocol and Viewer protocol policy, see\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html","comment_id":"1084882","timestamp":"1717202340.0","poster":"Jeff1719"},{"timestamp":"1712817660.0","poster":"dilleman","content":"Selected Answer: BD\\nB and D are the correct ones.\\nB: Setting the Origin Protocol Policy to \u201cHTTPS Only\u201d ensures that CloudFront always uses HTTPS to connect to the origin, which is the web application in this scenario.\\nD: Setting the Viewer Protocol Policy to \u201cHTTPS Only\u201d ensures that CloudFront will only serve requests over HTTPS. Setting it to \u201cRedirect HTTP to HTTPS\u201d ensures that any HTTP request from viewers is redirected to HTTPS.","upvote_count":"4","comment_id":"1040253"},{"content":"Selected Answer: BD\\nThe correct answers are (B) and (D).\\n\\nTo meet the requirement to encrypt all traffic between users and CloudFront, your organization must set the Viewer Protocol Policy to \u201cHTTPS Only\u201d or \u201cRedirect HTTP to HTTPS\u201d. This will force users to use HTTPS to connect to CloudFront.\\n\\nTo meet the requirement to encrypt all traffic between CloudFront and the web application, your organization must set the Origin Protocol Policy to \u201cHTTPS Only\u201d. This will force CloudFront to use HTTPS to connect to the web application.","comment_id":"1026432","timestamp":"1712399460.0","poster":"Digo30sp","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:57:04.202Z","extraction_method":"api_direct_v1"},{"question_id":"YvQAnlrr6yCpvSH4V0ND","question_number":57,"page":12,"question_text":"A developer is deploying an AWS Lambda function The developer wants the ability to return to older versions of the function quickly and seamlessly.\\nHow can the developer achieve this goal with the LEAST operational overhead?","choices":{"A":"Use AWS OpsWorks to perform blue/green deployments.","D":"Use AWS CodePipeline for deployments and rollbacks.","B":"Use a function alias with different versions.","C":"Maintain deployment packages for older versions in Amazon S3."},"correct_answer":"B","answer_ET":"B","answers_community":["B (95%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102742-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-15 23:35:00","unix_timestamp":1678919700,"discussion_count":10,"discussion":[{"poster":"Untamables","timestamp":"1679398980.0","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html","upvote_count":"7","comment_id":"845568"},{"poster":"sumanshu","upvote_count":"2","content":"Selected Answer: B\\nA) Eliminated - OpsWorks is unnecessary for Lambda function deployments.Blue/green deployments are more suited for EC2 or ECS applications, not for a simple Lambda rollback.\\nB) Correct - Quickly switch the alias to an older version\\nC) Eliminated - Requires manual work to download and redeploy older versions.\\nD) Eliminated - CodePipeline introduces unnecessary complexity","comment_id":"1329814","timestamp":"1734755580.0"},{"content":"Selected Answer: B\\nkeyword: LEAST operational overhead\\n\\n=> discard D: it does more work, so cost for many works also increase\\n=> discard C: it makes effort for manual work, adding operational overhead and delays.\\n=> Discard A: Designed for managing server configurations, not for managing lambda function\\n\\nB: most seamless, only change version by pointing an alias (eg: production) to specific Lambda Version. On the other hand, it\'s free","poster":"trieudo","upvote_count":"1","timestamp":"1734049560.0","comment_id":"1325923"},{"upvote_count":"1","content":"Selected Answer: A\\nI am not sure if the question is about which deployment strategy to choose from if we want to roll back seamlessly once deployed. Or is the question about how to manage the deployment versions to be able to roll back. does anyone has similar doubts ? please help , thanks","timestamp":"1733455860.0","poster":"f271c23","comment_id":"1322608"},{"upvote_count":"2","poster":"65703c1","comment_id":"1214993","timestamp":"1716299520.0","content":"Selected Answer: B\\nB is the correct answer."},{"timestamp":"1711535820.0","upvote_count":"1","poster":"mghectorenjoyer69","comment_id":"1183999","content":"c ra unga amma"},{"timestamp":"1684055280.0","content":"B is the least overhead solution","poster":"ubiqinon","comment_id":"897425","upvote_count":"3"},{"timestamp":"1681220760.0","upvote_count":"2","poster":"zk1200","content":"Selected Answer: B\\nI considered D as well which refers to using CodeDeploy. however using codedeploy adds more work. So alias makes more sense.","comment_id":"867361"},{"comment_id":"858008","poster":"ihta_2031","timestamp":"1680359160.0","upvote_count":"4","content":"Selected Answer: B\\nlambda function version => alias"},{"timestamp":"1678919700.0","poster":"aragon_saa","upvote_count":"3","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/96149-exam-aws-certified-developer-associate-topic-1-question-441/","comment_id":"840375"}],"answer_description":"","extracted_at":"2025-12-24T08:57:04.202Z","extraction_method":"api_direct_v1"},{"question_id":"6jgfZtlFpVZ1DLldQRwg","question_number":58,"page":12,"question_text":"A developer is planning to migrate on-premises company data to Amazon S3. The data must be encrypted, and the encryption keys must support automatic annual rotation. The company must use AWS Key Management Service (AWS KMS) to encrypt the data.\\n\\nWhich type of keys should the developer use to meet these requirements?","choices":{"D":"Symmetric customer managed keys with imported key material","C":"Asymmetric customer managed keys with key material that is generated by AWS","B":"Symmetric customer managed keys with key material that is generated by AWS","A":"Amazon S3 managed keys"},"correct_answer":"B","answer_ET":"B","answers_community":["B (72%)","A (28%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122571-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:54:00","unix_timestamp":1696550040,"discussion_count":12,"discussion":[{"timestamp":"1713000840.0","poster":"PrakashM14","comment_id":"1042519","content":"Selected Answer: B\\nAsymmetric keys (option C) are typically used for different use cases, such as digital signatures and key pairs, and may not be as suitable for automatic rotation in the described scenario.\\n\\nImported key material (option D) means that you bring your own key material, and AWS KMS doesn\'t support automatic rotation for such keys.\\n\\nAmazon S3 managed keys (option A) are used specifically for Amazon S3 and don\'t support automatic rotation.\\n\\nso, option B is correct","upvote_count":"13"},{"comment_id":"1216156","upvote_count":"1","poster":"65703c1","timestamp":"1732333680.0","content":"Selected Answer: B\\nB is the correct answer."},{"poster":"SerialiDr","timestamp":"1725198840.0","content":"Selected Answer: B\\nThis option allows for automatic rotation of the keys, aligning with AWS best practices for key management and security. AWS KMS supports key rotation, which can be configured to occur automatically on an annual basis for customer managed keys. This ensures that data remains encrypted with a key that is periodically rotated, enhancing the security posture of the data stored in Amazon S3.","comment_id":"1163612","upvote_count":"2"},{"upvote_count":"1","timestamp":"1724583420.0","comment_id":"1158715","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html Its a symmetric key rotation","poster":"KarBiswa"},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html\\n\\nServer-side encryption protects data at rest. Amazon S3 encrypts each object with a unique key. As an additional safeguard, it encrypts the key itself with a key that it rotates regularly. Amazon S3 server-side encryption uses 256-bit Advanced Encryption Standard Galois/Counter Mode (AES-GCM) to encrypt all uploaded objects.","comment_id":"1138649","poster":"konieczny69","upvote_count":"3","timestamp":"1722603180.0"},{"poster":"SerialiDr","comment_id":"1125840","upvote_count":"2","content":"Selected Answer: B\\nB. Symmetric customer managed keys with key material that is generated by AWS: This option allows the developer to create and manage their own encryption keys in AWS KMS, with AWS generating the key material. AWS KMS supports automatic rotation of customer managed keys. You can configure the key to rotate automatically once per year.","timestamp":"1721299320.0"},{"timestamp":"1718218620.0","content":"Selected Answer: B\\nB is correct, it must use KMS","upvote_count":"1","poster":"Certified101","comment_id":"1094960"},{"poster":"ShawnWon","content":"Option A (Amazon S3 managed keys) does not involve using AWS Key Management Service (AWS KMS) directly. Instead, it relies on Amazon S3 to manage the keys for server-side encryption. If the requirement is specifically to use AWS KMS for encryption, then Option A would not meet that requirement.","upvote_count":"1","comment_id":"1075143","timestamp":"1716171840.0"},{"comment_id":"1055925","upvote_count":"1","poster":"wonder_man","timestamp":"1714264560.0","content":"Selected Answer: B\\nOnly this option supports AWS KMS with the key rotation"},{"comment_id":"1042517","timestamp":"1713000720.0","content":"Asymmetric keys (option C) are typically used for different use cases, such as digital signatures and key pairs, and may not be as suitable for automatic rotation in the described scenario.\\n\\nImported key material (option D) means that you bring your own key material, and AWS KMS doesn\'t support automatic rotation for such keys.\\n\\nAmazon S3 managed keys (option A) are used specifically for Amazon S3 and don\'t support automatic rotation.\\n\\nso, option B is correct","poster":"PrakashM14","upvote_count":"1"},{"content":"Selected Answer: A\\nA: https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html","upvote_count":"2","comment_id":"1040256","timestamp":"1712817840.0","poster":"dilleman"},{"timestamp":"1712399880.0","content":"Selected Answer: A\\nA) Amazon S3 Managed Keys\\nhttps://docs.aws.amazon.com/pt_br/AmazonS3/latest/userguide/serv-side-encryption.html","upvote_count":"3","comment_id":"1026438","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:57:04.202Z","extraction_method":"api_direct_v1"},{"question_id":"OyJH1gSYtUxCBFFzvnzh","question_number":59,"page":12,"question_text":"A team of developers is using an AWS CodePipeline pipeline as a continuous integration and continuous delivery (CI/CD) mechanism for a web application. A developer has written unit tests to programmatically test the functionality of the application code. The unit tests produce a test report that shows the results of each individual check. The developer now wants to run these tests automatically during the CI/CD process.\\n\\nWhich solution will meet this requirement with the LEAST operational effort?","choices":{"D":"Add a new stage to the pipeline. Use Jenkins as the provider. Configure CodePipeline to use Jenkins to run the unit tests. Write a Jenkinsfile that fails the stage if any test does not pass. Use the test report plugin for Jenkins to integrate the report with the Jenkins dashboard. View the test results in Jenkins. Resolve any issues.","B":"Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage after the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.","A":"Write a Git pre-commit hook that runs the tests before every commit. Ensure that each developer who is working on the project has the pre-commit hook installed locally. Review the test report and resolve any issues before pushing changes to AWS CodeCommit.","C":"Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage before the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues."},"correct_answer":"C","answer_ET":"C","answers_community":["C (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122569-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:46:00","unix_timestamp":1696549560,"discussion_count":8,"discussion":[{"poster":"SerialiDr","timestamp":"1705598760.0","comment_id":"1126076","upvote_count":"6","content":"Selected Answer: C\\nThis is the most efficient and integrated approach. AWS CodeBuild is fully integrated with AWS CodePipeline and can be used to run unit tests as part of the CI/CD process. Placing the testing stage before deployment ensures that only tested code is deployed. The buildspec can be configured to fail the build if tests do not pass, and CodeBuild\'s test reports feature allows for easy viewing and analysis of test results."},{"comment_id":"1216458","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716460320.0"},{"poster":"xxxx1","timestamp":"1709795700.0","content":"c is the correct answer","comment_id":"1167739","upvote_count":"1"},{"comment_id":"1056030","upvote_count":"1","content":"Correct answer: B","poster":"NinjaCloud","timestamp":"1698477660.0"},{"content":"c is the correct answer","comment_id":"1042516","timestamp":"1697189460.0","poster":"Gold07","upvote_count":"1"},{"timestamp":"1697035920.0","upvote_count":"2","poster":"Cerakoted","comment_id":"1040782","content":"Selected Answer: C\\nI think C is correct.\\nTypical consists of stages are..\\nBuild -> Test -> Deploy(test) -> Load Test -> and others"},{"comment_id":"1039376","content":"Selected Answer: C\\nC should be correct.","upvote_count":"3","poster":"dilleman","timestamp":"1696934160.0"},{"comments":[{"upvote_count":"1","poster":"04075e0","timestamp":"1730675520.0","comment_id":"1306677","content":"definitely not B, since nobody doing tests after deployment. No sense"},{"comments":[{"upvote_count":"1","poster":"Dibaal","timestamp":"1698247380.0","content":"funny \ud83d\ude01","comment_id":"1053828"}],"timestamp":"1696934100.0","poster":"dilleman","content":"This does not make sense. Why run the tests after the deploy when you can choose option C, to run the tests before the deploy? C should be best practice and the same amount of effort as B.","upvote_count":"5","comment_id":"1039375"}],"content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nSolution (B) is the simplest and requires the least operational effort. It involves adding a new stage to the CodePipeline pipeline that uses AWS CodeBuild to run the unit tests. The CodeBuild stage can be configured to fail if any tests fail. The CodeBuild test report can be integrated into the CodeBuild console so that developers can view test results.","upvote_count":"1","timestamp":"1696588740.0","poster":"Digo30sp","comment_id":"1026440"}],"answer_description":"","extracted_at":"2025-12-24T08:57:04.202Z","extraction_method":"api_direct_v1"},{"question_id":"DMJBbl4xyRvoGA61SwWt","question_number":60,"page":12,"question_text":"A company has multiple Amazon VPC endpoints in the same VPC. A developer needs to configure an Amazon S3 bucket policy so users can access an S3 bucket only by using these VPC endpoints.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create a single S3 bucket policy that has the aws:SourceVpc value and in the StringNotEquals condition to use VPC ID.","C":"Create a single S3 bucket policy that has the aws:SourceVpce value and in the StringNotEquals condition to use vpce*.","D":"Create a single S3 bucket policy that has multiple aws:sourceVpce value in the StringNotEquals condition. Repeat for all the VPC endpoint IDs.","A":"Create multiple S3 bucket polices by using each VPC endpoint ID that have the aws:SourceVpce value in the StringNotEquals condition."},"correct_answer":"D","answer_ET":"D","answers_community":["D (87%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122572-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:55:00","unix_timestamp":1696550100,"discussion_count":12,"discussion":[{"content":"I don\'t think any of the options is correct. Seriously StringNotEquals not StringEquals?","poster":"CrescentShared","comments":[{"comment_id":"1089591","timestamp":"1701884520.0","upvote_count":"1","poster":"shake76","comments":[{"content":"StringNotEqual is for the deny of outher that mentioned vpce.\\n\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Id\\": \\"Policy1415115909152\\",\\n \\"Statement\\": [\\n {\\n \\"Sid\\": \\"Access-to-specific-VPCE-only\\",\\n \\"Principal\\": \\"*\\",\\n \\"Action\\": \\"s3:*\\",\\n \\"Effect\\": \\"Deny\\",\\n \\"Resource\\": [\\"arn:aws:s3:::awsexamplebucket1\\",\\n \\"arn:aws:s3:::awsexamplebucket1/*\\"],\\n \\"Condition\\": {\\n \\"StringNotEquals\\": {\\n \\"aws:SourceVpce\\": \\"vpce-1a2b3c4d\\"\\n }\\n }\\n }\\n ]\\n}","comment_id":"1172425","upvote_count":"2","timestamp":"1710325140.0","comments":[{"timestamp":"1722375960.0","upvote_count":"1","poster":"examtopics111","comment_id":"1258424","content":"for bucket policy, if vpce isnt explicitly allowed, it\'s by default denied anyway so it should have been allow string equal vpce?"}],"poster":"vipyodha"}],"content":"I think the same \\"A developer needs to configure an Amazon S3 bucket policy so users can access an S3 bucket only by using these VPC endpoints\\""}],"upvote_count":"7","comment_id":"1070055","timestamp":"1699942740.0"},{"poster":"dilleman","upvote_count":"7","comment_id":"1039386","timestamp":"1696934700.0","content":"Selected Answer: D\\nC works as well but It is a broad solution I think it\'s better practice to use D and specify the exact endpoints that the user can access from. \\n\\"aws:sourceVpce\\": [\\"vpce-id1\\", \\"vpce-id2\\", \\"...\\"]"},{"timestamp":"1727323680.0","comment_id":"1289279","content":"Selected Answer: D\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Sid\\": \\"DenyAccessIfNotFromSpecificVPCEndpoints\\",\\n \\"Effect\\": \\"Deny\\",\\n \\"Principal\\": \\"*\\",\\n \\"Action\\": \\"s3:*\\",\\n \\"Resource\\": [\\n \\"arn:aws:s3:::your-bucket-name\\",\\n \\"arn:aws:s3:::your-bucket-name/*\\"\\n ],\\n \\"Condition\\": {\\n \\"StringNotEquals\\": {\\n \\"aws:SourceVpce\\": [\\n \\"vpce-0123456789abcdef0\\",\\n \\"vpce-0fedcba9876543210\\",\\n \\"vpce-0a1b2c3d4e5f6a7b8\\"\\n ]\\n }\\n }\\n }\\n ]\\n}","upvote_count":"3","poster":"albert_kuo"},{"comment_id":"1216460","timestamp":"1716460500.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html typically explained the same scenario. D beyond doubt.","poster":"KarBiswa","upvote_count":"2","timestamp":"1708872660.0","comment_id":"1158875"},{"upvote_count":"1","timestamp":"1706842440.0","content":"Selected Answer: D\\nD, based on the following documentation:\\n\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html#example-bucket-policies-restrict-accesss-vpc-endpoint","poster":"joshnort","comment_id":"1138068"},{"content":"Why it\'s StringNotEquals instead of StringEquals? Is the question wrong or my English is too bad to understand this?","upvote_count":"2","timestamp":"1706247720.0","comments":[{"content":"It is StringNotEqual, means if source vpce is not this then deny access\\n\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Id\\": \\"Policy1415115909152\\",\\n \\"Statement\\": [\\n {\\n \\"Sid\\": \\"Access-to-specific-VPCE-only\\",\\n \\"Principal\\": \\"*\\",\\n \\"Action\\": \\"s3:*\\",\\n \\"Effect\\": \\"Deny\\",\\n \\"Resource\\": [\\"arn:aws:s3:::awsexamplebucket1\\",\\n \\"arn:aws:s3:::awsexamplebucket1/*\\"],\\n \\"Condition\\": {\\n \\"StringNotEquals\\": {\\n \\"aws:SourceVpce\\": \\"vpce-1a2b3c4d\\"\\n }\\n }\\n }\\n ]\\n}","upvote_count":"3","comment_id":"1172423","timestamp":"1710324780.0","poster":"vipyodha"}],"comment_id":"1132281","poster":"CrescentShared"},{"upvote_count":"2","poster":"SerialiDr","comment_id":"1126079","content":"Selected Answer: D\\nThis option is the closest to being correct, but it should use StringEquals instead of StringNotEquals. The correct approach is to use a single S3 bucket policy with a condition that includes aws:SourceVpce with StringEquals for the specific VPC endpoint IDs. This will ensure that access is allowed only from those specified endpoints.","timestamp":"1705599060.0"},{"comment_id":"1111199","poster":"rrshah83","upvote_count":"2","timestamp":"1704116040.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html#example-bucket-policies-restrict-access-vpc"},{"comment_id":"1094963","upvote_count":"1","content":"Selected Answer: D\\nD is correct","poster":"Certified101","timestamp":"1702414740.0"},{"comments":[{"poster":"ekutas","upvote_count":"1","content":"D says \\"aws:sourceVpce value in the StringNotEquals condition\\". StringNotEquals won\'t work, it deny access for specified VPC ids","comment_id":"1060918","comments":[{"poster":"ekutas","timestamp":"1698960120.0","upvote_count":"2","content":"Od course if we use \\"Effect\\": \\"Allow\\"))","comment_id":"1060920"}],"timestamp":"1698959700.0"}],"upvote_count":"2","comment_id":"1042699","poster":"PrakashM14","timestamp":"1697203140.0","content":"Selected Answer: D\\nin option C :\\nCondition\\": {\\n \\"StringNotEqualsIfExists\\": {\\n \\"aws:sourceVpce\\": \\"vpce*\\",\\n }\\n}\\nit might Deny access from all VPC endpoints.\\n\\nso the ans is D"},{"comment_id":"1026441","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nSolution (C) is the simplest and will meet the company\'s requirements. It creates a single S3 bucket policy that has the value aws:SourceVpce and the StringNotEquals condition to use vpce*. This will only allow users who are using a VPC endpoint in the same VPC to access the S3 bucket.","upvote_count":"1","poster":"Digo30sp","timestamp":"1696588800.0"}],"answer_description":"","extracted_at":"2025-12-24T08:57:04.202Z","extraction_method":"api_direct_v1"},{"question_id":"HsutMJAWdrKQ5bcbeU9d","question_number":61,"page":13,"question_text":"A company uses a custom root certificate authority certificate chain (Root CA Cert) that is 10 KB in size to generate SSL certificates for its on-premises HTTPS endpoints. One of the company\u2019s cloud-based applications has hundreds of AWS Lambda functions that pull data from these endpoints. A developer updated the trust store of the Lambda execution environment to use the Root CA Cert when the Lambda execution environment is initialized. The developer bundled the Root CA Cert as a text file in the Lambda deployment bundle.\\n\\nAfter 3 months of development, the Root CA Cert is no longer valid and must be updated. The developer needs a more efficient solution to update the Root CA Cert for all deployed Lambda functions. The solution must not include rebuilding or updating all Lambda functions that use the Root CA Cert. The solution must also work for all development, testing, and production environments. Each environment is managed in a separate AWS account.\\n\\nWhich combination of steps should the developer take to meet these requirements MOST cost-effectively? (Choose two.)","choices":{"E":"Refactor the Lambda code to load the Root CA Cert from the Root CA Cert\u2019s location. Modify the runtime trust store outside the Lambda function handler.","B":"Store the Root CA Cert as a SecureString parameter in AWS Systems Manager Parameter Store. Create a resource-based policy. Add IAM users to allow access to the policy.","D":"Refactor the Lambda code to load the Root CA Cert from the Root CA Cert\u2019s location. Modify the runtime trust store inside the Lambda function handler.","A":"Store the Root CA Cert as a secret in AWS Secrets Manager. Create a resource-based policy. Add IAM users to allow access to the secret.","C":"Store the Root CA Cert in an Amazon S3 bucket. Create a resource-based policy to allow access to the bucket."},"correct_answer":"AE","answer_ET":"AE","answers_community":["AE (41%)","CE (24%)","BE (20%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122570-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:50:00","unix_timestamp":1696549800,"discussion_count":21,"discussion":[{"comment_id":"1044271","upvote_count":"11","comments":[{"upvote_count":"7","timestamp":"1701386400.0","comment_id":"1084831","poster":"not_a_bot_definitely","content":"Secrets Manager is not cost-effective compared to option C - S3 bucket.\\nQuestion clearly asks \\"MOST cost-effective\\"\\n\\nhttps://www.examtopics.com/discussions/amazon/view/96242-exam-aws-certified-developer-associate-topic-1-question-429/\\n\\nSo answer is CE"}],"timestamp":"1697383800.0","poster":"kiwtirApp","content":"Selected Answer: AE\\nThe max size of storage in Secrets Manager is 10kb. For SSM Parameter store, it\'s 8Kb.\\n\\nCorrect options are A and E."},{"poster":"thalasi","timestamp":"1747643460.0","upvote_count":"1","comment_id":"1570138","content":"Selected Answer: AE\\nIn AWS, a Root CA certificate (Public CA) can be stored using either AWS Secrets Manager or AWS Certificate Manager (ACM). Secrets Manager is a secure way to store sensitive data like certificates and API keys, while ACM helps manage public and private certificates for use within AWS."},{"poster":"ShakthiGCP","timestamp":"1730846700.0","upvote_count":"1","comment_id":"1307601","content":"Selected Answer: AE\\nbeyond cost effective. AWS always recommend the secured way. in that case, it will be A and E"},{"timestamp":"1730028180.0","content":"In both A and B why does it say IAM user? should it not be IAM role? IAM role for Lambda to access them?","poster":"9d8dd9c","upvote_count":"1","comment_id":"1303557","comments":[{"comment_id":"1571490","upvote_count":"1","content":"States on premises , and not mention IAM anywhere . So guessing that\'s why its USER , not Role .","poster":"AlmeroSenior","timestamp":"1747973640.0"}]},{"poster":"65703c1","comment_id":"1216465","timestamp":"1716461100.0","upvote_count":"1","content":"Selected Answer: AE\\nAE is the correct answer."},{"content":"Selected Answer: BE\\nThis solution will meet the requirements by storing the Root CA Cert as a Secure String parameter in AWS Systems Manager Parameter Store, which is a secure and scalable service for storing and managing configuration data and secrets. The resource-based policy will allow IAM users in different AWS accounts and environments to access the parameter without requiring cross-account roles or permissions. The Lambda code will be refactored to load the Root CA Cert from the parameter store and modify the runtime trust store outside the Lambda function handler, which will improve performance and reduce latency by avoiding repeated calls to Parameter Store and trust store modifications for each invocation of the Lambda function.","comment_id":"1190787","poster":"Melisa202401","timestamp":"1712470260.0","upvote_count":"3"},{"timestamp":"1710673200.0","comment_id":"1175737","content":"Selected Answer: CE\\nCost effective, use S3 instead of Secrets Manager.","poster":"yingying920928","upvote_count":"2"},{"upvote_count":"1","timestamp":"1708873440.0","poster":"KarBiswa","content":"Selected Answer: AE\\nAfter going through the links :\\nA : https://aws.amazon.com/blogs/security/use-aws-secrets-manager-to-simplify-the-management-of-private-certificates/\\nE : https://docs.aws.amazon.com/acm/latest/userguide/renew-private-cert.html","comment_id":"1158882"},{"timestamp":"1705761420.0","content":"Selected Answer: CE\\nC.E.\\nSecrets Manager is the most expensive amongst all options. S3 seems more cost-effective. \\nB. is incorrect, because at the end it states about accessing to the policy, not to the parameter itself.","poster":"dostonbekabdullaev","upvote_count":"3","comment_id":"1127332"},{"timestamp":"1705599780.0","poster":"SerialiDr","upvote_count":"1","comment_id":"1126085","content":"Selected Answer: BE\\nAlso AE works, but BE is more cost effective.","comments":[{"content":"Pay attention on this part \\"Add IAM users to allow access to the policy.\\" It should give an access to the parameter, not to the policy.","poster":"dostonbekabdullaev","upvote_count":"3","comment_id":"1127329","timestamp":"1705761300.0"}]},{"poster":"CalvinL4","content":"CE should be the answer. The string size is over 4/8 kb which the parameter store allows. So, the parameter store is out. Comparing the price, s3 is much cheaper than secrets manager.","upvote_count":"2","comment_id":"1114306","timestamp":"1704435000.0"},{"content":"Selected Answer: AE\\nhttps://aws.amazon.com/blogs/security/use-aws-secrets-manager-to-simplify-the-management-of-private-certificates/","comment_id":"1111208","poster":"rrshah83","upvote_count":"1","timestamp":"1704116400.0"},{"content":"Selected Answer: AE\\ncan you do resource based policies for param store?","upvote_count":"1","timestamp":"1704116280.0","comment_id":"1111204","poster":"rrshah83"},{"poster":"Hanny","upvote_count":"1","comment_id":"1092985","content":"Selected Answer: CE\\nhttps://www.examtopics.com/discussions/amazon/view/96242-exam-aws-certified-developer-associate-topic-1-question-429/","timestamp":"1702255020.0"},{"upvote_count":"1","poster":"tqiu654","content":"Selected Answer: BD\\nCHatGPT: BD","comment_id":"1086569","timestamp":"1701575220.0"},{"comment_id":"1055928","content":"Selected Answer: CE\\nI can\'t see why using AWS Secrets Manager can be cost-effective, so I\'m voting for C","timestamp":"1698454200.0","poster":"wonder_man","upvote_count":"4"},{"comment_id":"1050862","upvote_count":"2","poster":"Rameez1","timestamp":"1697992260.0","content":"Selected Answer: BE\\nUsing Parameter store is more cost effective then secrets manager."},{"comment_id":"1045935","timestamp":"1697543220.0","poster":"TallManDan","upvote_count":"4","content":"Secrets Manager is an additional cost over Parameter Store. So if you see a question that looks for the least amount of overhead, Secrets Manager is much more versatile. But for least amount of cost, Parameter Store is included with the service for no additional costs."},{"poster":"PrakashM14","content":"Selected Answer: BC\\nWhy the remaining answers are not suitable:\\n\\nA. Storing the Root CA Cert in AWS Secrets Manager is a valid option, but Secrets Manager is typically used for managing sensitive information like database credentials. It might be overkill for just a certificate, and using Systems Manager Parameter Store or S3 is a more straightforward solution in this case.\\n\\nD. Refactoring the Lambda code to load the Root CA Cert from its location and modifying the runtime trust store inside the Lambda function handler would require code changes and rebuilding the Lambda functions, which contradicts the requirement of not updating all Lambda functions.\\n\\nE. Refactoring the Lambda code to load the Root CA Cert from its location and modifying the runtime trust store outside the Lambda function handler may still require code changes and may not be as scalable or easily manageable as using Systems Manager Parameter Store or S3.","comment_id":"1042729","timestamp":"1697205900.0","upvote_count":"3"},{"timestamp":"1696935060.0","content":"Selected Answer: BE\\nB. AWS Systems Manager Parameter Store can store data both in plain text and encrypted format (using the SecureString type). It\'s a cost-effective solution for centralized configuration management across environments and accounts.\\nE. Modifying the runtime trust store outside the Lambda function handler ensures that the trust store is modified only once when the Lambda container is initialized, making it a more efficient approach than option D where it\'s initlialized in every lambda function.","comment_id":"1039397","upvote_count":"2","poster":"dilleman"},{"content":"Selected Answer: AD\\nthe correct answers are (A) and (D).\\n\\nSolution (A) is the most cost-effective as it uses AWS Secrets Manager, which is a managed service. The developer can simply store the root CA certificate as a secret in Secrets Manager and create a resource-based policy to allow IAM users to access the secret. This does not require any modifications to the Lambda code.\\n\\nSolution (D) is also cost-effective as it does not require any modifications to the Lambda code. The developer can simply refactor the Lambda code to load the root CA certificate from the root CA certificate location. This can be done by modifying the runtime trust store outside of the Lambda function handler.","timestamp":"1696588860.0","comment_id":"1026447","poster":"Digo30sp","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T08:57:15.249Z","extraction_method":"api_direct_v1"},{"question_id":"kkLoUtsXK8id31uVeOzy","question_number":62,"page":13,"question_text":"A developer maintains applications that store several secrets in AWS Secrets Manager. The applications use secrets that have changed over time. The developer needs to identify required secrets that are still in use. The developer does not want to cause any application downtime.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Create a secretsmanager-secret-unused AWS Config managed rule. Create an Amazon EventBridge rule to initiate notifications when the AWS Config managed rule is met.","D":"Configure AWS X-Ray for the applications. Create a sampling rule to match the GetSecretValue Secrets Manager API operation requests.","A":"Configure an AWS CloudTrail log file delivery to an Amazon S3 bucket. Create an Amazon CloudWatch alarm for the GetSecretValue Secrets Manager API operation requests.","C":"Deactivate the applications secrets and monitor the applications error logs temporarily."},"correct_answer":"B","answer_ET":"B","answers_community":["B (71%)","A (29%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122573-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:56:00","unix_timestamp":1696550160,"discussion_count":14,"discussion":[{"timestamp":"1699156680.0","poster":"chris_777","comment_id":"1062581","content":"Selected Answer: B\\nI think B is correct https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-secret-unused.html\\n\\nA. could work but requires additional work to identify unused secrets.\\nC. is too risky and could cause downtime.\\nD. not the right use case","upvote_count":"7"},{"timestamp":"1730028600.0","comment_id":"1303560","poster":"9d8dd9c","upvote_count":"1","content":"With option A, if you want to know what secrets are not used anymore for the past 90 days, then you need to wait 90 days, get a list of the ones that are used then minus this from the total list... but option B returns the unused list for the last 90 days directly"},{"content":"source copilot: Why Option A is Better:\\n1. Real-Time Monitoring: By using CloudTrail and CloudWatch, you can monitor GetSecretValue API calls in real-time, providing immediate insights into which secrets are being accessed.\\n2. Detailed Logging: CloudTrail logs provide detailed information about each API call, including the source IP, user, and timestamp, which can help identify the specific applications or instances accessing the secrets.\\n3. Customizable Alerts: CloudWatch alarms can be configured to trigger notifications based on specific patterns or thresholds, offering more flexibility and control over monitoring.","upvote_count":"1","comment_id":"1293245","poster":"MasoudK","timestamp":"1728069120.0"},{"content":"Why Option B Might Not Be the Best Choice:\\n1. Rule Limitation: The secretsmanager-secret-unused AWS Config managed rule checks if a secret has not been retrieved for a specified period. However, it might not provide real-time insights into which secrets are currently in use.\\n2. Delayed Detection: This rule might only detect secrets that have not been used for a while, potentially missing secrets that are infrequently accessed but still required.\\n3. Lack of Granularity: The rule might not provide detailed information about the specific applications or instances accessing the secrets, making it harder to pinpoint which secrets are actively used.","timestamp":"1728068760.0","comment_id":"1293242","poster":"MasoudK","upvote_count":"1"},{"poster":"65703c1","timestamp":"1716461580.0","comment_id":"1216475","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1"},{"comment_id":"1158889","poster":"KarBiswa","content":"Selected Answer: B\\nWe need \\"secrets that are still in use\\". \\"B\\" secretsmanager-secret-unused returns unused. So we can easily determine the used secrets if it is not falling under this scanner","upvote_count":"2","timestamp":"1708874400.0"},{"comment_id":"1136974","content":"My choice is \\"A\\".\\nWe need \\"secrets that are still in use\\". \\"B\\" secretsmanager-secret-unused returns unused.","poster":"rimaSamir","upvote_count":"1","timestamp":"1706719980.0"},{"comment_id":"1126931","timestamp":"1705692660.0","poster":"SerialiDr","content":"Selected Answer: A\\nA. Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function: This is a viable and efficient solution. AWS Step Functions can orchestrate the Lambda function invocations and manage the workflow, including handling API call rate limits. The Wait state can be used to introduce delays between API calls to ensure compliance with the rate limits. This approach also allows for handling errors and retries effectively.\\n\\nB. Use an Amazon Simple Queue Service (Amazon SQS) queue to hold the API calls. Configure the Lambda function to poll the queue within the API threshold limits: While using SQS to queue API call requests is a good way to manage workload, it adds complexity to the solution. The Lambda function would need to be modified to manage the queue and ensure API calls are made within the threshold limits. This approach might not be as straightforward and efficient as using Step Functions.","upvote_count":"2"},{"content":"Selected Answer: A\\nChatGPT:A","timestamp":"1701573660.0","comment_id":"1086559","poster":"tqiu654","upvote_count":"1"},{"comment_id":"1080103","poster":"kaes","content":"It\'s easier to use a built-in solution in AWS Config (check chris_777 answer)","upvote_count":"1","timestamp":"1700925240.0"},{"content":"Selected Answer: A\\nI think A is a more direct way, while B needs an inference after receiving the notification for \'unused\'.","poster":"CrescentShared","upvote_count":"1","timestamp":"1700029440.0","comment_id":"1071133"},{"upvote_count":"1","timestamp":"1697773620.0","content":"Selected Answer: B\\nB is correct for this one.","comment_id":"1048348","poster":"LemonGremlin"},{"content":"Selected Answer: A\\nA is correct. . AWS CloudTrail can track API calls, including the GetSecretValue call for AWS Secrets Manager. By setting up CloudTrail log delivery to an S3 bucket, the developer can analyze which secrets are being accessed. Using CloudWatch to create an alarm for the GetSecretValue API call provides insight into which secrets are actively being retrieved, thus indicating which secrets are in use.","poster":"dilleman","comments":[{"content":"I think i change my mind to B. B Must be correct..","comment_id":"1042372","timestamp":"1697179800.0","upvote_count":"3","poster":"dilleman","comments":[{"content":"Why did you change your mind, please? A looks super correct to me.","poster":"CrescentShared","comment_id":"1071134","upvote_count":"1","timestamp":"1700029500.0"}]}],"timestamp":"1697007060.0","comment_id":"1040265","upvote_count":"2"},{"poster":"Digo30sp","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nSolution (B) is the best option to meet the developer\'s requirements. It allows the developer to identify necessary secrets that are still in use without causing any application downtime.","upvote_count":"3","timestamp":"1696588920.0","comment_id":"1026448"}],"answer_description":"","extracted_at":"2025-12-24T08:57:15.249Z","extraction_method":"api_direct_v1"},{"question_id":"LL9HN9fsjgY1AJJc3BU7","question_number":63,"page":13,"question_text":"A developer is writing a serverless application that requires an AWS Lambda function to be invoked every 10 minutes.\\n\\nWhat is an automated and serverless way to invoke the function?","choices":{"B":"Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.","A":"Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.","D":"Create an Amazon Simple Notification Service (Amazon SNS) topic that has a subscription to the Lambda function with a 600-second timer.","C":"Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122574-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:58:00","unix_timestamp":1696550280,"discussion_count":5,"discussion":[{"timestamp":"1718596380.0","content":"This appear at 17 Jun exam","poster":"tsangckl","comment_id":"1231702","upvote_count":"1"},{"upvote_count":"2","comment_id":"1216477","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716461820.0"},{"comment_id":"1126095","timestamp":"1705600500.0","poster":"SerialiDr","upvote_count":"3","content":"Selected Answer: C\\nC. Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function: This is the correct and most suitable option. Amazon EventBridge (formerly CloudWatch Events) allows you to set up rules that trigger on a schedule. You can create a rule with a cron or rate expression to invoke the Lambda function every 10 minutes. This approach is fully serverless and does not require managing any servers or additional infrastructure."},{"comment_id":"1040268","content":"Selected Answer: C\\nC is correct.\\nAmazon EventBridge can be used to run Lambda functions on a regular schedule. You can set a cron or rate expression to define the schedule.","timestamp":"1697007180.0","poster":"dilleman","upvote_count":"3"},{"comment_id":"1026449","poster":"Digo30sp","timestamp":"1696588980.0","upvote_count":"2","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nSolution (C) is the best option to meet the developer\'s requirements. It allows the developer to invoke the Lambda function in an automated and serverless way."}],"answer_description":"","extracted_at":"2025-12-24T08:57:15.249Z","extraction_method":"api_direct_v1"},{"question_id":"k3gPaYbJpNTmyadeulyq","question_number":64,"page":13,"question_text":"A company is using Amazon OpenSearch Service to implement an audit monitoring system. A developer needs to create an AWS CloudFormation custom resource that is associated with an AWS Lambda function to configure the OpenSearch Service domain. The Lambda function must access the OpenSearch Service domain by using OpenSearch Service internal master user credentials.\\n\\nWhat is the MOST secure way to pass these credentials to the Lambda function?","choices":{"B":"Use a CloudFormation parameter to pass the master user credentials at deployment to the OpenSearch Service domain\u2019s MasterUserOptions and to create a parameter in AWS Systems Manager Parameter Store. Set the NoEcho attribute to true. Create an IAM role that has the ssm:GetParameter permission. Assign the role to the Lambda function. Store the parameter name as the Lambda function\u2019s environment variable. Resolve the parameter\u2019s value at runtime.","C":"Use a CloudFormation parameter to pass the master user credentials at deployment to the OpenSearch Service domain\u2019s MasterUserOptions and the Lambda function\u2019s environment variable. Encrypt the parameter\u2019s value by using the AWS Key Management Service (AWS KMS) encrypt command.","A":"Use a CloudFormation parameter to pass the master user credentials at deployment to the OpenSearch Service domain\u2019s MasterUserOptions and the Lambda function\u2019s environment variable. Set the NoEcho attribute to true.","D":"Use CloudFormation to create an AWS Secrets Manager secret. Use a CloudFormation dynamic reference to retrieve the secret\u2019s value for the OpenSearch Service domain\u2019s MasterUserOptions. Create an IAM role that has the secretsmanager:GetSecretValue permission. Assign the role to the Lambda function. Store the secret\u2019s name as the Lambda function\u2019s environment variable. Resolve the secret\u2019s value at runtime."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122575-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:59:00","unix_timestamp":1696550340,"discussion_count":4,"discussion":[{"poster":"65703c1","upvote_count":"2","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1732366860.0","comment_id":"1216479"},{"comment_id":"1126912","content":"Selected Answer: D\\nThis approach is the most secure and aligns with best practices for managing secrets. The credentials are stored in AWS Secrets Manager, which is specifically designed for managing and protecting secrets. The credentials are retrieved dynamically at runtime by the Lambda function, and the use of IAM roles ensures that only the Lambda function has access to these secrets. This method also benefits from the security and rotation features of AWS Secrets Manager.","timestamp":"1721409180.0","upvote_count":"2","poster":"SerialiDr"},{"timestamp":"1712818620.0","content":"Selected Answer: D\\nD is correct.","upvote_count":"2","poster":"dilleman","comment_id":"1040273"},{"timestamp":"1712400180.0","poster":"Digo30sp","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nSolution (D) is the most secure way to pass the credentials to the Lambda function because it uses AWS Secrets Manager to store the credentials in encrypted form.","comment_id":"1026450","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:57:15.249Z","extraction_method":"api_direct_v1"},{"question_id":"gxNVRjXveMhZPm3LZPu3","question_number":65,"page":13,"question_text":"An application runs on multiple EC2 instances behind an ELB.\\n\\nWhere is the session data best written so that it can be served reliably across multiple requests?","choices":{"B":"Write data to Amazon Elastic Block Store.","C":"Write data to Amazon EC2 Instance Store.","A":"Write data to Amazon ElastiCache.","D":"Write data to the root filesystem."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122576-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 01:59:00","unix_timestamp":1696550340,"discussion_count":4,"discussion":[{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732366920.0","upvote_count":"2","poster":"65703c1","comment_id":"1216481"},{"content":"Selected Answer: A\\nAmazon ElastiCache provides a fast, in-memory data store or cache. It is often used for session management in distributed applications. Data stored in ElastiCache can be accessed quickly and reliably by any of the EC2 instances behind the ELB, making it an ideal choice for session data that needs to be shared across multiple servers.","timestamp":"1721409600.0","upvote_count":"2","comment_id":"1126919","poster":"SerialiDr"},{"comment_id":"1040274","timestamp":"1712818680.0","upvote_count":"3","content":"Selected Answer: A\\nA is correct.\\nBy storing session data in ElastiCache, you ensure that regardless of which EC2 instance handles a given request, the session data can be consistently and rapidly accessed.","poster":"dilleman"},{"comment_id":"1026452","timestamp":"1712400240.0","content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nAmazon ElastiCache is a distributed memory caching solution that is ideal for session data. ElastiCache provides high-performance and durable session data storage that can be shared across multiple EC2 instances.","upvote_count":"3","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:57:15.249Z","extraction_method":"api_direct_v1"},{"question_id":"lwdSpQqArMhLzqQB2tkx","question_number":66,"page":14,"question_text":"An ecommerce application is running behind an Application Load Balancer. A developer observes some unexpected load on the application during non-peak hours. The developer wants to analyze patterns for the client IP addresses that use the application.\\n\\nWhich HTTP header should the developer use for this analysis?","choices":{"A":"The X-Forwarded-Proto header","B":"The X-Forwarded-Host header","D":"The X-Forwarded-Port header","C":"The X-Forwarded-For header"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122577-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:02:00","unix_timestamp":1696550520,"discussion_count":6,"discussion":[{"upvote_count":"9","timestamp":"1714874820.0","poster":"chris_777","content":"Selected Answer: C\\nC is correct.\\n\\nX-Forwarded-Proto: protocol (HTTP/HTTPS) \\nX-Forwarded-Host: original Host header requested by the client\\nX-Forwarded-For: original IP address of a client (CORRECT)\\nX-Forwarded-Port header: original port that the client used to connect","comment_id":"1062594"},{"poster":"65703c1","upvote_count":"1","timestamp":"1732367100.0","comment_id":"1216483","content":"Selected Answer: C\\nC is the correct answer."},{"upvote_count":"1","timestamp":"1714317420.0","content":"Selected Answer: C\\nC is correct","poster":"tapan666","comment_id":"1056283"},{"comment_id":"1040275","timestamp":"1712818800.0","upvote_count":"1","content":"Selected Answer: C\\nC is correct","poster":"dilleman"},{"upvote_count":"1","poster":"Cerakoted","content":"Selected Answer: C\\nX-Forwarded-For HTTP header contains the IP address of the original client","timestamp":"1712742300.0","comment_id":"1039351"},{"upvote_count":"2","timestamp":"1712400300.0","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nThe X-Forwarded-For HTTP header contains the IP address of the original client that made the request. The developer can use this header to analyze patterns for the IP addresses of clients using the application.","poster":"Digo30sp","comment_id":"1026455"}],"answer_description":"","extracted_at":"2025-12-24T08:57:26.221Z","extraction_method":"api_direct_v1"},{"question_id":"ic3UpqFHw80PmseKZqCV","question_number":67,"page":14,"question_text":"A developer migrated a legacy application to an AWS Lambda function. The function uses a third-party service to pull data with a series of API calls at the end of each month. The function then processes the data to generate the monthly reports. The function has been working with no issues so far.\\n\\nThe third-party service recently issued a restriction to allow a fixed number of API calls each minute and each day. If the API calls exceed the limit for each minute or each day, then the service will produce errors. The API also provides the minute limit and daily limit in the response header. This restriction might extend the overall process to multiple days because the process is consuming more API calls than the available limit.\\n\\nWhat is the MOST operationally efficient way to refactor the serverless application to accommodate this change?","choices":{"C":"Use an Amazon CloudWatch Logs metric to count the number of API calls. Configure an Amazon CloudWatch alarm that stops the currently running instance of the Lambda function when the metric exceeds the API threshold limits.","D":"Use Amazon Kinesis Data Firehose to batch the API calls and deliver them to an Amazon S3 bucket with an event notification to invoke the Lambda function.","A":"Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function.","B":"Use an Amazon Simple Queue Service (Amazon SQS) queue to hold the API calls. Configure the Lambda function to poll the queue within the API threshold limits."},"correct_answer":"A","answer_ET":"A","answers_community":["A (64%)","B (33%)","3%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122578-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:03:00","unix_timestamp":1696550580,"discussion_count":17,"discussion":[{"poster":"wonder_man","upvote_count":"7","timestamp":"1698463440.0","comment_id":"1055960","content":"Selected Answer: A\\nB: I don\'t see how the Lamba function can be configured this way"},{"upvote_count":"1","timestamp":"1734742200.0","poster":"trieudo","comments":[{"comment_id":"1329768","upvote_count":"1","content":"refer: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html?utm_source=chatgpt.com","timestamp":"1734742260.0","poster":"trieudo"}],"comment_id":"1329767","content":"Selected Answer: A\\nA: makes the most sense in this question: Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function.\\n\\nB: SQS queue wouldn\'t work because the maximum delay allowed in an SQS queue is 15 minutes. ==> \'extend the overall process to multiple days\' will be violated"},{"poster":"tsangckl","content":"This appear at 17 Jun exam","comment_id":"1231703","upvote_count":"1","timestamp":"1718596380.0"},{"comment_id":"1216486","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716462600.0"},{"comments":[{"content":"Changing to A","comment_id":"1170416","poster":"KarBiswa","timestamp":"1710085020.0","upvote_count":"3"}],"upvote_count":"1","content":"Selected Answer: C\\nI would go for option C because response value always contains the limit value and which can be retrieved into the cloudwatch and can be used to block the the lambda calls","poster":"KarBiswa","comment_id":"1158923","timestamp":"1708875660.0"},{"content":"Selected Answer: A\\nThe solution that will meet the requirements is to use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function. This way, the developer can refactor the serverless application to accommodate the change in a way that is automated and scalable. The developer can use Step Functions to orchestrate the Lambda function and handle any errors or retries. The developer can also use the Wait state to pause the execution for a specified duration or until a specified timestamp, which can help avoid exceeding the API limits. The other options either involve using additional services that are not necessary or appropriate for this scenario, or do not address the issue of API failures.\\n\\nhttps://www.freecram.net/question/Amazon.DVA-C02.v2023-11-29.q68/a-developer-migrated-a-legacy-application-to-an-aws-lambda-function-the-function-uses-a-third-party-18#","upvote_count":"3","comment_id":"1157024","timestamp":"1708680060.0","poster":"KillThemWithKindness"},{"upvote_count":"4","timestamp":"1706887380.0","comment_id":"1138669","poster":"konieczny69","content":"Selected Answer: A\\nWho is going to orchestrate lambda invocation?\\nSQS is for decoupling, not for scheduled invocations.\\n\\nA is the only option."},{"timestamp":"1706331000.0","poster":"CrescentShared","content":"Selected Answer: B\\nOption A with AWS Step Functions can handle the frequency of API calls by introducing a delay (Wait state) between retries after a failure due to rate limiting, it doesn\'t inherently solve the problem of the total number of calls per day. If the total number of necessary API calls exceeds the daily limit set by the third-party service, simply adding a delay between retries will not prevent the overall daily limit from being exceeded.","comment_id":"1133062","upvote_count":"4"},{"timestamp":"1705692780.0","content":"Selected Answer: A\\nA. Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function: This is a viable and efficient solution. AWS Step Functions can orchestrate the Lambda function invocations and manage the workflow, including handling API call rate limits. The Wait state can be used to introduce delays between API calls to ensure compliance with the rate limits. This approach also allows for handling errors and retries effectively.\\n\\nB. Use an Amazon Simple Queue Service (Amazon SQS) queue to hold the API calls. Configure the Lambda function to poll the queue within the API threshold limits: While using SQS to queue API call requests is a good way to manage workload, it adds complexity to the solution. The Lambda function would need to be modified to manage the queue and ensure API calls are made within the threshold limits. This approach might not be as straightforward and efficient as using Step Functions.","comment_id":"1126934","poster":"SerialiDr","upvote_count":"3"},{"timestamp":"1704865140.0","comment_id":"1118209","content":"Selected Answer: B\\nB is the most operationally efficient way","upvote_count":"1","poster":"JohnPl"},{"content":"Selected Answer: B\\nb is the answer","poster":"Snape","comment_id":"1116115","upvote_count":"1","timestamp":"1704654420.0"},{"content":"Selected Answer: B\\nsqs decouples lambda from api service","upvote_count":"1","timestamp":"1704117000.0","poster":"rrshah83","comment_id":"1111219"},{"upvote_count":"1","timestamp":"1703095860.0","content":"Selected Answer: B\\nWhile Step Functions can be used for workflow orchestration, it may not be the most straightforward solution for handling rate limits in this scenario.","poster":"chewasa","comment_id":"1101818"},{"poster":"tqiu654","upvote_count":"2","timestamp":"1701574920.0","content":"Selected Answer: A\\nChatGPT: A","comment_id":"1086568"},{"poster":"ShawnWon","upvote_count":"3","content":"B.\\nOption A (AWS Step Functions) might introduce unnecessary complexity and does not directly address the need to control the rate of API calls within the specified limits.\\n\\nOption C (CloudWatch Logs metric and alarm) provides monitoring capabilities but doesn\'t offer a direct mechanism to control the rate of API calls within the Lambda function.\\n\\nOption D (Kinesis Data Firehose) is designed for real-time streaming and might not be the most suitable option for this scenario, as it may not provide the fine-grained control needed to stay within the API call limits.","timestamp":"1700386320.0","comment_id":"1074552"},{"content":"Selected Answer: A\\nA is Correct. AWS Step Functions can be used to create a workflow to handle the API calls. You can make the Lambda function inspect the response headers from the third-party service to determine the current API call limits and then pass that to the Wait state of the state machine for proper delays.","timestamp":"1697007840.0","comment_id":"1040278","poster":"dilleman","upvote_count":"2"},{"timestamp":"1696589160.0","poster":"Digo30sp","upvote_count":"4","comment_id":"1026458","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nSolution (B) is the most operationally efficient way to refactor the serverless application to accommodate this change. This solution allows the Lambda function to continue executing API calls even if the API call limit is reached. The Amazon SQS queue will act as a buffer for API calls that exceed the limit. The Lambda function can then poll the queue within the API limits."}],"answer_description":"","extracted_at":"2025-12-24T08:57:26.221Z","extraction_method":"api_direct_v1"},{"question_id":"z3BB6uIEcwDeeleHufW8","question_number":68,"page":14,"question_text":"A developer has written an AWS Lambda function. The function is CPU-bound. The developer wants to ensure that the function returns responses quickly.\\nHow can the developer improve the function\'s performance?","choices":{"D":"Increase the function\'s timeout.","B":"Increase the function\'s memory.","C":"Increase the function\'s reserved concurrency.","A":"Increase the function\'s CPU core count."},"correct_answer":"B","answer_ET":"B","answers_community":["B (98%)","2%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103444-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 07:20:00","unix_timestamp":1679379600,"discussion_count":16,"discussion":[{"upvote_count":"15","comment_id":"858011","poster":"ihta_2031","timestamp":"1680359280.0","content":"Selected Answer: B\\nCpu utilisation => increase memory"},{"comment_id":"967162","upvote_count":"10","timestamp":"1690723860.0","poster":"Kashan6109","content":"Selected Answer: B\\nOption B is correct, the only adjustable parameter (in terms of hardware) is lambda memory. Increasing lambda memory will result in automatic adjustment of CPU.\\n\\nLambda memory is adjustable from 128 MB upto 10 GB"},{"content":"Selected Answer: B\\nA) Eliminated - We cannot directly control the CPU core count.\\nB) Correct - increasing memory not only gives more memory but also allocates more CPU power to the function.\\nC) Eliminated - Reserved concurrency controls how many instances of the function can run at the same time, but it doesn\u2019t improve the performance of a single function execution\\nD) Eliminated - Increasing the timeout allows the function to run longer, but it doesn\u2019t improve the speed of the function","timestamp":"1734755700.0","comment_id":"1329815","poster":"sumanshu","upvote_count":"2"},{"comment_id":"1325937","timestamp":"1734051900.0","content":"Selected Answer: B\\n==> discard A: can\'t directly increase lambda CPU\\n==> discard C: concurrecny for handling many tasks at same time capacibility, not increase speed response when CPU-bound\\n=> discard D: be not relevant, increase maximum time to wait function to finish\\n\\nB: with lambda, you can increase memory, implicity CPU usage for lambda also up too","upvote_count":"1","poster":"trieudo"},{"comment_id":"1303476","content":"Selected Answer: B\\nthe only way to adjust the vCPU assigned to your function, is through an increase in memory","timestamp":"1730002080.0","poster":"rue_","upvote_count":"1"},{"timestamp":"1723011840.0","upvote_count":"1","comment_id":"1261966","poster":"tgood","content":"Selected Answer: B\\nB is correct"},{"poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1","comment_id":"1214995","timestamp":"1716299580.0"},{"content":"Selected Answer: B\\nIf you increase the memory on a Lambda Function hence your vCPU also increased","poster":"leonardoliveros","comment_id":"1072036","timestamp":"1700093580.0","upvote_count":"1"},{"comment_id":"1064535","upvote_count":"3","content":"Selected Answer: B\\nQuote \'If a function is CPU-, network- or memory-bound, then changing the memory setting can dramatically improve its performance.\' at https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","poster":"james2033","timestamp":"1699337280.0"},{"timestamp":"1685420220.0","comment_id":"909874","poster":"Majong","upvote_count":"5","content":"Selected Answer: B\\nLambda allocates CPU power in proportion to the amount of memory configured. You can read more here:\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html#configuration-memory-console"},{"comment_id":"893274","content":"Increasing the function\'s CPU core count is not an option in AWS Lambda. AWS Lambda automatically manages the allocation of CPU power and only allows scaling of memory.","upvote_count":"2","poster":"Devon_Fazekas","timestamp":"1683647880.0"},{"timestamp":"1683390540.0","poster":"geekdamsel","comment_id":"890874","upvote_count":"3","content":"Correct answer is B."},{"upvote_count":"1","comment_id":"890726","content":"Selected Answer: B\\n. Increase the function\'s memory.\\n\\nThe performance of an AWS Lambda function is primarily determined by the amount of allocated memory. When you increase the memory, you also increase the available CPU and network resources. This can result in faster execution times, especially for CPU-bound functions. Increasing the CPU core count, reserved concurrency, or timeout may not have as significant an impact on performance as increasing memory.","poster":"Bibay","timestamp":"1683374700.0"},{"content":"Selected Answer: B\\nAdding more memory proportionally increases the amount of CPU, increasing the overall computational power available. If a function is CPU-, network- or memory-bound, then changing the memory setting can dramatically improve its performance.\\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","timestamp":"1682559360.0","comment_id":"882150","poster":"blathul","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\\nOn this particular question the answer is A.\\nwhile increasing memory can indirectly improve CPU performance, it\'s not always the most effective solution for CPU-bound functions, and increasing the CPU core count is usually a better option for improving performance in such cases. Please note - CPU-Bound functions. This question is to trick you","comments":[{"poster":"Majong","comment_id":"909873","timestamp":"1685420160.0","content":"In this particular question it is B. You are right that in normal question it might be A but for a Lambda function you are not able to change the CPU. Lambda allocates CPU power in proportion to the amount of memory configured. You can read more here:\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html#configuration-memory-console","upvote_count":"4"}],"comment_id":"871491","timestamp":"1681623420.0","poster":"Syre"},{"comment_id":"845571","poster":"Untamables","upvote_count":"3","timestamp":"1679379600.0","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html#configuration-memory-console"}],"answer_description":"","extracted_at":"2025-12-24T08:57:26.221Z","extraction_method":"api_direct_v1"},{"question_id":"AMOZQIlyDp2NYnJdLwDP","question_number":69,"page":14,"question_text":"A developer must analyze performance issues with production-distributed applications written as AWS Lambda functions. These distributed Lambda applications invoke other components that make up the applications.\\n\\nHow should the developer identify and troubleshoot the root cause of the performance issues in production?","choices":{"D":"Run Amazon Inspector agents and then analyze performance.","A":"Add logging statements to the Lambda functions, then use Amazon CloudWatch to view the logs.","B":"Use AWS CloudTrail and then examine the logs.","C":"Use AWS X-Ray, then examine the segments and errors."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122579-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:03:00","unix_timestamp":1696550580,"discussion_count":3,"discussion":[{"poster":"Digo30sp","comment_id":"1026461","upvote_count":"5","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nAWS X-Ray is the best tool for identifying and addressing the root cause of performance issues in distributed production applications. X-Ray provides an overview of the entire call stack, including the Lambda functions and other components they invoke.","timestamp":"1712400420.0"},{"upvote_count":"1","timestamp":"1732367460.0","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1216490"},{"upvote_count":"4","content":"Selected Answer: C\\nC is correct.","comment_id":"1040284","timestamp":"1712819280.0","poster":"dilleman"}],"answer_description":"","extracted_at":"2025-12-24T08:57:26.221Z","extraction_method":"api_direct_v1"},{"question_id":"fZ4FhXtvwpV4NYu9rmsA","question_number":70,"page":14,"question_text":"A developer wants to deploy a new version of an AWS Elastic Beanstalk application. During deployment, the application must maintain full capacity and avoid service interruption. Additionally, the developer must minimize the cost of additional resources that support the deployment.\\n\\nWhich deployment method should the developer use to meet these requirements?","choices":{"B":"Rolling with additional batch","D":"Immutable","A":"All at once","C":"Blue/green"},"correct_answer":"B","answer_ET":"B","answers_community":["B (55%)","D (37%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122580-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:04:00","unix_timestamp":1696550640,"discussion_count":14,"discussion":[{"comment_id":"1047145","timestamp":"1697654160.0","upvote_count":"15","poster":"Nagasoracle","content":"Selected Answer: B\\nB: Rolling with additional batch , considering \\"minimize the cost of additional resources\\"\\nC costly than B, due to double capacity"},{"timestamp":"1705700160.0","comment_id":"1126980","poster":"SerialiDr","content":"Selected Answer: D\\nD. Immutable\\n\\nThe immutable method strikes a balance between maintaining service availability and controlling costs. It avoids the downtime associated with the all-at-once method and doesn\'t require the more extensive resource duplication of the blue/green method. While it does temporarily increase resource usage (similar to rolling with an additional batch), it\'s generally more efficient and less risky than updating instances in-place.","comments":[{"upvote_count":"1","poster":"aws_god","timestamp":"1730360760.0","comment_id":"1305319","content":"you mean D"}],"upvote_count":"5"},{"comment_id":"1307990","timestamp":"1730910120.0","poster":"ShakthiGCP","content":"Selected Answer: B\\nRolling deployments reuse existing instances for a portion of the deployment time. While new instances are launched, old ones continue to serve traffic. This minimizes idle compute time and reduces costs.","upvote_count":"1"},{"comment_id":"1216495","timestamp":"1716462960.0","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2"},{"timestamp":"1713157740.0","comments":[{"comment_id":"1305320","upvote_count":"1","content":"you mean D","poster":"aws_god","timestamp":"1730360820.0"}],"poster":"a5fc516","upvote_count":"1","content":"Ans-B: The immutable deployment method updates an application by launching new instances with the new version in a new Auto Scaling group, alongside the existing instances running the old version. This ensures that the application maintains full capacity during the deployment because the existing environment is unaffected until the new environment is fully deployed and verified. Once the deployment is successful, traffic is shifted to the new instances, and the old ones are terminated. This minimizes downtime and provides a quick rollback if needed. The cost of additional resources is limited to the duration of the deployment, after which the old resources are terminated.","comment_id":"1195810"},{"upvote_count":"1","timestamp":"1708878240.0","comment_id":"1158949","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/whitepapers/latest/practicing-continuous-integration-continuous-delivery/deployment-methods.html#:~:text=During%20the%20deployment%20process%20two%20software%20versions%2C%20new%20and%20old%2C%20are%20running%20on%20the%20same%20fleet.%20This%20method%20allows%20a%20zero%2Ddowntime%20update.%20If%20the%20deployment%20fails%2C%20only%20the%20updated%20portion%20of%20the%20fleet%20will%20be%20affected.\\nIt does not need a new instance","poster":"KarBiswa"},{"content":"Selected Answer: D\\nThis method performs updates by launching a new set of instances in a new Auto Scaling group. Once the new instances pass health checks, they are moved into the existing Auto Scaling group, and the old instances are terminated. This method ensures full capacity, avoids downtime, and minimizes additional costs because it does not double the environment\'s running resources for an extended period. It adds resources temporarily and only in the amount necessary to maintain capacity.","upvote_count":"3","poster":"Roimasu","timestamp":"1698675120.0","comment_id":"1057852"},{"poster":"NinjaCloud","upvote_count":"4","timestamp":"1698604740.0","comment_id":"1057076","content":"Shoulc be B \\"Ultimately, the choice between \\"Rolling with additional batch\\" and \\"Blue/green\\" deployments should depend on your specific requirements and constraints. If maintaining full capacity is a crucial factor, then \\"Rolling with additional batch\\" could be the better choice.\\""},{"comment_id":"1053650","upvote_count":"1","poster":"ut18","content":"MS Bing answer: B vs Chag GPT answer: C\\nYour choice?","comments":[{"content":"ChatGPT4 changed its mind to select D today.","upvote_count":"1","poster":"CrescentShared","comment_id":"1071209","timestamp":"1700035920.0"}],"timestamp":"1698231660.0"},{"upvote_count":"1","timestamp":"1697328060.0","poster":"Learning4life","content":"C and D are wrong, since they both require additional resources.","comment_id":"1043774"},{"poster":"joosh96","content":"Selected Answer: C\\nchat gpt replied","upvote_count":"1","timestamp":"1697115780.0","comment_id":"1041748"},{"timestamp":"1697034600.0","comment_id":"1040755","upvote_count":"4","content":"Selected Answer: B\\nAnswer is B\\nOne of requirement - the developer [must minimize the cost of additional resources] that support the deployment.","poster":"Cerakoted"},{"timestamp":"1697008380.0","upvote_count":"4","poster":"dilleman","content":"Selected Answer: D\\nI vote for D since the requirement is to minimize the costs of resources. Blue/green is a good and safe way to solve this but it costs more resources than an Immutable rollout.\\nImmutable: Launches a new set of instances in a new temporary environment to ensure that the new version works as expected. Once the new version is verified, traffic is rerouted to the new set of instances, and the old instances are terminated. This method maintains full capacity, avoids service interruptions, and minimizes the cost compared to blue/green deployments since the overlap in running resources is shorter.","comment_id":"1040289"},{"poster":"Digo30sp","timestamp":"1696589280.0","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nThe blue/green deployment method is the best option to meet the developer\'s requirements. Blue/green allows the developer to deploy a new version of the application without service interruption. This is done by creating a blue production environment and a green production environment. The blue environment is the current production environment and the green environment is the new version of the application. The developer can then test the new version of the application in the green environment before putting it into production.","upvote_count":"2","comment_id":"1026463"}],"answer_description":"","extracted_at":"2025-12-24T08:57:26.221Z","extraction_method":"api_direct_v1"},{"question_id":"OcUZNOOYwf7oVL0j3eLn","question_number":71,"page":15,"question_text":"A developer has observed an increase in bugs in the AWS Lambda functions that a development team has deployed in its Node.js application. To minimize these bugs, the developer wants to implement automated testing of Lambda functions in an environment that closely simulates the Lambda environment.\\n\\nThe developer needs to give other developers the ability to run the tests locally. The developer also needs to integrate the tests into the team\u2019s continuous integration and continuous delivery (CI/CD) pipeline before the AWS Cloud Development Kit (AWS CDK) deployment.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create sample events based on the Lambda documentation. Create a Docker container from the Node.js base image to invoke the Lambda functions. Check the response. Document how to run the Docker container for the other developers on the team. Update the CI/CD pipeline to run the Docker container.","C":"Install the AWS Serverless Application Model (AWS SAM) CLI tool. Use the sam local generate-event command to generate sample events for the automated tests. Create automated test scripts that use the sam local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts.","B":"Install a unit testing framework that reproduces the Lambda execution environment. Create sample events based on the Lambda documentation. Invoke the handler function by using a unit testing framework. Check the response. Document how to run the unit testing framework for the other developers on the team. Update the CI/CD pipeline to run the unit testing framework.","A":"Create sample events based on the Lambda documentation. Create automated test scripts that use the cdk local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122582-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:10:00","unix_timestamp":1696551000,"discussion_count":5,"discussion":[{"timestamp":"1732368300.0","comment_id":"1216506","poster":"65703c1","upvote_count":"3","content":"Selected Answer: C\\nC is the correct answer."},{"timestamp":"1726479780.0","comment_id":"1174939","poster":"KarBiswa","upvote_count":"3","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/using-sam-cli-local-generate-event.html"},{"comment_id":"1126985","content":"Selected Answer: C\\nThis is the most suitable option. AWS SAM CLI is a tool designed for building, testing, and debugging serverless applications, and it includes the ability to locally test Lambda functions. The sam local invoke command allows you to invoke Lambda functions locally in a Docker container that simulates the Lambda execution environment. The sam local generate-event command can be used to generate sample events. This approach allows developers to run tests locally and can be integrated into CI/CD pipelines.","upvote_count":"3","poster":"SerialiDr","timestamp":"1721418300.0"},{"content":"Selected Answer: C\\nC should be correct","upvote_count":"2","comment_id":"1040294","timestamp":"1712819820.0","poster":"dilleman"},{"comment_id":"1026464","timestamp":"1712400540.0","poster":"Digo30sp","upvote_count":"4","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nSolution (C) is the best option to meet the developer\'s requirements. The AWS SAM CLI tool provides an easy way to generate sample events and invoke Lambda functions locally. The solution is also easy to document and integrate into the CI/CD pipeline."}],"answer_description":"","extracted_at":"2025-12-24T08:57:37.157Z","extraction_method":"api_direct_v1"},{"question_id":"iR129wcmXTmo3Hx1ADPo","question_number":72,"page":15,"question_text":"A developer is troubleshooting an application that uses Amazon DynamoDB in the us-west-2 Region. The application is deployed to an Amazon EC2 instance. The application requires read-only permissions to a table that is named Cars. The EC2 instance has an attached IAM role that contains the following IAM policy:\\n\\n//IMG//\\n\\n\\nWhen the application tries to read from the Cars table, an Access Denied error occurs.\\n\\nHow can the developer resolve this error?","choices":{"D":"Create a trust relationship between the role and dynamodb.amazonaws.com.","A":"Modify the IAM policy resource to be \u201carn:aws:dynamodb:us-west-2:account-id:table/*\u201d.","B":"Modify the IAM policy to include the dynamodb:* action.","C":"Create a trust policy that specifies the EC2 service principal. Associate the role with the policy."},"correct_answer":"C","answer_ET":"C","answers_community":["C (79%)","14%","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122581-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image12.png"],"answer_images":[],"timestamp":"2023-10-06 02:07:00","unix_timestamp":1696550820,"discussion_count":6,"discussion":[{"poster":"LemonGremlin","comments":[{"comment_id":"1138694","timestamp":"1706889240.0","poster":"konieczny69","content":"What is a trust policy?\\nI know trust relationship, not a trust policy.","upvote_count":"1"}],"content":"Selected Answer: C\\nThe most reasonable answer here is C. But I think the question is missing some information.\\nhttps://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/","timestamp":"1697773800.0","comment_id":"1048352","upvote_count":"6"},{"comment_id":"1289808","poster":"albert_kuo","content":"Selected Answer: A\\nThe current policy specifies the resource as \\"arn:aws:dynamodb:us-west-2:account-id:table/Cars\\". This means the policy only applies to the specific \\"Cars\\" table.\\nHowever, when working with DynamoDB, it\'s common for the SDK or API calls to need permissions on the table\'s indexes as well as the table itself.\\nBy changing the resource to \\"arn:aws:dynamodb:us-west-2:account-id:table/*\\", you\'re granting the specified read-only actions (GetItem, BatchGetItem, Scan, Query, ConditionCheckItem) on all tables in the account in the us-west-2 region, including any indexes associated with the Cars table.\\nThis broader permission will likely resolve the Access Denied error, as it will cover both the table and any associated indexes.","upvote_count":"2","timestamp":"1727410980.0"},{"upvote_count":"1","content":"Selected Answer: C\\nWell, I will guess that this question is badly written on purpose. Anyway: C makes more sense since A and B are going against best practices of least privilege. D makes no sense since the role must trust the service that will use it rather then the service that will be accessed.","comment_id":"1272895","timestamp":"1724689260.0","poster":"wh1t4k3r"},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","comment_id":"1216509","timestamp":"1716463800.0","poster":"65703c1"},{"upvote_count":"1","comment_id":"1046974","content":"Selected Answer: D\\nD.Create a trust relationship between the role and dynamodb.amazonaws.com.\\n\\nExplanation:\\n\\nTrust Relationship: In AWS, a trust relationship defines who or what entity can assume a role. In this case, the role attached to the EC2 instance needs to trust DynamoDB. The trust relationship is specified in a JSON policy document.\\n\\nDynamoDB Service Principal: The correct service principal for DynamoDB is dynamodb.amazonaws.com. This is the entity that the role needs to trust to allow access to DynamoDB resources.","poster":"PrakashM14","comments":[{"upvote_count":"3","content":"Complete nonsense. Role needs to trust EC2, since its the EC2 who is to assume the role.","comment_id":"1138697","timestamp":"1706889540.0","poster":"konieczny69"}],"timestamp":"1697637660.0"},{"upvote_count":"3","content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/96497-exam-aws-certified-developer-associate-topic-1-question-380/","poster":"Digo30sp","comment_id":"1026469","timestamp":"1696589400.0"}],"answer_description":"","extracted_at":"2025-12-24T08:57:37.157Z","extraction_method":"api_direct_v1"},{"question_id":"UTSzgq4RGtyT3YK1YKFs","question_number":73,"page":15,"question_text":"When using the AWS Encryption SDK, how does the developer keep track of the data encryption keys used to encrypt data?","choices":{"C":"The SDK stores the data encryption keys automatically in Amazon S3.","B":"The SDK encrypts the data encryption key and stores it (encrypted) as part of the returned ciphertext.","A":"The developer must manually keep track of the data encryption keys used for each data object.","D":"The data encryption key is stored in the Userdata for the EC2 instance."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122586-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:16:00","unix_timestamp":1696551360,"discussion_count":7,"discussion":[{"timestamp":"1718596440.0","comment_id":"1231704","poster":"tsangckl","comments":[{"comment_id":"1275241","content":"What was the correct answer to it?","upvote_count":"1","poster":"gabyslim","timestamp":"1725045420.0"}],"upvote_count":"1","content":"This appear at 17 Jun exam"},{"content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"3","comment_id":"1216512","timestamp":"1716464040.0","poster":"65703c1"},{"upvote_count":"2","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/concepts.html#:~:text=An%20encryption%20context%20is%20a,encrypted%20message%20that%20it%20returns.","poster":"KarBiswa","comment_id":"1166336","timestamp":"1709631600.0"},{"timestamp":"1705701300.0","content":"Selected Answer: B\\nIn the AWS Encryption SDK, data is encrypted using a DEK. This DEK is then encrypted with a Key Encryption Key (KEK), usually managed by AWS Key Management Service (AWS KMS) or another key management infrastructure. The encrypted DEK is stored alongside the encrypted data (ciphertext). This allows the SDK to manage the DEKs seamlessly.","comment_id":"1126988","upvote_count":"3","poster":"SerialiDr"},{"upvote_count":"3","timestamp":"1702385520.0","poster":"TanTran04","comment_id":"1094519","content":"Selected Answer: B\\nWhen using the AWS Encryption SDK, it is a common practice to encrypt the data encryption key (DEK) along with the data. The DEK is used to encrypt the actual data, and it is itself encrypted using a key management system, often called a key encryption key (KEK). This encrypted DEK is then stored alongside the encrypted data."},{"poster":"dilleman","comment_id":"1040306","upvote_count":"3","content":"Selected Answer: B\\nB is correct","timestamp":"1697009640.0"},{"timestamp":"1696589520.0","comment_id":"1026474","content":"Selected Answer: B\\nhttps://www.examtopics.com/discussions/amazon/view/96427-exam-aws-certified-developer-associate-topic-1-question-398/","upvote_count":"3","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:57:37.157Z","extraction_method":"api_direct_v1"},{"question_id":"4gDX3irWFfNmwXq97z4X","question_number":74,"page":15,"question_text":"An application that runs on AWS Lambda requires access to specific highly confidential objects in an Amazon S3 bucket. In accordance with the principle of least privilege, a company grants access to the S3 bucket by using only temporary credentials.\\n\\nHow can a developer configure access to the S3 bucket in the MOST secure way?","choices":{"C":"Create a Lambda function execution role. Attach a policy to the role that grants access to specific objects in the S3 bucket.","D":"Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID as environment variables in Lambda. Use the environment variables to access the required S3 objects.","B":"Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID in AWS Secrets Manager. Configure the application to retrieve the Secrets Manager secret and use the credentials to access the S3 objects.","A":"Hardcode the credentials that are required to access the S3 objects in the application code. Use the credentials to access the required S3 objects."},"correct_answer":"C","answer_ET":"C","answers_community":["C (76%)","B (24%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122585-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:15:00","unix_timestamp":1696551300,"discussion_count":5,"discussion":[{"upvote_count":"12","comment_id":"1040317","poster":"dilleman","content":"Selected Answer: C\\nC should be correct:\\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/least-privilege.html","timestamp":"1697010180.0"},{"upvote_count":"6","timestamp":"1696589580.0","comment_id":"1026476","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nOption (B) is the most secure way to configure S3 bucket access because the credentials are stored in a safe and secure location. AWS Secrets Manager uses public key cryptography to protect stored secrets.","comments":[{"content":"B goes against the least privilege principle beacuse it gives access to the whole bucket","upvote_count":"6","comments":[{"upvote_count":"1","poster":"aws_god","timestamp":"1730361120.0","comment_id":"1305322","content":"It states: \\"grants access to specific objects in the S3 bucket\\" so it will not give access to the whole bucket"},{"upvote_count":"1","timestamp":"1712462460.0","content":"Store credentials in aws secret manager, it will be rotated => so it comply the least privilege principle!","comment_id":"1190752","poster":"Melisa202401"}],"comment_id":"1045406","poster":"dezoito","timestamp":"1697501820.0"}],"poster":"Digo30sp"},{"comment_id":"1216513","timestamp":"1716464220.0","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","poster":"65703c1"},{"content":"Selected Answer: C\\nThis is the most secure and recommended approach. By attaching an IAM policy to the Lambda execution role that grants access only to the specific S3 objects needed, you adhere to the principle of least privilege. This method also uses AWS\'s built-in mechanism for providing temporary credentials to the Lambda function, eliminating the need to manage access keys.","timestamp":"1705701900.0","poster":"SerialiDr","comment_id":"1126991","upvote_count":"2"},{"content":"Selected Answer: C\\nC. Create a Lambda function execution role. Attach a policy to the role that grants access to specific objects in the S3 bucket.","timestamp":"1697556180.0","poster":"LemonGremlin","upvote_count":"4","comment_id":"1046139"}],"answer_description":"","extracted_at":"2025-12-24T08:57:37.157Z","extraction_method":"api_direct_v1"},{"question_id":"mJcAWRg2UmPcqxHQeOFR","question_number":75,"page":15,"question_text":"A developer has code that is stored in an Amazon S3 bucket. The code must be deployed as an AWS Lambda function across multiple accounts in the same AWS Region as the S3 bucket. An AWS CloudFormation template that runs for each account will deploy the Lambda function.\\n\\nWhat is the MOST secure way to allow CloudFormation to access the Lambda code in the S3 bucket?","choices":{"D":"Use a service-based link to grant the Lambda function the S3 GetObject permission. Add a resource of \u201c*\u201d to allow access to the S3 bucket.","B":"Grant the CloudFormation service role the S3 GetObject permission. Add a bucket policy to Amazon S3 with the principal of \u201c*\u201d.","C":"Use a service-based link to grant the Lambda function the S3 ListBucket and GetObject permissions by explicitly adding the S3 bucket\u2019s account number in the resource.","A":"Grant the CloudFormation service role the S3 ListBucket and GetObject permissions. Add a bucket policy to Amazon S3 with the principal of \u201cAWS\u201d: [account numbers]."},"correct_answer":"A","answer_ET":"A","answers_community":["A (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122584-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:13:00","unix_timestamp":1696551180,"discussion_count":5,"discussion":[{"upvote_count":"1","comment_id":"1282873","timestamp":"1726181460.0","poster":"NSA_Poker","content":"Selected Answer: B\\n(CD) eliminated. service-based link is not supported by Lambda.\\n(A) S3 ListBucket permission violates the principle of least privilege and therefore is not the most secure. Bucket policy to list principles of multiple accounts requires additional overhead. The list can change.\\n(B) allows the CloudFormation service role to access the S3 bucket from any account, as\\nlong as it has the S3 GetObject permission. The bucket policy grants access to any principal with the GetObject permission, which is the least privilege needed to deploy the Lambda code."},{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216515","upvote_count":"1","poster":"65703c1","timestamp":"1716464280.0"},{"upvote_count":"4","timestamp":"1705740420.0","content":"Selected Answer: A\\nThis approach is secure and provides a granular level of control. By granting the CloudFormation service role in each account the necessary S3 permissions and specifying the account numbers in the S3 bucket policy, you ensure that only the specified accounts can access the Lambda code. However, the ListBucket permission is not necessary if the CloudFormation template already knows the exact S3 object key.","comment_id":"1127151","poster":"SerialiDr"},{"poster":"TanTran04","timestamp":"1702299180.0","content":"Selected Answer: A\\nFollowing ChatGPT 3.5, Option A is the best choice. I guess.\\n- Follows the principle of least privilege by granting only the necessary permissions (ListBucket and GetObject) to the CloudFormation service role.\\n- Adding a bucket policy with the principal of \\"AWS\\": [account numbers] restricts access to only the specified AWS accounts, providing a more secure access control mechanism.\\n- This ensures that only the CloudFormation service role in the specified AWS accounts can access the Lambda code in the S3 bucket.","comment_id":"1093461","upvote_count":"2"},{"comment_id":"1026478","upvote_count":"4","timestamp":"1696589640.0","poster":"Digo30sp","content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nOption (A) is the safest way to allow CloudFormation to access the Lambda code in the S3 bucket because it limits access to the specific accounts that need to deploy the Lambda functions. The bucket policy grants S3 ListBucket and GetObject permissions to the CloudFormation service role only for the accounts specified in the principal."}],"answer_description":"","extracted_at":"2025-12-24T08:57:37.157Z","extraction_method":"api_direct_v1"},{"question_id":"wPtAqwVA2WRFbebUgzCs","question_number":76,"page":16,"question_text":"A developer at a company needs to create a small application that makes the same API call once each day at a designated time. The company does not have infrastructure in the AWS Cloud yet, but the company wants to implement this functionality on AWS.\\n\\nWhich solution meets these requirements in the MOST operationally efficient manner?","choices":{"A":"Use a Kubernetes cron job that runs on Amazon Elastic Kubernetes Service (Amazon EKS).","C":"Use an AWS Lambda function that is invoked by an Amazon EventBridge scheduled event.","B":"Use an Amazon Linux crontab scheduled job that runs on Amazon EC2.","D":"Use an AWS Batch job that is submitted to an AWS Batch job queue."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122587-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:17:00","unix_timestamp":1696551420,"discussion_count":4,"discussion":[{"comment_id":"1216518","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1732369200.0","upvote_count":"2"},{"comment_id":"1138938","timestamp":"1722642120.0","upvote_count":"3","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html","poster":"joshnort"},{"comment_id":"1040329","timestamp":"1712821740.0","content":"Selected Answer: C\\nC is correct","upvote_count":"3","poster":"dilleman"},{"comment_id":"1026482","upvote_count":"2","content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/88703-exam-aws-certified-developer-associate-topic-1-question-229/","poster":"Digo30sp","timestamp":"1712400900.0"}],"answer_description":"","extracted_at":"2025-12-24T08:57:48.175Z","extraction_method":"api_direct_v1"},{"question_id":"A35A5zofa7oWCgUF2fZT","question_number":77,"page":16,"question_text":"A developer is building a serverless application that is based on AWS Lambda. The developer initializes the AWS software development kit (SDK) outside of the Lambda handler function.\\n\\nWhat is the PRIMARY benefit of this action?","choices":{"D":"Creates a new SDK instance for each invocation","A":"Improves legibility and stylistic convention","B":"Takes advantage of runtime environment reuse","C":"Provides better error handling"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122588-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:18:00","unix_timestamp":1696551480,"discussion_count":4,"discussion":[{"content":"This appear at 17 Jun exam","poster":"tsangckl","comment_id":"1231709","upvote_count":"1","timestamp":"1718597880.0"},{"poster":"65703c1","timestamp":"1716464400.0","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1216519","upvote_count":"2"},{"content":"Selected Answer: B\\nB it is!","timestamp":"1697010660.0","comment_id":"1040331","upvote_count":"3","poster":"dilleman"},{"comment_id":"1026743","upvote_count":"3","timestamp":"1696605000.0","poster":"Digo30sp","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nInitializing the AWS SDK outside of the Lambda handler function takes advantage of runtime environment reuse. This means that the SDK only needs to be initialized once for all Lambda function invocations. This can improve application performance and efficiency."}],"answer_description":"","extracted_at":"2025-12-24T08:57:48.175Z","extraction_method":"api_direct_v1"},{"question_id":"Gai7e3IOPzPhvlELVTBD","question_number":78,"page":16,"question_text":"A company is using Amazon RDS as the backend database for its application. After a recent marketing campaign, a surge of read requests to the database increased the latency of data retrieval from the database. The company has decided to implement a caching layer in front of the database. The cached content must be encrypted and must be highly available.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Amazon CloudFront","D":"Amazon DynamoDB Accelerator (DAX)","B":"Amazon ElastiCache for Memcached","C":"Amazon ElastiCache for Redis in cluster mode"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122589-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:18:00","unix_timestamp":1696551480,"discussion_count":4,"discussion":[{"poster":"dilleman","upvote_count":"11","content":"Selected Answer: C\\nShould be C since ElastiCache for Redis supports encryption at rest and in transit. ElastiCache for Memcached does not support encryption at rest.\\nDynamoDB Accelerator is for DynamoDB and does not fit this case.","timestamp":"1712822040.0","comment_id":"1040335"},{"comment_id":"1216523","upvote_count":"1","poster":"65703c1","timestamp":"1732369320.0","content":"Selected Answer: C\\nC is the correct answer."},{"comment_id":"1127155","upvote_count":"3","poster":"SerialiDr","content":"Selected Answer: C\\nElastiCache for Redis provides both encryption in transit and at rest. In cluster mode, it also offers high availability and scalability. This makes it well-suited for caching database queries while ensuring data security and high availability.","timestamp":"1721458920.0"},{"comment_id":"1026488","timestamp":"1712401080.0","poster":"Digo30sp","content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/82917-exam-aws-certified-developer-associate-topic-1-question-95/","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T08:57:48.175Z","extraction_method":"api_direct_v1"},{"question_id":"eP76doTlMGeXZXR2zyYh","question_number":79,"page":16,"question_text":"For a deployment using AWS Code Deploy, what is the run order of the hooks for in-place deployments?","choices":{"C":"BeforeInstall -> ApplicationStop -> ValidateService -> ApplicationStart","D":"ApplicationStop -> BeforeInstall -> ValidateService -> ApplicationStart","A":"BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall","B":"ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart"},"correct_answer":"B","answer_ET":"B","answers_community":["B (88%)","12%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102743-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-15 23:35:00","unix_timestamp":1678919700,"discussion_count":24,"discussion":[{"content":"Selected Answer: B\\nIt\'s B. Check the image in the link.\\n\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-server","upvote_count":"24","timestamp":"1679894760.0","comment_id":"851747","poster":"pratchatcap","comments":[{"poster":"awsdummie","comment_id":"908882","content":"Answer A For InPlace deployment","timestamp":"1685309880.0","upvote_count":"2"}]},{"upvote_count":"1","poster":"sumanshu","content":"Selected Answer: B\\nApplicationStop: Stops the currently running application (if any) on the instance.\\nBeforeInstall: Runs tasks or scripts before the new application revision is installed.\\nInstall: Deploys the new application revision.\\nAfterInstall: Runs tasks or scripts after the new application revision is installed.\\nApplicationStart: Starts the application after installation.\\nValidateService: Validates that the service is running as expected after the application starts.","timestamp":"1734755880.0","comment_id":"1329816","comments":[{"upvote_count":"1","timestamp":"1734755940.0","poster":"sumanshu","comment_id":"1329817","content":"A) Eliminated - The ApplicationStop hook must be the first step to stop the currently running application\\n\\nC) BeforeInstall cannot occur before ApplicationStop because the application needs to be stopped first.\\n\\nD) Eliminated - ValidateService should run after the application starts, not before."}]},{"poster":"trieudo","content":"Selected Answer: B\\n==> discard C, D: ValidateService is invalid lifecycle in In-place CodeDeploy\\n==> discard A: it is not logic, cuz install --\x3e then stop app => pointless \\n\\nSo I choose B","timestamp":"1734087360.0","comment_id":"1326086","upvote_count":"1"},{"poster":"Anandesh","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-server","comment_id":"1248798","upvote_count":"1","timestamp":"1721123040.0"},{"upvote_count":"1","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215003","timestamp":"1716300120.0"},{"poster":"SD_CS","content":"Selected Answer: B\\nAnswer is B. There is no doubt - please go to the URL https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html\\nand search with \\"In-place deployments\\"\\n\\nIn fact none of the deployments follow the order mentioned in A","upvote_count":"2","timestamp":"1706852940.0","comment_id":"1138144"},{"upvote_count":"4","poster":"ez_24","content":"B\\n\\nIn AWS CodeDeploy for in-place deployments, the hooks run in the following order:\\n\\nApplicationStop: Executed before the new application revision is downloaded.\\nDownloadBundle: The new application revision is downloaded.\\nBeforeInstall: Executed after the new revision is downloaded but before the new version is installed.\\nInstall: The application revision specified in the deployment is installed.\\nAfterInstall: Executed after the application revision is installed.\\nApplicationStart: Invoked to start any services that were stopped during ApplicationStop.\\nValidateService: Ensures the service is operating correctly after the new deployment.\\nThis sequence ensures a smooth deployment process by systematically stopping, updating, and restarting the application.","comment_id":"1096697","timestamp":"1702575660.0"},{"comment_id":"1040067","upvote_count":"1","content":"ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart -> ValidateService.\\nRef: https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html","timestamp":"1696989720.0","poster":"quanbui"},{"timestamp":"1695549600.0","upvote_count":"2","comment_id":"1015655","poster":"Skywalker23","content":"Selected Answer: B\\nApplication must be stopped before installation. Otherwise the installation may corrupt the running application\u2019s files and cause damages. Not good."},{"timestamp":"1693742820.0","upvote_count":"3","content":"Selected Answer: B\\nStopped -> Installed -> Started -> Validated\\nGo with B.","poster":"Tony88","comment_id":"997587"},{"timestamp":"1692278880.0","content":"Selected Answer: B\\nI\'s B as per doc https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-server:~:text=a%20load%20balancer.-,Lifecycle%20event%20hook%20availability,-The%20following%20table","poster":"ninomfr64","comment_id":"983677","upvote_count":"1"},{"comment_id":"981238","content":"Application start is after install","timestamp":"1692067620.0","upvote_count":"1","poster":"sp323"},{"content":"Selected Answer: B\\nFor in-place deployment B is correct.\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html","comment_id":"968170","timestamp":"1690812420.0","poster":"fcbc62d","upvote_count":"1"},{"comment_id":"966289","poster":"jipark","content":"Selected Answer: B\\nthis image explain all :\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-server","timestamp":"1690623720.0","upvote_count":"1"},{"content":"Definitely, B: the order is the same in case of InPlace and Blue/Green deployment: https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#reference-appspec-file-structure-hooks-availability","upvote_count":"1","poster":"ScherbakovMike","timestamp":"1685459460.0","comment_id":"910366"},{"poster":"Nagendhar","content":"Ans: A\\n\\nFor an in-place deployment using AWS CodeDeploy, the run order of the hooks is option A, \\"BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall.\\"\\n\\nThis is the correct order of hooks for an in-place deployment, where the deployment package is installed on the same set of Amazon EC2 instances that are running the current version of the application.","comment_id":"892588","timestamp":"1683592440.0","upvote_count":"2"},{"poster":"DeaconStJohn","timestamp":"1682011800.0","content":"Selected Answer: B\\nI\'ll go with B based on the link provided by others","upvote_count":"2","comment_id":"875819"},{"upvote_count":"3","poster":"Syre","comments":[{"content":"From the below link:\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-server\\n\\nNeither type of deployment follows this order.\\nBeforeInstall -> ApplicationStop -> AfterInstall -> ApplicationStart","comment_id":"875818","poster":"DeaconStJohn","timestamp":"1682011740.0","upvote_count":"2"}],"content":"Selected Answer: A\\nYou guys should read the questions carefully. Answer is A.\\nYou are confusing the run order of hooks for in-place deployments with the run order of hooks for blue/green deployments.\\n\\nFor blue/green deployments, the run order of the hooks is indeed ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart, which matches option B. However, for in-place deployments, the correct run order of the hooks is BeforeInstall -> ApplicationStop -> AfterInstall -> ApplicationStart, as stated in option A.","timestamp":"1681623900.0","comment_id":"871495"},{"poster":"brandon87","content":"Selected Answer: B\\nRefer to table.\\nValidationService is last step in this scenario.\\n\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html","upvote_count":"3","comment_id":"858872","timestamp":"1680442080.0"},{"timestamp":"1679546520.0","poster":"March2023","upvote_count":"2","content":"Selected Answer: A\\nThe answer is A","comment_id":"847811","comments":[{"timestamp":"1679789220.0","comment_id":"850568","content":"Looks like its B","poster":"March2023","upvote_count":"2"}]},{"timestamp":"1679431440.0","content":"Selected Answer: B\\nB is correct answer","comment_id":"846330","upvote_count":"3","poster":"svrnvtr"},{"timestamp":"1679309700.0","upvote_count":"1","comment_id":"844780","content":"It should B","poster":"prabhay786"},{"content":"Selected Answer: A\\nThe correct answer is A.\\n\\nThe run order of the hooks for in-place deployments in AWS CodeDeploy is as follows:\\n\\nBeforeInstall: This hook is used to perform any tasks that are necessary before the application is installed.\\n\\nApplicationStop: This hook is used to stop the current version of the application.\\n\\nApplicationStart: This hook is used to start the new version of the application.\\n\\nAfterInstall: This hook is used to perform any tasks that are necessary after the application is installed.\\n\\nTherefore, the correct run order of hooks for in-place deployments is BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall.","comments":[{"content":"Sorry B:\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html","upvote_count":"4","poster":"nickolaj","comment_id":"843048","timestamp":"1679163480.0"}],"comment_id":"842558","upvote_count":"1","poster":"nickolaj","timestamp":"1679125680.0"},{"timestamp":"1678919700.0","upvote_count":"3","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/5462-exam-aws-certified-developer-associate-topic-1-question-58/","comment_id":"840377","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T08:57:48.175Z","extraction_method":"api_direct_v1"},{"question_id":"kcTOglMlq1TWoTwc7Eoe","question_number":80,"page":16,"question_text":"A developer at a company recently created a serverless application to process and show data from business reports. The application\u2019s user interface (UI) allows users to select and start processing the files. The UI displays a message when the result is available to view. The application uses AWS Step Functions with AWS Lambda functions to process the files. The developer used Amazon API Gateway and Lambda functions to create an API to support the UI.\\n\\nThe company\u2019s UI team reports that the request to process a file is often returning timeout errors because of the size or complexity of the files. The UI team wants the API to provide an immediate response so that the UI can display a message while the files are being processed. The backend process that is invoked by the API needs to send an email message when the report processing is complete.\\n\\nWhat should the developer do to configure the API to meet these requirements?","choices":{"A":"Change the API Gateway route to add an X-Amz-Invocation-Type header with a static value of \u2018Event\u2019 in the integration request. Deploy the API Gateway stage to apply the changes.","C":"Change the API Gateway timeout value to match the Lambda function timeout value. Deploy the API Gateway stage to apply the changes.","D":"Change the API Gateway route to add an X-Amz-Target header with a static value of \u2018Async\u2019 in the integration request. Deploy the API Gateway stage to apply the changes.","B":"Change the configuration of the Lambda function that implements the request to process a file. Configure the maximum age of the event so that the Lambda function will run asynchronously."},"correct_answer":"A","answer_ET":"A","answers_community":["A (75%)","D (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122590-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:19:00","unix_timestamp":1696551540,"discussion_count":12,"discussion":[{"upvote_count":"5","content":"Selected Answer: A\\nChange the API Gateway route to add an X-Amz-Invocation-Type header with a static value of \u2018Event\u2019 in the integration request: This is the correct approach. By setting the X-Amz-Invocation-Type header to Event in the API Gateway integration request, the API Gateway will invoke the Lambda function asynchronously. In asynchronous execution, the Lambda function returns an immediate response (202 or Accepted status) to API Gateway, which can then relay it back to the UI. Meanwhile, the Lambda function processes the file in the background.","timestamp":"1705741680.0","poster":"SerialiDr","comment_id":"1127156"},{"content":"Selected Answer: A\\ncurl -X POST \\\\\\n -H \\"X-Amz-Invocation-Type: Event\\" \\\\\\n https://lambda-endpoint.amazonaws.com/2015-03-31/functions/my-function/invocations \\\\\\n -d \'{ \\"key1\\": \\"value1\\" }\'","comment_id":"1289839","upvote_count":"1","poster":"albert_kuo","timestamp":"1727419320.0"},{"comment_id":"1283018","content":"According chatgpt correct is A. D is wrong because header value is set for Async and it should be set for Event\\n\\nThis header is incorrect for this use case. The correct header for asynchronous invocation of Lambda is X-Amz-Invocation-Type with the value \'Event\', not \'Async\'.","timestamp":"1726204260.0","upvote_count":"1","poster":"ltfalcon"},{"poster":"Saurabh04","comment_id":"1265640","upvote_count":"1","timestamp":"1723632480.0","content":"Selected Answer: D\\nBy adding the X-Amz-Target header with a value of \'Async\', the API Gateway will invoke the backend Lambda function asynchronously."},{"content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","comment_id":"1216526","timestamp":"1716464700.0","upvote_count":"1"},{"poster":"JLLNOR","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-integration-async.html","comment_id":"1108491","timestamp":"1703839080.0","upvote_count":"4"},{"timestamp":"1702646460.0","content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/82655-exam-aws-certified-developer-associate-topic-1-question-85/","poster":"Certified101","comment_id":"1097340","upvote_count":"3"},{"upvote_count":"1","timestamp":"1702386120.0","content":"Selected Answer: D\\nOption A is incorrect because the X-Amz-Invocation-Type header with a static value of \'Event\' is used for the AWS Lambda asynchronous invocation, but it doesn\'t address the issue of providing an immediate response to the UI.\\n\\nOption D is the correct choice. By adding an X-Amz-Target header with a static value of \'Async\' in the integration request, the API Gateway will immediately return a response to the UI, allowing it to display a message while the backend processing continues asynchronously. This ensures that the UI team does not encounter timeout errors due to long-running processes.","comments":[{"comment_id":"1101651","poster":"TanTran04","content":"I miss something, Option D is undocumented. \\n=> A is the best choice","upvote_count":"2","timestamp":"1703083920.0"}],"comment_id":"1094527","poster":"TanTran04"},{"timestamp":"1697773920.0","poster":"LemonGremlin","upvote_count":"2","content":"Selected Answer: A\\nReference: https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-integration-async.html","comment_id":"1048354"},{"comment_id":"1046948","content":"Selected Answer: D\\nOption A involves changing the API Gateway route to add an X-Amz-Invocation-Type header with a static value of \'Event\' in the integration request. This header is typically used when you want to invoke a Lambda function asynchronously, but it doesn\'t ensure that you get an immediate response. It essentially sends the request to a queue for asynchronous execution and doesn\'t wait for the processing to complete before providing a response.\\n\\nIn contrast, option D suggests using the X-Amz-Target header with a static value of \'Async,\' which is a more appropriate choice when you need to provide an immediate response to the client while offloading the processing for background execution. This approach better aligns with the requirement of displaying a message to the user while the files are being processed, which is typically achieved through asynchronous processing with notification upon completion.","timestamp":"1697635800.0","poster":"kashtelyan","upvote_count":"4"},{"upvote_count":"2","comment_id":"1026493","content":"Selected Answer: A\\nA) https://www.examtopics.com/discussions/amazon/view/82655-exam-aws-certified-developer-associate-topic-1-question-85/","timestamp":"1696589940.0","poster":"Digo30sp"},{"content":"aaaaaaaaaAAAAAAAAAAAAAAAA","upvote_count":"2","poster":"fordiscussionstwo","comment_id":"1026069","timestamp":"1696551540.0"}],"answer_description":"","extracted_at":"2025-12-24T08:57:48.175Z","extraction_method":"api_direct_v1"},{"question_id":"5RmT4e1GCkCPzIk92d2u","question_number":81,"page":17,"question_text":"A developer has an application that is composed of many different AWS Lambda functions. The Lambda functions all use some of the same dependencies. To avoid security issues, the developer is constantly updating the dependencies of all of the Lambda functions. The result is duplicated effort for each function.\\n\\nHow can the developer keep the dependencies of the Lambda functions up to date with the LEAST additional complexity?","choices":{"C":"Define a Lambda layer that contains all of the shared dependencies.","B":"Upgrade the Lambda functions to the most recent runtime version.","D":"Use an AWS CodeCommit repository to host the dependencies in a centralized location.","A":"Define a maintenance window for the Lambda functions to ensure that the functions get updated copies of the dependencies."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122591-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:21:00","unix_timestamp":1696551660,"discussion_count":4,"discussion":[{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","comment_id":"1216565","timestamp":"1732372500.0","poster":"65703c1"},{"content":"Selected Answer: C\\nTo share dependencies across multiple functions. After you create a layer, you can apply it to any number of functions in your account. Without layers, you need to include the same dependencies in each individual deployment package.\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/chapter-layers.html","poster":"TanTran04","comment_id":"1101653","timestamp":"1718888040.0","upvote_count":"2"},{"poster":"dilleman","upvote_count":"2","content":"Selected Answer: C\\nC is correct.","comment_id":"1040340","timestamp":"1712822520.0"},{"comment_id":"1026495","upvote_count":"2","poster":"Digo30sp","timestamp":"1712401200.0","content":"Selected Answer: C\\nC) https://www.examtopics.com/discussions/amazon/view/96245-exam-aws-certified-developer-associate-topic-1-question-436/"}],"answer_description":"","extracted_at":"2025-12-24T08:57:59.165Z","extraction_method":"api_direct_v1"},{"question_id":"DFNQHfMl51mA9Y0v7Joi","question_number":82,"page":17,"question_text":"A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed.\\n\\nWhat is the MOST cost-effective way to delete posts that are older than 48 hours?","choices":{"C":"For each item, add a new attribute of type Date that has a timestamp that is set to 48 hours after the blog post creation time. Create a global secondary index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the BatchWriteItem API operation. Schedule the function with an Amazon CloudWatch event every minute.","A":"For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.","B":"For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.","D":"For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122593-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:26:00","unix_timestamp":1696551960,"discussion_count":4,"discussion":[{"comment_id":"1216566","timestamp":"1732372560.0","content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","upvote_count":"2"},{"poster":"SerialiDr","timestamp":"1721483880.0","content":"Selected Answer: D\\nThis is the most cost-effective and efficient solution. The TTL feature allows DynamoDB to automatically delete items past a certain timestamp, which is perfect for this use case. By adding a TTL attribute to each item (set to 48 hours after the post creation time), DynamoDB will automatically delete the items when they expire, without any need for custom scripts, additional AWS services, or manual intervention.","upvote_count":"2","comment_id":"1127368"},{"comment_id":"1040343","timestamp":"1712822700.0","content":"Selected Answer: D\\nD is correct. DynamoDB tables can clean up data itself based on provided configuration.","poster":"dilleman","upvote_count":"3"},{"timestamp":"1712401380.0","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nSolution (D) is the most cost-effective because it uses DynamoDB\'s Time to Live (TTL) to automatically remove expired items. The TTL is an item attribute that specifies the duration of time that an item should remain in the table. When an item\'s TTL expires, the item is automatically deleted from the table.","upvote_count":"3","poster":"Digo30sp","comment_id":"1026501"}],"answer_description":"","extracted_at":"2025-12-24T08:57:59.165Z","extraction_method":"api_direct_v1"},{"question_id":"EYK8Hjx2E6tPiqRdidmZ","question_number":83,"page":17,"question_text":"A developer is modifying an existing AWS Lambda function. While checking the code, the developer notices hardcoded parameter values for an Amazon RDS for SQL Server user name, password, database, host, and port. There are also hardcoded parameter values for an Amazon DynamoDB table, an Amazon S3 bucket, and an Amazon Simple Notification Service (Amazon SNS) topic.\\n\\nThe developer wants to securely store the parameter values outside the code in an encrypted format and wants to turn on rotation for the credentials. The developer also wants to be able to reuse the parameter values from other applications and to update the parameter values without modifying code.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic.","D":"Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Store the DynamoDB table, S3 bucket, and SNS topic in Amazon S3. Create a Lambda function and set the logic for the credentials rotation. Invoke the Lambda function on a schedule.","C":"Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. Create a Lambda function and set the logic for the credentials rotation task. Schedule the credentials rotation task in Amazon EventBridge.","B":"Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122592-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:25:00","unix_timestamp":1696551900,"discussion_count":4,"discussion":[{"timestamp":"1732372740.0","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1216570"},{"timestamp":"1721485920.0","content":"Selected Answer: B\\nAWS Secrets Manager is designed to handle sensitive information like database credentials and supports automatic rotation. Using SecureString parameters in Systems Manager Parameter Store for other parameters provides a secure and centralized way to manage them. This approach also enables reusability and easy updating without code modifications.","comment_id":"1127393","poster":"SerialiDr","upvote_count":"4"},{"content":"Selected Answer: B\\nB is correct","timestamp":"1712822820.0","upvote_count":"3","poster":"dilleman","comment_id":"1040346"},{"poster":"Digo30sp","content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/88929-exam-aws-certified-developer-associate-topic-1-question-338/","timestamp":"1712404920.0","comment_id":"1026570","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:57:59.165Z","extraction_method":"api_direct_v1"},{"question_id":"5crN68yEsWVDWkDiXVsE","question_number":84,"page":17,"question_text":"A developer accesses AWS CodeCommit over SSH. The SSH keys configured to access AWS CodeCommit are tied to a user with the following permissions:\\n\\n//IMG//\\n\\n\\nThe developer needs to create/delete branches.\\n\\nWhich specific IAM permissions need to be added, based on the principle of least privilege?","choices":{"C":"\\"codecommit:Update*\\"","D":"\\"codecommit:*\\"","A":"\\"codecommit:CreateBranch\\"\\n\\"codecommit:DeleteBranch\\"","B":"\\"codecommit:Put*\\""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122594-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image13.png"],"answer_images":[],"timestamp":"2023-10-06 02:27:00","unix_timestamp":1696552020,"discussion_count":4,"discussion":[{"timestamp":"1732372980.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216572","upvote_count":"3"},{"poster":"TanTran04","upvote_count":"2","comment_id":"1101661","timestamp":"1718888460.0","content":"Selected Answer: A\\nTake a look at CodeCommit API Operations and Required Permissions for Actions on Branches in https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-permissions-reference.html#aa-branches => A"},{"poster":"dilleman","timestamp":"1712822940.0","upvote_count":"3","comment_id":"1040349","content":"Selected Answer: A\\nA of course"},{"timestamp":"1712405040.0","upvote_count":"2","comment_id":"1026571","content":"Selected Answer: A\\nA) https://www.examtopics.com/discussions/amazon/view/4364-exam-aws-certified-developer-associate-topic-1-question-190/","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:57:59.165Z","extraction_method":"api_direct_v1"},{"question_id":"7e8XTc1Qyn4uBvIoiTeU","question_number":85,"page":17,"question_text":"An application that is deployed to Amazon EC2 is using Amazon DynamoDB. The application calls the DynamoDB REST API. Periodically, the application receives a ProvisionedThroughputExceededException error when the application writes to a DynamoDB table.\\n\\nWhich solutions will mitigate this error MOST cost-effectively? (Choose two.)","choices":{"A":"Modify the application code to perform exponential backoff when the error is received.","E":"Create a second DynamoDB table. Distribute the reads and writes between the two tables.","B":"Modify the application to use the AWS SDKs for DynamoDB.","D":"Create a DynamoDB Accelerator (DAX) cluster for the DynamoDB table.","C":"Increase the read and write throughput of the DynamoDB table."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (89%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122595-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:28:00","unix_timestamp":1696552080,"discussion_count":8,"discussion":[{"comment_id":"1127371","poster":"SerialiDr","content":"Selected Answer: AB\\nA. Modify the application code to perform exponential backoff when the error is received: This is a cost-effective and recommended approach. Exponential backoff is a standard error-retry strategy where the time between retries gradually increases. This strategy helps to efficiently manage request retries without immediately consuming additional throughput, thus reducing the likelihood of repeatedly hitting the throughput limits.\\n\\nB. Modify the application to use the AWS SDKs for DynamoDB: The AWS SDKs implement best practices, including automatic retry logic with exponential backoff. Using an AWS SDK for DynamoDB can simplify the implementation and is more efficient than directly calling the DynamoDB REST API. This change can help mitigate throughput exceedance errors.","upvote_count":"6","timestamp":"1705766880.0"},{"comment_id":"1324488","content":"Selected Answer: AB\\nYes AB is the right set of answers.","poster":"f271c23","timestamp":"1733826120.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1310578","content":"Key Words Why They Matter\\nProvisionedThroughputExceededException Indicates the application is exceeding the provisioned capacity of the DynamoDB table.\\n\\nPeriodically Suggests that the issue happens under specific conditions, such as traffic spikes.\\n\\nREST API Implies the application is making direct API calls, possibly without SDK optimizations.\\n\\nCost-effectively Points towards solutions that avoid increasing DynamoDB capacity (which costs more).\\nWrites to a DynamoDB table\\n Identifies the operation likely causing the throttling issue.\\n\\nModify application code Indicates that a code change is necessary to handle throttling errors better.\\n\\nExponential backoff A retry strategy to reduce the impact of throttling.\\n\\nAWS SDKs Built-in solutions for efficient, optimized interactions with DynamoDB.","poster":"CloudChingon","timestamp":"1731415380.0"},{"poster":"aws_god","upvote_count":"1","comment_id":"1305329","timestamp":"1730362140.0","content":"Selected Answer: BC\\nThis is what the exception looks like:\\n\\"boto.dynamodb2.exceptions.ProvisionedThroughputExceededException: ProvisionedThroughputExceededException: 400 Bad Request\\n{u\'message\': u\'The level of configured provisioned throughput for the table was exceeded. Consider increasing your provisioning level with the UpdateTable API\', u\'__type\': u\'com.amazonaws.dynamodb.v20120810#ProvisionedThroughputExceededException\'}\\"\\n\\nYou need B since the AWS SDK includes automatic retry logic with exponential backoff specifically designed to deal with this automatically and C since increasing the provisioned level also helps solve this issue."},{"poster":"65703c1","upvote_count":"1","timestamp":"1716468300.0","comment_id":"1216574","content":"Selected Answer: AB\\nAB is the correct answer."},{"poster":"TanTran04","comment_id":"1093505","upvote_count":"1","content":"Selected Answer: AC\\nFollowing ChatGPT 3.5, Option A and C\\nOption B (Modify the application to use the AWS SDKs for DynamoDB) is not directly related to resolving throughput issues. It\'s generally recommended to use the AWS SDKs as they provide more efficient and convenient ways to interact with AWS services, but it may not directly address the ProvisionedThroughputExceededException issue.","timestamp":"1702301760.0"},{"timestamp":"1697011920.0","poster":"dilleman","comment_id":"1040351","content":"Selected Answer: AB\\nA and B.\\nExponential backoff is a standard error-handling strategy for network applications. The idea is to retry a failed request with increasing delays between each attempt.\\n\\nAnd the AWS SDKs have built-in support for handling these errors.","upvote_count":"4"},{"timestamp":"1696593900.0","content":"Selected Answer: AB\\nA and B: https://www.examtopics.com/discussions/amazon/view/69199-exam-aws-certified-developer-associate-topic-1-question-385/","comment_id":"1026573","poster":"Digo30sp","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:57:59.165Z","extraction_method":"api_direct_v1"},{"question_id":"38JO30QtpuSIz2PdDcT6","question_number":86,"page":18,"question_text":"When a developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters.\\n\\nWhat is the recommended solution?","choices":{"C":"Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.","B":"Use Amazon Cognito to store key-value pairs for large numbers of environment variables.","D":"Use AWS Systems Manager Parameter Store to store large numbers of environment variables.","A":"Add the export LC_ALL=\\"en_US.utf8\\" command to the pre_build section to ensure POSIX localization."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122596-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:29:00","unix_timestamp":1696552140,"discussion_count":4,"discussion":[{"upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1732373160.0","comment_id":"1216575"},{"timestamp":"1721494020.0","upvote_count":"4","comment_id":"1127450","poster":"SerialiDr","content":"Selected Answer: D\\nAWS Systems Manager Parameter Store is specifically designed for managing configuration data and secrets. It can store large numbers of parameters, including environment variables, and makes them easily accessible and manageable. It also provides features like versioning, fine-grained access control, and integration with AWS Identity and Access Management (IAM)."},{"timestamp":"1712823240.0","poster":"dilleman","content":"Selected Answer: D\\nBest solution is D","upvote_count":"4","comment_id":"1040357"},{"content":"Selected Answer: D\\nD) https://docs.aws.amazon.com/codebuild/latest/userguide/troubleshooting.html","comment_id":"1026574","timestamp":"1712405220.0","upvote_count":"4","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:58:10.166Z","extraction_method":"api_direct_v1"},{"question_id":"i7DUcFCg2gmIRK2V5kSF","question_number":87,"page":18,"question_text":"A company is expanding the compatibility of its photo-sharing mobile app to hundreds of additional devices with unique screen dimensions and resolutions. Photos are stored in Amazon S3 in their original format and resolution. The company uses an Amazon CloudFront distribution to serve the photos. The app includes the dimension and resolution of the display as GET parameters with every request.\\n\\nA developer needs to implement a solution that optimizes the photos that are served to each device to reduce load time and increase photo quality.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"A":"Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a dynamic CloudFront origin that automatically maps the request of each device to the corresponding photo variant.","C":"Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. Change the CloudFront TTL cache policy to the maximum value possible.","D":"Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. In the same function, store a copy of the processed photos on Amazon S3 for subsequent requests.","B":"Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a Lambda@Edge function to route requests to the corresponding photo variant by using request headers."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122597-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:32:00","unix_timestamp":1696552320,"discussion_count":11,"discussion":[{"poster":"tsangckl","upvote_count":"1","content":"This appear at 17 Jun exam","comment_id":"1231710","timestamp":"1718597940.0"},{"timestamp":"1716468480.0","comment_id":"1216577","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","poster":"65703c1"},{"content":"C\\nI dont see any aws docs about Cloutfront cache=> so maybe it is cost-effective","poster":"Melisa202401","timestamp":"1712394360.0","upvote_count":"1","comment_id":"1190317"},{"content":"Selected Answer: D\\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/resizing-images-with-amazon-cloudfront-lambdaedge-aws-cdn-blog/","timestamp":"1706931900.0","comment_id":"1138987","poster":"joshnort","upvote_count":"3"},{"comment_id":"1127453","content":"Selected Answer: D\\nThis solution is the most cost-effective. Lambda@Edge processes the photos dynamically based on the device\'s requirements, which means no pre-generation of multiple variants is required. Processed photos are stored on S3, ensuring that subsequent requests for the same photo variant are served directly from S3, reducing Lambda@Edge invocations and further optimizing costs.","upvote_count":"4","poster":"SerialiDr","timestamp":"1705776720.0"},{"content":"Selected Answer: D\\nhttps://aws.amazon.com/es/blogs/networking-and-content-delivery/image-optimization-using-amazon-cloudfront-and-aws-lambda/","timestamp":"1701967740.0","poster":"Mimi666","upvote_count":"4","comment_id":"1090449"},{"comments":[{"content":"CloudFront has a Maximum TTL of 365 days. Would it not be cheaper to store the images in the CloudFront cache, instead of storing it in S3 which would incur costs?\\n\\nWe may need to assume it would be unlikely the users would access the same photo more than a year after the initial access.","upvote_count":"1","comment_id":"1254643","timestamp":"1721869560.0","poster":"BrainFried"}],"upvote_count":"1","poster":"jingle4944","content":"According to https://aws.amazon.com/blogs/networking-and-content-delivery/resizing-images-with-amazon-cloudfront-lambdaedge-aws-cdn-blog/, \\"static resources like images should have a long Time to Live (TTL) as possible to improve cache-hit ratios.\\". The photo cache here is likely to be static and should be preserved forever.","comment_id":"1063838","timestamp":"1699274820.0"},{"upvote_count":"1","comment_id":"1055989","poster":"ut18","timestamp":"1698472620.0","content":"Why not B?\\nThe developer can use S3 Batch Operations to create new variants of the photos with the required dimensions and resolutions."},{"poster":"TallManDan","comments":[{"comment_id":"1254644","poster":"BrainFried","upvote_count":"1","content":"CloudFront cache has a Maximum TTL of 365 days. Would it not be cheaper to store the images in the CloudFront cache, instead of storing it in S3 which would incur costs?\\n\\nWe may need to assume it would be unlikely the users would access the same photo more than a year after the initial access.","timestamp":"1721869620.0"}],"upvote_count":"2","comment_id":"1046281","content":"Selected Answer: D\\nYou only want to convert the pictures that get requests. If you convert them all through batch processing, you have wasted time and expense on any possible photo that never gets viewed. The Minimum TTL is set to 60 seconds, the Default TTL is set to 300 seconds, and the Maximum TTL is set to 3600 seconds. S3 is the way to go.","timestamp":"1697568480.0"},{"upvote_count":"1","timestamp":"1697012220.0","poster":"dilleman","comment_id":"1040360","content":"Selected Answer: D\\nD is correct"},{"upvote_count":"1","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/89564-exam-aws-certified-developer-associate-topic-1-question-320/","poster":"Digo30sp","comment_id":"1026576","timestamp":"1696594080.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:10.166Z","extraction_method":"api_direct_v1"},{"question_id":"e63cgKIHwzgbZaSnnupc","question_number":88,"page":18,"question_text":"A company is building an application for stock trading. The application needs sub-millisecond latency for processing trade requests. The company uses Amazon DynamoDB to store all the trading data that is used to process each trading request.\\n\\nA development team performs load testing on the application and finds that the data retrieval time is higher than expected. The development team needs a solution that reduces the data retrieval time with the least possible effort.\\n\\nWhich solution meets these requirements?","choices":{"C":"Add retries with exponential backoff for DynamoDB queries.","B":"Store the trading data in Amazon S3, and use S3 Transfer Acceleration.","A":"Add local secondary indexes (LSIs) for the trading data.","D":"Use DynamoDB Accelerator (DAX) to cache the trading data."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122598-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:33:00","unix_timestamp":1696552380,"discussion_count":7,"discussion":[{"upvote_count":"2","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1732373400.0","poster":"65703c1","comment_id":"1216578"},{"poster":"joshnort","timestamp":"1722649620.0","content":"Selected Answer: D\\nhttps://aws.amazon.com/dynamodb/dax/","upvote_count":"1","comment_id":"1138990"},{"poster":"SerialiDr","upvote_count":"4","comment_id":"1127457","timestamp":"1721494560.0","content":"Selected Answer: D\\nDAX is an in-memory cache for DynamoDB that delivers fast read performance for your tables at scale by enabling you to get sub-millisecond response times for accessing your data. DAX is particularly beneficial for read-heavy and bursty workloads. Since it reduces the time to retrieve data, it\'s the most appropriate solution for achieving sub-millisecond latency in data retrieval."},{"comment_id":"1126300","content":"Selected Answer: D\\nUse DynamoDB Accelerator (DAX)","upvote_count":"2","poster":"JohnPl","timestamp":"1721344500.0"},{"timestamp":"1718766060.0","upvote_count":"2","poster":"TanTran04","content":"Selected Answer: D\\nhttps://aws.amazon.com/dynamodb/dax/\\nDAX delivers up to a 10 times performance improvement\u2014from milliseconds to microseconds\u2014even at millions of requests per second. only pay for the capacity you provision.","comment_id":"1100311"},{"comment_id":"1040364","upvote_count":"3","content":"Selected Answer: D\\nThis is a perfect scenario for DAX so correct answer is D","timestamp":"1712823540.0","poster":"dilleman"},{"upvote_count":"3","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/4971-exam-aws-certified-developer-associate-topic-1-question-14/","comment_id":"1026578","poster":"Digo30sp","timestamp":"1712405340.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:10.166Z","extraction_method":"api_direct_v1"},{"question_id":"gYqUbq87SFY9gwPwhVvZ","question_number":89,"page":18,"question_text":"A developer is working on a Python application that runs on Amazon EC2 instances. The developer wants to enable tracing of application requests to debug performance issues in the code.\\n\\nWhich combination of actions should the developer take to achieve this goal? (Choose two.)","choices":{"C":"Configure the application to write JSON-formatted logs to /var/log/cloudwatch.","B":"Install the AWS X-Ray daemon on the EC2 instances.","E":"Install and configure the AWS X-Ray SDK for Python in the application.","D":"Configure the application to write trace data to /var/log/xray.","A":"Install the Amazon CloudWatch agent on the EC2 instances."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122600-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:35:00","unix_timestamp":1696552500,"discussion_count":5,"discussion":[{"comment_id":"1026580","upvote_count":"9","content":"Selected Answer: BE\\nThe correct answers are (E) and (B).\\n\\n(E) is the most important action to enable application request tracking using AWS X-Ray. The AWS X-Ray SDK for Python provides a set of APIs that a developer can use to instrument their application code for tracing.\\n\\n(B) is the second most important action. The AWS X-Ray daemon runs on each EC2 instance and collects application trace data","poster":"Digo30sp","timestamp":"1712405460.0"},{"upvote_count":"1","content":"Selected Answer: BE\\nBE is the correct answer.","poster":"65703c1","timestamp":"1732373520.0","comment_id":"1216581"},{"comment_id":"1127460","timestamp":"1721494800.0","upvote_count":"3","content":"Selected Answer: BE\\nB. Install the AWS X-Ray daemon on the EC2 instances: This is a required step for enabling AWS X-Ray tracing. The X-Ray daemon listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. This is necessary for collecting and sending trace data from the application to X-Ray.\\nE. Install and configure the AWS X-Ray SDK for Python in the application: This is a critical step for enabling X-Ray tracing in your Python application. The X-Ray SDK for Python provides classes and methods to collect data about the requests that your application serves, and sends this data to the X-Ray daemon.","poster":"SerialiDr"},{"poster":"NinjaCloud","comment_id":"1058278","content":"Answer: E,B","upvote_count":"3","timestamp":"1714504140.0"},{"timestamp":"1712826420.0","content":"Selected Answer: BE\\nB and E","upvote_count":"4","poster":"dilleman","comment_id":"1040409"}],"answer_description":"","extracted_at":"2025-12-24T08:58:10.166Z","extraction_method":"api_direct_v1"},{"question_id":"4ATWQikofBTt0gmIFtgl","question_number":90,"page":18,"question_text":"A company is building a serverless application on AWS. The application uses an AWS Lambda function to process customer orders 24 hours a day, 7 days a week. The Lambda function calls an external vendor\'s HTTP API to process payments.\\nDuring load tests, a developer discovers that the external vendor payment processing API occasionally times out and returns errors. The company expects that some payment processing API calls will return errors.\\nThe company wants the support team to receive notifications in near real time only when the payment processing external API error rate exceed 5% of the total number of transactions in an hour. Developers need to use an existing Amazon Simple Notification Service (Amazon SNS) topic that is configured to notify the support team.\\nWhich solution will meet these requirements?","choices":{"B":"Publish custom metrics to CloudWatch that record the failures of the external payment processing API calls. Configure a CloudWatch alarm to notify the existing SNS topic when error rate exceeds the specified rate.","C":"Publish the results of the external payment processing API calls to a new Amazon SNS topic. Subscribe the support team members to the new SNS topic.","D":"Write the results of the external payment processing API calls to Amazon S3. Schedule an Amazon Athena query to run at regular intervals. Configure Athena to send notifications to the existing SNS topic when the error rate exceeds the specified rate.","A":"Write the results of payment processing API calls to Amazon CloudWatch. Use Amazon CloudWatch Logs Insights to query the CloudWatch logs. Schedule the Lambda function to check the CloudWatch logs and notify the existing SNS topic."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103466-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 12:33:00","unix_timestamp":1679398380,"discussion_count":9,"discussion":[{"content":"Selected Answer: B\\nB. Publish custom metrics to CloudWatch that record the failures of the external payment processing API calls. Configure a CloudWatch alarm to notify the existing SNS topic when the error rate exceeds the specified rate is the best solution to meet the requirements.\\n\\nWith CloudWatch custom metrics, developers can publish and monitor custom data points, including the number of failed requests to the external payment processing API. A CloudWatch alarm can be configured to notify an SNS topic when the error rate exceeds the specified rate, allowing the support team to be notified in near real-time.\\n\\nOption A is not optimal since it involves scheduling a Lambda function to check the CloudWatch logs. Option C may not provide the desired functionality since it does not specify a rate at which to notify the support team. Option D is more complex than necessary, as it involves writing the results to S3 and configuring an Athena query to send notifications to an SNS topic.","timestamp":"1683376140.0","poster":"Bibay","comment_id":"890733","upvote_count":"14"},{"timestamp":"1679398380.0","upvote_count":"7","content":"Selected Answer: B\\nThe correct answer is B.\\nYou can use the Embedded Metrics format to embed custom metrics alongside detailed log event data. CloudWatch automatically extracts the custom metrics so you can visualize and alarm on them, for real-time incident detection.\\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/custom-metrics.html","poster":"Untamables","comment_id":"845860"},{"upvote_count":"2","content":"Selected Answer: B\\nA) Eliminated - Requires manual log queries and a custom Lambda function to process logs, introducing operational overhead.\\n\\nB) Correct - CloudWatch Alarms can calculate error rates using metric math and automatically notify the SNS topic.\\n\\nC) Eliminated - This approach notifies the support team for every API failure, not just when the error rate exceeds 5%.\\n\\nD) Eliminated - Adds significant operational complexity (managing S3 storage, Athena queries, and scheduling).","poster":"sumanshu","timestamp":"1734772920.0","comment_id":"1329898"},{"comment_id":"1326094","timestamp":"1734088860.0","content":"Selected Answer: B\\nkeyword: error rate exceed 5%, receive notifications in near real time \\n\\n==> discard A,: use lamdba or athena with schedule, violate \' receive notifications in near real time \'\\n==> discard C: die in spam of message if any, and don\'t know when error up 5%\\n\\nB is most good solution: CloudWatch Alarm can calculate 5% with setup, and notify righ away when reach thresold set-up","upvote_count":"1","poster":"trieudo"},{"content":"Selected Answer: B\\nIt\'s B, allows you to customize the metrics as required in the question, and sends notification in near real time instead of polling","poster":"rue_","upvote_count":"1","timestamp":"1730002380.0","comment_id":"1303479"},{"poster":"65703c1","timestamp":"1716300780.0","comment_id":"1215013","upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer."},{"comments":[{"content":"In the question, it is also mentioned that \\"Developer needs to use the existing SNS topic....\\"","comment_id":"1061954","timestamp":"1699084440.0","poster":"Ponyi","upvote_count":"1"}],"comment_id":"997578","content":"Selected Answer: B\\nRequire \\"near real-time\\" notification, so you should not use scheduled solution.\\nCreating a new SNS topic is no sense.","poster":"Tony88","upvote_count":"2","timestamp":"1693742400.0"},{"timestamp":"1691612280.0","content":"Option B. Using custom metrics, Developers will be able to publish and monitor custom data points such as the no. of failed requests to the external payment processing API. Create a CloudWatch alarm and configure it to be triggered when the rate of error exceeds the specified number in the question.","upvote_count":"1","poster":"jayvarma","comment_id":"977003"},{"upvote_count":"3","comment_id":"846331","timestamp":"1679431560.0","poster":"svrnvtr","content":"Selected Answer: B\\nIt is B"}],"answer_description":"","extracted_at":"2025-12-24T08:58:10.166Z","extraction_method":"api_direct_v1"},{"question_id":"5J5uaQ0bpoEGzKJhmkC0","question_number":91,"page":19,"question_text":"A company has an application that runs as a series of AWS Lambda functions. Each Lambda function receives data from an Amazon Simple Notification Service (Amazon SNS) topic and writes the data to an Amazon Aurora DB instance.\\n\\nTo comply with an information security policy, the company must ensure that the Lambda functions all use a single securely encrypted database connection string to access Aurora.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Use IAM database authentication for Aurora to enable secure database connections for all the Lambda functions.","C":"Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.","D":"Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption.","B":"Store the credentials and read the credentials from an encrypted Amazon RDS DB instance."},"correct_answer":"C","answer_ET":"C","answers_community":["C (64%)","A (25%)","11%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122601-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:37:00","unix_timestamp":1696552620,"discussion_count":11,"discussion":[{"poster":"dilleman","upvote_count":"13","comment_id":"1040413","content":"Selected Answer: C\\nC.\\nAWS Systems Manager Parameter Store offers a more centralized way to manage encrypted secrets across multiple services than Lambda environment variables, making it a better fit for this scenario.","timestamp":"1697015400.0"},{"poster":"ShawnWon","timestamp":"1700384880.0","upvote_count":"7","comment_id":"1074546","content":"C.\\nOption A (IAM database authentication) may provide secure authentication, but it doesn\'t directly address the storage and retrieval of the connection string.\\n\\nOption B (storing credentials in an encrypted RDS DB instance) might introduce unnecessary complexity and potential security risks.\\n\\nOption D (Lambda environment variables with a shared AWS KMS key) is a viable option, but using Parameter Store is generally considered a more centralized and managed approach for storing and retrieving sensitive data in AWS.\\n\\nTherefore, option C is the most appropriate choice for securely managing the database connection string in this scenario."},{"comment_id":"1272949","poster":"wh1t4k3r","content":"Selected Answer: C\\nC is the best choice. For those that chose A: simply enabling the DB IAM auth does not address the need to use a single secure string. It would require more steps to make this work regarding lambda execution role, iam policies and etc.","timestamp":"1724694780.0","upvote_count":"1"},{"poster":"tsangckl","comment_id":"1231711","timestamp":"1718597940.0","upvote_count":"1","content":"This appear at 17 Jun exam"},{"upvote_count":"1","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716468840.0","comment_id":"1216586"},{"timestamp":"1709634540.0","poster":"KarBiswa","comment_id":"1166354","content":"Selected Answer: A\\nhttps://aws.amazon.com/blogs/database/iam-role-based-authentication-to-amazon-aurora-from-serverless-applications/","upvote_count":"1"},{"comment_id":"1157462","upvote_count":"2","poster":"KillThemWithKindness","content":"Selected Answer: A\\nThe developer can create an IAM role with permission to connect to Aurora DB instance and attach it to each Lambda function. The developer can also configure Aurora DB instance to use IAM database authentication and enable encryption in transit using SSL certificates. \\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html","timestamp":"1708718940.0"},{"comment_id":"1137639","poster":"rimaSamir","upvote_count":"2","comments":[{"upvote_count":"1","poster":"rimaSamir","content":"In Amazon Aurora, you can associate the database users with the IAM user and roles.","timestamp":"1706793540.0","comment_id":"1137640"}],"content":"The answer is A.\\nhttps://aws.amazon.com/ru/blogs/database/iam-role-based-authentication-to-amazon-aurora-from-serverless-applications/","timestamp":"1706793420.0"},{"content":"Selected Answer: C\\nC. Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter: This is a strong option. Systems Manager Parameter Store provides secure, hierarchical storage for configuration data and secrets. It can store data such as passwords and database connection strings securely, and it integrates with AWS Key Management Service (AWS KMS) for encryption. Lambda functions can then retrieve the connection string securely at runtime.\\n\\nD. Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption: While Lambda environment variables can be encrypted with AWS KMS and used to store sensitive information like database connection strings, they are not as centrally manageable as Parameter Store. Each Lambda function\'s environment variables would need to be updated individually if the connection string changes, which is less efficient and more prone to error.","comment_id":"1127464","upvote_count":"3","timestamp":"1705777680.0","poster":"SerialiDr"},{"comment_id":"1046293","poster":"TallManDan","timestamp":"1697569320.0","upvote_count":"4","content":"Selected Answer: A\\nhttps://aws.amazon.com/blogs/database/iam-role-based-authentication-to-amazon-aurora-from-serverless-applications/"},{"poster":"Digo30sp","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nSolution (D) is the best option because it uses Lambda environment variables with an AWS Key Management Service (AWS KMS) shared key for encryption.","upvote_count":"3","timestamp":"1696594500.0","comment_id":"1026586"}],"answer_description":"","extracted_at":"2025-12-24T08:58:21.228Z","extraction_method":"api_direct_v1"},{"question_id":"gtprG6hznpAEEWQzfccF","question_number":92,"page":19,"question_text":"A developer is troubleshooting an Amazon API Gateway API. Clients are receiving HTTP 400 response errors when the clients try to access an endpoint of the API.\\n\\nHow can the developer determine the cause of these errors?","choices":{"C":"Turn on AWS X-Ray for the API stage. Create an Amazon CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.","D":"Turn on execution logging and access logging in Amazon CloudWatch Logs for the API stage. Create a CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.","B":"Turn on AWS CloudTrail Insights and create a trail. Specify the Amazon Resource Name (ARN) of the trail for the stage of the API.","A":"Create an Amazon Kinesis Data Firehose delivery stream to receive API call logs from API Gateway. Configure Amazon CloudWatch Logs as the delivery stream\u2019s destination."},"correct_answer":"D","answer_ET":"D","answers_community":["D (76%)","B (18%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122602-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:37:00","unix_timestamp":1696552620,"discussion_count":9,"discussion":[{"timestamp":"1719986880.0","comment_id":"1112593","content":"Selected Answer: D\\nwhy not C,X-Ray is more focused on the internal workings and performance of the API rather than the validity or structure of incoming requests.according to the error 400,it should be the client side error like incorrect request syntax, invalid request message framing, or deceptive request routing","poster":"walala97","upvote_count":"6"},{"comment_id":"1216594","upvote_count":"1","poster":"65703c1","timestamp":"1732374480.0","content":"Selected Answer: D\\nD is the correct answer."},{"upvote_count":"2","content":"Selected Answer: D\\nChanging answer to D:\\nCloudTrail records API-level events, but it may not capture the payloads, headers, or other details of the requests and responses that are essential for understanding the cause of HTTP 400 response errors.","poster":"yingying920928","timestamp":"1726564440.0","comment_id":"1175747"},{"comment_id":"1172376","poster":"yingying920928","timestamp":"1726208820.0","content":"Selected Answer: B\\nLogging events of API -> AWS CloudTrail","upvote_count":"1"},{"comments":[{"comment_id":"1174845","content":"Switching my vote to D","upvote_count":"1","poster":"KarBiswa","timestamp":"1726467540.0"}],"content":"Selected Answer: B\\nCloud Trail logs","comment_id":"1166357","upvote_count":"2","poster":"KarBiswa","timestamp":"1725525180.0"},{"comment_id":"1164013","content":"Selected Answer: C\\nAlways the rule of thump is Cloud trail to trace the logging events of API\'s.\\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-insights-events-with-cloudtrail.html#:~:text=AWS%20CloudTrail%20Insights,write%20management%20APIs.","timestamp":"1725261600.0","comments":[{"content":"Sorry its not C its B","upvote_count":"1","poster":"KarBiswa","comment_id":"1166356","timestamp":"1725525120.0"}],"poster":"KarBiswa","upvote_count":"1"},{"content":"D according to https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html","comment_id":"1047918","upvote_count":"3","poster":"dezoito","timestamp":"1713531240.0"},{"upvote_count":"2","content":"Selected Answer: D\\nD should be correct","timestamp":"1712826720.0","poster":"dilleman","comment_id":"1040415"},{"upvote_count":"2","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/88807-exam-aws-certified-developer-associate-topic-1-question-264/","timestamp":"1712405760.0","poster":"Digo30sp","comment_id":"1026588"}],"answer_description":"","extracted_at":"2025-12-24T08:58:21.228Z","extraction_method":"api_direct_v1"},{"question_id":"68doL3zT9OVSzsTXi11V","question_number":93,"page":19,"question_text":"A company developed an API application on AWS by using Amazon CloudFront, Amazon API Gateway, and AWS Lambda. The API has a minimum of four requests every second. A developer notices that many API users run the same query by using the POST method. The developer wants to cache the POST request to optimize the API resources.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Save the latest request response in Lambda /tmp directory. Update the Lambda function to check the /tmp directory.","B":"Override the cache method in the selected stage of API Gateway. Select the POST method.","A":"Configure the CloudFront cache. Update the application to return cached content based upon the default request headers.","D":"Save the latest request in AWS Systems Manager Parameter Store. Modify the Lambda function to take the latest request response from Parameter Store."},"correct_answer":"B","answer_ET":"B","answers_community":["B (96%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122604-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:41:00","unix_timestamp":1696552860,"discussion_count":8,"discussion":[{"poster":"kr5031","upvote_count":"7","comments":[{"content":"I agree, I think B is correct as well looking into it more.","poster":"dilleman","timestamp":"1697180880.0","comment_id":"1042389","upvote_count":"2"}],"comment_id":"1041794","content":"Selected Answer: B\\nA is incorrect, because of\\n\\nCloudFront always caches responses to GET and HEAD requests. You can also configure CloudFront to cache responses to OPTIONS requests. CloudFront does not cache responses to requests that use the other methods.\\n(https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html)","timestamp":"1697120640.0"},{"content":"Selected Answer: B\\nWhy A is not correct\\n\\nAmazon CloudFront does not cache the responses to POST, PUT, DELETE, and PATCH requests \u2013 these requests are proxied back to the origin server. You may enable caching for the responses to OPTIONS requests.","timestamp":"1697201280.0","poster":"Jing2023","comment_id":"1042672","upvote_count":"5"},{"poster":"Anandesh","upvote_count":"1","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html#override-api-gateway-stage-cache-for-method-cache","comment_id":"1260480","timestamp":"1722732540.0"},{"comment_id":"1216597","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","timestamp":"1716469800.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1709371560.0","comment_id":"1164014","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html#:~:text=When%20you%20enable,caching%20is%20disabled.","poster":"KarBiswa"},{"upvote_count":"5","timestamp":"1705858500.0","content":"Selected Answer: B\\nAPI Gateway allows caching of responses, and you can enable caching for specific methods, including POST. This option is a viable solution as it leverages the built-in capabilities of API Gateway to cache responses. By configuring caching at the API Gateway stage level, the developer can cache responses to POST requests based on defined parameters.","poster":"SerialiDr","comment_id":"1128014"},{"content":"Selected Answer: A\\nA is the correct answer here. CloudFront can be configured to cache based on request headers, query strings, and POST request bodies.\\nOption B might work but it does not work by default and it\'s not an effective way to solve this.","poster":"dilleman","comment_id":"1040422","upvote_count":"1","timestamp":"1697015760.0"},{"poster":"Digo30sp","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nSolution (B) is the best option because it uses the Amazon API Gateway cache to cache POST requests.","upvote_count":"2","comment_id":"1026590","timestamp":"1696594680.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:21.228Z","extraction_method":"api_direct_v1"},{"question_id":"GcZYU2fAqd48A8iKkWU0","question_number":94,"page":19,"question_text":"A company is building a microservices application that consists of many AWS Lambda functions. The development team wants to use AWS Serverless Application Model (AWS SAM) templates to automatically test the Lambda functions. The development team plans to test a small percentage of traffic that is directed to new updates before the team commits to a full deployment of the application.\\n\\nWhich combination of steps will meet these requirements in the MOST operationally efficient way? (Choose two.)","choices":{"A":"Use AWS SAM CLI commands in AWS CodeDeploy to invoke the Lambda functions to test the deployment.","B":"Declare the EventInvokeConfig on the Lambda functions in the AWS SAM templates with OnSuccess and OnFailure configurations.","D":"Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment.","E":"Set the deployment preference type to Linear10PercentEvery10Minutes. Use hooks to test the deployment.","C":"Enable gradual deployments through AWS SAM templates."},"correct_answer":"CD","answer_ET":"CD","answers_community":["CD (75%)","AD (15%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122606-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:43:00","unix_timestamp":1696552980,"discussion_count":10,"discussion":[{"poster":"dilleman","content":"Selected Answer: CD\\nC and D should be correct.\\nGiven that \\"The development team plans to test a small percentage of traffic that is directed to new updates before the team commits to a full deployment of the application.\\" then Option D makes more sense than Option E.","comment_id":"1040426","upvote_count":"6","timestamp":"1697016120.0"},{"comment_id":"1250144","timestamp":"1721279460.0","upvote_count":"1","content":"Selected Answer: CD\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\\nYou need to enable the gradual deployment first then only codeDeploy will invoke lambda function","poster":"Anandesh"},{"upvote_count":"1","timestamp":"1716469980.0","poster":"65703c1","comment_id":"1216598","content":"Selected Answer: CD\\nCD is the correct answer."},{"timestamp":"1711181400.0","upvote_count":"1","comment_id":"1180700","poster":"KarBiswa","content":"Selected Answer: AC\\nFor A - https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-automated-tests.html#:~:text=You%20can%20use%20the%20sam%20local%20invoke%20command%20to%20manually%20test%20your%20code%20by%20running%20Lambda%20functions%20locally.%20With%20the%20AWS%20SAM%C2%A0CLI%2C%20you%20can%20easily%20author%20automated%20integration%20tests%20by%20first%20running%20tests%20against%20local%20Lambda%20functions%20before%20deploying%20to%20the%20AWS%20Cloud.\\nC - https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html"},{"comment_id":"1166362","timestamp":"1709635800.0","content":"Selected Answer: CD\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html","poster":"KarBiswa","upvote_count":"1"},{"poster":"KarBiswa","content":"Selected Answer: AD\\nI will got A & D \\nD is nice and clear no debates\\nFor A - https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-automated-tests.html#:~:text=You%20can%20use%20the%20sam%20local%20invoke%20command%20to%20manually%20test%20your%20code%20by%20running%20Lambda%20functions%20locally.%20With%20the%20AWS%20SAM%C2%A0CLI%2C%20you%20can%20easily%20author%20automated%20integration%20tests%20by%20first%20running%20tests%20against%20local%20Lambda%20functions%20before%20deploying%20to%20the%20AWS%20Cloud.","comment_id":"1164018","timestamp":"1709371800.0","comments":[{"upvote_count":"1","timestamp":"1709635740.0","poster":"KarBiswa","content":"changing the option to C, D","comment_id":"1166361"}],"upvote_count":"1"},{"upvote_count":"2","poster":"SerialiDr","timestamp":"1705858920.0","content":"Selected Answer: CD\\nC. Enable gradual deployments through AWS SAM templates: Gradual deployments allow you to safely deploy your application while exposing new versions to only a portion of your traffic. This approach is ideal for testing new updates in a production environment without impacting all users. AWS SAM supports the configuration of deployment preferences directly within the SAM template.\\n\\nD. Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment: The Canary deployment type is suitable for gradually introducing a new version of the Lambda function. In this case, \\"Canary10Percent30Minutes\\" means that 10% of the traffic will be directed to the new version for 30 minutes. If no issues are detected, the rest of the traffic is shifted to the new version. The use of hooks allows for automated tests to run against the new deployment, ensuring its stability before full traffic shift.","comment_id":"1128020"},{"upvote_count":"2","timestamp":"1702996020.0","content":"Selected Answer: AD\\nA: test code during deploy https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-automated-tests.html\\n\\nD: Canary, to deploy a small percentage","poster":"c9ebec2","comment_id":"1100699"},{"content":"Selected Answer: CD\\nC. Enable gradual deployments through AWS SAM templates.\\nD. Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment.","timestamp":"1698834300.0","upvote_count":"4","comment_id":"1059573","poster":"PrakashM14"},{"timestamp":"1696594800.0","content":"Selected Answer: CE\\nThe correct answers are (C) and (E).\\n\\n(C) is the most important step because it allows you to deploy new Lambda function updates to a small percentage of your traffic.\\n\\n(E) is the second most important step because it allows you to test new Lambda function updates using hooks.","upvote_count":"1","poster":"Digo30sp","comment_id":"1026592"}],"answer_description":"","extracted_at":"2025-12-24T08:58:21.228Z","extraction_method":"api_direct_v1"},{"question_id":"vgzNgpx7kxeWQd9rqAmX","question_number":95,"page":19,"question_text":"A company is using AWS CloudFormation to deploy a two-tier application. The application will use Amazon RDS as its backend database. The company wants a solution that will randomly generate the database password during deployment. The solution also must automatically rotate the database password without requiring changes to the application.\\n\\nWhat is the MOST operationally efficient solution that meets these requirements?","choices":{"D":"Use an AWS Secrets Manager resource to generate and rotate the password.","A":"Use an AWS Lambda function as a CloudFormation custom resource to generate and rotate the password.","B":"Use an AWS Systems Manager Parameter Store resource with the SecureString data type to generate and rotate the password.","C":"Use a cron daemon on the application\u2019s host to generate and rotate the password."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122605-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:41:00","unix_timestamp":1696552860,"discussion_count":3,"discussion":[{"upvote_count":"6","comment_id":"1040431","poster":"dilleman","timestamp":"1712827440.0","content":"Selected Answer: D\\nD is correct"},{"comment_id":"1216600","upvote_count":"2","content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","timestamp":"1732374900.0"},{"timestamp":"1712406000.0","poster":"Digo30sp","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/88814-exam-aws-certified-developer-associate-topic-1-question-270/","comment_id":"1026593","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:58:21.228Z","extraction_method":"api_direct_v1"},{"question_id":"Z9Jpwj5PDx3uhh2lL1Fu","question_number":96,"page":20,"question_text":"A developer has been asked to create an AWS Lambda function that is invoked any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being invoked.\\n\\nWhich option would enable DynamoDB table updates to invoke the Lambda function?","choices":{"A":"Change the StreamViewType parameter value to NEW_AND_OLD_IMAGES for the DynamoDB table.","B":"Configure event source mapping for the Lambda function.","C":"Map an Amazon Simple Notification Service (Amazon SNS) topic to the DynamoDB streams.","D":"Increase the maximum runtime (timeout) setting of the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122607-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:43:00","unix_timestamp":1696552980,"discussion_count":6,"discussion":[{"timestamp":"1727494740.0","comment_id":"1290486","content":"Selected Answer: B\\naws lambda create-event-source-mapping \\\\\\n --function-name MyLambdaFunction \\\\\\n --event-source-arn arn:aws:dynamodb:region:account-id:table/MyTable/stream/2023-01-01T12:00:00.000 \\\\\\n --batch-size 100 \\\\\\n --starting-position LATEST","poster":"albert_kuo","upvote_count":"1"},{"upvote_count":"2","timestamp":"1716470460.0","comment_id":"1216601","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"upvote_count":"2","timestamp":"1709442600.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html","comment_id":"1164503","poster":"KarBiswa"},{"poster":"joshnort","upvote_count":"1","content":"Selected Answer: B\\nConfigure event source mapping for the Lambda function after enabling Streams","timestamp":"1706976840.0","comment_id":"1139442"},{"content":"Selected Answer: B\\nB is the only option that makes sense here","comment_id":"1040433","upvote_count":"3","poster":"dilleman","timestamp":"1697016360.0"},{"poster":"Digo30sp","content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/4365-exam-aws-certified-developer-associate-topic-1-question-35/#","comment_id":"1026595","upvote_count":"3","timestamp":"1696594860.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:32.127Z","extraction_method":"api_direct_v1"},{"question_id":"9Q3Jv15dxglcqdJW3CK5","question_number":97,"page":20,"question_text":"A developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize.\\n\\nHow should the environment variables be passed to the container?","choices":{"D":"Define an array that includes the environment variables under the entryPoint parameter within the service definition.","C":"Define an array that includes the environment variables under the entryPoint parameter within the task definition.","A":"Define an array that includes the environment variables under the environment parameter within the service definition.","B":"Define an array that includes the environment variables under the environment parameter within the task definition."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122608-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:44:00","unix_timestamp":1696553040,"discussion_count":6,"discussion":[{"timestamp":"1696594920.0","poster":"Digo30sp","upvote_count":"7","comment_id":"1026598","content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/28795-exam-aws-certified-developer-associate-topic-1-question-108/"},{"comment_id":"1290487","timestamp":"1727494920.0","poster":"albert_kuo","content":"Selected Answer: B\\n{\\n \\"containerDefinitions\\": [\\n {\\n \\"name\\": \\"my-container\\",\\n \\"image\\": \\"my-image\\",\\n \\"environment\\": [\\n {\\n \\"name\\": \\"ENV_VAR_1\\",\\n \\"value\\": \\"value1\\"\\n },\\n {\\n \\"name\\": \\"ENV_VAR_2\\",\\n \\"value\\": \\"value2\\"\\n }\\n ]\\n }\\n ]\\n}","upvote_count":"1"},{"poster":"65703c1","comment_id":"1216609","upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716471180.0"},{"poster":"joshnort","upvote_count":"3","comment_id":"1139452","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html","timestamp":"1706977320.0"},{"content":"Selected Answer: B\\nFollowing ChatGPT 3.5, The correct option is B\\nWhen using Amazon ECS, the task definition is where you define parameters for your containers, including environment variables. The environment parameter within the task definition allows you to specify environment variables for your containers. This approach provides a clear separation of concerns, allowing you to define the environment variables at the task definition level, which is then used by the service when running tasks.\\nOption A is incorrect because the environment variables are typically defined in the task definition rather than the service definition.\\n\\nOptions C and D are incorrect because the entryPoint parameter is used for specifying the entry point (command) for the container, not for defining environment variables.","poster":"TanTran04","upvote_count":"4","comment_id":"1094463","timestamp":"1702383840.0"},{"upvote_count":"4","poster":"dilleman","content":"Selected Answer: B\\nB is correct","timestamp":"1697016480.0","comment_id":"1040434"}],"answer_description":"","extracted_at":"2025-12-24T08:58:32.127Z","extraction_method":"api_direct_v1"},{"question_id":"zoGoRalCUeQYgDUPtSps","question_number":98,"page":20,"question_text":"A development team maintains a web application by using a single AWS RDS, template. The template defines web servers and an Amazon RDS database. The team uses the CloudFormation template to deploy the CloudFormation stack to different environments.\\n\\nDuring a recent application deployment, a developer caused the primary development database to be dropped and recreated. The result of this incident was a loss of data. The team needs to avoid accidental database deletion in the future.\\n\\nWhich solutions will meet these requirements? (Choose two.)","choices":{"E":"Add a CloudFormation DeletionPolicy attribute with the Retain value to the stack.","D":"Create a CloudFormation stack set for the web application and database deployments.","C":"Modify the database to use a Multi-AZ deployment.","B":"Update the CloudFormation stack policy to prevent updates to the database.","A":"Add a CloudFormation DeletionPolicy attribute with the Retain value to the database resource."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122609-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:46:00","unix_timestamp":1696553160,"discussion_count":5,"discussion":[{"content":"Selected Answer: AB\\nAB is the correct answer.","timestamp":"1732376280.0","comment_id":"1216612","poster":"65703c1","upvote_count":"3"},{"content":"Selected Answer: AB\\nhttps://repost.aws/knowledge-center/cloudformation-accidental-updates","timestamp":"1722695280.0","upvote_count":"2","poster":"joshnort","comment_id":"1139456"},{"content":"Selected Answer: AB\\nA. Add a CloudFormation DeletionPolicy attribute with the Retain value to the database resource.\\n\\nThe DeletionPolicy attribute can be used in the CloudFormation template to protect a resource from being accidentally deleted. By setting the DeletionPolicy to Retain, the resource is retained when the stack is deleted, thus preventing accidental data loss. This should be applied directly to the database resource in the CloudFormation template.\\nB. Update the CloudFormation stack policy to prevent updates to the database.\\n\\nA stack policy can be used to prevent changes to certain resources during stack updates. By defining a stack policy that prohibits actions on the database resource, the team can prevent accidental modifications or deletions of the database during stack updates.","poster":"SerialiDr","timestamp":"1721579220.0","upvote_count":"3","comment_id":"1128048"},{"content":"The answer is A and D","comment_id":"1045991","upvote_count":"2","timestamp":"1713357180.0","poster":"Gold07"},{"comment_id":"1026599","upvote_count":"4","poster":"Digo30sp","content":"Selected Answer: AB\\nA and B) https://www.examtopics.com/discussions/amazon/view/103521-exam-aws-certified-developer-associate-dva-c02-topic-1/#","timestamp":"1712406180.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:32.127Z","extraction_method":"api_direct_v1"},{"question_id":"YUBVtic4U6Q3GdwPWEhu","question_number":99,"page":20,"question_text":"A developer is storing sensitive data generated by an application in Amazon S3. The developer wants to encrypt the data at rest. A company policy requires an audit trail of when the AWS Key Management Service (AWS KMS) key was used and by whom.\\n\\nWhich encryption option will meet these requirements?","choices":{"A":"Server-side encryption with Amazon S3 managed keys (SSE-S3)","D":"Server-side encryption with self-managed keys","B":"Server-side encryption with AWS KMS managed keys (SSE-KMS)","C":"Server-side encryption with customer-provided keys (SSE-C)"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122610-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:46:00","unix_timestamp":1696553160,"discussion_count":5,"discussion":[{"upvote_count":"1","content":"This appear at 17 Jun exam","poster":"tsangckl","timestamp":"1718598060.0","comment_id":"1231713"},{"poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716471660.0","comment_id":"1216614","upvote_count":"3"},{"content":"Selected Answer: B\\nSSE-KMS provides an additional layer of security by requiring separate permissions for the use of an encryption key to the bucket. This option also provides an audit trail by logging the use of the key in AWS CloudTrail, which is a requirement according to the company policy. The audit trail includes information about who used the key and when it was used, which fulfills the requirement for auditing.","timestamp":"1705861980.0","upvote_count":"2","poster":"SerialiDr","comment_id":"1128053"},{"timestamp":"1697016660.0","poster":"dilleman","content":"Selected Answer: B\\nB, since we need an audit trail of the AWK KMS key then this is the one to use.","comment_id":"1040436","upvote_count":"3"},{"timestamp":"1696595040.0","comment_id":"1026602","poster":"Digo30sp","upvote_count":"4","content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/28801-exam-aws-certified-developer-associate-topic-1-question-217/"}],"answer_description":"","extracted_at":"2025-12-24T08:58:32.127Z","extraction_method":"api_direct_v1"},{"question_id":"e96S3KI80czbEO47RHPN","question_number":100,"page":20,"question_text":"A company has an ecommerce application. To track product reviews, the company\u2019s development team uses an Amazon DynamoDB table.\\n\\nEvery record includes the following:\\n\\n\u2022 A Review ID, a 16-digit universally unique identifier (UUID)\\n\u2022 A Product ID and User ID, 16-digit UUIDs that reference other tables\\n\u2022 A Product Rating on a scale of 1-5\\n\u2022 An optional comment from the user\\n\\nThe table partition key is the Review ID. The most performed query against the table is to find the 10 reviews with the highest rating for a given product.\\n\\nWhich index will provide the FASTEST response for this query?","choices":{"A":"A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key","B":"A global secondary index (GSI) with Product ID as the partition key and Review ID as the sort key","D":"A local secondary index (LSI) with Review ID as the partition key and Product ID as the sort key","C":"A local secondary index (LSI) with Product ID as the partition key and Product Rating as the sort key"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122611-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:47:00","unix_timestamp":1696553220,"discussion_count":5,"discussion":[{"timestamp":"1732376640.0","comment_id":"1216615","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"2"},{"comment_id":"1164507","content":"Selected Answer: A\\nRating for a product these two are essential and already ReviewID has partitions","poster":"KarBiswa","upvote_count":"2","timestamp":"1725333720.0"},{"timestamp":"1721583900.0","comment_id":"1128089","poster":"SerialiDr","upvote_count":"3","content":"Selected Answer: A\\nThis GSI allows for queries that are based on Product ID, efficiently narrowing down the reviews for a specific product. The Product Rating as the sort key enables sorting the reviews by their rating, which directly supports the need to find the top 10 reviews. GSIs also support a different partition key than the base table, which is necessary in this case since the base table\'s partition key is Review ID."},{"comment_id":"1040437","timestamp":"1712827920.0","poster":"dilleman","upvote_count":"3","content":"Selected Answer: A\\nA should be correct"},{"comment_id":"1026603","upvote_count":"3","content":"Selected Answer: A\\nA) https://www.examtopics.com/discussions/amazon/view/88995-exam-aws-certified-developer-associate-topic-1-question-362/","timestamp":"1712406300.0","poster":"Digo30sp"}],"answer_description":"","extracted_at":"2025-12-24T08:58:32.127Z","extraction_method":"api_direct_v1"},{"question_id":"eSTtYrT1ff8ot0twWzja","question_number":101,"page":21,"question_text":"A company is offering APIs as a service over the internet to provide unauthenticated read access to statistical information that is updated daily. The company uses Amazon API Gateway and AWS Lambda to develop the APIs. The service has become popular, and the company wants to enhance the responsiveness of the APIs.\\nWhich action can help the company achieve this goal?","choices":{"C":"Enable cross-origin resource sharing (CORS) for the APIs.","D":"Configure usage plans and API keys in API Gateway.","B":"Configure API Gateway to use an interface VPC endpoint.","A":"Enable API caching in API Gateway."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103467-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 12:40:00","unix_timestamp":1679398800,"discussion_count":11,"discussion":[{"timestamp":"1683376200.0","poster":"Bibay","upvote_count":"29","content":"Selected Answer: A\\nA. Enable API caching in API Gateway can help the company enhance the responsiveness of the APIs. By enabling caching, API Gateway stores the responses from the API and returns them for subsequent requests instead of forwarding the requests to Lambda. This reduces the number of requests to Lambda, improves API performance, and reduces latency for users.","comment_id":"890734"},{"poster":"sumanshu","timestamp":"1734773280.0","comment_id":"1329902","upvote_count":"1","content":"Selected Answer: A\\nA) Cached data reduces calls to the backend (in this case, Lambda) and serves responses directly from the cache. Since the data updates only once per day, caching is highly effective\\n\\nB) Eliminated - This is useful for securing private APIs inside a VPC, but the scenario involves public, unauthenticated APIs over the internet\\n\\nC) Eliminated - CORS is related to resolving client-side browser compatibility issues\\n\\nD) Eliminated - Usage plans and API keys manage access control and rate limiting, which are useful for monetization"},{"comment_id":"1326098","upvote_count":"1","poster":"trieudo","content":"Selected Answer: A\\nkeyword: updated daily, enhance the responsiveness\\n\\n=> A","timestamp":"1734089520.0"},{"timestamp":"1721754720.0","comment_id":"1253807","upvote_count":"1","poster":"ahadh7621","content":"Selected Answer: A\\nAnswer is A"},{"upvote_count":"1","poster":"65703c1","comment_id":"1215015","timestamp":"1716300960.0","content":"Selected Answer: A\\nA is the correct answer."},{"poster":"badsati","upvote_count":"1","comment_id":"1191747","content":"Selected Answer: A\\nAnswer is A. Caching will enhance the responsiveness of the APIs.","timestamp":"1712599860.0"},{"poster":"leonardoliveros","comment_id":"1072041","upvote_count":"2","timestamp":"1700094000.0","content":"Selected Answer: A\\nCaching the request is the best option because the request don\'t forwared to Lambda Function and this reduces latency and also recude costs"},{"comment_id":"997572","timestamp":"1693741620.0","poster":"Tony88","upvote_count":"4","content":"Selected Answer: A\\nGo with A.\\nA. Caching is the general solution to improve performance of non-frequently change data. (in this case, daily, not really frequent)\\nB. interface endpoint is a VPC concept, in this architect we don\'t need to concern with VPC. For those who are interested, go check with interface endpoint and gateway endpoint.\\nC. CORS is short for cross origin resource share. it is a distractor here. You may consider CORS when your client cannot access to your API Gateway resource, not when you want to improve the performance.\\nD. usage plan is used when your API client\'s behaviour is predictable, and it can avoid anormal usage."},{"comment_id":"989676","timestamp":"1692940620.0","poster":"yuruyenucakc","upvote_count":"1","content":"A-> Caching frequently accessed api calls allows reducing process time every time api is called. \\n\\nB-> You shloud configure VPC if you want to change network security of your application. So it does not neccessarily increase the performance. \\n\\nC-> CORS (Cross Origin Resource Sharing), allows you to proccess the api calls that comes from outside of your AWS organization.\\n Again nothing to do with the performance. One of the use case of this feature is if you want to keep your web app apis reachable from public internet you should enable CORS for it.\\nD\u2192 This is mainly for throttling and controlling who can access the API and at what rate. While it\'s useful for controlling and metering access, it doesn\'t enhance the responsiveness of the API"},{"comment_id":"846333","timestamp":"1679431680.0","content":"Selected Answer: A\\nI vote for A","upvote_count":"3","poster":"svrnvtr"},{"comment_id":"845868","content":"Selected Answer: A\\nA\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","timestamp":"1679398800.0","poster":"Untamables","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:58:43.167Z","extraction_method":"api_direct_v1"},{"question_id":"j6UWX6UuSIaDrLepGeYg","question_number":102,"page":21,"question_text":"A company needs to distribute firmware updates to its customers around the world.\\n\\nWhich service will allow easy and secure control of the access to the downloads at the lowest cost?","choices":{"C":"Use Amazon CloudFront with AWS Lambda@Edge.","A":"Use Amazon CloudFront with signed URLs for Amazon S3.","D":"Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.","B":"Create a dedicated Amazon CloudFront Distribution for each customer."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122612-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:48:00","unix_timestamp":1696553280,"discussion_count":6,"discussion":[{"comment_id":"1094473","poster":"TanTran04","content":"Selected Answer: A\\nA. Use Amazon CloudFront with signed URLs for Amazon S3.\\n\\nUsing Amazon CloudFront with signed URLs is a secure and cost-effective way to control access to downloads. With signed URLs, you can generate URLs with limited time validity, ensuring that only users with the correct URL and during the specified time window can access the firmware updates. This provides both security and control over access.\\n\\nOption B (Create a dedicated Amazon CloudFront Distribution for each customer) may result in higher costs and increased complexity. Option C (Use Amazon CloudFront with AWS Lambda@Edge) is more focused on customization and additional processing at the edge locations, which may not be necessary for simple access control. Option D (Use Amazon API Gateway and AWS Lambda) is more suited for managing APIs and might be an overkill for a straightforward firmware update distribution scenario.","timestamp":"1718188260.0","upvote_count":"5"},{"comment_id":"1216616","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"2","poster":"65703c1","timestamp":"1732376760.0"},{"poster":"SerialiDr","upvote_count":"3","timestamp":"1721584320.0","content":"Selected Answer: A\\nAmazon CloudFront is a content delivery network (CDN) service that can efficiently distribute files globally. Using signed URLs provides a secure method to control access to the firmware updates. Only users with valid signed URLs can download the files, ensuring controlled access. This approach is cost-effective as it leverages CloudFront\'s caching capabilities to reduce load on the origin (Amazon S3) and reduces data transfer costs.","comment_id":"1128092"},{"comment_id":"1115596","timestamp":"1720319940.0","content":"Selected Answer: A\\nobtion B,for each customer,will bring high costs","poster":"walala97","upvote_count":"2"},{"content":"Selected Answer: A\\nA is correct","timestamp":"1712827980.0","comment_id":"1040438","poster":"dilleman","upvote_count":"3"},{"poster":"Digo30sp","comment_id":"1026604","upvote_count":"4","timestamp":"1712406360.0","content":"Selected Answer: A\\nA) https://www.examtopics.com/discussions/amazon/view/8792-exam-aws-certified-developer-associate-topic-1-question-179/#"}],"answer_description":"","extracted_at":"2025-12-24T08:58:43.167Z","extraction_method":"api_direct_v1"},{"question_id":"h2iAJskeHIRWfQZTKyJu","question_number":103,"page":21,"question_text":"A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries.\\n\\nHow can the developer troubleshoot the failure?","choices":{"C":"Configure Amazon Simple Workflow Service to process any direct unprocessed events.","A":"Configure AWS CloudTrail logging to investigate the invocation failures.","D":"Configure AWS Config to process any direct unprocessed events.","B":"Configure Dead Letter Queues by sending events to Amazon SQS for investigation."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122613-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:49:00","unix_timestamp":1696553340,"discussion_count":4,"discussion":[{"timestamp":"1718188320.0","content":"Selected Answer: B\\nIn AWS Lambda, you can use Dead Letter Queues (DLQ) to capture and retain events that couldn\'t be processed successfully after a specified number of retries. By configuring a DLQ, the failed events are sent to an Amazon SQS queue, allowing you to investigate and analyze the reasons for the failures.","upvote_count":"6","poster":"TanTran04","comment_id":"1094475"},{"content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1","timestamp":"1732376880.0","poster":"65703c1","comment_id":"1216619"},{"poster":"dilleman","comment_id":"1040444","upvote_count":"4","timestamp":"1712828100.0","content":"Selected Answer: B\\nDead Letter Queues (DLQ) can be configured for Lambda functions to capture failed asynchronous invocations. Events that cannot be processed will be sent to an SQS queue (or an SNS topic) you specify, allowing for further investigation and reprocessing."},{"content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/28638-exam-aws-certified-developer-associate-topic-1-question-317/#","upvote_count":"2","comment_id":"1026607","poster":"Digo30sp","timestamp":"1712406360.0"}],"answer_description":"","extracted_at":"2025-12-24T08:58:43.167Z","extraction_method":"api_direct_v1"},{"question_id":"DxGlzBjN0umUBcGUmdJR","question_number":104,"page":21,"question_text":"A company is migrating its PostgreSQL database into the AWS Cloud. The company wants to use a database that will secure and regularly rotate database credentials. The company wants a solution that does not require additional programming overhead.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.","D":"Use Amazon DynamoDB for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.","C":"Use Amazon DynamoDB for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.","B":"Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122615-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:51:00","unix_timestamp":1696553460,"discussion_count":3,"discussion":[{"upvote_count":"8","poster":"Digo30sp","timestamp":"1712406540.0","comment_id":"1026612","content":"Selected Answer: B\\nB) The correct answer is (B).\\n\\nSolution (B) is the best option because it meets all the requirements:\\n\\nUsing a database that secures and regularly changes database credentials: Amazon Aurora PostgreSQL offers built-in credential rotation, which allows you to change database credentials at regular intervals.\\nSolution that requires no additional programming overhead: Amazon Aurora PostgreSQL credential rotation is fully automated, so it requires no additional programming overhead."},{"comment_id":"1216620","upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","timestamp":"1732377000.0"},{"comment_id":"1094479","poster":"TanTran04","content":"Selected Answer: B\\nAWS Secrets Manager is a service designed to rotate, manage, and retrieve database credentials, API keys, and other secrets. In this scenario, storing the database credentials in AWS Secrets Manager and enabling rotation ensures that your database credentials are regularly rotated without requiring additional programming overhead.\\n\\nOption B is the most suitable because it specifically addresses the need for securing and regularly rotating database credentials in the AWS Cloud. Amazon Aurora PostgreSQL is a fully managed relational database service, and AWS Secrets Manager seamlessly integrates with it for secure credential management.","timestamp":"1718188380.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T08:58:43.167Z","extraction_method":"api_direct_v1"},{"question_id":"oubY6p6us4NYLwXkWinq","question_number":105,"page":21,"question_text":"A developer is creating a mobile application that will not require users to log in.\\n\\nWhat is the MOST efficient method to grant users access to AWS resources?","choices":{"A":"Use an identity provider to securely authenticate with the application.","D":"Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.","B":"Create an AWS Lambda function to create an IAM user when a user accesses the application.","C":"Create credentials using AWS KMS and apply these credentials to users when using the application."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122614-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:50:00","unix_timestamp":1696553400,"discussion_count":4,"discussion":[{"comment_id":"1026622","upvote_count":"8","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/4245-exam-aws-certified-developer-associate-topic-1-question-79/","poster":"Digo30sp","timestamp":"1712407140.0"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","comment_id":"1216621","timestamp":"1732377120.0","poster":"65703c1"},{"poster":"SerialiDr","comment_id":"1128784","content":"Selected Answer: D\\nAmazon Cognito allows you to create unique identities for users of your application and assign permissions to these identities using IAM roles. By using Cognito\'s unauthenticated identities (also known as guest users), you can grant limited AWS resource access to users without requiring them to log in. This approach is secure, scalable, and does not require managing user credentials.","timestamp":"1721652720.0","upvote_count":"3"},{"comment_id":"1094481","upvote_count":"1","content":"Selected Answer: D\\nAmazon Cognito is designed to handle user identity and access management for mobile and web applications","timestamp":"1718188500.0","poster":"TanTran04"}],"answer_description":"","extracted_at":"2025-12-24T08:58:43.167Z","extraction_method":"api_direct_v1"},{"question_id":"34Qc73Bl7gOvl2RSfLFj","question_number":106,"page":22,"question_text":"A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI.\\n\\nWhich step should the developer complete prior to deploying the application?","choices":{"B":"Test the new AWS Lambda function by first tracing it in AWS X-Ray.","C":"Bundle the serverless application using a SAM package.","A":"Compress the application to a .zip file and upload it into AWS Lambda.","D":"Create the application environment using the eb create my-env command."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122616-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:52:00","unix_timestamp":1696553520,"discussion_count":6,"discussion":[{"timestamp":"1727498820.0","upvote_count":"1","poster":"albert_kuo","comment_id":"1290507","content":"Selected Answer: C\\nsam package --template-file template.yaml --s3-bucket my-deployment-bucket --output-template-file packaged.yaml"},{"upvote_count":"2","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716472500.0","comment_id":"1216627"},{"comment_id":"1128792","poster":"SerialiDr","timestamp":"1705935360.0","content":"Selected Answer: C\\nUsing sam package (or aws cloudformation package) command, the developer can package the Lambda functions, along with any dependencies and resources defined in the SAM template, into a deployment package. This command uploads local artifacts (like Lambda function code and Swagger files) to an S3 bucket and produces a modified SAM template file, formatted for deployment.","upvote_count":"4"},{"upvote_count":"1","poster":"TanTran04","comment_id":"1094485","timestamp":"1702384560.0","content":"Selected Answer: C\\nC. Bundle the serverless application using a SAM package.\\n\\nBefore deploying a serverless application using the AWS Serverless Application Model (AWS SAM) CLI, the developer should bundle the application using the sam package command. This command packages and uploads the local artifacts of your serverless application to Amazon S3, and it produces a packaged AWS SAM template file that you can deploy with the sam deploy command."},{"timestamp":"1697017200.0","poster":"dilleman","content":"Selected Answer: C\\nC is correct","comment_id":"1040449","upvote_count":"2"},{"comment_id":"1026624","poster":"Digo30sp","upvote_count":"4","timestamp":"1696596000.0","content":"Selected Answer: C\\nC) https://www.examtopics.com/discussions/amazon/view/28650-exam-aws-certified-developer-associate-topic-1-question-312/"}],"answer_description":"","extracted_at":"2025-12-24T08:58:54.172Z","extraction_method":"api_direct_v1"},{"question_id":"Q5AmuOO3jzmITJHHDe6P","question_number":107,"page":22,"question_text":"A company wants to automate part of its deployment process. A developer needs to automate the process of checking for and deleting unused resources that supported previously deployed stacks but that are no longer used.\\n\\nThe company has a central application that uses the AWS Cloud Development Kit (AWS CDK) to manage all deployment stacks. The stacks are spread out across multiple accounts. The developer\u2019s solution must integrate as seamlessly as possible within the current deployment process.\\n\\nWhich solution will meet these requirements with the LEAST amount of configuration?","choices":{"C":"In the central AWS CDK, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an API in AWS Amplify. Use the API to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.","B":"In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.","D":"In the AWS Lambda console, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to import the Lambda function into the stack and to invoke the Lambda function when the deployment stack runs.","A":"In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CloudFormation template from a JSON file. Use the template to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122617-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:53:00","unix_timestamp":1696553580,"discussion_count":5,"discussion":[{"poster":"tsangckl","comment_id":"1231714","upvote_count":"1","timestamp":"1718598120.0","content":"This appear at 17 Jun exam"},{"poster":"65703c1","timestamp":"1716475980.0","upvote_count":"2","comment_id":"1216660","content":"Selected Answer: B\\nB is the correct answer."},{"comment_id":"1128804","content":"Selected Answer: B\\nThis approach integrates directly into the existing AWS CDK deployment process. By writing a handler function within the CDK application, the developer can leverage the AWS SDK to programmatically identify and delete unused resources. The AWS CDK custom resource can then be used to invoke this function as part of the deployment process. This solution is efficient as it keeps everything within the CDK ecosystem and minimizes additional external configurations.","poster":"SerialiDr","timestamp":"1705935900.0","upvote_count":"3"},{"timestamp":"1697017380.0","comment_id":"1040452","upvote_count":"1","poster":"dilleman","content":"Selected Answer: B\\nB. In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs."},{"content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nSolution (B) is the best option because:\\n\\nRequires the LEAST amount of configuration: Solution (B) uses an AWS CDK custom resource, which is a type of resource that can be defined in AWS CDK code. Custom resources are a convenient way to add custom functionality to your AWS CloudFormation stacks.\\nIntegrates seamlessly into the current deployment process: Solution (B) uses the AWS CDK custom resource to attach function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs. This means that the solution does not require any changes to the existing AWS CDK code.","upvote_count":"4","poster":"Digo30sp","timestamp":"1696596120.0","comment_id":"1026625"}],"answer_description":"","extracted_at":"2025-12-24T08:58:54.172Z","extraction_method":"api_direct_v1"},{"question_id":"QnVUNnM2NCcnxG7bJ79U","question_number":108,"page":22,"question_text":"A company built a new application in the AWS Cloud. The company automated the bootstrapping of new resources with an Auto Scaling group by using AWS CloudFormation templates. The bootstrap scripts contain sensitive data.\\n\\nThe company needs a solution that is integrated with CloudFormation to manage the sensitive data in the bootstrap scripts.\\n\\nWhich solution will meet these requirements in the MOST secure way?","choices":{"D":"Put the sensitive data into Amazon Elastic File System (Amazon EFS). Enforce EFS encryption after file system creation. Update the CloudFormation templates to retrieve data from Amazon EFS.","C":"Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.","A":"Put the sensitive data into a CloudFormation parameter. Encrypt the CloudFormation templates by using an AWS Key Management Service (AWS KMS) key.","B":"Put the sensitive data into an Amazon S3 bucket. Update the CloudFormation templates to download the object from Amazon S3 during bootstrap."},"correct_answer":"C","answer_ET":"C","answers_community":["C (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122618-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:56:00","unix_timestamp":1696553760,"discussion_count":6,"discussion":[{"upvote_count":"7","poster":"Digo30sp","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nSolution (C) is the best option because:\\n\\nIt\'s the most secure solution: Sensitive data is stored in AWS Systems Manager Parameter Store, which is a secret management service managed by AWS. Secure string parameters in AWS Systems Manager Parameter Store are encrypted with an AWS KMS key.\\nIt\'s integrated with CloudFormation: Secure string parameters can be referenced in CloudFormation templates using dynamic references. This means that sensitive data does not need to be stored in CloudFormation code.","comment_id":"1026627","timestamp":"1712407440.0"},{"content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1216664","timestamp":"1732381140.0"},{"upvote_count":"1","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html","timestamp":"1725334200.0","poster":"KarBiswa","comment_id":"1164512"},{"timestamp":"1718188860.0","comment_id":"1094491","upvote_count":"2","content":"Selected Answer: C\\nAWS Systems Manager Parameter Store is a secure and scalable solution for storing configuration data, including sensitive information. In this case, using a secure string parameter allows you to store the sensitive data in Parameter Store in an encrypted form.\\n\\nOption C is the most secure because it leverages AWS Systems Manager Parameter Store\'s capabilities for securely storing sensitive data, and dynamic references allow you to directly reference the parameter values in CloudFormation templates. This approach avoids exposing sensitive data in the templates themselves and provides a central and secure storage solution for sensitive configuration information.","poster":"TanTran04"},{"poster":"kashtelyan","timestamp":"1713449580.0","comment_id":"1046983","upvote_count":"1","content":"Selected Answer: A\\nA option leverages CloudFormation parameters, which can securely store sensitive data. By using an AWS KMS key to encrypt the CloudFormation templates, you ensure that the sensitive data is protected. It follows the principle of least privilege and provides secure access to sensitive information directly within CloudFormation.\\n\\nOption B is less secure because it involves storing sensitive data in an S3 bucket, which could be compromised.\\n\\nOption C suggests using AWS Systems Manager Parameter Store, which is secure, but using CloudFormation parameters and KMS keys provides an integrated solution directly within CloudFormation.\\n\\nOption D involves Amazon EFS, which is typically used for file storage and is not designed for securely storing sensitive data directly within CloudFormation."},{"content":"Selected Answer: C\\nC is the correct choice. Parameter Store\'s secure string parameter encrypts the data using AWS KMS","upvote_count":"4","timestamp":"1712828700.0","poster":"dilleman","comment_id":"1040455"}],"answer_description":"","extracted_at":"2025-12-24T08:58:54.172Z","extraction_method":"api_direct_v1"},{"question_id":"q2IQAWSyV8sGImxERIxF","question_number":109,"page":22,"question_text":"A company needs to set up secure database credentials for all its AWS Cloud resources. The company\u2019s resources include Amazon RDS DB instances, Amazon DocumentDB clusters, and Amazon Aurora DB instances. The company\u2019s security policy mandates that database credentials be encrypted at rest and rotated at a regular interval.\\n\\nWhich solution will meet these requirements MOST securely?","choices":{"C":"Store the database access credentials as an encrypted Amazon S3 object in an S3 bucket. Block all public access on the S3 bucket. Use S3 server-side encryption to set up automatic rotation on the encryption key.","D":"Create an AWS Lambda function by using the SecretsManagerRotationTemplate template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.","A":"Set up IAM database authentication for token-based access. Generate user tokens to provide centralized access to RDS DB instances, Amazon DocumentDB clusters, and Aurora DB instances.","B":"Create parameters for the database credentials in AWS Systems Manager Parameter Store. Set the Type parameter to SecureString. Set up automatic rotation on the parameters."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122619-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:56:00","unix_timestamp":1696553760,"discussion_count":7,"discussion":[{"upvote_count":"1","comment_id":"1273601","timestamp":"1724779080.0","content":"I love how they added the lambda b**ls**t just to confuse who\'s doing the test.","poster":"wh1t4k3r"},{"poster":"65703c1","timestamp":"1716476460.0","upvote_count":"2","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1216665"},{"timestamp":"1702384980.0","upvote_count":"3","content":"Selected Answer: D\\nRotate auto SecretsManager","comment_id":"1094494","poster":"TanTran04"},{"comment_id":"1049020","timestamp":"1697826360.0","poster":"nickolaj","upvote_count":"2","content":"https://aws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/"},{"poster":"dilleman","content":"Selected Answer: D\\nthe best and most secure option is:\\nD. Create an AWS Lambda function by using the SecretsManagerRotationTemplate template in the AWS Secrets Manager console.","comment_id":"1040459","timestamp":"1697017620.0","upvote_count":"4"},{"upvote_count":"4","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nSolution (D) is the best option because:\\n\\nIt\'s the most secure solution: AWS Secrets Manager is an AWS-managed secrets management service that provides encryption at rest and automatic secret rotation.\\nMeets the company\'s security requirements: The solution meets the company\'s security requirements because:\\nDatabase credentials are encrypted at rest using AWS Key Management Service (AWS KMS).\\nDatabase credentials are automatically rotated at regular intervals.","poster":"Digo30sp","timestamp":"1696596480.0","comment_id":"1026631"},{"comment_id":"1026106","content":"DDDDDDD","timestamp":"1696553760.0","upvote_count":"3","poster":"fordiscussionstwo"}],"answer_description":"","extracted_at":"2025-12-24T08:58:54.172Z","extraction_method":"api_direct_v1"},{"question_id":"2BDHssYOpVFQV8HnKHBQ","question_number":110,"page":22,"question_text":"A developer has created an AWS Lambda function that makes queries to an Amazon Aurora MySQL DB instance. When the developer performs a test, the DB instance shows an error for too many connections.\\n\\nWhich solution will meet these requirements with the LEAST operational effort?","choices":{"A":"Create a read replica for the DB instance. Query the replica DB instance instead of the primary DB instance.","C":"Configure the Amazon Aurora MySQL DB instance for Multi-AZ deployment.","D":"Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.","B":"Migrate the data to an Amazon DynamoDB database."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122620-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 02:57:00","unix_timestamp":1696553820,"discussion_count":8,"discussion":[{"content":"Please educated me why is it not A?","upvote_count":"1","comment_id":"1315720","poster":"jasonkym","timestamp":"1732177380.0"},{"comment_id":"1216670","upvote_count":"2","poster":"65703c1","timestamp":"1716476640.0","content":"Selected Answer: D\\nD is the correct answer."},{"poster":"Dzok5050","comment_id":"1215195","timestamp":"1716319620.0","content":"Selected Answer: D\\nToo many Connections = Proxy","upvote_count":"2"},{"content":"Selected Answer : D","comment_id":"1187629","timestamp":"1711999380.0","upvote_count":"1","poster":"SathyaJS"},{"comment_id":"1094497","content":"too many connections => proxy","poster":"TanTran04","timestamp":"1702385040.0","upvote_count":"1"},{"comment_id":"1040461","poster":"dilleman","timestamp":"1697017680.0","content":"Selected Answer: D\\nD.\\nRDS Proxy sits between the application and the database to manage and pool connections, reducing the chance of exhausting database connections when many Lambda functions try to connect simultaneously.","upvote_count":"3"},{"comment_id":"1026775","upvote_count":"1","timestamp":"1696607220.0","poster":"Digo30sp","content":"Selected Answer: D\\nD) https://www.examtopics.com/discussions/amazon/view/88969-exam-aws-certified-developer-associate-topic-1-question-358/"},{"timestamp":"1696553820.0","poster":"fordiscussionstwo","content":"DDDDDDDDDDD","upvote_count":"3","comment_id":"1026107"}],"answer_description":"","extracted_at":"2025-12-24T08:58:54.172Z","extraction_method":"api_direct_v1"},{"question_id":"zfPTPmDT2BRAtJqKyAwK","question_number":111,"page":23,"question_text":"A developer is creating a new REST API by using Amazon API Gateway and AWS Lambda. The development team tests the API and validates responses for the known use cases before deploying the API to the production environment.\\n\\nThe developer wants to make the REST API available for testing by using API Gateway locally.\\n\\nWhich AWS Serverless Application Model Command Line Interface (AWS SAM CLI) subcommand will meet these requirements?","choices":{"B":"Sam local generate-event","A":"Sam local invoke","C":"Sam local start-lambda","D":"Sam local start-api"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122621-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:00:00","unix_timestamp":1696554000,"discussion_count":5,"discussion":[{"poster":"Digo30sp","comment_id":"1026632","upvote_count":"9","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nThe AWS SAM CLI sam local start-api subcommand is used to start a local API Gateway instance. This allows you to test your REST API locally before deploying it to the production environment.\\n\\nThe other subcommands will not meet the developer\'s requirements:\\n\\nLocal invocation of Sam is used to invoke a Lambda function locally.\\nSam\'s local event generation is used to generate a local event file to be used to invoke a Lambda function locally.\\nSam local start-lambda is used to start a local instance of a Lambda function.","timestamp":"1712407800.0"},{"content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1216676","timestamp":"1732381860.0","upvote_count":"1","poster":"65703c1"},{"comment_id":"1164514","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-start-api.html","poster":"KarBiswa","timestamp":"1725334560.0","upvote_count":"1"},{"poster":"dilleman","comment_id":"1040462","content":"Selected Answer: D\\nD is correct","timestamp":"1712829000.0","upvote_count":"3"},{"content":"DDDDDDDDDDD","comment_id":"1026109","poster":"fordiscussionstwo","upvote_count":"4","timestamp":"1712365200.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:05.430Z","extraction_method":"api_direct_v1"},{"question_id":"yGEkaKEVkfYgsdGymh6A","question_number":112,"page":23,"question_text":"A company is running Amazon EC2 instances in multiple AWS accounts. A developer needs to implement an application that collects all the lifecycle events of the EC2 instances. The application needs to store the lifecycle events in a single Amazon Simple Queue Service (Amazon SQS) queue in the company\'s main AWS account for further processing.\\nWhich solution will meet these requirements?","choices":{"D":"Configure the permissions on the main account event bus to receive events from all accounts. Create an Amazon EventBridge rule in each account to send all the EC2 instance lifecycle events to the main account event bus. Add an EventBridge rule to the main account event bus that matches all EC2 instance lifecycle events. Set the SQS queue as a target for the rule.","B":"Use the resource policies of the SQS queue in the main account to give each account permissions to write to that SQS queue. Add to the Amazon EventBridge event bus of each account an EventBridge rule that matches all EC2 instance lifecycle events. Add the SQS queue in the main account as a target of the rule.","A":"Configure Amazon EC2 to deliver the EC2 instance lifecycle events from all accounts to the Amazon EventBridge event bus of the main account. Add an EventBridge rule to the event bus of the main account that matches all EC2 instance lifecycle events. Add the SQS queue as a target of the rule.","C":"Write an AWS Lambda function that scans through all EC2 instances in the company accounts to detect EC2 instance lifecycle changes. Configure the Lambda function to write a notification message to the SQS queue in the main account if the function detects an EC2 instance lifecycle change. Add an Amazon EventBridge scheduled rule that invokes the Lambda function every minute."},"correct_answer":"D","answer_ET":"D","answers_community":["D (81%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102782-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 09:57:00","unix_timestamp":1678957020,"discussion_count":22,"discussion":[{"upvote_count":"20","comments":[{"timestamp":"1691112960.0","comment_id":"971600","content":"thanks a lot","poster":"jipark","upvote_count":"1"}],"timestamp":"1679359440.0","comment_id":"845391","poster":"Untamables","content":"Selected Answer: D\\nThe correct answer is D.\\nAmazon EC2 instances can send the state-change notification events to Amazon EventBridge.\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instance-state-changes.html\\nAmazon EventBridge can send and receive events between event buses in AWS accounts.\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cross-account.html"},{"timestamp":"1683389940.0","poster":"geekdamsel","content":"This question came in exam. Correct answer is D.","comment_id":"890859","upvote_count":"11"},{"timestamp":"1750136460.0","comment_id":"1578213","poster":"thinei","content":"Selected Answer: D\\nAnswer is D.\\nAmazon EC2 sends an EC2 Instance State-change Notification event to Amazon EventBridge when the state of an instance changes.","upvote_count":"1"},{"timestamp":"1738671240.0","poster":"7948dca","comment_id":"1351332","upvote_count":"1","content":"Selected Answer: C\\nEither C or D. Down side of C: Needs to trigger everyone min but very flexible. D: is completely automated but giving access to other aws account is not safe."},{"upvote_count":"1","comments":[{"poster":"sumanshu","content":"A) Eliminated - Amazon EC2 itself does not send lifecycle events directly to EventBridge in another account. The EC2 lifecycle events would be published to EventBridge within the account where the EC2 instance resides.\\n\\nThe key here is using EventBridge cross-account event bus access. Amazon EventBridge allows for event buses to receive events from other AWS accounts if the appropriate permissions are set.","comments":[{"poster":"sumanshu","content":"B) Will work as Option B is implying a direct route from each AWS account\u2019s EventBridge to the main account\u2019s SQS queue, bypassing the main account\'s EventBridge event bus - Eliminated - as No centralized events, which is in Option D","comments":[{"poster":"sumanshu","timestamp":"1734701580.0","upvote_count":"1","comment_id":"1329469","content":"C) Eliminated - more maintenance overhead of LAMBDA"}],"comment_id":"1329468","timestamp":"1734701520.0","upvote_count":"1"}],"comment_id":"1329449","timestamp":"1734700260.0","upvote_count":"1"}],"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/us_en/eventbridge/latest/userguide/eb-cross-account.html#:~:text=You%20can%20configure%20EventBridge%20to%20send%20and%20receive,events%20from%20the%20event%20bus%20in%20your%20account.","poster":"sumanshu","timestamp":"1734700080.0","comment_id":"1329447"},{"timestamp":"1733913660.0","content":"Selected Answer: D\\n==> Discard C: lamdba scans ==> it will be delay by scan all data\\n==> Discard A: \'matches all EC2 instance\' ==> hard to maintain, when updating many times can occurs\\n==> Discard B: it works, but it maybe have some security problem when pushing raw data (not clean) into SQS. It also doesn\'t take advantage of \\n\\nD: By configuring the main account\'s event bus to accept events from other accounts and adding rules in those accounts to forward lifecycle events, this solution achieves secure and efficient centralization. EventBridge then routes the events to an SQS queue in the main account for further processing.","comment_id":"1324981","upvote_count":"2","poster":"trieudo"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cross-account.html","poster":"Anandesh","comment_id":"1248763","timestamp":"1721118120.0","upvote_count":"1"},{"timestamp":"1717257360.0","content":"Selected Answer: D\\nD is correct answer.","comment_id":"1222763","poster":"NagaoShingo","upvote_count":"1"},{"poster":"65703c1","upvote_count":"1","comment_id":"1214940","timestamp":"1716295380.0","content":"D is the correct answer."},{"timestamp":"1702747140.0","poster":"xdkonorek2","upvote_count":"1","comment_id":"1098347","content":"Selected Answer: D\\nTried to implement both B and D\\nIt\'s tricky, because B could be possible but you can\'t select cross-account SQS as target to the rule, option D is 100% correct"},{"comment_id":"1061908","timestamp":"1699075140.0","poster":"dongocanh272","content":"Selected Answer: D\\nMy answer is D","upvote_count":"2"},{"poster":"Digo30sp","upvote_count":"1","comment_id":"1027586","content":"Selected Answer: D\\nAnswer C is correct","timestamp":"1696703640.0"},{"comment_id":"964057","poster":"TeeTheMan","upvote_count":"5","timestamp":"1690393440.0","content":"Selected Answer: B\\nSeems to me the correct answer is B. The current most voted answer is B, but can someone explain why it\u2019s better than B? I think B is better because it has fewer steps. The events go straight from each account into the queue. Unlike in D which has the intermediate step of the event bus of the main account. Also, why would you want to pollute the event bus of the main account with events from other accounts when it isn\u2019t necessary?"},{"timestamp":"1689356400.0","comment_id":"951712","upvote_count":"2","content":"B\\nAnswer A is incorrect because Amazon EventBridge events can\'t be sent directly from one account\'s event bus to another.\\n\\nAnswer C is incorrect because it\'s unnecessary and inefficient to use Lambda to periodically scan all EC2 instances for lifecycle changes. Amazon EventBridge can capture these events automatically as they occur.\\n\\nAnswer D is incorrect because it is not possible to configure the main account event bus to receive events from all accounts directly, and Amazon EventBridge events can\'t be sent directly from one account\'s event bus to another. The EventBridge rules need to be set up in the accounts where the events are generated.","poster":"KillThemWithKindness","comments":[{"content":"Sorry Im wrong, AWS allow to send and receive Amazon EventBridge events between AWS accounts. https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cross-account.html\\n\\nBoth B and D works, but D is more centralized","upvote_count":"4","poster":"KillThemWithKindness","comment_id":"951732","timestamp":"1689357900.0"}]},{"comment_id":"910136","poster":"ezredame","content":"Selected Answer: D\\nThe correct answer is D.\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cross-account.html","timestamp":"1685441100.0","upvote_count":"2"},{"upvote_count":"1","comment_id":"890673","timestamp":"1683368220.0","content":"Selected Answer: A\\nOption D is not the best solution because it involves configuring the permissions on the main account\'s EventBridge event bus to receive events from all accounts, which can lead to potential security risks. Allowing other AWS accounts to send events to the main account\'s EventBridge event bus can potentially open up a security vulnerability, as it increases the attack surface area for the main account.\\n\\nOn the other hand, option A is the best solution because it involves using Amazon EventBridge, which is a serverless event bus that can be used to route events between AWS services or AWS accounts. By configuring Amazon EC2 to deliver the EC2 instance lifecycle events from all accounts to the Amazon EventBridge event bus of the main account, and adding the SQS queue as a target of the rule, the application can collect all the lifecycle events of the EC2 instances in a single queue in the main account without compromising the security posture of the AWS environment.","poster":"Bibay"},{"comment_id":"883792","upvote_count":"1","content":"Selected Answer: B\\nB solution meets all da requirements. By using resource policies, you can grant permissions for other accounts to write to the SQS queue in the main account. \\nThen, you create EventBridge rules in each account dat match EC2 lifecycle events and use da main account\'s SQS queue as a target for these rules. It\'s da best choice for dis scenario.","timestamp":"1682703780.0","poster":"ihebchorfi"},{"upvote_count":"2","poster":"MrTee","comment_id":"879760","content":"Selected Answer: D\\nThis solution allows the collection of all the lifecycle events of the EC2 instances from multiple AWS accounts and stores them in a single Amazon SQS queue in the company\u2019s main AWS account for further processing","timestamp":"1682377920.0"},{"timestamp":"1679987820.0","content":"For Option C using lambda does not seem to be a good solution as we would have to trigger lambda on some schedule and it will has less granularity in time.\\n\\nFor D. Why would we be matching EC2 instance lifecycle events in Main account event bus and not in each account event bus and reducing overhead for main account","upvote_count":"1","poster":"shahs10","comment_id":"852935"},{"comment_id":"840850","timestamp":"1678964460.0","upvote_count":"4","poster":"good_","content":"I think the answer to this question is also A."},{"poster":"haaris786","upvote_count":"5","content":"Answer A: This makes more sense and a simplified solution.","comment_id":"840738","timestamp":"1678957860.0"},{"content":"D\\nhttps://www.examtopics.com/discussions/amazon/view/96209-exam-aws-certified-developer-associate-topic-1-question-396/","poster":"aragon_saa","comment_id":"840715","upvote_count":"4","timestamp":"1678957020.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:05.430Z","extraction_method":"api_direct_v1"},{"question_id":"4CLfZnqKifzkp2WaoWDN","question_number":113,"page":23,"question_text":"A developer wants to store information about movies. Each movie has a title, release year, and genre. The movie information also can include additional properties about the cast and production crew. This additional information is inconsistent across movies. For example, one movie might have an assistant director, and another movie might have an animal trainer.\\nThe developer needs to implement a solution to support the following use cases:\\nFor a given title and release year, get all details about the movie that has that title and release year.\\nFor a given title, get all details about all movies that have that title.\\nFor a given genre, get all details about all movies in that genre.\\nWhich data store configuration will meet these requirements?","choices":{"C":"On an Amazon RDS DB instance, create a table that contains columns for title, release year, and genre. Configure the title as the primary key.","D":"On an Amazon RDS DB instance, create a table where the primary key is the title and all other data is encoded into JSON format as one additional column.","B":"Create an Amazon DynamoDB table. Configure the table with a primary key that consists of the genre as the partition key and the release year as the sort key. Create a global secondary index that uses the title as the partition key.","A":"Create an Amazon DynamoDB table. Configure the table with a primary key that consists of the title as the partition key and the release year as the sort key. Create a global secondary index that uses the genre as the partition key and the title as the sort key."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103468-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 13:30:00","unix_timestamp":1679401800,"discussion_count":12,"discussion":[{"content":"Selected Answer: A\\nA. Create an Amazon DynamoDB table. Configure the table with a primary key that consists of the title as the partition key and the release year as the sort key. Create a global secondary index that uses the genre as the partition key and the title as the sort key.\\n\\nThis option is the best choice for the given requirements. By using DynamoDB, the developer can store the movie information in a flexible and scalable NoSQL database. The primary key can be set to the title and release year, allowing for efficient retrieval of information about a specific movie. The global secondary index can be created using the genre as the partition key, allowing for efficient retrieval of information about all movies in a specific genre. Additionally, the use of a NoSQL database like DynamoDB allows for the flexible storage of additional properties about the cast and crew, as each movie can have different properties without affecting the structure of the database.","timestamp":"1683378540.0","poster":"Bibay","upvote_count":"16","comment_id":"890753"},{"poster":"sumanshu","comment_id":"1329905","timestamp":"1734774180.0","upvote_count":"2","content":"Selected Answer: A\\nB) Eliminated - No efficient way to query by title + release year since the primary key is genre + release year, and the GSI only has the title\\n\\nC) Eliminated - Adding new columns for properties like assistant director or animal trainer becomes cumbersome and violates flexibility.\\n\\nD) Eliminated - JSON in RDS is harder to query"},{"timestamp":"1734092040.0","content":"Selected Answer: A\\nkeyword: (title + release year), title, genre, each film has differential cast and crew\\n\\n=> Discard C,D: when it store film by structure && option C must scan all data that is not primary key(title), seem be not flexible && option D is horrible way, when storing data as json structure, take time to extract this json\\n==> discard B: querry (title + release year) must scan all item without combining them in primary key(partition key and sort key) at primary table or GSI","poster":"trieudo","comment_id":"1326112","upvote_count":"2"},{"timestamp":"1721754780.0","poster":"ahadh7621","content":"Selected Answer: A\\nThis question was on my exam July 23rd, 2024. Answer is A","comment_id":"1253808","upvote_count":"3"},{"content":"A is mostly correct , but I do see one problem there because in one year there can be same title movies can come which invalidate our primary key having title as partition key and year as a. Sort. key","poster":"sid4510","upvote_count":"1","timestamp":"1719982140.0","comment_id":"1241161"},{"poster":"65703c1","upvote_count":"1","comment_id":"1215018","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716301260.0"},{"comment_id":"1072044","poster":"leonardoliveros","upvote_count":"2","timestamp":"1700094300.0","content":"Selected Answer: A\\nIf you create a primary key with title(pk) and release(sk) date you corvered two scenaries, and also you need a GSI by last scenary with genre so you should creating a GSI with genre (pk) and title (sk)"},{"timestamp":"1693741140.0","comment_id":"997570","content":"Selected Answer: A\\nGo with A.\\nNoSQL is good when data attributes are inconsistent -> DynamoDB\\nPrimary key should be unique, go with title + release year.","upvote_count":"4","poster":"Tony88"},{"poster":"jayvarma","timestamp":"1691613780.0","upvote_count":"4","content":"As the schema for each entry of data into the database is not the same all the time, We would require a NoSQL database. So, RDS DB instance is ruled out. The answer is between A and B.\\n\\nAs we would need the partition key to be as unique as possible, we would like to have the title of the movie as the partition key. Because having the partition key as the genre will create a hot partition problem and our data stored in the DynamoDB will be skewed. \\n\\nSo option A is the answer.","comment_id":"977016"},{"timestamp":"1680683640.0","upvote_count":"2","content":"Selected Answer: A\\nIt\'s A - I totally agree. It\'s a single appropriate solution. But in my opinion genre isn\'t a quite good option as GSI partition key - it isn\'t high distribution and we can get a hot partition.","comment_id":"861890","poster":"Krok"},{"comment_id":"853271","upvote_count":"2","poster":"shahs10","timestamp":"1680008880.0","content":"Selected Answer: A\\nOption A because we have to search on the basis of title so it is better to partition by title. Also we have to search by genre so it is good option to make GSI using genre as partition key"},{"upvote_count":"3","comment_id":"845936","content":"Selected Answer: A\\nThe correct answer is A.\\nAmazon DynamoDB is suited for storing inconsistent attributes data across items.\\nOption B is wrong. This solution does not help get items with the condition of the combination, title and release year.","poster":"Untamables","timestamp":"1679401800.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:05.430Z","extraction_method":"api_direct_v1"},{"question_id":"KJQxRYadFucVblpEBETu","question_number":114,"page":23,"question_text":"A company has a serverless application on AWS that uses a fleet of AWS Lambda functions that have aliases. The company regularly publishes new Lambda function by using an in-house deployment solution. The company wants to improve the release process and to use traffic shifting. A newly published function version should initially make available only to a fixed percentage of production users.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Configure routing on the alias of the new function by using a weighted alias.","D":"Configure a linear deployment type for Lambda.","C":"Configure routing on the new versions by using environment variables.","B":"Configure a canary deployment type for Lambda."},"correct_answer":"A","answer_ET":"A","answers_community":["A (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122622-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:01:00","unix_timestamp":1696554060,"discussion_count":6,"discussion":[{"timestamp":"1696596780.0","upvote_count":"8","comment_id":"1026633","poster":"Digo30sp","content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nWeighted aliases allow you to route traffic to different versions of a function based on weights that you assign. This allows you to implement a canary deployment, where you initially route a small percentage of your traffic to the new version of the function, and then gradually increase the percentage as you gain confidence in the new version.","comments":[{"timestamp":"1708169400.0","poster":"rimaSamir","comments":[{"poster":"albert_kuo","timestamp":"1727499960.0","content":"While canary deployments are a valid strategy for gradual rollouts, Lambda doesn\'t have a built-in \\"canary deployment type.\\" This option is misleading and not applicable in the context of Lambda functions.","comment_id":"1290509","upvote_count":"1"},{"comment_id":"1254032","timestamp":"1721783100.0","poster":"albert_kuo","content":"the key word is \\"fixed percentage\\"","upvote_count":"2"}],"comment_id":"1152513","content":"If we need Canary deployment, then why not B ?\\nHow you will use A in automated deployment?","upvote_count":"3"}]},{"timestamp":"1716477540.0","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216681","upvote_count":"1","poster":"65703c1"},{"content":"Selected Answer: B\\nI am struggling to see how the correct answer isn\'t canary. please feel free to enlighten me as I am at a loss how this question description is anything but canary","comments":[{"upvote_count":"1","content":"is this question a case of what naming convention is used within Lambda service. i.e. Canary deployments via Weighted Aliases.","poster":"DeaconStJohn","comment_id":"1178094","comments":[{"timestamp":"1710927480.0","content":"Still very on the fence with this one. \\nMy key take aways are that the question says an in house deployment solution and not \\"codedeploy.\\"\\nBy using weighted aliases we are in fact performing a canary deployments.\\n\\nBitch of a question.","comments":[{"content":"My thought process is this. They can\'t use Canary Deployment because that is specifically for AWS CodeDeploy: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html\\n\\nThey are using an in-house deployment method, so AWS canary deployments aren\'t applicable. They can, however, use routing configuration on an alias to send a portion of traffic to a second function version. For example, you can reduce the risk of deploying a new version by configuring the alias to send most of the traffic to the existing version, and only a small percentage of traffic to the new version.\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html#configuring-alias-routing","timestamp":"1721266680.0","poster":"ahadh7621","comment_id":"1250053","upvote_count":"2"}],"upvote_count":"1","comment_id":"1178110","poster":"DeaconStJohn"}],"timestamp":"1710927120.0"}],"comment_id":"1178086","timestamp":"1710926820.0","poster":"DeaconStJohn","upvote_count":"1"},{"timestamp":"1709378520.0","comment_id":"1164078","poster":"KarBiswa","upvote_count":"2","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html#configuring-alias-routing:~:text=function%20version.%20For%20example%2C%20you%20can%20reduce%20the%20risk%20of%20deploying%20a%20new%20version%20by%20configuring%20the%20alias%20to%20send%20most%20of%20the%20traffic%20to%20the%20existing%20version%2C%20and%20only%20a%20small%20percentage%20of%20traffic%20to%20the%20new%20version."},{"poster":"NijeshT","timestamp":"1701443460.0","content":"Answer is A.\\nweighted aliases offer fixed, predefined percentages","upvote_count":"4","comment_id":"1085304"},{"timestamp":"1696554060.0","comment_id":"1026112","poster":"fordiscussionstwo","upvote_count":"4","content":"AAAAAAAAAAA"}],"answer_description":"","extracted_at":"2025-12-24T08:59:05.430Z","extraction_method":"api_direct_v1"},{"question_id":"NKbovAzgCGsiFelzun6H","question_number":115,"page":23,"question_text":"A company has an application that stores data in Amazon RDS instances. The application periodically experiences surges of high traffic that cause performance problems. During periods of peak traffic, a developer notices a reduction in query speed in all database queries.\\n\\nThe team\u2019s technical lead determines that a multi-threaded and scalable caching solution should be used to offload the heavy read traffic. The solution needs to improve performance.\\n\\nWhich solution will meet these requirements with the LEAST complexity?","choices":{"D":"Use Amazon ElastiCache for Redis to offload read requests from the main database.","A":"Use Amazon ElastiCache for Memcached to offload read requests from the main database.","B":"Replicate the data to Amazon DynamoDSet up a DynamoDB Accelerator (DAX) cluster.","C":"Configure the Amazon RDS instances to use Multi-AZ deployment with one standby instance. Offload read requests from the main database to the standby instance."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122623-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:03:00","unix_timestamp":1696554180,"discussion_count":7,"discussion":[{"poster":"kashtelyan","upvote_count":"8","comment_id":"1039844","content":"Selected Answer: A\\nWhen deciding between Memcached and Redis, here are a few questions to consider:\\n\\nIs object caching your primary goal, for example to offload your database? If so, use Memcached.\\n\\nhttps://docs.aws.amazon.com/whitepapers/latest/scale-performance-elasticache/memcached-vs.-redis.html","timestamp":"1696968360.0"},{"upvote_count":"1","comment_id":"1290514","poster":"albert_kuo","timestamp":"1727500980.0","content":"Selected Answer: A\\noption A (using ElastiCache for Memcached) provides the best balance of meeting the requirements (multi-threaded, scalable caching to improve performance) while maintaining the least complexity."},{"timestamp":"1716478620.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216695"},{"comment_id":"1141495","timestamp":"1707168060.0","poster":"tsdsmth","content":"Selected Answer: A\\nA. If you\'re looking for a multi-threaded solution, then ElastiCache for Memcached (not Redis) is the solution.","upvote_count":"1"},{"comment_id":"1128913","timestamp":"1705946280.0","content":"Selected Answer: A\\nA. Use Amazon ElastiCache for Memcached to offload read requests from the main database.\\n\\nElastiCache for Memcached is a good fit for this scenario. It\'s a high-performance, distributed, in-memory caching system that can easily scale to manage surges in read traffic. It\'s simple to set up and integrate with an existing RDS instance.\\nD. Use Amazon ElastiCache for Redis to offload read requests from the main database.\\n\\nElastiCache for Redis also offers high performance and is capable of handling surges in read traffic. Redis provides more advanced data structures and features compared to Memcached, like persistence, built-in replication, and support for complex data types. However, it might be more complex to set up and manage than Memcached, depending on the use case.","poster":"SerialiDr","upvote_count":"3"},{"content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nAmazon ElastiCache for Memcached is a scalable, multithreaded caching solution that can be used to offload heavy read traffic from Amazon RDS instances. ElastiCache for Memcached is easy to configure and manage, making it a low-effort solution to meet technical lead requirements.","upvote_count":"3","comment_id":"1026637","timestamp":"1696597140.0","poster":"Digo30sp"},{"poster":"fordiscussionstwo","comment_id":"1026116","content":"AAAAAAAAA","upvote_count":"3","timestamp":"1696554180.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:05.430Z","extraction_method":"api_direct_v1"},{"question_id":"gvE5YtPSCPcy7VKua12B","question_number":116,"page":24,"question_text":"A developer must provide an API key to an AWS Lambda function to authenticate with a third-party system. The Lambda function will run on a schedule. The developer needs to ensure that the API key remains encrypted at rest.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Store the API key as a value in the application code.","D":"Use Lambda@Edge and only communicate over the HTTPS protocol.","A":"Store the API key as a Lambda environment variable by using an AWS Key Management Service (AWS KMS) customer managed key.","B":"Configure the application to prompt the user to provide the password to the Lambda function on the first run."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122624-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:06:00","unix_timestamp":1696554360,"discussion_count":4,"discussion":[{"timestamp":"1712419080.0","poster":"Digo30sp","comment_id":"1026781","content":"Selected Answer: A\\nThe correct answer is (A).\\n\\nStoring the API key as a Lambda environment variable using an AWS Key Management Service (AWS KMS) customer-managed key is the most secure solution. AWS KMS is a managed encryption service that provides customer-managed keys. Customer-managed keys are encrypted with an AWS KMS master key, which is stored in an AWS KMS vault.","upvote_count":"8"},{"upvote_count":"1","timestamp":"1732385040.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216718"},{"content":"Selected Answer: A\\nLambda environment variables can be encrypted using a customer managed key in AWS KMS. This approach ensures that the API key is encrypted at rest and seamlessly integrated into the Lambda function. When the function is executed, it can access the decrypted value of the API key for authenticating with the third-party system.","upvote_count":"3","timestamp":"1721664180.0","comment_id":"1128918","poster":"SerialiDr"},{"content":"AAAAAAAAAA","upvote_count":"2","poster":"fordiscussionstwo","comment_id":"1026118","timestamp":"1712365560.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:16.187Z","extraction_method":"api_direct_v1"},{"question_id":"8GBbbReRH6wCNoYoT0eU","question_number":117,"page":24,"question_text":"An IT department uses Amazon S3 to store sensitive images. After more than 1 year, the company moves the images into archival storage. The company rarely accesses the images, but the company wants a storage solution that maximizes resiliency. The IT department needs access to the images that have been moved to archival storage within 24 hours.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"D":"Use S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.","B":"Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.","A":"Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.","C":"Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images."},"correct_answer":"A","answer_ET":"A","answers_community":["A (50%)","C (25%)","B (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122625-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:06:00","unix_timestamp":1696554360,"discussion_count":19,"discussion":[{"content":"A is correct. The requirement of maximizing resiliency rules out One Zone. Standard recover is within 12 hours, which fits the requirement of within 24 hours. https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html","poster":"Learning4life","timestamp":"1697382240.0","upvote_count":"8","comment_id":"1044252"},{"poster":"f271c23","comment_id":"1324852","timestamp":"1733890440.0","upvote_count":"1","content":"Selected Answer: A\\nI had incorrectly selected B but the right option is A. the main reason is the retrieval time in the standard way is within 12 hours which meets the requirement"},{"upvote_count":"1","poster":"MasoudK","comment_id":"1294607","content":"Option A is not most Cost effective the standard approach maximize resiliency but is more expensive than Option B. Option B handles both goals.","timestamp":"1728370200.0"},{"poster":"albert_kuo","content":"Selected Answer: B\\nThe average retrieval time for bulk retrievals typically ranges from 5 to 12 hours, but it can take up to 48 hours. This method is suitable for cold storage data, making it a highly cost-effective option when retrieval frequency is low, and there are no stringent requirements on retrieval time.","upvote_count":"2","comment_id":"1290516","comments":[{"upvote_count":"1","content":"bulk retrievals take 48 hours\\nstandard retrievals take 24hours\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html\\nRefer the table 2 row","timestamp":"1728526920.0","comment_id":"1295368","poster":"lambdaFun"}],"timestamp":"1727501460.0"},{"upvote_count":"2","comment_id":"1265802","timestamp":"1723643280.0","content":"Selected Answer: B\\nMOST cost-effective solution is:\\n\\nB. Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.\\n\\nHere\u2019s why:\\n\\nS3 Standard-Infrequent Access (S3 Standard-IA):\\nProvides a balance between cost and retrieval speed.\\nSuitable for long-lived, less frequently accessed data.\\nAccessible within hours.","poster":"Saurabh04"},{"timestamp":"1721538780.0","upvote_count":"1","poster":"Anandesh","comment_id":"1252235","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/glacier-storage-classes.html#archival-storage"},{"poster":"65703c1","upvote_count":"1","comment_id":"1216748","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716482280.0"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html#:~:text=Deep%20Archive%20or-,S3%20Intelligent%2DTiering%20Deep%20Archive%20Access,-Not%20available","comments":[{"poster":"DeaconStJohn","upvote_count":"1","timestamp":"1711352940.0","comment_id":"1182290","content":"Initially I thought C also. However, lifecycle policies seem to be better for this use case. S3-IT will start at standard pricing, after 30 days > IA, after 90 days > archive instant retrieval. None of these are the most cost effective. S3-IT works well for use cases were there is no defined policy in place, i.e. after 1 year move to archive. reqs state archive after 365 days. s3-IT will action this after 90 days depending on access patterns."}],"comment_id":"1164084","timestamp":"1709379300.0","poster":"KarBiswa","upvote_count":"1"},{"upvote_count":"3","poster":"SerialiDr","timestamp":"1705946940.0","content":"Selected Answer: A\\nS3 Standard-IA is designed for data that is accessed less frequently but requires rapid access when needed. It offers a lower storage cost while still providing high durability, availability, and performance.\\nS3 Glacier Deep Archive is the most cost-effective option for archival storage in AWS and is designed for data that is accessed very rarely. The standard retrieval option in Glacier Deep Archive typically returns data within 12 hours, meeting the requirement of access within 24 hours.","comment_id":"1128923"},{"comments":[{"content":"As a society we need to learn to challenge AI models.\\n\\nhttps://aws.amazon.com/s3/faqs/#Amazon_S3_Glacier_Deep_Archive\\nWhen restoring an archived object, you can specify one of the following options in the Tier element of the request body: Standard is the default tier and lets you access any of your archived objects within 12 hours, with retrievals typically starting within 9 hours when initiated using S3 Batch Operations. Bulk lets you retrieve large amounts of data, even petabytes of data, inexpensively and typically completes within 48 hours.","comment_id":"1182282","poster":"DeaconStJohn","timestamp":"1711352220.0","upvote_count":"2"}],"comment_id":"1128534","timestamp":"1705921080.0","content":"ChatGPT goes with B","poster":"_YaWeb","upvote_count":"2"},{"timestamp":"1705242840.0","content":"Selected Answer: A\\nAAAAAAAAA","upvote_count":"1","comment_id":"1122602","poster":"dostonbekabdullaev"},{"content":"Selected Answer: A\\nA is correct -Bulk retrival is 48hours","upvote_count":"1","poster":"Certified101","comment_id":"1098080","timestamp":"1702723500.0"},{"content":"Selected Answer: B\\nWith Option A: Standard retrieval would provide faster access to the archived images (typically within 3-5 hours), it is more expensive than Bulk retrieval. Since the company has indicated they can wait up to 24 hours for access, the slower but cheaper\\n\\n=> Option B is the best choice.","comment_id":"1096260","poster":"TanTran04","upvote_count":"1","timestamp":"1702544940.0"},{"content":"Selected Answer: C\\nC. Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.","comment_id":"1094568","timestamp":"1702388100.0","poster":"Hanny","upvote_count":"2"},{"upvote_count":"2","comment_id":"1088275","timestamp":"1701764580.0","poster":"tqiu654","content":"Selected Answer: B\\nGPT: B. Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive and select Batch Retrieval to store and retrieve archived images."},{"upvote_count":"4","comments":[{"content":"Check the requirement : \\n The IT department needs access to the images that have been moved to archival storage within 24 hours.","comment_id":"1059730","timestamp":"1698845340.0","upvote_count":"1","poster":"ut18"}],"timestamp":"1698223200.0","content":"Selected Answer: C\\nA : Glacier Deep Archive is cheaper than Standard-IA. \\nC : Standard archival is 12h.\\nB : bulk retrieval is 48h\\nD : S3 One Zone-IA - cross-out due to \\"maximizes resiliency\\"","comment_id":"1053578","poster":"hcsaba1982"},{"poster":"Cerakoted","content":"Selected Answer: A\\nIt is A","timestamp":"1697029260.0","comment_id":"1040667","upvote_count":"2"},{"upvote_count":"4","comment_id":"1026653","timestamp":"1696598280.0","content":"Selected Answer: A\\nA) Correct A) because the standard recovery is carried out within 12 hours and the requirement says that it must be recovered within 24 hours.\\nBulk recovery takes up to 48 hours","poster":"Digo30sp"},{"upvote_count":"2","timestamp":"1696554360.0","poster":"fordiscussionstwo","comment_id":"1026119","content":"BBBBBBBBBB"}],"answer_description":"","extracted_at":"2025-12-24T08:59:16.187Z","extraction_method":"api_direct_v1"},{"question_id":"So1mSbmp3cIFasxgwpQ2","question_number":118,"page":24,"question_text":"A developer is building a serverless application by using the AWS Serverless Application Model (AWS SAM). The developer is currently testing the application in a development environment. When the application is nearly finished, the developer will need to set up additional testing and staging environments for a quality assurance team.\\n\\nThe developer wants to use a feature of the AWS SAM to set up deployments to multiple environments.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"A":"Add a configuration file in TOML format to group configuration entries to every environment. Add a table for each testing and staging environment. Deploy updates to the environments by using the sam deploy command and the --config-env flag that corresponds to each environment.","B":"Create additional AWS SAM templates for each testing and staging environment. Write a custom shell script that uses the sam deploy command and the --template-file flag to deploy updates to the environments.","D":"Use the existing AWS SAM template. Add additional parameters to configure specific attributes for the serverless function and database table resources that are in each environment. Deploy updates to the testing and staging environments by using the sam deploy command.","C":"Create one AWS SAM configuration file that has default parameters. Perform updates to the testing and staging environments by using the --parameter-overrides flag in the AWS SAM CLI and the parameters that the updates will override."},"correct_answer":"A","answer_ET":"A","answers_community":["A (63%)","C (29%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122626-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:07:00","unix_timestamp":1696554420,"discussion_count":18,"discussion":[{"upvote_count":"10","poster":"SerialiDr","content":"Selected Answer: A\\nTo set up deployments to multiple environments with the least development effort in a serverless application using the AWS Serverless Application Model (AWS SAM), the developer can utilize a configuration file in TOML format with grouped configuration entries for each environment. This approach allows for easy management of different environment configurations and streamlines the deployment process. The specific steps would include:\\n\\nCreating a configuration file in TOML format: This file will include a table for each testing and staging environment, where each table contains the specific configuration for that environment.\\nUsing the sam deploy command with the --config-env flag: This flag allows specifying which environment configuration to use for the deployment, corresponding to the tables defined in the configuration file.\\nThis solution aligns with Option A:","timestamp":"1706003700.0","comment_id":"1129401"},{"content":"Selected Answer: A\\nA should be correct\\nreference this stackoverflow post https://stackoverflow.com/questions/68826108/how-to-deploy-to-different-environments-with-aws-sam","timestamp":"1697285520.0","upvote_count":"8","comment_id":"1043409","poster":"Jing2023"},{"upvote_count":"1","content":"Selected Answer: A\\nsam deploy --config-env default\\nsam deploy --config-env testing\\nsam deploy --config-env production","timestamp":"1727502840.0","poster":"albert_kuo","comment_id":"1290518"},{"content":"Selected Answer: A\\nAWS SAM supports configuration files in TOML format, which allows you to define multiple environments in a single file.","poster":"KennethNg923","upvote_count":"1","timestamp":"1724298000.0","comment_id":"1270474"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-config.html#serverless-sam-cli-config-default","upvote_count":"1","poster":"Anandesh","comment_id":"1244662","timestamp":"1720496640.0"},{"comment_id":"1216750","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716482460.0"},{"upvote_count":"2","content":"Selected Answer: C\\nC. Create one AWS SAM configuration file that has default parameters. Perform updates to the testing and staging environments by using the --parameter-overrides flag in the AWS SAM CLI and the parameters that the updates will override.","timestamp":"1710834660.0","comment_id":"1177064","poster":"41eb566"},{"upvote_count":"2","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-config.html","comment_id":"1164088","poster":"KarBiswa","timestamp":"1709379840.0"},{"poster":"Certified101","content":"Selected Answer: C\\nC with least development overhead","timestamp":"1702723680.0","comment_id":"1098083","upvote_count":"1"},{"comment_id":"1094597","upvote_count":"3","poster":"TanTran04","timestamp":"1702390140.0","content":"Selected Answer: C\\nWith at LEAST development effort, Option C is better than A\\n\\nWhile this approach may work, it introduces additional complexity with the need for a separate configuration file, and it may not be as straightforward as using parameter overrides, as suggested in option C. The use of TOML format might be more suited for certain scenarios, but in the context of AWS SAM, which commonly relies on YAML or JSON configurations, it might be an extra layer of complexity that isn\'t necessary.\\n\\nOption C, on the other hand, recommends using a single AWS SAM configuration file with default parameters and updating testing and staging environments using the --parameter-overrides flag. This approach is more aligned with typical AWS SAM practices and is simpler and more straightforward than managing multiple configuration files."},{"timestamp":"1702390080.0","comment_id":"1094596","content":"With at LEAST development effort, Option C is better than A\\n\\nWhile this approach may work, it introduces additional complexity with the need for a separate configuration file, and it may not be as straightforward as using parameter overrides, as suggested in option C. The use of TOML format might be more suited for certain scenarios, but in the context of AWS SAM, which commonly relies on YAML or JSON configurations, it might be an extra layer of complexity that isn\'t necessary.\\n\\nOption C, on the other hand, recommends using a single AWS SAM configuration file with default parameters and updating testing and staging environments using the --parameter-overrides flag. This approach is more aligned with typical AWS SAM practices and is simpler and more straightforward than managing multiple configuration files.","poster":"TanTran04","upvote_count":"1"},{"content":"C. Create one AWS SAM configuration file that has default parameters. Perform updates to the testing and staging environments by using the --parameter-overrides flag in the AWS SAM CLI and the parameters that the updates will override.","timestamp":"1702388160.0","upvote_count":"2","poster":"Hanny","comment_id":"1094571"},{"comment_id":"1059960","timestamp":"1698860700.0","content":"Correct Answer: C, \\nYou can create a single AWS SAM configuration file with default parameters and then use the --parameter-overrides flag with the AWS SAM CLI to specify parameters that override the defaults for each testing and staging environment. This approach keeps the AWS SAM template file (the infrastructure-as-code) consistent and minimizes duplication. It\'s a clean and simple way to manage multiple environments without having to create separate templates or custom scripts.","poster":"NinjaCloud","upvote_count":"8"},{"comment_id":"1049073","content":"Selected Answer: C\\nHere all the options can do the Job but option C does it with least effort.","poster":"Rameez1","upvote_count":"2","timestamp":"1697830380.0"},{"timestamp":"1697796060.0","upvote_count":"2","comment_id":"1048622","poster":"PrakashM14","content":"Selected Answer: C\\nOptions A and B introduce additional complexities such as configuration files in TOML format or writing custom shell scripts. These might require more effort and maintenance.\\n\\nOption D involves adding additional parameters to the existing AWS SAM template, which can work but may lead to a more complex and less maintainable template as the number of environments grows.\\n\\nTherefore, option C is a straightforward and efficient solution for deploying to multiple environments with AWS SAM."},{"comment_id":"1040494","timestamp":"1697019360.0","poster":"dilleman","content":"Selected Answer: A\\nA is correct","upvote_count":"4"},{"poster":"Digo30sp","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nUsing the existing AWS SAM template is the option that requires the LEAST development effort. To configure deployments across multiple environments, you can add additional parameters to your AWS SAM template to configure specific attributes for the serverless function and database table resources that are in each environment.","upvote_count":"3","timestamp":"1696598520.0","comment_id":"1026660"},{"upvote_count":"3","comment_id":"1026121","timestamp":"1696554420.0","content":"AAAAAAAAAA","poster":"fordiscussionstwo"}],"answer_description":"","extracted_at":"2025-12-24T08:59:16.187Z","extraction_method":"api_direct_v1"},{"question_id":"05HVPsjN0ZYkcYM8EMXQ","question_number":119,"page":24,"question_text":"A developer is working on an application that processes operating data from IoT devices. Each IoT device uploads a data file once every hour to an Amazon S3 bucket. The developer wants to immediately process each data file when the data file is uploaded to Amazon S3.\\n\\nThe developer will use an AWS Lambda function to process the data files from Amazon S3. The Lambda function is configured with the S3 bucket information where the files are uploaded. The developer wants to configure the Lambda function to immediately invoke after each data file is uploaded.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Add an Amazon EventBridge event to the Lambda function. Select the S3 bucket as the source.","D":"Add a layer to the Lambda function. Select the S3 bucket as the source.","A":"Add an asynchronous invocation to the Lambda function. Select the S3 bucket as the source.","C":"Add a trigger to the Lambda function. Select the S3 bucket as the source."},"correct_answer":"C","answer_ET":"C","answers_community":["C (80%)","B (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122627-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:09:00","unix_timestamp":1696554540,"discussion_count":11,"discussion":[{"comment_id":"1026661","timestamp":"1696598580.0","poster":"Digo30sp","upvote_count":"6","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nAdding a trigger to your Lambda function is the solution that will meet these requirements. A trigger is an event that can invoke a Lambda function. In the case of this issue, the trigger must be an Amazon S3 event that fires when a new file is uploaded to the bucket."},{"timestamp":"1723644120.0","poster":"Saurabh04","content":"Selected Answer: B\\nOption B is quicker than Option C, because S3 bucket trigger does not guarantee immediate invocation. It relies on event notification from S3.","upvote_count":"1","comment_id":"1265810"},{"content":"Selected Answer: B\\nYou cannot add a Trigger directly to Lambda. If you want to choose C, then the answer should state: \\"Add a trigger to S3, select Lambda as the destination\\"\\n\\nSince C states \\"Add trigger to Lambda\\" (which isn\'t possible), I will select answer B.\\n\\nSee https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html\\n\\"The trigger is actually stored and managed by the service that generates the events, not by Lambda.\\"","upvote_count":"1","timestamp":"1721955360.0","poster":"BrainFried","comment_id":"1255315"},{"upvote_count":"2","poster":"Anandesh","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html","timestamp":"1721539140.0","comment_id":"1252237"},{"content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1216754","timestamp":"1716482700.0","upvote_count":"1","poster":"65703c1"},{"comment_id":"1204375","timestamp":"1714459200.0","content":"Selected Answer: B\\nsure that B, give me a link why everyone want C.","upvote_count":"1","poster":"1dfed2b","comments":[{"comment_id":"1227876","timestamp":"1718024520.0","poster":"tsangckl","content":"https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html","comments":[{"content":"From what I\'ve read, you do not add a trigger to a lambda, you add it else-where (in this case, you add the trigger to S3). The answer says \\"Add a trigger to Lambda\\" - this isn\'t possible!\\n\\nRead: https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html\\n\\"The trigger is actually stored and managed by the service that generates the events, not by Lambda.\\"\\n\\nThe answer should be B then, since EventBridge can monitor S3 bucket and invoke Lambda with the new data.","comment_id":"1255313","timestamp":"1721955120.0","poster":"BrainFried","upvote_count":"1"}],"upvote_count":"1"}]},{"poster":"SerialiDr","timestamp":"1706003940.0","comment_id":"1129407","content":"Selected Answer: C\\nTo meet the requirement of processing data files immediately after they are uploaded to an Amazon S3 bucket, the best solution is to add a trigger to the AWS Lambda function with the S3 bucket as the source. This will configure the Lambda function to be automatically invoked when a new file is uploaded to the specified S3 bucket.","upvote_count":"3"},{"upvote_count":"1","poster":"Certified101","content":"Selected Answer: C\\nC using S3 Events, no need for EventBridge here.","timestamp":"1702723860.0","comment_id":"1098090"},{"comment_id":"1092603","upvote_count":"1","comments":[{"poster":"LR2023","timestamp":"1702222800.0","comment_id":"1092605","content":"You can use Amazon EventBridge to monitor an S3 bucket for new image uploads. When a new image is detected, EventBridge triggers a Lambda function that processes the image, applies filters, and generates thumbnails, all without manual intervention","upvote_count":"1"}],"poster":"LR2023","timestamp":"1702222740.0","content":"Selected Answer: B\\nEventBridge can be employed to collect real-time data streams from various sources like IoT devices, mobile apps, or web applications. Lambda functions can then process this data to perform analytics, generate alerts, or update dashboards."},{"comment_id":"1040497","content":"Selected Answer: C\\nC is correct","upvote_count":"3","timestamp":"1697019540.0","poster":"dilleman"},{"poster":"fordiscussionstwo","comment_id":"1026124","content":"CCCCCCCCCCCCCC","timestamp":"1696554540.0","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:59:16.187Z","extraction_method":"api_direct_v1"},{"question_id":"1cOYmwrAeD4PZ7bjU7jZ","question_number":120,"page":24,"question_text":"A developer is setting up infrastructure by using AWS CloudFormation. If an error occurs when the resources described in the Cloud Formation template are provisioned, successfully provisioned resources must be preserved. The developer must provision and update the CloudFormation stack by using the AWS CLI.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Add an --enable-termination-protection command line option to the create-stack command and the update-stack command.","C":"Add a --parameters ParameterKey=PreserveResources,ParameterValue=True command line option to the create-stack command and the update-stack command.","D":"Add a --tags Key=PreserveResources,Value=True command line option to the create-stack command and the update-stack command.","B":"Add a --disable-rollback command line option to the create-stack command and the update-stack command."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122628-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:10:00","unix_timestamp":1696554600,"discussion_count":9,"discussion":[{"poster":"Digo30sp","comment_id":"1026662","timestamp":"1696598640.0","upvote_count":"7","content":"Selected Answer: B\\nThe correct answer is (B).\\n\\nThe --disable-rollback command-line option will prevent CloudFormation from rolling back the stack to the previous state if an error occurs. This will ensure that successfully provisioned resources are preserved."},{"poster":"albert_kuo","timestamp":"1727503320.0","comment_id":"1290524","content":"Selected Answer: B\\naws cloudformation create-stack \\\\\\n --stack-name my-app-stack \\\\\\n --template-body file://my-template.yaml \\\\\\n --parameters ParameterKey=InstanceType,ParameterValue=t2.micro \\\\\\n --disable-rollback\\n\\n\\naws cloudformation update-stack \\\\\\n --stack-name my-app-stack \\\\\\n --template-body file://my-template-updated.yaml \\\\\\n --parameters ParameterKey=InstanceType,ParameterValue=t2.medium \\\\\\n --disable-rollback","upvote_count":"1"},{"comment_id":"1216757","upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716482820.0","poster":"65703c1"},{"poster":"KarBiswa","comment_id":"1164531","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stack-failure-options.html","upvote_count":"1","timestamp":"1709446800.0"},{"content":"Selected Answer: B\\nIt should look like this:\\n\\naws cloudformation create-stack --stack-name myteststack --template-body file://DOC-EXAMPLE-BUCKET.json --disable-rollback\\n\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stack-failure-options.html#stack-failure-options-cli","comment_id":"1139695","poster":"joshnort","timestamp":"1707008100.0","upvote_count":"3"},{"upvote_count":"3","timestamp":"1701001620.0","comment_id":"1080630","content":"Selected Answer: B\\n\\"Specify the disable-rollback option or on-failure DO_NOTHING enumeration during a create-stack operation\\"\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stack-failure-options.html","poster":"kaes"},{"comment_id":"1040506","upvote_count":"3","content":"Selected Answer: B\\nB is correct","poster":"dilleman","timestamp":"1697019840.0"},{"content":"Selected Answer: B\\nhttps://www.cloudhesive.com/blog-posts/cloudformation-disable-rollback/","comment_id":"1039852","timestamp":"1696969320.0","upvote_count":"4","poster":"kashtelyan"},{"timestamp":"1696554600.0","upvote_count":"3","poster":"fordiscussionstwo","content":"BBBBBBBBBBBBBBBBB","comment_id":"1026125"}],"answer_description":"","extracted_at":"2025-12-24T08:59:16.187Z","extraction_method":"api_direct_v1"},{"question_id":"fJrlDLXON83lj5Uk7YuS","question_number":121,"page":25,"question_text":"A developer is building a serverless application that connects to an Amazon Aurora PostgreSQL database. The serverless application consists of hundreds of AWS Lambda functions. During every Lambda function scale out, a new database connection is made that increases database resource consumption.\\n\\nThe developer needs to decrease the number of connections made to the database. The solution must not impact the scalability of the Lambda functions.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Enable cluster cache management for Aurora PostgreSQL. Change the connection string of each Lambda function to point to cluster cache management.","D":"Configure reserved concurrency for each Lambda function by setting the ReservedConcurrentExecutions parameter to 10.","A":"Configure provisioned concurrency for each Lambda function by setting the ProvisionedConcurrentExecutions parameter to 10.","C":"Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122629-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:11:00","unix_timestamp":1696554660,"discussion_count":4,"discussion":[{"content":"Selected Answer: C\\nC: Amazon RDS Proxy is designed to improve application scalability and resilience by pooling and reusing database connections. This can significantly reduce the number of connections each Lambda function has to establish","poster":"dilleman","upvote_count":"9","comment_id":"1040507","timestamp":"1712831160.0"},{"timestamp":"1732388160.0","poster":"65703c1","upvote_count":"1","comment_id":"1216759","content":"Selected Answer: C\\nC is the correct answer."},{"poster":"Digo30sp","comment_id":"1026666","upvote_count":"4","content":"Selected Answer: C\\nThe correct answer is (C).\\n\\nAmazon RDS Proxy is a solution that allows you to create a connection pool to manage database connections. This can help reduce the number of connections made to the database.","timestamp":"1712409960.0"},{"timestamp":"1712365860.0","comment_id":"1026126","poster":"fordiscussionstwo","content":"CCCCCCCCCCCCCCC","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:59:27.157Z","extraction_method":"api_direct_v1"},{"question_id":"905kfjqb7G8C5GgBbm5n","question_number":122,"page":25,"question_text":"A developer is preparing to begin development of a new version of an application. The previous version of the application is deployed in a production environment. The developer needs to deploy fixes and updates to the current version during the development of the new version of the application. The code for the new version of the application is stored in AWS CodeCommit.\\n\\nWhich solution will meet these requirements?","choices":{"A":"From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.","D":"Create a new CodeCommit repository for development of the new version of the application. Create a Git tag for the development of the new version.","C":"From the main branch, create a branch of the code that is currently deployed in production. Apply an IAM policy that ensures no other users can push or merge to the branch.","B":"Create a Git tag of the code that is currently deployed in production. Create a Git tag for the development of the new version. Push the two tags to the CodeCommit repository."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122630-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:11:00","unix_timestamp":1696554660,"discussion_count":5,"discussion":[{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732390080.0","upvote_count":"2","poster":"65703c1","comment_id":"1216822"},{"content":"Selected Answer: A\\nThe best option here is:\\n\\nA. From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.\\n\\nHere\u2019s why this solution is the most suitable:\\n\\nSeparation of Concerns: Creating separate branches for bug fixes and new feature development ensures that changes made for the current production version and the new version do not interfere with each other. This separation is crucial to avoid introducing new bugs into the production version from the development version.\\n\\nContinuous Integration and Delivery (CI/CD): This approach supports CI/CD practices. Bug fixes can be developed, tested, and merged into the main branch and deployed without impacting the ongoing development of the new version.","upvote_count":"2","timestamp":"1721730540.0","comment_id":"1129502","poster":"SerialiDr"},{"upvote_count":"3","comment_id":"1040510","content":"Selected Answer: A\\nA is a common code version control strategy","poster":"dilleman","timestamp":"1712831340.0"},{"content":"Selected Answer: A\\nA resposta correta \xe9 (A).\\n\\nCriar uma ramifica\xe7\xe3o de recursos para corre\xe7\xf5es de bugs de produ\xe7\xe3o e uma segunda ramifica\xe7\xe3o de recursos para desenvolvimento da nova vers\xe3o \xe9 a solu\xe7\xe3o que atender\xe1 a esses requisitos.\\n\\nA primeira ramifica\xe7\xe3o de recursos pode ser usada para corrigir bugs ou implementar atualiza\xe7\xf5es para a vers\xe3o atual do aplicativo. A segunda ramifica\xe7\xe3o de recursos pode ser usada para desenvolver a nova vers\xe3o do aplicativo.","timestamp":"1712409960.0","poster":"Digo30sp","upvote_count":"2","comment_id":"1026667"},{"timestamp":"1712365860.0","poster":"fordiscussionstwo","content":"AAAAAAAAAAAAAA","comment_id":"1026127","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:59:27.157Z","extraction_method":"api_direct_v1"},{"question_id":"B4ohBi9ruTsvdT8O8XGx","question_number":123,"page":25,"question_text":"A developer is creating an AWS CloudFormation stack. The stack contains IAM resources with custom names. When the developer tries to deploy the stack, they receive an InsufficientCapabilities error.\\n\\nWhat should the developer do to resolve this issue?","choices":{"C":"Specify the CAPABILITY_IAM capability in the CloudFormation stack.","A":"Specify the CAPABILITY_AUTO_EXPAND capability in the CloudFormation stack.","B":"Use an administrators role to deploy IAM resources with CloudFormation.","D":"Specify the CAPABILITY_NAMED_IAM capability in the CloudFormation stack."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122631-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:14:00","unix_timestamp":1696554840,"discussion_count":8,"discussion":[{"comment_id":"1026669","timestamp":"1696598880.0","content":"Selected Answer: D\\nThe correct answer is (D).\\n\\nTo deploy IAM resources with custom names, you must specify the CAPABILITY_NAMED_IAM resource in the CloudFormation stack.\\n\\nThe CAPABILITY_IAM resource allows CloudFormation to create and modify IAM resources. The CAPABILITY_NAMED_IAM resource allows CloudFormation to create IAM resources with custom names.\\n\\nTo resolve the issue, the developer must specify the CAPABILITY_NAMED_IAM resource in the CloudFormation stack.","poster":"Digo30sp","upvote_count":"9"},{"timestamp":"1697383860.0","comment_id":"1044272","content":"D.\\n If you have IAM resources with custom names, you must specify CAPABILITY_NAMED_IAM. See more details in this link https://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_CreateStack.html","upvote_count":"5","poster":"Learning4life"},{"content":"Selected Answer: D\\naws cloudformation create-stack \\\\\\n --stack-name my-iam-stack \\\\\\n --template-body file://my-template.yaml \\\\\\n --capabilities CAPABILITY_NAMED_IAM","poster":"albert_kuo","upvote_count":"1","timestamp":"1727504520.0","comment_id":"1290539"},{"comment_id":"1216824","timestamp":"1716485340.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"upvote_count":"2","poster":"SerialiDr","timestamp":"1709477400.0","comment_id":"1164860","content":"Selected Answer: D\\nThis capability is required when you are deploying IAM resources with custom names using CloudFormation, as it acknowledges that you\'re creating IAM resources that might affect permissions in your AWS environment."},{"timestamp":"1697020200.0","poster":"dilleman","comment_id":"1040514","content":"Selected Answer: D\\nD is correct","upvote_count":"3"},{"upvote_count":"1","content":"CCC\\nccccccc","timestamp":"1696602780.0","poster":"Patel_ajay745","comment_id":"1026717"},{"upvote_count":"3","timestamp":"1696554840.0","poster":"fordiscussionstwo","content":"DDDDDDDDDD","comment_id":"1026129"}],"answer_description":"","extracted_at":"2025-12-24T08:59:27.157Z","extraction_method":"api_direct_v1"},{"question_id":"gLV5g4tNwTqsshTnNlWT","question_number":124,"page":25,"question_text":"A developer maintains an Amazon API Gateway REST API. Customers use the API through a frontend UI and Amazon Cognito authentication.\\nThe developer has a new version of the API that contains new endpoints and backward-incompatible interface changes. The developer needs to provide beta access to other developers on the team without affecting customers.\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Specify new API Gateway endpoints for the API endpoints that the developer wants to add.","C":"Implement a query parameter in the API application code that determines which code version to call.","A":"Define a development stage on the API Gateway API. Instruct the other developers to point the endpoints to the development stage.","B":"Define a new API Gateway API that points to the new API application code. Instruct the other developers to point the endpoints to the new API."},"correct_answer":"A","answer_ET":"A","answers_community":["A (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102899-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-17 09:46:00","unix_timestamp":1679042760,"discussion_count":19,"discussion":[{"upvote_count":"14","timestamp":"1683379740.0","poster":"Bibay","content":"Selected Answer: A\\nOption A is the correct solution to meet the requirements with the least operational overhead.\\n\\nDefining a development stage on the API Gateway API enables other developers to test the new version of the API without affecting the production environment. This approach allows the developers to work on the new version of the API independently and avoid conflicts with the production environment.\\n\\nThe other options involve creating a new API or new endpoints, which could introduce additional operational overhead, such as managing multiple APIs or endpoints, configuring access control, and updating the frontend UI to point to the new endpoints or API. Option C also introduces additional complexity by requiring the implementation of a query parameter to determine which code version to call.","comment_id":"890763","comments":[{"timestamp":"1717857780.0","poster":"beekeeper0101","content":"Thank you!","comment_id":"1226779","upvote_count":"1"}]},{"upvote_count":"1","poster":"dangtunguyen","comment_id":"1572410","content":"Selected Answer: A\\nA is correct. DEV/SIT/QA/STG/PT are shared env before release to PROD","timestamp":"1748255640.0"},{"content":"Selected Answer: A\\nA) Correct - The developer can deploy the new version of the API to a development stage while keeping the existing API in the production stage for customers. Beta users (team developers) can use the unique URL of the development stage to access the new API version.\\n\\nB) Eliminated - This involves duplicating the API Gateway setup and potentially managing additional resources\\n\\nC) Eliminated - This requires modifying the application logic, which increases the development effort and complexity. - Add complexity and operational overhead.\\n\\nD) Eliminated - The goal is to let beta users test the new API without affecting existing customers. Mixing endpoints in the same API Gateway does not provide a clean separation, which increases the risk of customer impact.","poster":"sumanshu","upvote_count":"3","comment_id":"1329931","timestamp":"1734778080.0"},{"timestamp":"1734093240.0","content":"Selected Answer: A\\nkeyword: LEAST operational overhead, backward-incompatible, beta access to other developers on the team without affecting customers.(separate)\\n\\n==> Discard B: take effort to operation and maintain many API gateway instances\\n==> Discard C: It is not separate API production and beta, make effort to understand, transfer, or fixing something when misunderstading. Violate backward-incompitable, when new version can also use old endpoint version 100% (just adding, not delete or modify)\\n==> Discard D: like a bit with C, mixing 2 environment prod and beta,","upvote_count":"1","comment_id":"1326114","poster":"trieudo"},{"poster":"AnthonyTL","upvote_count":"1","comment_id":"1284118","content":"A is correct as the Q asked for \'with the LEAST operational overhead\'\\nC got less operation than B but more than A","timestamp":"1726404660.0"},{"timestamp":"1722511140.0","content":"Selected Answer: A\\nIt is A you chutiyas","upvote_count":"1","comment_id":"1259327","poster":"ACurryDeveloper"},{"upvote_count":"2","timestamp":"1721754780.0","poster":"ahadh7621","content":"This question was on my exam July 23rd, 2024. Answer is A","comment_id":"1253809"},{"content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","comment_id":"1215023","timestamp":"1716301500.0","poster":"65703c1"},{"content":"Selected Answer: B\\nB ra unga amma","timestamp":"1711536660.0","upvote_count":"1","comment_id":"1184009","poster":"mghectorenjoyer69"},{"comment_id":"1175171","content":"Selected Answer: A\\nThe correct answer is A (development stage).\\nYou can configure a development stage for your API Gateway API and then integrate it with the new version of the backend functionality that has new endpoints and backward-incompatible interface changes. The customers can continue to use the existing API.","timestamp":"1710611760.0","poster":"HayLLlHuK","upvote_count":"1"},{"upvote_count":"2","comment_id":"1170490","poster":"41eb566","content":"Selected Answer: B\\nThe option that meets the requirements with the least operational overhead is:\\n\\nB. Define a new API Gateway API that points to the new API application code. Instruct the other developers to point the endpoints to the new API.\\n\\nHere\'s why:\\n\\nA. Defining a development stage on the existing API Gateway API could potentially affect customers if not managed properly. It might introduce changes or issues to the existing API that customers are using.\\n\\nC. Implementing a query parameter in the API application code to determine the code version introduces complexity and potential risk, as it requires changes to the application code itself. It also doesn\'t isolate the beta access from the main API.\\n\\nD. Specifying new API Gateway endpoints for the new API endpoints adds complexity and overhead. It requires managing multiple endpoints, potentially affecting the API\'s simplicity and increasing maintenance overhead.","timestamp":"1710092220.0"},{"upvote_count":"1","poster":"hungnv6_rikkei","comment_id":"1142959","content":"A is answer","timestamp":"1707282180.0"},{"poster":"Alearn","comment_id":"1104025","timestamp":"1703336460.0","content":"Selected Answer: B\\nLEAST operational overhead would be B.","upvote_count":"2"},{"upvote_count":"2","timestamp":"1700094480.0","poster":"leonardoliveros","content":"Selected Answer: A\\nThe stages gives the capacity to tests a new version in an APIg without affecting customers in others stages","comment_id":"1072045"},{"timestamp":"1693742940.0","upvote_count":"3","poster":"Tony88","comment_id":"997589","content":"Selected Answer: A\\nThe best practice is to define a development stage."},{"poster":"jayvarma","content":"Option A is the right answer. Defining a development stage on the API Gateway API would provide other developers with a way to test the newer version of the API without affecting prod.\\n\\nThe rest of the options would create a lot of operational overhead.","comment_id":"977021","timestamp":"1691614200.0","upvote_count":"1"},{"poster":"MrTee","upvote_count":"1","comment_id":"879814","timestamp":"1682386320.0","content":"Selected Answer: A\\nThe developer should define a development stage on the API Gateway API. They should then instruct the other developers to point the endpoints to the development stage. This solution will meet the requirements with the least operational overhead"},{"content":"Selected Answer: A\\nA\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-stages.html\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html","comment_id":"845955","poster":"Untamables","timestamp":"1679403060.0","upvote_count":"3"},{"poster":"aragon_saa","comment_id":"841802","timestamp":"1679042760.0","content":"A\\nhttps://www.examtopics.com/discussions/amazon/view/88872-exam-aws-certified-developer-associate-topic-1-question-318/","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T08:59:27.157Z","extraction_method":"api_direct_v1"},{"question_id":"KynxpeDlAvHZ2ZjsbXJg","question_number":125,"page":25,"question_text":"A company uses Amazon API Gateway to expose a set of APIs to customers. The APIs have caching enabled in API Gateway. Customers need a way to invalidate the cache for each API when they test the API.\\n\\nWhat should a developer do to give customers the ability to invalidate the API cache?","choices":{"D":"Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to add the INVALIDATE_CACHE query string parameter when they make an API call.","B":"Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.","A":"Ask the customers to use AWS credentials to call the InvalidateCache API operation.","C":"Ask the customers to use the AWS SDK API Gateway class to invoke the InvalidateCache API operation."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/122632-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-06 03:14:00","unix_timestamp":1696554840,"discussion_count":8,"discussion":[{"upvote_count":"8","comment_id":"1026671","content":"Selected Answer: B\\nB) https://www.examtopics.com/discussions/amazon/view/4166-exam-aws-certified-developer-associate-topic-1-question-69/","poster":"Digo30sp","timestamp":"1712410140.0"},{"poster":"65703c1","comment_id":"1216829","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732390260.0","upvote_count":"1"},{"poster":"KarBiswa","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html#:~:text=A%20client%20of,the%20integration%20endpoint.","comment_id":"1164540","upvote_count":"2","timestamp":"1725337560.0"},{"poster":"KillThemWithKindness","timestamp":"1724434260.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","upvote_count":"3","comment_id":"1157431"},{"content":"invalidate an API Gateway cache entry\\nA client of your API can invalidate an existing cache entry and reload it from the integration endpoint for individual requests. The client must send a request that contains the Cache-Control: max-age=0 header. The client receives the response directly from the integration endpoint instead of the cache, provided that the client is authorized to do so. This replaces the existing cache entry with the new response, which is fetched from the integration endpoint. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","poster":"Mimi666","comment_id":"1088152","upvote_count":"2","timestamp":"1717548000.0"},{"content":"Seems to be B but policies/roles have nothing to do with cache","poster":"dezoito","timestamp":"1713538320.0","upvote_count":"1","comment_id":"1048042"},{"content":"it is DDDDDD","comment_id":"1026716","timestamp":"1712413980.0","comments":[{"poster":"fordiscussionstwo","comment_id":"1028121","content":"why? because chatGPDUMP said that? all your anwers are wrong.","timestamp":"1712591220.0","upvote_count":"8"}],"upvote_count":"1","poster":"Patel_ajay745"},{"content":"BBBBBBBBBBBBBB","poster":"fordiscussionstwo","timestamp":"1712366040.0","comment_id":"1026130","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:59:27.157Z","extraction_method":"api_direct_v1"},{"question_id":"fAkOGJBFM1twEgK43VK4","question_number":126,"page":26,"question_text":"A developer is creating an AWS Lambda function that will generate and export a file. The function requires 100 MB of temporary storage for temporary files while running. These files will not be needed after the function is complete.\\n\\nHow can the developer MOST efficiently handle the temporary files?","choices":{"B":"Copy the files to Amazon Elastic File System (Amazon EFS) and delete the files at the end of the Lambda function.","C":"Store the files in the /tmp directory and delete the files at the end of the Lambda function.","A":"Store the files in Amazon Elastic Block Store (Amazon EBS) and delete the files at the end of the Lambda function.","D":"Copy the files to an Amazon S3 bucket with a lifecycle policy to delete the files."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124750-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-27 21:55:00","unix_timestamp":1698436500,"discussion_count":8,"discussion":[{"comment_id":"1231715","content":"This appear at 17 Jun exam","upvote_count":"1","poster":"tsangckl","timestamp":"1718598180.0"},{"content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716486240.0","upvote_count":"2","comment_id":"1216867"},{"poster":"RPRAMSUBU","comment_id":"1141903","content":"C is the correct answer","timestamp":"1707205800.0","upvote_count":"2"},{"poster":"SerialiDr","content":"Selected Answer: C\\nThis is the most efficient and straightforward option. AWS Lambda provides a /tmp directory in its execution environment with a storage limit of 512 MB. This space can be used for temporary storage during the function execution. Since the requirement is 100 MB, it falls well within the limits of the /tmp directory.","upvote_count":"3","timestamp":"1706022480.0","comment_id":"1129708"},{"poster":"JohnPl","upvote_count":"1","timestamp":"1704960900.0","comment_id":"1119495","content":"Selected Answer: C\\nC is the correct answer"},{"comment_id":"1091465","content":"Starting March 2022, Lambda now supports increasing /tmp directory\'s maximum size limit up to 10,240MB. More information available. \\nhttps://aws.amazon.com/blogs/aws/aws-lambda-now-supports-up-to-10-gb-ephemeral-storage/","upvote_count":"4","poster":"sankhagg","timestamp":"1702099500.0"},{"comment_id":"1055940","upvote_count":"3","content":"C. Store the files in the /tmp directory and delete the files at the end of the Lambda function.\\nThe /tmp directory is a dedicated temporary storage location provided by AWS Lambda for storing temporary files during the execution of the function.\\n\\nIt\'s cost-effective and efficient because it doesn\'t involve additional AWS services or storage costs.\\n\\nAWS Lambda automatically manages the /tmp directory for you, including clearing its contents after the function execution is complete. You don\'t need to explicitly delete the files; Lambda takes care of it.","poster":"Claire_KMT","timestamp":"1698458040.0"},{"content":"Selected Answer: C\\nOption C is the best choice for efficient handling of temporary files within an AWS Lambda function.","poster":"LemonGremlin","comment_id":"1055808","timestamp":"1698436500.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T08:59:38.161Z","extraction_method":"api_direct_v1"},{"question_id":"GrlviUALYksrGNWmhPPP","question_number":127,"page":26,"question_text":"A company uses Amazon DynamoDB as a data store for its order management system. The company frontend application stores orders in a DynamoDB table. The DynamoDB table is configured to send change events to a DynamoDB stream. The company uses an AWS Lambda function to log and process the incoming orders based on data from the DynamoDB stream.\\n\\nAn operational review reveals that the order quantity of incoming orders is sometimes set to 0. A developer needs to create a dashboard that will show how many unique customers this problem affects each day.\\n\\nWhat should the developer do to implement the dashboard?","choices":{"D":"Turn on custom Amazon CloudWatch metrics for the DynamoDB stream of the DynamoDB table. Create a CloudWatch alarm that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add the CloudWatch alarm to a CloudWatch dashboard.","C":"Configure the Lambda function to send events to Amazon EventBridge. Create an EventBridge rule that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add a CloudWatch dashboard as the target of the rule.","B":"Use Amazon Athena to query AWS CloudTrail API logs for API calls. Implement an Athena query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the Athena query to an Amazon CloudWatch dashboard.","A":"Grant the Lambda function\u2019s execution role permissions to upload logs to Amazon CloudWatch Logs. Implement a CloudWatch Logs Insights query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the CloudWatch Logs Insights query to a CloudWatch dashboard."},"correct_answer":"A","answer_ET":"A","answers_community":["A (81%)","D (19%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124765-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 03:55:00","unix_timestamp":1698458100,"discussion_count":10,"discussion":[{"content":"A. Grant the Lambda function\u2019s execution role permissions to upload logs to Amazon CloudWatch Logs. Implement a CloudWatch Logs Insights query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the CloudWatch Logs Insights query to a CloudWatch dashboard.\\n\\nHere\'s why this option is the best choice:\\n\\nCloudWatch Logs Insights is designed for querying and analyzing log data, making it well-suited for this task.\\n\\nBy configuring the Lambda function\'s execution role to upload logs to CloudWatch Logs, you ensure that the log data is available for analysis.\\n\\nYou can use a CloudWatch Logs Insights query to identify unique customers for orders with a quantity of 0 and group the results by day, providing the desired daily count of affected customers.\\n\\nThe results of the query can be added to a CloudWatch dashboard, making it easily accessible for monitoring.","timestamp":"1698458100.0","poster":"Claire_KMT","upvote_count":"5","comment_id":"1055941"},{"comment_id":"1139056","timestamp":"1706944860.0","content":"Selected Answer: A\\nD is invalid. There are no such custom metrics:\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/metrics-dimensions.html\\n\\nA is the right choice","poster":"konieczny69","upvote_count":"5"},{"timestamp":"1730476620.0","content":"Selected Answer: A\\nI am with A","poster":"Saudis","upvote_count":"1","comment_id":"1305909"},{"poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","comment_id":"1216874","timestamp":"1716486480.0"},{"content":"Selected Answer: A\\nThis approach involves enhancing the existing Lambda function to log relevant information about orders (especially those with order quantity 0) to CloudWatch Logs. The developer can then use CloudWatch Logs Insights to query these logs for unique customer counts and visualize this data on a CloudWatch dashboard. This solution is feasible and effective, as it leverages the existing Lambda function and CloudWatch capabilities.","timestamp":"1706090340.0","comment_id":"1130472","poster":"SerialiDr","upvote_count":"2"},{"content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/96212-exam-aws-certified-developer-associate-topic-1-question-402/","comment_id":"1098098","upvote_count":"2","timestamp":"1702724940.0","poster":"Certified101"},{"content":"Selected Answer: D\\nChoose D\\nOption A is more suitable for log analysis, but in this case, the issue is related to DynamoDB data, and CloudWatch Logs may not be the most efficient way to track it.","upvote_count":"1","comment_id":"1096473","poster":"TanTran04","timestamp":"1702558620.0"},{"timestamp":"1700948940.0","upvote_count":"2","content":"Selected Answer: A\\nI choose A","comment_id":"1080353","poster":"chris_777"},{"comment_id":"1072834","content":"https://www.examtopics.com/discussions/amazon/view/96212-exam-aws-certified-developer-associate-topic-1-question-402/","timestamp":"1700171520.0","upvote_count":"3","poster":"bhanupriya07"},{"upvote_count":"2","timestamp":"1698820620.0","content":"Selected Answer: D\\nOption A suggests using CloudWatch Logs Insights, which is typically used for analyzing log data. However, in this scenario, the issue is related to metrics (order quantity), and using CloudWatch Metrics and Alarms is a more suitable approach.\\n\\nI\'d go with option D. It seems like a more direct and efficient approach. By using custom CloudWatch metrics for the DynamoDB stream, you can specifically track the relevant data without the need for additional CloudWatch Logs Insights queries. The alarm will then allow you to easily visualize and monitor the number of unique customers affected by the issue each day on the CloudWatch dashboard.","comment_id":"1059403","poster":"PrakashM14"}],"answer_description":"","extracted_at":"2025-12-24T08:59:38.161Z","extraction_method":"api_direct_v1"},{"question_id":"nx8WAfnYiW9xE5t4TfcQ","question_number":128,"page":26,"question_text":"A developer needs to troubleshoot an AWS Lambda function in a development environment. The Lambda function is configured in VPC mode and needs to connect to an existing Amazon RDS for SQL Server DB instance. The DB instance is deployed in a private subnet and accepts connections by using port 1433.\\n\\nWhen the developer tests the function, the function reports an error when it tries to connect to the database.\\n\\nWhich combination of steps should the developer take to diagnose this issue? (Choose two.)","choices":{"A":"Check that the function\u2019s security group has outbound access on port 1433 to the DB instance\u2019s security group. Check that the DB instance\u2019s security group has inbound access on port 1433 from the function\u2019s security group.","D":"Check that the function\u2019s execution role permissions include rds:DescribeDBInstances, rds:ModifyDBInstance. and rds:DescribeDBSecurityGroups for the DB instance.","E":"Check that the function\u2019s execution role permissions include ec2:CreateNetworkInterface, ec2:DescribeNetworkInterfaces, and ec2:DeleteNetworkInterface.","B":"Check that the function\u2019s security group has inbound access on port 1433 from the DB instance\u2019s security group. Check that the DB instance\u2019s security group has outbound access on port 1433 to the function\u2019s security group.","C":"Check that the VPC is set up for a NAT gateway. Check that the DB instance has the public access option turned on."},"correct_answer":"AE","answer_ET":"AE","answers_community":["AE (71%)","AD (25%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124780-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:48:00","unix_timestamp":1698475680,"discussion_count":13,"discussion":[{"poster":"kaes","timestamp":"1716721140.0","content":"Selected Answer: AE\\n- A: The function needs outbound access to DB and the DB needs to allow inbound access from the function\\n- E: The function needs AWSLambdaVPCAccessExecutionRole role to work correctly in the VPC (https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-permissions)\\n\\nD is incorrect as the function\u2019s execution role does not need to make any of those DB actions: Describe Modify and DescribeDB security groups!","upvote_count":"11","comment_id":"1080645"},{"timestamp":"1714323180.0","content":"I believe It\'s A and D. Unsure on A, but D seems to be confirmed by this link: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/lambda-rds-connect.html","poster":"mitch151","upvote_count":"8","comment_id":"1056339"},{"comment_id":"1216879","poster":"65703c1","timestamp":"1732391640.0","content":"Selected Answer: AE\\nAE is the correct answer.","upvote_count":"1"},{"content":"Selected Answer: AE\\nA. Check that the function\u2019s security group has outbound access on port 1433 to the DB instance\u2019s security group. Ensure that the DB instance\u2019s security group has inbound access on port 1433 from the function\u2019s security group. This setup allows the Lambda function to initiate a connection to the DB instance through the specified port.\\n\\nE. Check that the function\u2019s execution role permissions include ec2:CreateNetworkInterface, ec2:DescribeNetworkInterfaces, and ec2:DeleteNetworkInterface. These permissions are necessary for the Lambda function to create, manage, and clean up the network interfaces that allow it to connect to resources within a VPC, including the RDS instance.","poster":"SerialiDr","comment_id":"1164900","upvote_count":"2","timestamp":"1725371580.0"},{"comment_id":"1164547","content":"Selected Answer: AE\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-permissions","timestamp":"1725338820.0","poster":"KarBiswa","upvote_count":"1"},{"upvote_count":"1","poster":"konieczny69","timestamp":"1722662640.0","content":"Selected Answer: AE\\nAE\\n\\nThis is a network issue, not a governance issue, hence D is invalid.\\nBetween A and B its an obvious choice.\\nC is invalid - DB is in a private subnet","comment_id":"1139058"},{"timestamp":"1721593740.0","comment_id":"1128218","content":"ChatGPT goes with A and D","upvote_count":"1","poster":"_YaWeb"},{"comment_id":"1116295","content":"Selected Answer: AB\\ninbound and outbound connection between Lambda and the RDS should be set properly.","timestamp":"1720393380.0","poster":"Snape","upvote_count":"1"},{"upvote_count":"2","comment_id":"1111346","poster":"rrshah83","timestamp":"1719844320.0","content":"Selected Answer: AE\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-permissions"},{"comment_id":"1098101","content":"Selected Answer: AE\\nAgree with Kaes \\n\\n- A: The function needs outbound access to DB and the DB needs to allow inbound access from the function\\n- E: The function needs AWSLambdaVPCAccessExecutionRole role to work correctly in the VPC (https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-permissions)\\n\\nD is incorrect as the function\u2019s execution role does not need to make any of those DB actions: Describe Modify and DescribeDB security groups!","timestamp":"1718529180.0","comments":[{"comment_id":"1139761","upvote_count":"1","poster":"joshnort","content":"This is excellent. Thanks for the link. Makes it very clear.","timestamp":"1722737100.0"}],"upvote_count":"2","poster":"Certified101"},{"comment_id":"1097042","poster":"TanTran04","timestamp":"1718419680.0","content":"Selected Answer: AD\\nWe need connection between lambda and RDS, not to VPC. So, option E is unsuitable. We can choose the related remain option like D\\nAbout option A, it\'s already correct.","upvote_count":"2"},{"timestamp":"1714346820.0","upvote_count":"5","content":"Selected Answer: AD\\nA and D","poster":"Jing2023","comment_id":"1056514"},{"upvote_count":"1","comment_id":"1056017","poster":"Claire_KMT","timestamp":"1714286880.0","content":"A and B"}],"answer_description":"","extracted_at":"2025-12-24T08:59:38.161Z","extraction_method":"api_direct_v1"},{"question_id":"mRvpH5p0Bydv6DVgre9L","question_number":129,"page":26,"question_text":"A developer needs to launch a new Amazon EC2 instance by using the AWS CLI.\\n\\nWhich AWS CLI command should the developer use to meet this requirement?","choices":{"B":"aws ec2 start-instances","D":"aws ec2 run-instances","C":"aws ec2 confirm-product-instance","A":"aws ec2 bundle-instance"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124777-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:46:00","unix_timestamp":1698475560,"discussion_count":4,"discussion":[{"comment_id":"1056012","upvote_count":"8","timestamp":"1698475560.0","poster":"Claire_KMT","content":"D. aws ec2 run-instances\\n\\nSo, to create a new EC2 instance using the AWS CLI, you would typically use the aws ec2 run-instances command, providing the necessary parameters such as the AMI ID, instance type, security groups, and key pair, among others."},{"upvote_count":"7","content":"Selected Answer: D\\nD. aws ec2 run-instances\\n\\nNote: B aws ec2 start-instances is used to \\"start an instance that you\'ve previously stopped\\"","timestamp":"1700951700.0","poster":"chris_777","comment_id":"1080378"},{"timestamp":"1727588760.0","upvote_count":"1","content":"Selected Answer: D\\naws ec2 run-instances \\\\\\n --image-id ami-xxxxxxxx \\\\\\n --count 1 \\\\\\n --instance-type t2.micro \\\\\\n --key-name MyKeyPair \\\\\\n --security-group-ids sg-xxxxxxxx \\\\\\n --subnet-id subnet-xxxxxxxx","poster":"albert_kuo","comment_id":"1290939"},{"comment_id":"1216883","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","timestamp":"1716486960.0","poster":"65703c1"}],"answer_description":"","extracted_at":"2025-12-24T08:59:38.161Z","extraction_method":"api_direct_v1"},{"question_id":"Kfeur8fD1P7MC2rYhIDE","question_number":130,"page":26,"question_text":"A developer needs to manage AWS infrastructure as code and must be able to deploy multiple identical copies of the infrastructure, stage changes, and revert to previous versions.\\n\\nWhich approach addresses these requirements?","choices":{"B":"Use Amazon CloudWatch metrics and alerts along with resource tagging to deploy and manage the infrastructure.","A":"Use cost allocation reports and AWS OpsWorks to deploy and manage the infrastructure.","D":"Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.","C":"Use AWS Elastic Beanstalk and AWS CodeCommit to deploy and manage the infrastructure."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124776-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:45:00","unix_timestamp":1698475500,"discussion_count":5,"discussion":[{"comment_id":"1056512","content":"Selected Answer: D\\nthis is the only option mentioning infra as code.","timestamp":"1698539100.0","upvote_count":"7","poster":"Jing2023"},{"poster":"Claire_KMT","timestamp":"1698475500.0","content":"D. Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.\\n\\nHere\'s why this is the most appropriate choice:\\n\\nAWS CloudFormation: It allows you to define your infrastructure as code using templates, which can be version-controlled. You can create, update, and delete stacks of AWS resources in a controlled and predictable manner. This aligns with the requirement to deploy multiple identical copies of the infrastructure, stage changes, and revert to previous versions.\\n\\nAWS CodeCommit: It provides a fully managed source control service, allowing you to store and version-control your CloudFormation templates. This ensures that you can manage and track changes to your infrastructure configurations.","comment_id":"1056011","upvote_count":"7"},{"upvote_count":"1","poster":"Saudis","comment_id":"1305916","timestamp":"1730477700.0","content":"Selected Answer: D\\nCloudFormation Iac"},{"content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716487020.0","poster":"65703c1","comment_id":"1216887","upvote_count":"1"},{"comment_id":"1130970","poster":"SerialiDr","timestamp":"1706119860.0","content":"Selected Answer: D\\nHere\'s why this option is the most suitable:\\n\\nAWS CloudFormation: This service allows you to model your entire infrastructure in a text file (either JSON or YAML). This infrastructure as code approach enables you to create and manage AWS resources efficiently, consistently, and repeatably. It\'s ideal for deploying multiple identical copies of the same infrastructure (like staging, production environments), and the text file can be version-controlled, allowing you to stage changes and revert to previous versions.\\n\\nAWS CodeCommit: This is a managed source control service that hosts private Git repositories. Integrating AWS CodeCommit with CloudFormation enables version control of your infrastructure templates. This supports staging changes and reverting to previous versions, enhancing collaboration among team members.","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T08:59:38.161Z","extraction_method":"api_direct_v1"},{"question_id":"TB6kuvajDLQVOtquXNNM","question_number":131,"page":27,"question_text":"A developer is working on an AWS Lambda function that accesses Amazon DynamoDB. The Lambda function must retrieve an item and update some of its attributes, or create the item if it does not exist. The Lambda function has access to the primary key.\\n\\nWhich IAM permissions should the developer request for the Lambda function to achieve this functionality?","choices":{"D":"dynamodb:UpdateItem\\ndynamodb:GetItem\\ndynamodb:PutItem","A":"dynamodb:DeleleItem\\ndynamodb:GetItem\\ndynamodb:PutItem","C":"dynamodb:GetRecords\\ndynamodb:PutItem\\ndynamodb:UpdateTable","B":"dynamodb:UpdateItem\\ndynamodb:GetItem\\ndynamodb:DescribeTable"},"correct_answer":"D","answer_ET":"D","answers_community":["D (91%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124769-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:32:00","unix_timestamp":1698474720,"discussion_count":6,"discussion":[{"comment_id":"1056018","timestamp":"1714287000.0","poster":"Claire_KMT","content":"D. dynamodb:UpdateItem, dynamodb:GetItem, and dynamodb:PutItem\\n\\nHere\'s why:\\n\\ndynamodb:GetItem: This permission allows the Lambda function to retrieve an item from DynamoDB.\\n\\ndynamodb:UpdateItem: This permission allows the Lambda function to update the attributes of an item in DynamoDB.\\n\\ndynamodb:PutItem: This permission allows the Lambda function to create a new item if it doesn\'t already exist in the DynamoDB table.","upvote_count":"8"},{"upvote_count":"2","comment_id":"1216889","poster":"65703c1","timestamp":"1732391880.0","content":"Selected Answer: D\\nD is the correct answer."},{"comment_id":"1116297","poster":"Snape","content":"Selected Answer: D\\nD is correct","timestamp":"1720393620.0","upvote_count":"2"},{"timestamp":"1719844980.0","poster":"rrshah83","upvote_count":"1","content":"Selected Answer: B\\nx A: as delete is not required. Plus Put item is not required, update lets you create a new item if it doesn\'t already exist\\n B: meets requirements. DescribeTable helps provide a list of attributes that can be used to update.\\nx C: put not required; getrecords does not exist\\nx D: put not required.","comment_id":"1111352"},{"timestamp":"1718420340.0","poster":"TanTran04","content":"Selected Answer: D\\nUpdateItem: Edits an existing item\'s attributes\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html\\nGetItem: retrieves attributes from the Thread table\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html#API_GetItem_Examples\\nPutItem: Creates a new item, or replaces an old item with a new item.\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html","comment_id":"1097047","upvote_count":"2"},{"comment_id":"1055999","content":"Selected Answer: D\\nPutItem is to CREATE new item or replace old item with new item\\nGetItem is to retrieve an item\\nUpdateItem so to update the attributes \\n\\nHence answer D","upvote_count":"4","timestamp":"1714285920.0","poster":"didorins"}],"answer_description":"","extracted_at":"2025-12-24T08:59:49.193Z","extraction_method":"api_direct_v1"},{"question_id":"rU9vIt7wyWNGyYJUmon0","question_number":132,"page":27,"question_text":"A developer has built a market application that stores pricing data in Amazon DynamoDB with Amazon ElastiCache in front. The prices of items in the market change frequently. Sellers have begun complaining that, after they update the price of an item, the price does not actually change in the product listing.\\n\\nWhat could be causing this issue?","choices":{"A":"The cache is not being invalidated when the price of the item is changed.","C":"The DynamoDB table was provisioned with insufficient read capacity.","B":"The price of the item is being retrieved using a write-through ElastiCache cluster.","D":"The DynamoDB table was provisioned with insufficient write capacity."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124781-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:53:00","unix_timestamp":1698475980,"discussion_count":4,"discussion":[{"comment_id":"1216891","poster":"65703c1","upvote_count":"1","timestamp":"1732391940.0","content":"Selected Answer: A\\nA is the correct answer."},{"poster":"Certified101","content":"Selected Answer: A\\nA is correct","timestamp":"1718529420.0","upvote_count":"3","comment_id":"1098103"},{"comment_id":"1080648","timestamp":"1716721440.0","content":"Selected Answer: A\\nANS: A\\nThe cache needs to be invalidated. The write-through approach could be helpful here","upvote_count":"4","poster":"kaes"},{"upvote_count":"4","poster":"Claire_KMT","comment_id":"1056019","content":"A. The cache is not being invalidated when the price of the item is changed.\\n\\nIn a caching setup using Amazon ElastiCache in front of Amazon DynamoDB, if the cache is not being invalidated or updated when data in DynamoDB is changed, it can result in stale data being served from the cache, leading to the observed behavior.\\n\\nTo resolve this issue, you should implement a mechanism to invalidate or update the cache whenever the price of an item is changed in DynamoDB to ensure that the most up-to-date data is retrieved from the cache or DynamoDB.","timestamp":"1714287180.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:49.193Z","extraction_method":"api_direct_v1"},{"question_id":"nmcJAD0cUCPXuEajmZLO","question_number":133,"page":27,"question_text":"A company requires that all applications running on Amazon EC2 use IAM roles to gain access to AWS services. A developer is modifying an application that currently relies on IAM user access keys stored in environment variables to access Amazon DynamoDB tables using boto, the AWS SDK for Python.\\n\\nThe developer associated a role with the same permissions as the IAM user to the EC2 instance, then deleted the IAM user. When the application was restarted, the AWS AccessDeniedException messages started appearing in the application logs. The developer was able to use their personal account on the server to run DynamoDB API commands using the AWS CLI.\\n\\nWhat is the MOST likely cause of the exception?","choices":{"B":"Disabled environment variable credentials are still being used by the application.","A":"IAM policies might take a few minutes to propagate to resources.","C":"The AWS SDK does not support credentials obtained using an instance role.","D":"The instance\u2019s security group does not allow access to http://169.254.169.254."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124770-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:34:00","unix_timestamp":1698474840,"discussion_count":4,"discussion":[{"upvote_count":"6","content":"Selected Answer: B\\nB is the only viable answer.","timestamp":"1698474840.0","poster":"didorins","comment_id":"1056000"},{"timestamp":"1724848380.0","comment_id":"1274046","content":"Selected Answer: B\\nB is the only one that make sense, although more steps would be needed then just configuring the app.","poster":"wh1t4k3r","upvote_count":"2"},{"timestamp":"1716487260.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1216892"},{"content":"B. Disabled environment variable credentials are still being used by the application.","upvote_count":"3","comment_id":"1056021","poster":"Claire_KMT","timestamp":"1698476220.0"}],"answer_description":"","extracted_at":"2025-12-24T08:59:49.193Z","extraction_method":"api_direct_v1"},{"question_id":"hc7VXUZu3kpjkCQuJsAq","question_number":134,"page":27,"question_text":"A company has an existing application that has hardcoded database credentials. A developer needs to modify the existing application. The application is deployed in two AWS Regions with an active-passive failover configuration to meet company\u2019s disaster recovery strategy.\\n\\nThe developer needs a solution to store the credentials outside the code. The solution must comply with the company\u2019s disaster recovery strategy.\\n\\nWhich solution will meet these requirements in the MOST secure way?","choices":{"B":"Store credentials in AWS Systems Manager Parameter Store in the primary Region. Enable parameter replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.","A":"Store the credentials in AWS Secrets Manager in the primary Region. Enable secret replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.","D":"Store credentials in a config file. Upload the config file to an Amazon Elastic File System (Amazon EFS) file system. Update the application to use the Amazon EFS file system Regional endpoints to access the config file in the primary and secondary Regions.","C":"Store credentials in a config file. Upload the config file to an S3 bucket in the primary Region. Enable Cross-Region Replication (CRR) to an S3 bucket in the secondary region. Update the application to access the config file from the S3 bucket, based on the Region."},"correct_answer":"A","answer_ET":"A","answers_community":["A (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124771-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:35:00","unix_timestamp":1698474900,"discussion_count":4,"discussion":[{"poster":"didorins","upvote_count":"10","comment_id":"1056001","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create-manage-multi-region-secrets.html","timestamp":"1714286100.0"},{"content":"Selected Answer: A\\nMust be A. The Secret Manager supports region replication out-of-the-box in contrast to the Paramter Store which doesn\'t support it.","upvote_count":"5","comment_id":"1080659","timestamp":"1716722100.0","poster":"kaes"},{"content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732392180.0","comment_id":"1216894","upvote_count":"1","poster":"65703c1"},{"poster":"Claire_KMT","timestamp":"1714287720.0","comment_id":"1056025","upvote_count":"3","content":"B. Store credentials in AWS Systems Manager Parameter Store in the primary Region. Enable parameter replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region."}],"answer_description":"","extracted_at":"2025-12-24T08:59:49.193Z","extraction_method":"api_direct_v1"},{"question_id":"Fd5ff0e5gY0ADxdTrOBh","question_number":135,"page":27,"question_text":"A developer is creating an application that will store personal health information (PHI). The PHI needs to be encrypted at all times. An encrypted Amazon RDS for MySQL DB instance is storing the data. The developer wants to increase the performance of the application by caching frequently accessed data while adding the ability to sort or rank the cached datasets.\\nWhich solution will meet these requirements?","choices":{"B":"Create an Amazon ElastiCache for Memcached instance. Enable encryption of data in transit and at rest. Store frequently accessed data in the cache.","D":"Create an Amazon DynamoDB table and a DynamoDB Accelerator (DAX) cluster for the table. Store frequently accessed data in the DynamoDB table.","A":"Create an Amazon ElastiCache for Redis instance. Enable encryption of data in transit and at rest. Store frequently accessed data in the cache.","C":"Create an Amazon RDS for MySQL read replica. Connect to the read replica by using SSL. Configure the read replica to store frequently accessed data."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103644-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 07:44:00","unix_timestamp":1679553840,"discussion_count":13,"discussion":[{"comment_id":"847880","timestamp":"1679553840.0","comments":[{"upvote_count":"4","timestamp":"1691130480.0","comment_id":"971726","content":"in sum,\\nREDIS featured encryption, PCI-DSS\\nMemCache support AutoDiscovery","poster":"jipark","comments":[{"upvote_count":"2","poster":"AnthonyTL","content":"Both supported encryption, but MemCache doesn\'t support \'sort or rank\'","timestamp":"1726405980.0","comment_id":"1284136"}]}],"upvote_count":"17","content":"Selected Answer: A\\nA\\nYou can use Amazon Elasticache for Redis Sorted Sets to easily implement a dashboard that keeps a list of sorted data by their rank.\\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/elasticache-use-cases.html#elasticache-for-redis-use-cases-gaming\\nhttps://aws.amazon.com/elasticache/redis-vs-memcached/","poster":"Untamables"},{"poster":"Bibay","comment_id":"890765","content":"Selected Answer: A\\nTo meet the requirements of caching frequently accessed data while adding the ability to sort or rank cached datasets, a developer should choose Amazon ElastiCache for Redis. ElastiCache is a web service that provides an in-memory data store in the cloud, and it supports both Memcached and Redis engines. While both engines are suitable for caching frequently accessed data, Redis is a better choice for this use case because it provides sorted sets and other data structures that allow for sorting and ranking of cached datasets. The data in ElastiCache can be encrypted at rest and in transit, ensuring the security of the PHI. Therefore, option A is the correct answer.","upvote_count":"12","timestamp":"1683380400.0"},{"poster":"anandkg","content":"Selected Answer: A\\nredis is having the sorting functionality","comment_id":"1561415","timestamp":"1744883280.0","upvote_count":"1"},{"upvote_count":"1","poster":"Hasitha99","content":"Selected Answer: A\\n* Amazon ElastiCache service provide in-memory cache in the cloud. \\n* Redis and MemCache are the 2 popular options which ElastiCache offerd for us.\\n* Both support encryption at rest and transist (previously only redis supported this).\\n* Redis offerd advance features like datastructures, transactions ,pub/sub etc.\\n\\nSince question is asking about most cost effective solution(already buit with MYSQL) , we have to ignore the DynamoDB option . \\n\\nNow we can pick Redis due to its natual sort facility.","comment_id":"1338497","timestamp":"1736453760.0"},{"poster":"sumanshu","content":"Selected Answer: A\\nB) Eliminated - Memcached does not support advanced data structure\\nC) Eliminated - A read replica is not a true caching solution. It is a secondary database instance that replicates data for read-heavy workloads\\nD) Eliminated - DynamoDB with DAX adds more operational overhead because you would be introducing a NoSQL database into the architecture when you\'re already using Amazon RDS (relational database) for storing data.","comment_id":"1329941","upvote_count":"2","timestamp":"1734778620.0"},{"timestamp":"1734136560.0","upvote_count":"1","poster":"trieudo","content":"Selected Answer: A\\nkeyword: caching, sort, rank\\n\\n==> discard B: not support \'sort\' and \'rank\'\\n==> discard C: not \'caching\'\\n==> discard D: caching only support NoSQL dynamoDB && sort and rank belong to primary key (partition and secondary) of DynamoDB\\n\\nA fit all requirement","comment_id":"1326285"},{"poster":"ahadh7621","comment_id":"1253814","upvote_count":"4","timestamp":"1721755140.0","content":"Selected Answer: A\\nThis question was on my exam July 23rd, 2024. Answer is A."},{"comment_id":"1231688","upvote_count":"4","content":"This appear at 17 Jun exam","poster":"tsangckl","timestamp":"1718595120.0"},{"comment_id":"1215027","poster":"65703c1","timestamp":"1716301680.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1"},{"content":"Sorted Sets in Elasticcache redis can do this job.","poster":"Vaibs099","upvote_count":"1","timestamp":"1713981180.0","comment_id":"1201558"},{"poster":"leonardoliveros","timestamp":"1700094660.0","upvote_count":"1","comment_id":"1072048","content":"Selected Answer: A\\nRedis is the best option to cached the results of queries and it also offer a encryption in-transit and at-rest"},{"comment_id":"1021928","content":"Redis: Supports various data structures such as strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, and geospatial indexes.\\nMemcached: Primarily supports string-based keys and values; does not support advanced data structures.","upvote_count":"4","timestamp":"1696122660.0","poster":"nmc12"},{"upvote_count":"7","timestamp":"1680442860.0","content":"Selected Answer: A\\nElastiCache for Redis also features Online Cluster Resizing, supports encryption, and is HIPAA eligible and PCI DSS compliant.\\n\\nhttps://aws.amazon.com/elasticache/redis-vs-memcached/","poster":"brandon87","comment_id":"858882"}],"answer_description":"","extracted_at":"2025-12-24T08:59:49.193Z","extraction_method":"api_direct_v1"},{"question_id":"3v3de8Aa359qOlJHZfpT","question_number":136,"page":28,"question_text":"A developer is receiving HTTP 400: ThrottlingException errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved.\\n\\nWhat best practice should first be applied to address this issue?","choices":{"B":"Use the AWS CLI to get the metrics.","C":"Analyze the applications and remove the API call.","D":"Retry the call with exponential backoff.","A":"Contact AWS Support for a limit increase."},"correct_answer":"D","answer_ET":"D","answers_community":["D (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124772-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:36:00","unix_timestamp":1698474960,"discussion_count":6,"discussion":[{"poster":"didorins","timestamp":"1714286220.0","comment_id":"1056003","content":"Selected Answer: D\\nBecause examtopic won\'t allow me to modify my previous answer to use the correct option. Exponential Backoff is D","upvote_count":"7"},{"upvote_count":"1","timestamp":"1732392240.0","content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","comment_id":"1216897"},{"poster":"SerialiDr","upvote_count":"3","comment_id":"1131013","timestamp":"1721839440.0","content":"Selected Answer: D\\nD. Retry the call with exponential backoff is the recommended best practice in this scenario. Exponential backoff is a standard error-handling strategy for network applications in which the client progressively increases the wait time between retries, up to a maximum number of retries, when a request fails due to server-side throttling. This approach helps to smooth out the rate of API calls, reducing the likelihood of hitting the rate limit."},{"comment_id":"1057536","content":"D. Retries with exponential backoff; operation with an exponentially increasing wait time","upvote_count":"4","timestamp":"1714464780.0","poster":"vruizrob"},{"content":"D. Retry the call with exponential backoff.","upvote_count":"4","poster":"Claire_KMT","comment_id":"1056026","timestamp":"1714287840.0"},{"upvote_count":"1","poster":"didorins","timestamp":"1714286160.0","content":"Selected Answer: A\\nYou are doing too many requests. Try less frequent with exponential backoff.","comment_id":"1056002"}],"answer_description":"","extracted_at":"2025-12-24T09:00:00.134Z","extraction_method":"api_direct_v1"},{"question_id":"no7SSepIdVyeNGXHFC53","question_number":137,"page":28,"question_text":"An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally.\\n\\nBased on this scenario, what is the MOST cost-effective solution to this problem?","choices":{"D":"Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.","B":"Remove the application from the ALCreate a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.","A":"Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.","C":"Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124773-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:38:00","unix_timestamp":1698475080,"discussion_count":4,"discussion":[{"timestamp":"1732393140.0","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1216912","upvote_count":"2","poster":"65703c1"},{"comment_id":"1131508","timestamp":"1721889000.0","poster":"SerialiDr","content":"Selected Answer: C\\nUse a Classic Load Balancer with HTTP protocol: While a Classic Load Balancer would also add the X-Forwarded-For header, there\'s no significant benefit in switching from an Application Load Balancer (ALB) to a Classic Load Balancer for this purpose. ALBs are generally preferred for application layer (HTTP/HTTPS) load balancing due to their advanced routing capabilities and other features.","comments":[{"poster":"SerialiDr","comment_id":"1131509","timestamp":"1721889000.0","content":"C. Inspect the X-Forwarded-For header: This is the most appropriate solution. The X-Forwarded-For header is added by ALBs (and other types of load balancers) to HTTP requests and contains the original IP address of the client. Modifying the application to use this header allows it to obtain the client\'s IP address without removing the benefits of load balancing.","upvote_count":"3"}],"upvote_count":"2"},{"comment_id":"1056117","timestamp":"1714300200.0","content":"C. Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header.","poster":"Claire_KMT","upvote_count":"1"},{"timestamp":"1714286280.0","comment_id":"1056005","content":"Selected Answer: C\\nIf you need to see external IP address and your app is behind ALB, always use x-forwarded-for\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/x-forwarded-headers.html","upvote_count":"4","poster":"didorins"}],"answer_description":"","extracted_at":"2025-12-24T09:00:00.134Z","extraction_method":"api_direct_v1"},{"question_id":"1jamYrDmapEgsvYMLWFb","question_number":138,"page":28,"question_text":"A developer is designing a serverless application that customers use to select seats for a concert venue. Customers send the ticket requests to an Amazon API Gateway API with an AWS Lambda function that acknowledges the order and generates an order ID. The application includes two additional Lambda functions: one for inventory management and one for payment processing. These two Lambda functions run in parallel and write the order to an Amazon Dynamo DB table.\\n\\nThe application must provide seats to customers according to the following requirements. If a seat is accidently sold more than once, the first order that the application received must get the seat. In these cases, the application must process the payment for only the first order. However, if the first order is rejected during payment processing, the second order must get the seat. In these cases, the application must process the payment for the second order.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Send the order ID to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda functions for inventory management and payment processing to the topic.","B":"Change the Lambda function that generates the order ID to initiate the Lambda function for inventory management. Then initiate the Lambda function for payment processing.","D":"Deliver the order ID to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda functions for inventory management and payment processing to poll the queue.","A":"Send the order ID to an Amazon Simple Notification Service (Amazon SNS) FIFO topic that fans out to one Amazon Simple Queue Service (Amazon SQS) FIFO queue for inventory management and another SQS FIFO queue for payment processing."},"correct_answer":"A","answer_ET":"A","answers_community":["A (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124805-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 12:36:00","unix_timestamp":1698489360,"discussion_count":7,"discussion":[{"content":"Selected Answer: A\\nA. The only viable solution","poster":"MarkTpTTT55","comment_id":"1061800","timestamp":"1699049820.0","upvote_count":"10"},{"timestamp":"1706178060.0","poster":"SerialiDr","upvote_count":"5","comment_id":"1131562","content":"Selected Answer: A\\nHere\'s why this solution is most appropriate:\\n\\nSNS FIFO Topic: A First-In-First-Out (FIFO) SNS topic ensures that messages are delivered in the exact order they are sent. This is critical for maintaining the order of ticket requests.\\n\\nSQS FIFO Queues: By having two separate FIFO queues for inventory management and payment processing, the application can process these aspects in parallel while still maintaining the order integrity. The FIFO nature of the queues ensures that if a seat is sold more than once, the first order received is processed first.\\n\\nOrder Processing Logic: With this setup, if the first order is rejected during payment processing, the second order can be processed next. The sequential processing inherent in FIFO queues ensures that this logic can be correctly implemented."},{"poster":"BrainFried","upvote_count":"2","timestamp":"1722042900.0","content":"None of these answers are correct.\\n\\nPeople say it is A - well then what prevents payment processing for order #1 if the inventory lambda failed to allocate a seat for order #1?\\n\\nThe correct answer should be for the order processing lambda to place orders into a queue (e.g. FIFO SQS) and then seat allocation lambda should poll this queue, check if seating is available and if so it should then invoke the payment processing lambda. This option isn\'t available.\\n\\nThe next best option would be Option B. Better than A, since you won\'t be charged for an order where seating isn\'t available.\\n\\nIf I am wrong, please explain it. Would love to hear. Thanks","comment_id":"1255383"},{"comment_id":"1216915","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716488700.0","upvote_count":"1"},{"comment_id":"1165783","upvote_count":"2","poster":"nder","content":"Selected Answer: A\\nFIFO is the only option that maintains ordering.","timestamp":"1709568660.0"},{"poster":"Claire_KMT","upvote_count":"2","comment_id":"1058400","content":"Selected Answer: D\\nD. Deliver the order ID to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda functions for inventory management and payment processing to poll the queue.","timestamp":"1698717540.0"},{"content":"D. Deliver the order ID to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda functions for inventory management and payment processing to poll the queue.","timestamp":"1698489360.0","poster":"Claire_KMT","upvote_count":"1","comment_id":"1056120"}],"answer_description":"","extracted_at":"2025-12-24T09:00:00.134Z","extraction_method":"api_direct_v1"},{"question_id":"yqkwMXdGc5FAu0KMAlpU","question_number":139,"page":28,"question_text":"An application uses AWS X-Ray to generate a large amount of trace data on an hourly basis. A developer wants to use filter expressions to limit the returned results through user-specified custom attributes.\\n\\nHow should the developer use filter expressions to filter the results in X-Ray?","choices":{"A":"Add custom attributes as annotations in the segment document.","D":"Create new sampling rules that are based on custom attributes.","C":"Add custom attributes as new segment fields in the segment document.","B":"Add custom attributes as metadata in the segment document."},"correct_answer":"A","answer_ET":"A","answers_community":["A (85%)","B (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124806-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 12:40:00","unix_timestamp":1698489600,"discussion_count":10,"discussion":[{"timestamp":"1727590860.0","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: A\\n\\"user-specified custom attributes\\" means custom annotations","comment_id":"1290950"},{"timestamp":"1716488760.0","comment_id":"1216918","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","upvote_count":"2"},{"upvote_count":"2","timestamp":"1709449500.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-java-segment.html#:~:text=Annotations%20are%20key%2Dvalue%20pairs%20with%20string%2C%20number%2C%20or%20Boolean%20values.%20Annotations%20are%20indexed%20for%20use%20with%20filter%20expressions.%20Use%20annotations%20to%20record%20data%20that%20you%20want%20to%20use%20to%20group%20traces%20in%20the%20console%2C%20or%20when%20calling%20the%20GetTraceSummaries%20API.","poster":"KarBiswa","comment_id":"1164555"},{"poster":"SerialiDr","comment_id":"1131625","content":"Selected Answer: A\\nAnnotations in AWS X-Ray are key-value pairs that are indexed for use with filter expressions. This means that you can use annotations to add custom attributes to your trace data, which can then be queried using X-Ray filter expressions. Annotations are used for values that you want to use for searching, filtering, or creating groups. By adding these custom attributes as annotations, the developer can effectively use filter expressions to limit the returned results based on these attributes.","upvote_count":"4","timestamp":"1706184360.0"},{"upvote_count":"2","comment_id":"1096521","timestamp":"1702562280.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-java-segment.html\\n filter expressions => annotations","poster":"TanTran04"},{"timestamp":"1701406260.0","upvote_count":"3","poster":"Jeff1719","content":"Selected Answer: A\\nAnnotations are indexed, used for filtering, unlike metadata","comment_id":"1084951"},{"upvote_count":"2","comment_id":"1064843","timestamp":"1699365240.0","content":"Selected Answer: A\\nIf you add annotations with the X-Ray SDK, you can also filter based on the presence of an annotation key or the value of a key.\\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html","poster":"jingle4944"},{"content":"Selected Answer: A\\nTo filter the results in AWS X-Ray using custom attributes, the developer should add custom attributes as annotations in the segment document.","timestamp":"1698825840.0","comment_id":"1059442","poster":"PrakashM14","upvote_count":"1"},{"content":"Selected Answer: B\\nB. Add custom attributes as metadata in the segment document.\\n\\nCustom attributes are best added as metadata in the segment document because X-Ray filter expressions can use metadata to filter traces. Annotations and new segment fields are not typically used for filtering traces in this context.","poster":"Claire_KMT","timestamp":"1698717660.0","upvote_count":"3","comment_id":"1058403"},{"content":"B. Add custom attributes as metadata in the segment document.\\n\\nCustom attributes are best added as metadata in the segment document because X-Ray filter expressions can use metadata to filter traces. Annotations and new segment fields are not typically used for filtering traces in this context.","comment_id":"1056121","upvote_count":"1","poster":"Claire_KMT","timestamp":"1698489600.0"}],"answer_description":"","extracted_at":"2025-12-24T09:00:00.134Z","extraction_method":"api_direct_v1"},{"question_id":"X41VfN405Hhilt9ImjZz","question_number":140,"page":28,"question_text":"A web application is using Amazon Kinesis Data Streams for clickstream data that may not be consumed for up to 12 hours.\\n\\nHow can the developer implement encryption at rest for data within the Kinesis Data Streams?","choices":{"B":"Use Amazon Kinesis Consumer Library.","A":"Enable SSL connections to Kinesis.","C":"Encrypt the data once it is at rest with a Lambda function.","D":"Enable server-side encryption in Kinesis Data Streams."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124774-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:42:00","unix_timestamp":1698475320,"discussion_count":5,"discussion":[{"comment_id":"1056009","timestamp":"1714286520.0","poster":"didorins","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/streams/latest/dev/server-side-encryption.html","upvote_count":"9"},{"comment_id":"1216919","timestamp":"1732393620.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"comment_id":"1164556","poster":"KarBiswa","timestamp":"1725340080.0","upvote_count":"2","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/streams/latest/dev/what-is-sse.html#:~:text=Server%2Dside%20encryption%20is,security%20of%20your%20data."},{"timestamp":"1714435260.0","poster":"Claire_KMT","comment_id":"1058406","content":"Selected Answer: D\\nD. Enable server-side encryption in Kinesis Data Streams.\\n\\nAmazon Kinesis Data Streams allows you to enable server-side encryption, which encrypts data at rest. This ensures that data stored within the Kinesis Data Streams is protected with encryption.","upvote_count":"4"},{"content":"D. Enable server-side encryption in Kinesis Data Streams.\\n\\nAmazon Kinesis Data Streams allows you to enable server-side encryption, which encrypts data at rest. This ensures that data stored within the Kinesis Data Streams is protected with encryption.","comment_id":"1056123","upvote_count":"3","poster":"Claire_KMT","timestamp":"1714300860.0"}],"answer_description":"","extracted_at":"2025-12-24T09:00:00.134Z","extraction_method":"api_direct_v1"},{"question_id":"kK9Cz6XcRDTFmOJW91zX","question_number":141,"page":29,"question_text":"An application is real-time processing millions of events that are received through an API.\\n\\nWhat service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?","choices":{"D":"Amazon Kinesis Data Streams","C":"Amazon Kinesis Firehose","B":"Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application","A":"Amazon SNS with fanout to an SQS queue for each application"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124775-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:45:00","unix_timestamp":1698475500,"discussion_count":4,"discussion":[{"comment_id":"1131636","content":"Selected Answer: D\\nThis service is specifically designed for real-time processing of large-scale streaming data. Kinesis Data Streams allows multiple consumers to process the same stream concurrently, making it highly suitable for scenarios where you have high-volume data streams that need to be processed in real-time by various applications. It offers high throughput, scalability, and durability for streaming data, and enables multiple applications to process the same stream concurrently, making it the most cost-effective and efficient choice for this scenario.","timestamp":"1721902560.0","poster":"SerialiDr","upvote_count":"5"},{"poster":"didorins","timestamp":"1714286700.0","upvote_count":"5","comment_id":"1056010","content":"Selected Answer: D\\nReal-time data processing is KDS"},{"upvote_count":"3","content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","comment_id":"1216921","timestamp":"1732393860.0"},{"upvote_count":"2","content":"D. Amazon Kinesis Data Streams.\\n\\nAmazon Kinesis Data Streams is designed for real-time data streaming and allows multiple consumers to process data concurrently and in real-time. It can handle millions of events and provides a scalable and cost-effective solution for handling high-throughput data streams.","poster":"Claire_KMT","timestamp":"1714300980.0","comment_id":"1056124"}],"answer_description":"","extracted_at":"2025-12-24T09:00:11.163Z","extraction_method":"api_direct_v1"},{"question_id":"mZveUOJuE2szeKjtplSm","question_number":142,"page":29,"question_text":"Given the following AWS CloudFormation template:\\n\\n//IMG//\\n\\n\\nWhat is the MOST efficient way to reference the new Amazon S3 bucket from another AWS CloudFormation template?","choices":{"B":"Add Exported: true to the Content.Bucket in the original template and use ImportResource in other templates.","C":"Create a custom AWS CloudFormation resource that gets the bucket name from the ContentBucket resource of the first stack.","A":"Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.","D":"Use Fn::Include to include the existing template in other templates and use the ContentBucket resource directly."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124817-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image14.png"],"answer_images":[],"timestamp":"2023-10-28 14:13:00","unix_timestamp":1698495180,"discussion_count":4,"discussion":[{"content":"Selected Answer: A\\nA. Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.","timestamp":"1715976240.0","poster":"bhanupriya07","comment_id":"1073665","upvote_count":"6"},{"content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","timestamp":"1732393920.0","comment_id":"1216922","upvote_count":"1"},{"poster":"KarBiswa","comment_id":"1164561","timestamp":"1725340740.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/walkthrough-crossstackref.html","upvote_count":"3"},{"comments":[{"poster":"papason","comment_id":"1058488","timestamp":"1714451640.0","upvote_count":"3","content":"By adding an Export declaration to the Outputs section of the original CloudFormation template, you can make the bucket name available for other templates to import and use. This allows you to reference the bucket name directly in other templates without the need for additional resources or custom logic."}],"upvote_count":"2","comment_id":"1056175","timestamp":"1714306380.0","content":"A. Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.","poster":"Claire_KMT"}],"answer_description":"","extracted_at":"2025-12-24T09:00:11.163Z","extraction_method":"api_direct_v1"},{"question_id":"BwmltdPUM5YcRjDSu2XN","question_number":143,"page":29,"question_text":"A developer has built an application that inserts data into an Amazon DynamoDB table. The table is configured to use provisioned capacity. The application is deployed on a burstable nano Amazon EC2 instance. The application logs show that the application has been failing because of a ProvisionedThroughputExceededException error.\\n\\nWhich actions should the developer take to resolve this issue? (Choose two.)","choices":{"B":"Increase the number of read capacity units (RCUs) that are provisioned for the DynamoDB table.","A":"Move the application to a larger EC2 instance.","E":"Change the capacity mode of the DynamoDB table from provisioned to on-demand.","D":"Increase the frequency of requests to DynamoDB by decreasing the retry delay.","C":"Reduce the frequency of requests to DynamoDB by implementing exponential backoff."},"correct_answer":"CE","answer_ET":"CE","answers_community":["CE (78%)","BC (22%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124816-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:12:00","unix_timestamp":1698495120,"discussion_count":12,"discussion":[{"timestamp":"1700259720.0","comment_id":"1073670","poster":"bhanupriya07","upvote_count":"6","content":"Selected Answer: CE\\nC. Reduce the frequency of requests to DynamoDB by implementing exponential backoff.\\nE. Change the capacity mode of the DynamoDB table from provisioned to on-demand."},{"timestamp":"1709467980.0","upvote_count":"5","poster":"chikuwan","comment_id":"1164756","content":"Selected Answer: CE\\nWhat the question said is insert data..so B increase read capacity is not correct.Hence C and E."},{"comment_id":"1296280","timestamp":"1728692340.0","poster":"MasoudK","upvote_count":"2","content":"B And C: While E could resolve the issue by automatically scaling the capacity, it may not be the most cost-effective solution if the traffic pattern is predictable and can be managed with provisioned capacity and backoff strategies."},{"upvote_count":"1","poster":"albert_kuo","timestamp":"1727591220.0","content":"Selected Answer: BC\\nBy implementing exponential backoff, the application will automatically retry failed requests with increasing delays between attempts. This helps to spread out the requests over time, reducing the likelihood of exceeding the provisioned throughput.\\n\\nSince the table is configured to use provisioned capacity, increasing the number of RCUs will allow the table to handle more read requests per second. This directly addresses the ProvisionedThroughputExceededException by increasing the table\'s capacity to handle more concurrent requests.","comment_id":"1290952"},{"poster":"ahadh7621","content":"Selected Answer: CE\\nAnswer is C & E:\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\\n\\nProvisionedThroughputExceededException\\nMessage: You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes. To view performance metrics for provisioned throughput vs. consumed throughput, open the Amazon CloudWatch console.\\n\\nExample: Your request rate is too high. The AWS SDKs for DynamoDB automatically retry requests that receive this exception. Your request is eventually successful, unless your retry queue is too large to finish. Reduce the frequency of requests using Error retries and exponential backoff.","timestamp":"1721357460.0","upvote_count":"1","comment_id":"1250791"},{"comment_id":"1216924","timestamp":"1716489360.0","poster":"65703c1","content":"Selected Answer: CE\\nCE is the correct answer.","upvote_count":"2"},{"poster":"KarBiswa","comment_id":"1166507","content":"Selected Answer: CE\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html","timestamp":"1709647260.0","upvote_count":"3"},{"upvote_count":"1","comment_id":"1164565","timestamp":"1709451060.0","poster":"KarBiswa","content":"Selected Answer: BC\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html#:~:text=The%20DynamoDB%20console%20displays%20Amazon%20CloudWatch%20metrics%20for%20your%20tables%2C%20so%20you%20can%20monitor%20throttled%20read%20requests%20and%20write%20requests.%20If%20you%20encounter%20excessive%20throttling%2C%20you%20should%20consider%20increasing%20your%20table%27s%20provisioned%20throughput%20settings.","comments":[]},{"timestamp":"1706206980.0","poster":"SerialiDr","upvote_count":"3","comment_id":"1131939","content":"Selected Answer: BC\\nB. This error indicates that the application\'s request rate is exceeding the throughput that has been provisioned for the table. Increasing the provisioned read capacity units (RCUs) and/or write capacity units (WCUs) for the DynamoDB table will allow it to handle a higher request rate, thereby reducing the likelihood of encountering this error. However, this approach requires careful capacity planning and may increase costs.\\n\\nC. Exponential backoff is a standard error retry strategy that involves progressively increasing the delay between retries when there is a ProvisionedThroughputExceededException. This approach helps to smooth out the rate of requests, giving the table time to accommodate bursts of read or write requests. Implementing exponential backoff in the application will help to effectively manage request retries and reduce the chance of continually hitting the provisioned throughput limit."},{"comment_id":"1098109","timestamp":"1702725960.0","poster":"Certified101","content":"Selected Answer: CE\\nC & E correct","upvote_count":"4"},{"content":"Selected Answer: BC\\nBased on ChatGPT: BC","poster":"tqiu654","comment_id":"1093992","upvote_count":"1","timestamp":"1702344660.0"},{"timestamp":"1698495120.0","comments":[{"poster":"tapan666","upvote_count":"10","timestamp":"1698549300.0","comment_id":"1056548","content":"It \'inserts\' data, so it needs WCUs and not RCUs. So option B is invalid too. C and E are the correct options."}],"upvote_count":"1","comment_id":"1056174","content":"B. Increase the number of read capacity units (RCUs) that are provisioned for the DynamoDB table.\\nOR\\nE. Change the capacity mode of the DynamoDB table from provisioned to on-demand.\\nC. Reduce the frequency of requests to DynamoDB by implementing exponential backoff.","poster":"Claire_KMT"}],"answer_description":"","extracted_at":"2025-12-24T09:00:11.163Z","extraction_method":"api_direct_v1"},{"question_id":"Iat79mVL1NDAibJQ9L8X","question_number":144,"page":29,"question_text":"A company is hosting a workshop for external users and wants to share the reference documents with the external users for 7 days. The company stores the reference documents in an Amazon S3 bucket that the company owns.\\n\\nWhat is the MOST secure way to share the documents with the external users?","choices":{"B":"Move the documents to an Amazon WorkDocs folder. Share the links of the WorkDocs folder with the external users.","D":"Create a role that has read-only access to the S3 bucket. Share the Amazon Resource Name (ARN) of this role with the external users.","C":"Create temporary IAM users that have read-only access to the S3 bucket. Share the access keys with the external users. Expire the credentials after 7 days.","A":"Use S3 presigned URLs to share the documents with the external users. Set an expiration time of 7 days."},"correct_answer":"A","answer_ET":"A","answers_community":["A (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124778-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 08:47:00","unix_timestamp":1698475620,"discussion_count":6,"discussion":[{"poster":"0bdf3af","comment_id":"1400987","upvote_count":"1","content":"Selected Answer: B\\nB is the answear.\\nPresinged URLs can be shared 12 hours max","timestamp":"1742465520.0"},{"upvote_count":"1","timestamp":"1718598300.0","comment_id":"1231716","content":"This appear at 17 Jun exam","poster":"tsangckl"},{"upvote_count":"2","poster":"65703c1","timestamp":"1716489420.0","comment_id":"1216926","content":"Selected Answer: A\\nA is the correct answer."},{"content":"Selected Answer: A\\nPresigned URLs are a secure way to provide temporary access to specific objects in an S3 bucket. By generating a presigned URL, you grant time-limited access to the files without having to alter the underlying permissions of the S3 bucket or objects. You can set an expiration time for the URL, ensuring that access to the document is automatically revoked after 7 days. This method is straightforward and does not require the management of user identities or permissions beyond the scope of the shared objects.","timestamp":"1706207640.0","upvote_count":"3","comment_id":"1131950","poster":"SerialiDr"},{"content":"A. Use S3 presigned URLs to share the documents with the external users. Set an expiration time of 7 days.","comment_id":"1056171","timestamp":"1698495120.0","upvote_count":"2","poster":"Claire_KMT"},{"content":"Selected Answer: A\\nTemporary access to S3 object to external users is Pre-signed URL","poster":"didorins","upvote_count":"4","timestamp":"1698475620.0","comment_id":"1056015"}],"answer_description":"","extracted_at":"2025-12-24T09:00:11.163Z","extraction_method":"api_direct_v1"},{"question_id":"YkEHjutIn6a2ZjkVasI0","question_number":145,"page":29,"question_text":"A developer is planning to use an Amazon API Gateway and AWS Lambda to provide a REST API. The developer will have three distinct environments to manage: development, test, and production.\\n\\nHow should the application be deployed while minimizing the number of resources to manage?","choices":{"D":"Create one API Gateway and one Lambda function, and use a REST parameter to identify the environment.","A":"Create a separate API Gateway and separate Lambda function for each environment in the same Region.","B":"Assign a Region for each environment and deploy API Gateway and Lambda to each Region.","C":"Create one API Gateway with multiple stages with one Lambda function with multiple aliases."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124815-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:12:00","unix_timestamp":1698495120,"discussion_count":5,"discussion":[{"poster":"SerialiDr","comment_id":"1131954","timestamp":"1721925660.0","upvote_count":"6","content":"Selected Answer: C\\nThis approach involves creating a single API Gateway and a single Lambda function. Within the API Gateway, you can create multiple stages, each corresponding to a different environment (development, test, production). Similarly, for the Lambda function, you can create multiple aliases, each pointing to a different version of the Lambda function that corresponds to each environment. This setup allows for clear separation of environments within the same set of resources. It simplifies deployment and management by reducing the number of resources and also provides an easy way to promote changes from one environment to another."},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"2","poster":"65703c1","timestamp":"1732394400.0","comment_id":"1216927"},{"upvote_count":"3","comment_id":"1097327","timestamp":"1718450100.0","content":"Selected Answer: C\\nAPI Gateway\\nA stage in API Gateway represents a deployment of your API. You can have separate stages for development, test, and production.\\nEach stage can have its own settings, such as stage variables, custom domains, and caching configurations.\\nLambda function\\nEach alias can point to a specific version of your Lambda function. This allows you to promote versions through different environments without changing the function\'s Amazon Resource Name (ARN) in your API Gateway.","poster":"TanTran04"},{"poster":"bhanupriya07","timestamp":"1715977440.0","upvote_count":"4","content":"Selected Answer: C\\nC. Create one API Gateway with multiple stages with one Lambda function with multiple aliases.","comment_id":"1073673"},{"timestamp":"1714306320.0","upvote_count":"3","poster":"Claire_KMT","comment_id":"1056170","content":"C. Create one API Gateway with multiple stages with one Lambda function with multiple aliases."}],"answer_description":"","extracted_at":"2025-12-24T09:00:11.163Z","extraction_method":"api_direct_v1"},{"question_id":"gRlxLcl2ZjfWruuTErCc","question_number":146,"page":30,"question_text":"A company has a multi-node Windows legacy application that runs on premises. The application uses a network shared folder as a centralized configuration repository to store configuration files in .xml format. The company is migrating the application to Amazon EC2 instances. As part of the migration to AWS, a developer must identify a solution that provides high availability for the repository.\\nWhich solution will meet this requirement MOST cost-effectively?","choices":{"C":"Create an Amazon S3 bucket to host the repository. Migrate the existing .xml files to the S3 bucket. Update the application code to use the AWS SDK to read and write configuration files from Amazon S3.","A":"Mount an Amazon Elastic Block Store (Amazon EBS) volume onto one of the EC2 instances. Deploy a file system on the EBS volume. Use the host operating system to share a folder. Update the application code to read and write configuration files from the shared folder.","D":"Create an Amazon S3 bucket to host the repository. Migrate the existing .xml files to the S3 bucket. Mount the S3 bucket to the EC2 instances as a local volume. Update the application code to read and write configuration files from the disk.","B":"Deploy a micro EC2 instance with an instance store volume. Use the host operating system to share a folder. Update the application code to read and write configuration files from the shared folder."},"correct_answer":"C","answer_ET":"C","answers_community":["C (77%)","D (23%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102900-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-17 09:47:00","unix_timestamp":1679042820,"discussion_count":18,"discussion":[{"timestamp":"1680009780.0","poster":"shahs10","content":"Why is not there EFS to replace shared file system","comments":[{"poster":"albert_kuo","upvote_count":"2","timestamp":"1726533900.0","content":"Windows legacy application","comment_id":"1284988"},{"comments":[{"poster":"alexandru_tata","content":"EFS would not have been an option. It does not work for Linux: https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.html","timestamp":"1711530120.0","comment_id":"1183954","upvote_count":"4","comments":[{"upvote_count":"3","poster":"serverlessme","content":"It does not work for Windows you meant to say?","comment_id":"1302016","timestamp":"1729682520.0"}]}],"upvote_count":"2","comment_id":"1088993","content":"This is what I was looking for - but not an option","timestamp":"1701834360.0","poster":"[Removed]"},{"comment_id":"1021936","content":"it is best solution. But we can use S3 without EFS","upvote_count":"3","poster":"nmc12","timestamp":"1696123200.0"}],"upvote_count":"15","comment_id":"853282"},{"upvote_count":"11","timestamp":"1684045860.0","comment_id":"897314","content":"c\\nOption C is the most cost-effective solution to provide high availability for the centralized configuration repository. Amazon S3 provides a highly durable and available object storage service. S3 stores objects redundantly across multiple devices and multiple facilities within a region, making it highly available. The developer can migrate the existing .xml files to an S3 bucket and update the application code to use the AWS SDK to read and write configuration files from Amazon S3.\\n\\nOption A and B are not the best solutions as they require the developer to use the host operating system to share a folder, which can lead to a single point of failure.\\n\\nOption D is not a recommended solution as it is not a direct way of accessing an S3 bucket. While it is possible to use third-party tools to mount an S3 bucket as a local disk, it can lead to performance issues and additional complexity.","poster":"Bibay"},{"content":"Selected Answer: C\\nA) Eliminated - We need to deploy and maintain a file system on EBS, which could lead to additional complexity\\n\\nB) Eliminated - Instance store volumes are ephemeral and will be lost if the EC2 instance is stopped or terminated.\\n\\nD) Eliminated - Mounting S3 directly as a volume is not natively supported without third-party solutions or tools like s3fs, which could add unnecessary complexity and overhead.","upvote_count":"2","timestamp":"1734780120.0","comment_id":"1329963","poster":"sumanshu"},{"content":"Selected Answer: C\\nKeyword: multi-node, Windows legacy application, shared folder as a centralized configuration repository, high availability, MOST cost-effectively\\n\\nmaybe many of you think EFS first when reach \'shared folder\', but EFS is not work with \'Windows legacy application\', it depnds on OS, MOST cost-effectively\\n\\n==> discard B: when you reboot or turn off EC2, data in \'instance store volumn will be lost, violate \'high availability \'\\n==> discard A: EBS at time, can link only one EC2, violate \'shared folder\'\\n==> discard D: complexity than option C, you must setup more, then maintain many things afterward, violate \'MOST cost-effectively\'\\n\\nC is match with all requirement","upvote_count":"2","poster":"trieudo","comment_id":"1326288","timestamp":"1734137520.0"},{"upvote_count":"1","content":"Selected Answer: D\\nI am not sure why D is not the best option. This could give a no code solution to legacy application.","comment_id":"1322609","timestamp":"1733457900.0","poster":"f271c23"},{"comments":[{"comment_id":"1328961","content":"Because EBS is way more costly than s3","timestamp":"1734610560.0","poster":"AWSArt","upvote_count":"1"}],"content":"Why A is not correct answer ?","timestamp":"1730770380.0","comment_id":"1307166","poster":"Venky786","upvote_count":"1"},{"comment_id":"1262511","poster":"tgood","timestamp":"1723124100.0","upvote_count":"1","comments":[{"timestamp":"1729682760.0","comment_id":"1302020","upvote_count":"1","content":"EFS does not work for Windows.","poster":"serverlessme"}],"content":"Selected Answer: C\\ni think EFS should be added to answer"},{"comment_id":"1215032","timestamp":"1716302280.0","poster":"65703c1","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer."},{"comment_id":"1202826","content":"S3 mountpoint does not support editing files or deleting directories. \\nSo the answer is C","timestamp":"1714167600.0","upvote_count":"2","poster":"teddyjr"},{"comment_id":"1198136","content":"D since we have s3 mountpoint available now\\nhttps://aws.amazon.com/about-aws/whats-new/2023/03/mountpoint-amazon-s3/\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/mountpoint.html","timestamp":"1713469200.0","upvote_count":"1","poster":"Dikshika"},{"content":"Selected Answer: C\\nOption C is the most cost-effective solution to provide high availability for the centralized configuration repository. Amazon S3 provides a highly durable and available object storage service. S3 stores objects redundantly across multiple devices and multiple facilities within a region, making it highly available. The developer can migrate the existing .xml files to an S3 bucket and update the application code to use the AWS SDK to read and write configuration files from Amazon S3.","timestamp":"1707536220.0","upvote_count":"2","poster":"someone234","comment_id":"1145911"},{"poster":"gqs3119","upvote_count":"2","comments":[{"timestamp":"1732025040.0","upvote_count":"1","comment_id":"1314690","content":"Mount doesn\'t support for Windows.","poster":"letsLearn_001"},{"upvote_count":"3","poster":"squeeze_talus0y","timestamp":"1705144500.0","comment_id":"1121545","content":"Your solution overcomplicates things."},{"timestamp":"1706854560.0","comment_id":"1138177","content":"But the apps are legacy windows app so mountpoints will not help - my opinion","poster":"SD_CS","upvote_count":"1"}],"content":"Selected Answer: D\\nToday It\'s D.\\nFew months ago I\'d pick C, but since then amazon released mountpoint for linux, so it\'s possible to mount S3 on any major Linux distro, by using WSL 2 it is also possible to mount S3 on Windows. Doing so cuts the cost of modifying the legacy application. \\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/mountpoint-installation.html\\nhttps://aws.plainenglish.io/mounting-amazon-s3-buckets-on-windows-52b5f1434cd7","timestamp":"1703014980.0","comment_id":"1100947"},{"timestamp":"1700095500.0","upvote_count":"2","comment_id":"1072053","content":"Selected Answer: C\\nEBS and Instance Store just attached one instance so these\'s expense and don\'t scalable, and S3 it\'s the best option to handle the repository of .xml because it\'s very scalable and low-cost","poster":"leonardoliveros"},{"poster":"HanTran0795","comment_id":"1044605","content":"Selected Answer: D\\nIt is a Windows legacy application. What if the sdk doesn\'t support the app? I choose D.","upvote_count":"2","timestamp":"1697424120.0","comments":[{"poster":"ronn555","content":"C\\nS3 Buckets can only be mounted directly to Linux EC2 instances","upvote_count":"1","comments":[{"content":"It can be mounted to many distros today, and using WSL2 also to Windows. \\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/mountpoint-installation.html","timestamp":"1703015100.0","comment_id":"1100951","upvote_count":"2","poster":"gqs3119"}],"comment_id":"1062156","timestamp":"1699107900.0"}]},{"content":"Correct answer is C","timestamp":"1693274760.0","comment_id":"992725","upvote_count":"1","poster":"AhmedAliHashmi"},{"upvote_count":"1","poster":"senadevtrd","timestamp":"1685399460.0","content":"Selected Answer: C\\nIn theses options, this is more correct","comment_id":"909759"},{"timestamp":"1679555040.0","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonS3.html\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingAWSSDK.html","comment_id":"847901","poster":"Untamables","upvote_count":"6"},{"upvote_count":"4","timestamp":"1679042820.0","comment_id":"841803","content":"C\\nhttps://www.examtopics.com/discussions/amazon/view/88701-exam-aws-certified-developer-associate-topic-1-question-227/","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T09:00:22.132Z","extraction_method":"api_direct_v1"},{"question_id":"QZ6m7HZZFdPBtz8uYs1n","question_number":147,"page":30,"question_text":"A developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB.\\n\\nWhy is the Lambda function not being invoked?","choices":{"D":"Cross-zone is not enabled on the ALB.","A":"A Lambda function cannot be registered as a target for an ALB.","B":"A Lambda function can be registered with an ALB using AWS Management Console only.","C":"The permissions to invoke the Lambda function are missing."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124818-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:14:00","unix_timestamp":1698495240,"discussion_count":6,"discussion":[{"timestamp":"1706208180.0","comment_id":"1131956","poster":"SerialiDr","content":"Selected Answer: C\\nTo allow an ALB to invoke a Lambda function, you need to grant the ALB permission to invoke the Lambda. This is typically done by adding a resource-based policy to the Lambda function, granting invoke permission to the ALB. If this permission is not set, the ALB will not be able to trigger the Lambda function in response to incoming requests.","upvote_count":"5"},{"comment_id":"1287597","upvote_count":"1","timestamp":"1726989180.0","poster":"preachr","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/lambda-functions.html\\n\\nPermissions to invoke the Lambda function\\nIf you create the target group and register the Lambda function using the AWS Management Console, the console adds the required permissions to your Lambda function policy on your behalf. Otherwise, after you create the target group and register the function using the AWS CLI, you must use the add-permission command to grant Elastic Load Balancing permission to invoke your Lambda function. We recommend that you use the aws:SourceAccount and aws:SourceArn condition keys to restrict function invocation to the specified target group. \\n\\n\\naws lambda add-permission \\\\\\n--function-name lambda-function-arn-with-alias-name \\\\ \\n--statement-id elb1 \\\\\\n--principal elasticloadbalancing.amazonaws.com \\\\\\n...."},{"timestamp":"1716489780.0","poster":"65703c1","comment_id":"1216931","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer."},{"poster":"TanTran04","content":"Selected Answer: C\\nThe Lambda function must have the lambda:InvokeFunction permission for the ALB to successfully invoke it.","comment_id":"1097330","upvote_count":"3","timestamp":"1702646220.0"},{"comment_id":"1080672","content":"Selected Answer: C\\nANS: C","poster":"kaes","timestamp":"1701006600.0","upvote_count":"3"},{"timestamp":"1698495240.0","upvote_count":"3","poster":"Claire_KMT","content":"C. The permissions to invoke the Lambda function are missing.","comment_id":"1056177"}],"answer_description":"","extracted_at":"2025-12-24T09:00:22.132Z","extraction_method":"api_direct_v1"},{"question_id":"lNDURprhyTnqbtHUNopz","question_number":148,"page":30,"question_text":"A developer is creating an AWS Lambda function that will connect to an Amazon RDS for MySQL instance. The developer wants to store the database credentials. The database credentials need to be encrypted and the database password needs to be automatically rotated.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Store the database credentials in AWS Secrets Manager. Set up managed rotation on the database credentials.","D":"Store the database credentials in the X-Amz-Security-Token parameter. Set up managed rotation on the parameter.","A":"Store the database credentials as environment variables for the Lambda function. Set the environment variables to rotate automatically.","C":"Store the database credentials in AWS Systems Manager Parameter Store as secure string parameters. Set up managed rotation on the parameters."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124819-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:15:00","unix_timestamp":1698495300,"discussion_count":4,"discussion":[{"comment_id":"1056178","content":"B. Store the database credentials in AWS Secrets Manager. Set up managed rotation on the database credentials.","poster":"Claire_KMT","timestamp":"1714306500.0","upvote_count":"9"},{"upvote_count":"5","poster":"TanTran04","comment_id":"1097331","timestamp":"1718450280.0","content":"Selected Answer: B\\nautomatically rotated => AWS Secrets Manager"},{"poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1216933","timestamp":"1732395000.0","upvote_count":"1"},{"poster":"Certified101","timestamp":"1718530080.0","comment_id":"1098111","content":"Selected Answer: B\\nBBBBBBBBBBB","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:00:22.132Z","extraction_method":"api_direct_v1"},{"question_id":"s0xnG19T2b96reEe7Mz9","question_number":149,"page":30,"question_text":"A developer wants to reduce risk when deploying a new version of an existing AWS Lambda function. To test the Lambda function, the developer needs to split the traffic between the existing version and the new version of the Lambda function.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create a function alias. Configure the alias to split the traffic between the two versions of the Lambda function.","C":"Create an Application Load Balancer (ALB) that uses the Lambda function as a target. Configure the ALB to split the traffic between the two versions of the Lambda function.","A":"Configure a weighted routing policy in Amazon Route 53. Associate the versions of the Lambda function with the weighted routing policy.","D":"Create the new version of the Lambda function as a Lambda layer on the existing version. Configure the function to split the traffic between the two layers."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124820-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:16:00","unix_timestamp":1698495360,"discussion_count":5,"discussion":[{"upvote_count":"2","poster":"65703c1","timestamp":"1732395180.0","comment_id":"1216935","content":"Selected Answer: B\\nB is the correct answer."},{"poster":"KarBiswa","upvote_count":"2","timestamp":"1725341820.0","comment_id":"1164567","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html"},{"upvote_count":"3","comment_id":"1116424","timestamp":"1720409520.0","content":"Selected Answer: B\\nThis approach is more efficient and cost-effective than other options such as configuring a weighted routing policy in Amazon Route 53, creating an Application Load Balancer (ALB) that uses the Lambda function as a target, or creating the new version of the Lambda function as a Lambda layer on the existing version","poster":"Snape"},{"content":"Selected Answer: B\\nhttps://www.examtopics.com/discussions/amazon/view/88419-exam-aws-certified-developer-associate-topic-1-question-350/","upvote_count":"4","poster":"BronJames","comment_id":"1084493","timestamp":"1717075500.0"},{"timestamp":"1714306560.0","poster":"Claire_KMT","upvote_count":"3","comment_id":"1056179","content":"B. Create a function alias. Configure the alias to split the traffic between the two versions of the Lambda function."}],"answer_description":"","extracted_at":"2025-12-24T09:00:22.132Z","extraction_method":"api_direct_v1"},{"question_id":"aX8QlaChFGgbhn8tvrRE","question_number":150,"page":30,"question_text":"A developer has created a large AWS Lambda function. Deployment of the function is failing because of an InvalidParameterValueException error. The error message indicates that the unzipped size of the function exceeds the maximum supported value.\\n\\nWhich actions can the developer take to resolve this error? (Choose two.)","choices":{"B":"Use a compression algorithm that is more efficient than ZIP.","D":"Zip the .zip file twice to compress the file more.","A":"Submit a quota increase request to AWS Support to increase the function to the required size.","C":"Break up the function into multiple smaller functions.","E":"Move common libraries, function dependencies, and custom runtimes into Lambda layers."},"correct_answer":"CE","answer_ET":"CE","answers_community":["CE (85%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/126181-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-11-15 04:27:00","unix_timestamp":1700018820,"discussion_count":9,"discussion":[{"upvote_count":"3","comment_id":"1216937","timestamp":"1716490440.0","content":"Selected Answer: CE\\nCE is the correct answer.","poster":"65703c1"},{"content":"Selected Answer: CE\\nin this case quota cannot be increased\\nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html#:~:text=The%20following%20quotas%20apply%20to%20function%20configuration%2C%20deployment%2C%20and%20execution.%20Except%20as%20noted%2C%20they%20can%27t%20be%20changed.","upvote_count":"2","poster":"KarBiswa","comment_id":"1164570","timestamp":"1709451840.0"},{"poster":"SerialiDr","content":"Selected Answer: CE\\nC. Break up the function into multiple smaller functions.\\n\\nIf the size of the Lambda function is too large, breaking it into smaller, more modular functions can help. Each function can be responsible for a specific part of the application\'s logic. This approach not only helps with deployment but also aligns with microservices best practices, potentially improving the maintainability and scalability of the application.\\nE. Move common libraries, function dependencies, and custom runtimes into Lambda layers.\\n\\nLambda layers are a way to manage and share common components across multiple Lambda functions. By moving libraries, dependencies, and runtimes into layers, you reduce the size of the Lambda function\'s deployment package. Layers can be shared across multiple functions, leading to more efficient use of storage and easier management of common code.","timestamp":"1706261940.0","upvote_count":"4","comment_id":"1132417"},{"upvote_count":"2","content":"Selected Answer: CE\\nC and E","poster":"Snape","timestamp":"1704692160.0","comment_id":"1116427"},{"poster":"nickqq","comment_id":"1115590","content":"A E no discussion","upvote_count":"2","timestamp":"1704600300.0"},{"poster":"kipr","timestamp":"1703780820.0","upvote_count":"2","content":"C and E\\nhttps://www.examtopics.com/discussions/amazon/view/5330-exam-aws-certified-developer-associate-topic-1-question-17/","comment_id":"1107963"},{"timestamp":"1702751880.0","upvote_count":"1","comment_id":"1098410","content":"Selected Answer: AD\\nA & E is correct","poster":"Certified101"},{"comment_id":"1097346","upvote_count":"1","content":"Selected Answer: AE\\nFollowing anasbakla document, we can see the default storage of Quota is 75 GB for uploaded functions (.zip file archives) and layers.","comments":[{"timestamp":"1726993620.0","poster":"preachr","upvote_count":"1","comment_id":"1287623","content":"you are reading the wrong place\\ncheck the line \\"Deployment package (.zip file archive) size\\""}],"timestamp":"1702646640.0","poster":"TanTran04"},{"poster":"anasbakla","upvote_count":"2","timestamp":"1700018820.0","content":"A and E\\nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html","comment_id":"1071038"}],"answer_description":"","extracted_at":"2025-12-24T09:00:22.132Z","extraction_method":"api_direct_v1"},{"question_id":"BiRdcoNNTU9XulJyB5CT","question_number":151,"page":31,"question_text":"A developer is troubleshooting an application in an integration environment. In the application, an Amazon Simple Queue Service (Amazon SQS) queue consumes messages and then an AWS Lambda function processes the messages. The Lambda function transforms the messages and makes an API call to a third-party service.\\n\\nThere has been an increase in application usage. The third-party API frequently returns an HTTP 429 Too Many Requests error message. The error message prevents a significant number of messages from being processed successfully.\\n\\nHow can the developer resolve this issue?","choices":{"C":"Increase the retry attempts and maximum event age in the Lambda function\u2019s asynchronous configuration.","D":"Configure maximum concurrency on the SQS event source based on the third-party service\u2019s documented rate limits.","B":"Configure provisioned concurrency for the Lambda function based on the third-party API\u2019s documented rate limits.","A":"Increase the SQS event source\u2019s batch size setting."},"correct_answer":"D","answer_ET":"D","answers_community":["D (68%)","B (26%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124821-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:26:00","unix_timestamp":1698495960,"discussion_count":12,"discussion":[{"content":"Selected Answer: D\\nhttps://aws.amazon.com/about-aws/whats-new/2023/01/aws-lambda-maximum-concurrency-amazon-sqs-event-source/","timestamp":"1700767920.0","upvote_count":"14","poster":"nickolaj","comment_id":"1078711"},{"poster":"Pangian","comment_id":"1231900","timestamp":"1718622780.0","upvote_count":"2","content":"Selected Answer: D\\nAt first i also thought of B, but D is more ideal for this scenario. \\"Restricting\\" the lambda executions will boost the SQS queue size, its better to put the \\"restriction\\" to the SQS itself"},{"content":"Selected Answer: B\\nIt has to be Option B because that is the only correct answer in Q311.\\n\\nHere is the correct answer for Q311, there is no option there for SQS concurrency:\\nB. Configure the REST API in API Gateway to write the requests directly into an Amazon Simple Queue Service (Amazon SQS) queue. **Configure the Lambda function with a reserved concurrency equal to the third-party stock application\'s threshold.** Set Lambda function to process the messages from the SQS queue.","upvote_count":"2","timestamp":"1717282920.0","comment_id":"1222936","poster":"ProfessorZ"},{"comment_id":"1216941","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","timestamp":"1716490980.0"},{"upvote_count":"1","timestamp":"1711625460.0","content":"Selected Answer: D\\nthis should bring the API in sync with the 3rd part service.","comment_id":"1184733","poster":"DeaconStJohn"},{"poster":"yingying920928","upvote_count":"1","comment_id":"1175788","content":"Selected Answer: B\\nConfiguring maximum concurrency on the SQS event source does not directly address the issue of the Lamba function making excessive requests to the third-party service (while it may help indirectly). While Option B: configuring provisioned concurrency for the Lambda function, directly addresses the issue by ensuring that the function scales in a controlled manner based on the third-party API\u2019s documented rate limits.","timestamp":"1710676920.0"},{"content":"Selected Answer: D\\nBy setting the maximum concurrency on the SQS event source, the developer can control the number of Lambda functions executing concurrently. This approach ensures that the rate of API calls does not exceed the rate limits set by the third-party service, thereby reducing the likelihood of encountering the HTTP 429 error. Adjusting the concurrency settings allows for better control of the throughput to match the API\u2019s capacity.","poster":"SerialiDr","timestamp":"1706262360.0","upvote_count":"3","comment_id":"1132423"},{"timestamp":"1704692400.0","content":"Selected Answer: B\\nThe developer can configure provisioned concurrency for the Lambda function based on the third-party API\'s documented rate limits. This can help to ensure that the function has sufficient concurrency to handle the incoming messages and make API calls without exceeding the rate limits of the third-party service","comment_id":"1116430","upvote_count":"2","poster":"Snape"},{"comment_id":"1068059","poster":"AMEJack","timestamp":"1699731480.0","content":"Selected Answer: C\\nProvisioned concurrency will not solve the problem as the number of instances can increase till it reaches the max number of unreserved limit (this is not reserved concurrency).","upvote_count":"1"},{"poster":"PrakashM14","timestamp":"1698828360.0","comment_id":"1059477","upvote_count":"3","content":"Selected Answer: B\\nOption B addresses the issue by configuring provisioned concurrency for the Lambda function. Provisioned concurrency ensures that a specified number of concurrent executions of the Lambda function are always available. This can help in managing the third-party API rate limits by controlling the number of simultaneous requests made to the API. By setting the provisioned concurrency to a value that aligns with the third-party API\'s rate limits, you can avoid exceeding those limits and reduce the occurrence of HTTP 429 errors."},{"timestamp":"1698546720.0","poster":"Jing2023","content":"Selected Answer: C\\nA. increase the batch size does not change how many items being processed. \\nC is from \\nConfiguring error handling for asynchronous invocation \u2014 You can set it up when creating the lambda.\\n\\nMaximum age of event \u2014 The maximum amount of time Lambda retains an event in the asynchronous event queue, up to 6 hours.\\nRetry attempts \u2014 The number of times Lambda retries when the function returns an error, between 0 and 2.","upvote_count":"1","comment_id":"1056535"},{"comment_id":"1056186","timestamp":"1698495960.0","poster":"Claire_KMT","upvote_count":"3","content":"B. Configure provisioned concurrency for the Lambda function based on the third-party API\u2019s documented rate limits."}],"answer_description":"","extracted_at":"2025-12-24T09:00:33.157Z","extraction_method":"api_direct_v1"},{"question_id":"VMYwjCm5HqyIsxa6wLOy","question_number":152,"page":31,"question_text":"A company has a three-tier application that is deployed in Amazon Elastic Container Service (Amazon ECS). The application is using an Amazon RDS for MySQL DB instance. The application performs more database reads than writes.\\n\\nDuring times of peak usage, the application\u2019s performance degrades. When this performance degradation occurs, the DB instance\u2019s ReadLatency metric in Amazon CloudWatch increases suddenly.\\n\\nHow should a developer modify the application to improve performance?","choices":{"C":"Add read capacity units (RCUs) to the DB instance.","D":"Modify the ECS task definition to increase the task memory.","B":"Scale the ECS cluster to contain more ECS instances.","A":"Use Amazon ElastiCache to cache query results."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124822-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:28:00","unix_timestamp":1698496080,"discussion_count":4,"discussion":[{"timestamp":"1721980200.0","comment_id":"1132425","poster":"SerialiDr","content":"Selected Answer: A\\nAmazon ElastiCache can significantly enhance the read performance of the application by caching frequently accessed data. This reduces the load on the RDS database by serving repeated read requests from the cache rather than querying the database each time. This is particularly effective for applications with a high read-to-write ratio and can lead to a substantial reduction in the ReadLatency metric of the database.","upvote_count":"6"},{"upvote_count":"1","timestamp":"1732395960.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216946"},{"poster":"kaes","comment_id":"1080682","timestamp":"1716724740.0","content":"Selected Answer: A\\nANS: A","upvote_count":"3"},{"poster":"Claire_KMT","upvote_count":"2","content":"A. Use Amazon ElastiCache to cache query results.","timestamp":"1714307280.0","comment_id":"1056187"}],"answer_description":"","extracted_at":"2025-12-24T09:00:33.157Z","extraction_method":"api_direct_v1"},{"question_id":"TcqtU6jlbGZSsIcP4PSt","question_number":153,"page":31,"question_text":"A company has an online web application that includes a product catalog. The catalog is stored in an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET. The application must be able to list the objects in the S3 bucket and must be able to download objects through an IAM policy.\\n\\nWhich policy allows MINIMUM access to meet these requirements?","choices":{"C":"","D":"","A":"","B":""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124825-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:37:00","unix_timestamp":1698496620,"discussion_count":4,"discussion":[{"timestamp":"1732396440.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216956","upvote_count":"3"},{"comment_id":"1098420","poster":"Certified101","upvote_count":"3","content":"Selected Answer: A\\nA is the correct answer","timestamp":"1718556240.0"},{"poster":"kaes","upvote_count":"2","content":"Selected Answer: A\\nANS: A","comment_id":"1080683","timestamp":"1716724800.0"},{"timestamp":"1714307820.0","content":"A is the correct answer.","poster":"Claire_KMT","upvote_count":"3","comment_id":"1056194"}],"answer_description":"","extracted_at":"2025-12-24T09:00:33.157Z","extraction_method":"api_direct_v1"},{"question_id":"Z9wgokLkeKROtD4ZivJz","question_number":154,"page":31,"question_text":"A developer is writing an application to encrypt files outside of AWS before uploading the files to an Amazon S3 bucket. The encryption must be symmetric and must be performed inside the application.\\n\\nHow can the developer implement the encryption in the application to meet these requirements?","choices":{"A":"Create a data key in AWS Key Management Service (AWS KMS). Use the AWS Encryption SDK to encrypt the files.","C":"Create a data key pair in AWS Key Management Service (AWS KMS). Use the AWS CLI to encrypt the files.","D":"Create a data key in AWS Key Management Service (AWS KMS). Use the AWS CLI to encrypt the files.","B":"Create a Hash-Based Message Authentication Code (HMAC) key in AWS Key Management Service (AWS KMS). Use the AWS Encryption SDK to encrypt the files."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124824-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:36:00","unix_timestamp":1698496560,"discussion_count":6,"discussion":[{"upvote_count":"6","poster":"SerialiDr","content":"Selected Answer: A\\nThis option aligns with the requirements. AWS KMS allows the creation of symmetric data keys which can be used for encryption outside of AWS. The AWS Encryption SDK is designed to simplify encryption and decryption operations, making it a suitable choice for implementing encryption within the application. The developer can use the data key obtained from AWS KMS for the encryption process.","timestamp":"1706271000.0","comment_id":"1132495"},{"poster":"Saudis","timestamp":"1730543940.0","content":"AWS Encryption SDK can used inside/outside AWS","upvote_count":"1","comment_id":"1306145"},{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216964","poster":"65703c1","upvote_count":"1","timestamp":"1716492480.0"},{"content":"Selected Answer: A\\nAAAAAA","comment_id":"1098423","poster":"Certified101","upvote_count":"2","timestamp":"1702752360.0"},{"timestamp":"1698546900.0","upvote_count":"4","poster":"Jing2023","content":"Selected Answer: A\\nC and D cannot make it within the application.","comment_id":"1056536"},{"content":"A. Create a data key in AWS Key Management Service (AWS KMS). Use the AWS Encryption SDK to encrypt the files.","upvote_count":"3","poster":"Claire_KMT","comment_id":"1056193","timestamp":"1698496560.0"}],"answer_description":"","extracted_at":"2025-12-24T09:00:33.157Z","extraction_method":"api_direct_v1"},{"question_id":"BUfH5PRvEoCMSQwqdKgK","question_number":155,"page":31,"question_text":"A developer is working on an application that is deployed on an Amazon EC2 instance. The developer needs a solution that will securely transfer files from the application to an Amazon S3 bucket.\\n\\nWhat should the developer do to meet these requirements in the MOST secure way?","choices":{"B":"Create an IAM role. Create an access key for the IAM role. Store the access key in the application\u2019s environment variables.","C":"Create an IAM role. Configure the IAM role to access the specific Amazon S3 API calls the application requires. Associate the IAM role with the EC2 instance.","D":"Configure an S3 bucket policy for the S3 bucket. Configure the S3 bucket policy to allow access for the EC2 instance ID.","A":"Create an IAM user. Create an access key for the IAM user. Store the access key in the application\u2019s environment variables."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124783-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 09:22:00","unix_timestamp":1698477720,"discussion_count":6,"discussion":[{"poster":"Claire_KMT","content":"C. Create an IAM role. Configure the IAM role to access the specific Amazon S3 API calls the application requires. Associate the IAM role with the EC2 instance.","timestamp":"1714307700.0","comment_id":"1056191","upvote_count":"10"},{"upvote_count":"8","comment_id":"1132498","timestamp":"1721988900.0","poster":"SerialiDr","content":"Selected Answer: C\\nThis approach follows AWS best practices. An IAM role can be created with the necessary permissions to access the S3 bucket. Then, this role can be associated with the EC2 instance. Applications running on the instance can then use the role\'s permissions to access S3 securely, without needing to manage access keys. This method leverages AWS\'s built-in security mechanisms and avoids the risks associated with managing static credentials."},{"timestamp":"1741628520.0","content":"Selected Answer: C\\nC is the correct answer","comment_id":"1384882","upvote_count":"1","poster":"Shamalka"},{"upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1216969","timestamp":"1732398060.0","poster":"65703c1"},{"content":"C is the correct answer","poster":"bammy","upvote_count":"6","timestamp":"1714451700.0","comment_id":"1058489"},{"poster":"didorins","timestamp":"1714288920.0","content":"Selected Answer: C\\nCreate role with required permissions. Attach it to IAM as instance profile.","upvote_count":"7","comment_id":"1056031"}],"answer_description":"","extracted_at":"2025-12-24T09:00:33.157Z","extraction_method":"api_direct_v1"},{"question_id":"Vab0e5jjAgyaLoRoHAJn","question_number":156,"page":32,"question_text":"A developer created a web API that receives requests by using an internet-facing Application Load Balancer (ALB) with an HTTPS listener. The developer configures an Amazon Cognito user pool and wants to ensure that every request to the API is authenticated through Amazon Cognito.\\n\\nWhat should the developer do to meet this requirement?","choices":{"A":"Add a listener rule to the listener to return a fixed response if the Authorization header is missing. Set the fixed response to 401 Unauthorized.","D":"Create a new target group that includes an AWS Lambda function target that validates the Authorization header by using Amazon Cognito. Associate the target group with the listener.","B":"Create an authentication action for the listener rules of the ALSet the rule action type to authenticate-cognito. Set the OnUnauthenticatedRequest field to \u201cdeny.\u201d","C":"Create an Amazon API Gateway API. Configure all API methods to be forwarded to the ALB endpoint. Create an authorizer of the COGNITO_USER_POOLS type. Configure every API method to use that authorizer."},"correct_answer":"B","answer_ET":"B","answers_community":["B (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124826-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:40:00","unix_timestamp":1698496800,"discussion_count":12,"discussion":[{"comment_id":"1132504","timestamp":"1706271900.0","poster":"SerialiDr","content":"Selected Answer: B\\nThis approach uses the built-in capabilities of the ALB to authenticate requests with Amazon Cognito. By configuring a rule action to authenticate with a Cognito user pool, the ALB can handle authentication before the request is forwarded to the target group. The OnUnauthenticatedRequest setting of \\"deny\\" ensures that unauthenticated requests are not allowed access, which aligns with the requirement to authenticate every request.","upvote_count":"10"},{"poster":"dostonbekabdullaev","timestamp":"1705817160.0","upvote_count":"6","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html#configure-user-authentication","comment_id":"1127654"},{"comment_id":"1287854","timestamp":"1727023020.0","content":"Selected Answer: B\\nOnUnauthenticatedRequest\\nThe behavior if the user is not authenticated. The following are possible values:\\n\\ndeny - Return an HTTP 401 Unauthorized error.\\n\\nallow - Allow the request to be forwarded to the target.\\n\\nauthenticate - Redirect the request to the IdP authorization endpoint. This is the default value.","upvote_count":"1","poster":"preachr"},{"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_AuthenticateCognitoActionConfig.html","timestamp":"1721012280.0","upvote_count":"1","poster":"Anandesh","comment_id":"1248036"},{"timestamp":"1718598360.0","poster":"tsangckl","comment_id":"1231717","upvote_count":"1","content":"This appear at 17 Jun exam"},{"comment_id":"1216976","timestamp":"1716493740.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer."},{"timestamp":"1705299300.0","poster":"JohnPl","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-enable-cognito-user-pool.html","upvote_count":"1","comment_id":"1123101"},{"comment_id":"1111364","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html#configure-user-authentication","poster":"rrshah83","upvote_count":"3","timestamp":"1704130620.0"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-integrate-with-cognito.html","upvote_count":"2","timestamp":"1703004360.0","poster":"c9ebec2","comment_id":"1100830"},{"content":"Selected Answer: B\\nhttps://www.examtopics.com/discussions/amazon/view/88889-exam-aws-certified-developer-associate-topic-1-question-332/","upvote_count":"3","comment_id":"1100657","timestamp":"1702992600.0","poster":"TanTran04"},{"timestamp":"1702752660.0","comment_id":"1098429","poster":"Certified101","content":"Selected Answer: C\\nI think its C - API G would work better ?","upvote_count":"1"},{"poster":"Claire_KMT","upvote_count":"2","content":"B. Create an authentication action for the listener rules of the ALSet the rule action type to authenticate-cognito. Set the OnUnauthenticatedRequest field to \u201cdeny.\u201d","comment_id":"1056196","timestamp":"1698496800.0"}],"answer_description":"","extracted_at":"2025-12-24T09:00:44.152Z","extraction_method":"api_direct_v1"},{"question_id":"IyU31TV54pIEnFzwQslk","question_number":157,"page":32,"question_text":"A company wants to deploy and maintain static websites on AWS. Each website\'s source code is hosted in one of several version control systems, including AWS CodeCommit, Bitbucket, and GitHub.\\nThe company wants to implement phased releases by using development, staging, user acceptance testing, and production environments in the AWS Cloud. Deployments to each environment must be started by code merges on the relevant Git branch. The company wants to use HTTPS for all data exchange. The company needs a solution that does not require servers to run continuously.\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Host each website on its own Amazon EC2 instance. Write a custom deployment script to bundle each website\'s static assets. Copy the assets to Amazon EC2. Set up a workflow to run the script when code is merged.","C":"Host each website in different Amazon S3 buckets for each environment. Configure AWS CodePipeline to pull source code from version control. Add an AWS CodeBuild stage to copy source code to Amazon S3.","B":"Host each website in AWS Elastic Beanstalk with multiple environments. Use the EB CLI to link each repository branch. Integrate AWS CodePipeline to automate deployments from version control code merges.","A":"Host each website by using AWS Amplify with a serverless backend. Conned the repository branches that correspond to each of the desired environments. Start deployments by merging code changes to a desired branch."},"correct_answer":"A","answer_ET":"A","answers_community":["A (87%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103646-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 08:22:00","unix_timestamp":1679556120,"discussion_count":11,"discussion":[{"timestamp":"1684046160.0","comment_id":"897317","content":"a\\nThe solution that will meet these requirements with the LEAST operational overhead is option A: Host each website by using AWS Amplify with a serverless backend. AWS Amplify is a fully managed service that allows developers to build and deploy web applications and static websites. With Amplify, developers can easily connect their repositories, such as AWS CodeCommit, Bitbucket, and GitHub, to automatically build and deploy changes to the website based on code merges. Amplify also supports phased releases with multiple environments, including development, staging, user acceptance testing, and production, which can be linked to specific branches in the repository. Additionally, Amplify uses HTTPS for all data exchange by default and has a serverless backend, which means there are no servers to maintain. Overall, this solution provides the least operational overhead while meeting all the specified requirements.","poster":"Bibay","upvote_count":"30","comments":[{"timestamp":"1685764320.0","poster":"yashika2005","upvote_count":"3","comment_id":"913241","content":"thanks a ton for all the explanations!"}]},{"timestamp":"1679556120.0","comment_id":"847921","upvote_count":"21","content":"Selected Answer: A\\nThe correct answer is A.\\nAWS Amplify is an all in one service for the requirement.\\nhttps://docs.aws.amazon.com/amplify/latest/userguide/welcome.html\\nOption C is almost correct, but it does not mention how to implement HTTPS.\\nOption B and D are wrong. They need to keep running servers.","poster":"Untamables"},{"upvote_count":"1","comments":[{"timestamp":"1734780900.0","upvote_count":"1","comment_id":"1329971","poster":"sumanshu","comments":[{"poster":"sumanshu","comment_id":"1348934","timestamp":"1738222440.0","upvote_count":"1","content":"C) Eliminated - Additional steps needed to configure CloudFront for HTTPS. Also need multiple S3 buckets (for dev, stg, prod etc).\\n\\nThough S3 is great choice, but as compare to Amplify, more effort"}],"content":"Sorry - By mistake Select \\"B\\", should be A"}],"content":"Selected Answer: B\\nA) AWS Amplify is purpose-built for deploying and hosting static websites and serverless backends with minimal operational overhead.\\n\\nB) Eliminated - Elastic Beanstalk is overkill for hosting static websites since it is designed for running full-stack web applications with servers \\n\\nC) Eliminated : S3 does not natively support branch-to-environment linking\\n\\nD) Eliminated: Using EC2 instances is entirely unnecessary for hosting static websites. It involves the highest operational overhead","timestamp":"1734780900.0","comment_id":"1329969","poster":"sumanshu"},{"upvote_count":"1","comment_id":"1326303","poster":"trieudo","content":"Selected Answer: A\\nkeyword: \\n- static websites\\n- version control systems, including AWS CodeCommit, Bitbucket, and GitHub.\\n- phased releases by using development, staging, user acceptance testing, and production environments\\n- use HTTPS for all data exchange\\n- not require servers to run continuously.\\n- LEAST operational overhead\\n\\n==> discard D: EC2 instance is not serverless, violate \'not require servers to run continuously\'\\n==> discard C: you must set up many thing manually, create each bucket for each stage,... .Violate \'LEAST operational overhead\'\\n==> Discard B: it excess capacity for \'static websites\', usually using when deploy dynamic complexity backend, you must manage EC2, ELB, Auto Scaling, ... so violate \'LEAST operational overhead\'\\n\\nA fits all requirement above","timestamp":"1734139080.0"},{"content":"Selected Answer: A\\nAmplify hosting provides a git based workflow for hosting full stack server less applications with continuous deployment.","timestamp":"1723826220.0","upvote_count":"1","poster":"Saurabh04","comment_id":"1267260"},{"comment_id":"1215037","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716302880.0","poster":"65703c1"},{"content":"Amplify is the best option here to host website / static site as well with Hosting Environment option which can pull code from github, codecommit and bitbucket. Webapp Hosting can be for different envs like Prod, Dev etc. This gives serverless hosting option along with HTTPS. S3 static website hosting has no HTTPS and EB and EC2 are running instances.","comment_id":"1201620","upvote_count":"2","timestamp":"1713989580.0","poster":"Vaibs099"},{"comment_id":"1041453","timestamp":"1697094360.0","content":"Selected Answer: A\\nCheck About AWS Amplify Hosting","upvote_count":"2","poster":"Cerakoted"},{"poster":"jayvarma","comment_id":"977026","timestamp":"1691615640.0","content":"Option A is the answer. Ofcourse, until now we have been used to the fact that we need to use S3 for static website hosting. \\n\\nBut there are a lot of requirements described in the question like the source code hosting, phased releases with different environments and HTTPS for all data exchange (which is not possible with S3 Hosting).\\n\\nAWS Amplify does all of this for you with the least operational overhead.","upvote_count":"5"},{"comment_id":"893291","timestamp":"1683649620.0","content":"For fellow ACloudGurus, I was taught to associate static website hosting to S3 buckets. But apparently, \\"least operational overhead\\" is achieved using Amplify, as it natively supports deployment to various environments and seamlessly integrates with version control systems. Whereas, S3 requires configuring multiple buckets, configuring CodePipeline and integrating with each bucket.","poster":"Devon_Fazekas","upvote_count":"4"},{"comment_id":"876282","poster":"Rpod","timestamp":"1682064960.0","content":"Selected Answer: C\\nStatic Website should be C ..using S3","comments":[{"timestamp":"1684181820.0","comment_id":"898687","content":"Sadly Static Web Hosting on S3 does not supports HTTPS . So Response is A ;-) \\n\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html","upvote_count":"8","poster":"Arnaud92","comments":[{"poster":"jipark","content":"that is critical key !! thanks a lot.","timestamp":"1691131260.0","comment_id":"971740","upvote_count":"2"}]}],"upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:00:44.152Z","extraction_method":"api_direct_v1"},{"question_id":"WVopEHBvpTmC5D3kitSY","question_number":158,"page":32,"question_text":"A company recently deployed an AWS Lambda function. A developer notices an increase in the function throttle metrics in Amazon CloudWatch.\\n\\nWhat are the MOST operationally efficient solutions to reduce the function throttling? (Choose two.)","choices":{"D":"Add the lambda:GetFunctionConcurrency action to the execution role.","A":"Migrate the function to Amazon Elastic Kubernetes Service (Amazon EKS).","C":"Increase the function\u2019s reserved concurrency.","E":"Request a service quota change for increased concurrency.","B":"Increase the maximum age of events in Lambda."},"correct_answer":"CE","answer_ET":"CE","answers_community":["CE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124827-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:41:00","unix_timestamp":1698496860,"discussion_count":6,"discussion":[{"comment_id":"1132507","upvote_count":"6","timestamp":"1721989800.0","content":"Selected Answer: CE\\nC. Increase the function\u2019s reserved concurrency.\\nReserved concurrency is a feature in AWS Lambda that allows you to allocate a specific amount of concurrency to a particular function. This ensures that the function has a dedicated amount of concurrency and is not affected by throttling due to high usage of other functions in your account. Increasing the reserved concurrency can help mitigate throttling issues, especially if the throttling is due to reaching account-level concurrency limits.\\n\\nE. Request a service quota change for increased concurrency.\\nAWS Lambda has default service quotas (formerly known as limits) for the maximum number of concurrent executions across all functions in your account. If your Lambda function is experiencing throttling due to reaching these account-level concurrency limits, requesting an increase in the service quota for Lambda concurrency can provide a solution.","poster":"SerialiDr"},{"timestamp":"1732398180.0","comment_id":"1216971","content":"Selected Answer: CE\\nCE is the correct answer.","poster":"65703c1","upvote_count":"1"},{"upvote_count":"3","poster":"KarBiswa","content":"Selected Answer: CE\\nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html#compute-and-storage\\nhttps://docs.aws.amazon.com/lambda/latest/dg/monitoring-metrics.html","timestamp":"1725343440.0","comment_id":"1164584"},{"content":"Selected Answer: CE\\nFollowing issue throttling.\\nC and E is suitable","timestamp":"1718452560.0","comment_id":"1097367","poster":"TanTran04","upvote_count":"3"},{"upvote_count":"3","comment_id":"1059460","timestamp":"1714544460.0","content":"The correct answer is C&E.","poster":"oussa_ama"},{"upvote_count":"3","comment_id":"1056197","content":"C. Increase the function\u2019s reserved concurrency: Reserved concurrency ensures that a specific number of concurrent executions are always available for your function.\\n\\nE. Request a service quota change for increased concurrency: If your application is experiencing throttling and the reserved concurrency isn\'t sufficient, you can request a service quota increase for additional concurrency.","timestamp":"1714308060.0","poster":"Claire_KMT"}],"answer_description":"","extracted_at":"2025-12-24T09:00:44.152Z","extraction_method":"api_direct_v1"},{"question_id":"Y04myiH7aED9WGQKXoGJ","question_number":159,"page":32,"question_text":"A company is creating a REST service using an Amazon API Gateway with AWS Lambda integration. The service must run different versions for testing purposes.\\n\\nWhat would be the BEST way to accomplish this?","choices":{"D":"Deploy the API versions as unique stages with unique endpoints and use stage variables to provide further context.","C":"Create an API Gateway resource policy to isolate versions and provide context to the Lambda function(s).","A":"Use an X-Version header to denote which version is being called and pass that header to the Lambda function(s).","B":"Create an API Gateway Lambda authorizer to route API clients to the correct API version."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124828-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:43:00","unix_timestamp":1698496980,"discussion_count":5,"discussion":[{"content":"Selected Answer: D\\nCreating unique stages for different versions is a common practice for managing and deploying different versions of REST APIs. => D","timestamp":"1718452680.0","comment_id":"1097369","upvote_count":"6","poster":"TanTran04"},{"comment_id":"1216979","upvote_count":"1","timestamp":"1732398960.0","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer."},{"timestamp":"1725343680.0","upvote_count":"2","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/stage-variables.html#:~:text=With%20deployment%20stages%20in%20API%20Gateway%2C%20you%20can%20manage%20multiple%20release%20stages%20for%20each%20API%2C%20such%20as%20alpha%2C%20beta%2C%20and%20production.%20Using%20stage%20variables%20you%20can%20configure%20an%20API%20deployment%20stage%20to%20interact%20with%20different%20backend%20endpoints.","poster":"KarBiswa","comment_id":"1164586"},{"comment_id":"1132593","poster":"SerialiDr","upvote_count":"3","timestamp":"1721998620.0","content":"Selected Answer: D\\nAPI Gateway allows you to create different stages for your API, each with its own configuration. These stages can represent different versions of your API (like development, test, and production). You can deploy your API to these stages and have different configurations for each stage, such as different Lambda functions, stage variables, or settings. This approach is straightforward and aligns with best practices for managing different environments in API Gateway."},{"timestamp":"1714308180.0","comment_id":"1056200","content":"D. Deploy the API versions as unique stages with unique endpoints and use stage variables to provide further context.","upvote_count":"4","poster":"Claire_KMT"}],"answer_description":"","extracted_at":"2025-12-24T09:00:44.152Z","extraction_method":"api_direct_v1"},{"question_id":"F6oYgXvYNqGr86FhHrpX","question_number":160,"page":32,"question_text":"A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the main branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application.\\n\\nThe pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application\u2019s source code, AWS CodeDeploy has not deployed the updated application as expected.\\n\\nWhat are the possible causes? (Choose two.)","choices":{"C":"One of the Amazon EC2 instances in the company\u2019s AWS CodePipeline cluster is inactive.","E":"AWS CodePipeline does not have permissions to access AWS CodeCommit.","A":"The change was not made in the main branch of the AWS CodeCommit repository.","D":"The AWS CodePipeline is incorrectly configured and is not invoking AWS CodeDeploy.","B":"One of the earlier stages in the pipeline failed and the pipeline has terminated."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (84%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124830-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:45:00","unix_timestamp":1698497100,"discussion_count":8,"discussion":[{"poster":"tapan666","comment_id":"1056560","timestamp":"1714356180.0","upvote_count":"10","content":"Selected Answer: AB\\nA. The change was not made in the main branch of the AWS CodeCommit repository: In this pipeline setup, if the change was made in a branch other than the main branch, it would not trigger the pipeline, and therefore, AWS CodeDeploy wouldn\'t deploy the updated application.\\nB. One of the earlier stages in the pipeline failed and the pipeline has terminated: If one of the preceding stages in the pipeline failed, it would prevent the subsequent stages, including AWS CodeDeploy, from being executed."},{"content":"Selected Answer: AB\\nAB is the correct answer.","timestamp":"1732399440.0","comment_id":"1216985","poster":"65703c1","upvote_count":"1"},{"comment_id":"1132598","upvote_count":"3","content":"Selected Answer: AB\\nA. The change was not made in the main branch of the AWS CodeCommit repository.\\nIf the change to the application\'s source code was not made in the main branch (or the branch that triggers the pipeline), AWS CodePipeline would not detect the change and therefore would not initiate the deployment process. It\'s crucial that changes are made in the correct branch that is configured to trigger the pipeline.\\n\\nB. One of the earlier stages in the pipeline failed and the pipeline has terminated.\\nIf any stage in AWS CodePipeline fails (such as a failure in the test or build stages in AWS CodeBuild), the pipeline stops and does not proceed to the deployment stage. It is common for pipelines to be configured to halt on failure to prevent the deployment of potentially faulty code.","poster":"SerialiDr","timestamp":"1721998800.0"},{"poster":"Certified101","content":"Selected Answer: AB\\nAB is correct - there have been no changes, so someone either merged code into the wrong branch (not triggering the pipeline) or it failed at an earlier stage. \\n\\nOther options dont make sence given the scenario","timestamp":"1718556960.0","upvote_count":"2","comment_id":"1098438"},{"timestamp":"1718037240.0","comment_id":"1092743","content":"Selected Answer: BC\\nThe delivery pipeline is triggered by changes to the main branch - so new code change should have triggered this but this cause errors for some reasons and option C","upvote_count":"1","poster":"LR2023"},{"poster":"ShawnWon","content":"AB\\nthe key word is \\"The pipeline has been operating successfully for several months and there have been no modifications.\\" So the \\"D. The codePipeline is incorrectly configured\\" is incorrect, because if the configuration is incorrect, it won\'t have been operating successfully for several months.","timestamp":"1716099960.0","upvote_count":"3","comment_id":"1074527"},{"upvote_count":"2","comment_id":"1065414","content":"Selected Answer: BD\\nB. One of the earlier stages in the pipeline failed and the pipeline has terminated.\\nD. The AWS CodePipeline is incorrectly configured and is not invoking AWS CodeDeploy.","poster":"PrakashM14","timestamp":"1715148960.0"},{"upvote_count":"1","comment_id":"1056202","timestamp":"1714308300.0","content":"B. One of the earlier stages in the pipeline failed and the pipeline has terminated.\\nD. The AWS CodePipeline is incorrectly configured and is not invoking AWS CodeDeploy.","poster":"Claire_KMT"}],"answer_description":"","extracted_at":"2025-12-24T09:00:44.152Z","extraction_method":"api_direct_v1"},{"question_id":"xJBsRBnHnSs6alQKEn5N","question_number":161,"page":33,"question_text":"A developer is building a serverless application by using AWS Serverless Application Model (AWS SAM) on multiple AWS Lambda functions. When the application is deployed, the developer wants to shift 10% of the traffic to the new deployment of the application for the first 10 minutes after deployment. If there are no issues, all traffic must switch over to the new version.\\n\\nWhich change to the AWS SAM template will meet these requirements?","choices":{"B":"Set the Deployment Preference Type to Linear10PercentEvery10Minutes. Set AutoPublishAlias property to the Lambda alias.","C":"Set the Deployment Preference Type to Canary10Percent10Minutes. Set the PreTraffic and PostTraffic properties to the Lambda alias.","D":"Set the Deployment Preference Type to Linear10PercentEvery10Minutes. Set PreTraffic and PostTraffic properties to the Lambda alias.","A":"Set the Deployment Preference Type to Canary10Percent10Minutes. Set the AutoPublishAlias property to the Lambda alias."},"correct_answer":"A","answer_ET":"A","answers_community":["A (73%)","C (28%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124747-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-27 21:39:00","unix_timestamp":1698435540,"discussion_count":23,"discussion":[{"poster":"didorins","comment_id":"1056037","content":"Selected Answer: C\\nC should be it. \\n\\nShift traffic in two batches is Canary \\nValidation is done with hooks\\n\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html","timestamp":"1698478560.0","upvote_count":"9"},{"upvote_count":"1","comment_id":"1307250","timestamp":"1730794920.0","content":"Selected Answer: A\\nA","poster":"aws_god"},{"timestamp":"1730546340.0","content":"Selected Answer: A\\nA. Set the Deployment Preference Type to Canary10Percent10Minutes. Set the AutoPublishAlias property to the Lambda alias. Most Voted","comment_id":"1306153","upvote_count":"1","poster":"Saudis"},{"poster":"MasoudK","timestamp":"1728713160.0","upvote_count":"1","content":"A is the answer. The PreTraffic and PostTraffic properties are used for specifying validation Lambda functions to run before and after traffic shifting, respectively. They are not required for the basic canary deployment scenario described.","comment_id":"1296356"},{"timestamp":"1727831820.0","poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: A\\nMyFunction:\\n Type: AWS::Serverless::Function\\n Properties:\\n # ... other properties ...\\n AutoPublishAlias: live\\n DeploymentPreference:\\n Type: Canary10Percent10Minutes","comment_id":"1292160"},{"timestamp":"1724865120.0","upvote_count":"1","poster":"wh1t4k3r","comment_id":"1274208","content":"Selected Answer: A\\nI will go with A since the question only mentions switch traffic gradually. Ideally A and C should be used as a combination."},{"upvote_count":"1","content":"Selected Answer: C\\nI feel it should be C.\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html","comment_id":"1252241","timestamp":"1721540160.0","poster":"Anandesh"},{"comment_id":"1250802","poster":"ahadh7621","upvote_count":"2","timestamp":"1721359140.0","content":"Selected Answer: A\\nAnswer is A:\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\\nWhen deploying a Lambda function gradually, CodeDeploy requires a previously deployed function version to shift traffic from. Therefore, your first deployment should be accomplished in two steps:\\n\\nStep 1: Deploy your Lambda function and automatically create aliases with AutoPublishAlias.\\n\\nStep 2: Perform your gradual deployment with DeploymentPreference."},{"poster":"65703c1","comment_id":"1216990","timestamp":"1716495000.0","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer."},{"comment_id":"1177357","timestamp":"1710854940.0","content":"Selected Answer: A\\nThis configuration specifies a canary deployment strategy where 10% of the traffic is directed to the new deployment for the first 10 minutes after deployment. If there are no issues, all traffic will automatically switch over to the new version. Setting the AutoPublishAlias property to the Lambda alias ensures that the specified alias is automatically updated after the canary period.","upvote_count":"3","poster":"41eb566"},{"upvote_count":"1","comment_id":"1164872","comments":[{"upvote_count":"1","poster":"Abdullah22","content":"change to A","timestamp":"1709478660.0","comment_id":"1164877"}],"poster":"Abdullah22","content":"I am going with C","timestamp":"1709478300.0"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\\nThe success or failure of the deployment is determined by hooks","upvote_count":"1","poster":"KarBiswa","timestamp":"1709457660.0","comment_id":"1164638"},{"upvote_count":"2","content":"Selected Answer: A\\nI go with A!","timestamp":"1709114040.0","poster":"Jisking","comment_id":"1161486"},{"upvote_count":"3","timestamp":"1706954040.0","comment_id":"1139143","content":"Selected Answer: A\\nAutoPublishAlias is a requirement.\\nPre and Post traffic handlers are nice to have","poster":"konieczny69"},{"poster":"SerialiDr","comment_id":"1132715","content":"Selected Answer: A\\nThis configuration will ensure that during deployment, 10% of the traffic is shifted to the new version for 10 minutes as a \\"canary\\" release. If no issues are detected during this period, AWS SAM will automatically shift the rest of the traffic to the new version. The AutoPublishAlias property is used to specify the alias that the AWS SAM deployment process will update to point to the new version of the function.","timestamp":"1706292180.0","upvote_count":"3"},{"upvote_count":"2","timestamp":"1704742380.0","poster":"Snape","content":"Selected Answer: A\\nset the Deployment Preference Type to Canary10Percent10Minutes and set the AutoPublishAlias property to the Lambda alias.","comment_id":"1116943"},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html","comment_id":"1111367","poster":"rrshah83","timestamp":"1704131100.0","upvote_count":"2"},{"content":"Selected Answer: A\\nHooks as post y pre are not obligatory required","poster":"Mimi666","timestamp":"1702942200.0","upvote_count":"2","comment_id":"1100114"},{"comment_id":"1094022","content":"Selected Answer: A\\nBased on ChatGPT: A. PostTraffic properties are not necessary.","timestamp":"1702347720.0","upvote_count":"2","poster":"tqiu654"},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html\\n\\nproperty to the Lambda alias.","upvote_count":"3","poster":"nickolaj","timestamp":"1700766480.0","comment_id":"1078680"},{"upvote_count":"3","comment_id":"1062138","timestamp":"1699106760.0","content":"Answer: A!\\nOption B, which uses the \\"Linear\\" deployment type, gradually shifts traffic, and doesn\'t fully meet the requirement of immediately switching all traffic if there are no issues within the first 10 minutes.","poster":"NinjaCloud"},{"upvote_count":"3","poster":"Claire_KMT","content":"A. Set the Deployment Preference Type to Canary10Percent10Minutes. Set the AutoPublishAlias property to the Lambda alias.","comment_id":"1056206","timestamp":"1698497220.0"},{"poster":"LemonGremlin","timestamp":"1698435540.0","comment_id":"1055800","content":"Option C is the best choice for a canary deployment with the specific requirements mentioned in the scenario.","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:00:55.211Z","extraction_method":"api_direct_v1"},{"question_id":"IqyerQvfKLLlxP6cFVJC","question_number":162,"page":33,"question_text":"An AWS Lambda function is running in a company\u2019s shared AWS account. The function needs to perform an additional ec2:DescribeInstances action that is directed at the company\u2019s development accounts. A developer must configure the required permissions across the accounts.\\n\\nHow should the developer configure the permissions to adhere to the principle of least privilege?","choices":{"A":"Create an IAM role in the shared account. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship between the development accounts for this role. Update the Lambda function IAM role in the shared account by adding the ec2:DescribeInstances permission to the role.","D":"Create an IAM role in the development accounts. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship with the shared account for this role. Update the Lambda function IAM role in the shared account by adding the ec2:DescribeInstances permission to the role.","C":"Create an IAM role in the shared account. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship between the development accounts for this role. Update the Lambda function IAM role in the shared account by adding the iam:AssumeRole permissions.","B":"Create an IAM role in the development accounts. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship with the shared account for this role. Update the Lambda function IAM role in the shared account by adding the iam:AssumeRole permissions."},"correct_answer":"B","answer_ET":"B","answers_community":["B (80%)","13%","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124787-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 09:40:00","unix_timestamp":1698478800,"discussion_count":8,"discussion":[{"poster":"PrakashM14","upvote_count":"8","timestamp":"1714549260.0","comment_id":"1059511","content":"Selected Answer: B\\nCreate an IAM role in the development accounts. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship with the shared account for this role. Update the Lambda function IAM role in the shared account by adding the iam:AssumeRole permissions."},{"poster":"65703c1","upvote_count":"1","timestamp":"1732400100.0","comment_id":"1216992","content":"Selected Answer: B\\nB is the correct answer."},{"timestamp":"1722010260.0","content":"Selected Answer: B\\nEstablish a trust relationship with the shared account for this role. Update the Lambda function IAM role in the shared account by adding the iam:AssumeRole permissions.","upvote_count":"2","comment_id":"1132723","poster":"SerialiDr"},{"upvote_count":"1","timestamp":"1720460220.0","comment_id":"1116947","poster":"Snape","content":"Selected Answer: B\\nClassic case of cross account access (CAA)"},{"comment_id":"1057053","upvote_count":"2","poster":"Kowsik_shashi","timestamp":"1714406100.0","content":"Selected Answer: C\\nBy using iam:AssumeRole, AWS allows you to implement the principle of least privilege, which means entities have only the permissions they require to perform specific tasks and nothing more."},{"poster":"lbaker12","content":"Selected Answer: A\\niam:AssumeRole doesn\'t exist it is sts:AssumeRole & creating IAM roles within development accounts is unnecessary work","upvote_count":"1","comment_id":"1056485","timestamp":"1714342860.0"},{"comment_id":"1056208","timestamp":"1714308660.0","poster":"Claire_KMT","content":"B. Create an IAM role in the development accounts. Add the ec2:DescribeInstances permission to the role. Establish a trust relationship with the shared account for this role. Update the Lambda function IAM role in the shared account by adding the iam:AssumeRole permissions.","upvote_count":"1"},{"timestamp":"1714290000.0","upvote_count":"3","content":"B \\nTo enable cross account AWS service actions, create role with required permissions in account which holds the resource. Enable trust relationship with account that will access the resource. Allow accessing account to assume the role.","poster":"didorins","comment_id":"1056039"}],"answer_description":"","extracted_at":"2025-12-24T09:00:55.211Z","extraction_method":"api_direct_v1"},{"question_id":"braUNwq9NDI5j3f7nl9v","question_number":163,"page":33,"question_text":"A developer is building a new application that will be deployed on AWS. The developer has created an AWS CodeCommit repository for the application. The developer has initialized a new project for the application by invoking the AWS Cloud Development Kit (AWS CDK) cdk init command.\\n\\nThe developer must write unit tests for the infrastructure as code (IaC) templates that the AWS CDK generates. The developer also must run a validation tool across all constructs in the CDK application to ensure that critical security configurations are activated.\\n\\nWhich combination of actions will meet these requirements with the LEAST development overhead? (Choose two.)","choices":{"E":"Use the CDK Aspects class to create custom rules to apply to the CDK application. Fall the stack synthesis if any violations are present.","C":"Use the CDK runtime context to set key-value pairs that must be present in the cdk.out file that the AWS CDK generates. Fail the stack synthesis if any violations are present.","B":"Use the CDK assertions module to integrate unit tests with the application. Run the unit tests in a continuous integration and continuous delivery (CI/CD) pipeline that is invoked after any commit to the repository.","A":"Use a unit testing framework to write custom unit tests against the cdk.out file that the AWS CDK generates. Run the unit tests in a continuous integration and continuous delivery (CI/CD) pipeline that is invoked after any commit to the repository.","D":"Write a script that searches the application for specific key configuration strings. Configure the script to produce a report of any security violations."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124831-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-28 14:53:00","unix_timestamp":1698497580,"discussion_count":6,"discussion":[{"content":"Selected Answer: BE\\nBE is the correct answer.","upvote_count":"1","comment_id":"1216994","poster":"65703c1","timestamp":"1732400340.0"},{"comment_id":"1132732","upvote_count":"3","poster":"SerialiDr","content":"Selected Answer: BE\\nB. The AWS CDK assertions library provides a convenient way to write unit tests for CDK applications. It allows developers to assert various aspects of the CDK constructs, such as properties and resource counts. Integrating these unit tests into the CI/CD pipeline ensures that they are automatically run after any commit, providing continuous validation of the infrastructure code.\\nE. Aspects in AWS CDK are a way to apply operations to all constructs in a CDK app or a part of the app. By using the Aspects class, the developer can create custom rules (like security configuration checks) and apply them across all constructs in the CDK application. If these rules find any violations, the stack synthesis can be set to fail, ensuring that the application adheres to critical security configurations.","timestamp":"1722010860.0"},{"timestamp":"1718811540.0","comment_id":"1100867","upvote_count":"3","content":"Selected Answer: BE\\nB: https://docs.aws.amazon.com/cdk/v2/guide/testing.html fine-grained assertions\\n\\nE: https://docs.aws.amazon.com/cdk/v2/guide/aspects.html","poster":"c9ebec2"},{"content":"Selected Answer: BE\\nOption B: \\nThe standard approach to testing AWS CDK apps uses the AWS CDK\'s assertions module\\nhttps://docs.aws.amazon.com/cdk/v2/guide/testing.html\\n\\nOption E: By using the CDK Aspects class to create custom rules, you can enforce specific conditions or checks on your CDK application, including security configurations. Failing the stack synthesis if any violations are present ensures that deployments do not proceed if critical security configurations are not met.\\nCHATGPT 3.5","comment_id":"1100694","timestamp":"1718799660.0","upvote_count":"1","poster":"TanTran04"},{"upvote_count":"1","comment_id":"1083597","content":"Option B allows writing unit tests for the infrastructure code using the built-in CDK assertions. Running them in a CI/CD pipeline on commits provides automated testing.\\n\\nOption E lets you define security validation rules as Aspects, which run on synth to catch issues early.","timestamp":"1716988080.0","poster":"deepak547"},{"poster":"Claire_KMT","content":"B. Use the CDK assertions module to integrate unit tests with the application. Run the unit tests in a continuous integration and continuous delivery (CI/CD) pipeline that is invoked after any commit to the repository.\\nE. Use the CDK Aspects class to create custom rules to apply to the CDK application. Fail the stack synthesis if any violations are present.","comment_id":"1056210","upvote_count":"3","timestamp":"1714308780.0"}],"answer_description":"","extracted_at":"2025-12-24T09:00:55.211Z","extraction_method":"api_direct_v1"},{"question_id":"cRXnrhiZ4k6lI7Pt0gU7","question_number":164,"page":33,"question_text":"An online sales company is developing a serverless application that runs on AWS. The application uses an AWS Lambda function that calculates order success rates and stores the data in an Amazon DynamoDB table. A developer wants an efficient way to invoke the Lambda function every 15 minutes.\\n\\nWhich solution will meet this requirement with the LEAST development effort?","choices":{"C":"Create an AWS Step Functions state machine. Configure the state machine to invoke the Lambda function execution role at a specified interval by using a Wait state. Set the interval to 15 minutes.","B":"Create an AWS Systems Manager document that has a script that will invoke the Lambda function on Amazon EC2. Use a Systems Manager Run Command task to run the shell script every 15 minutes.","A":"Create an Amazon EventBridge rule that has a rate expression that will run the rule every 15 minutes. Add the Lambda function as the target of the EventBridge rule.","D":"Provision a small Amazon EC2 instance. Set up a cron job that invokes the Lambda function every 15 minutes."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124748-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-27 21:42:00","unix_timestamp":1698435720,"discussion_count":5,"discussion":[{"poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1216996","timestamp":"1732400400.0","upvote_count":"2"},{"upvote_count":"3","content":"Selected Answer: A\\nAmazon EventBridge (formerly known as CloudWatch Events) allows you to set up a rule with a specific schedule using cron or rate expressions. In this case, a rate expression of rate(15 minutes) can be used. EventBridge rules can directly target a Lambda function, making this a straightforward and low-effort solution to execute the function at regular intervals.","timestamp":"1722011160.0","comment_id":"1132743","poster":"SerialiDr"},{"upvote_count":"3","content":"A. Create an Amazon EventBridge rule that has a rate expression that will run the rule every 15 minutes. Add the Lambda function as the target of the EventBridge rule.","timestamp":"1714344780.0","comment_id":"1056490","poster":"Claire_KMT"},{"comment_id":"1056042","content":"Selected Answer: A\\nRun Lambda as cron = Event Bridge","upvote_count":"4","timestamp":"1714290360.0","poster":"didorins"},{"poster":"LemonGremlin","comment_id":"1055802","timestamp":"1714246920.0","upvote_count":"4","content":"Selected Answer: A\\noption A is the most efficient and least development effort option for invoking the Lambda function every 15 minutes, as it leverages Amazon EventBridge\'s built-in scheduling capabilities and is fully serverless."}],"answer_description":"","extracted_at":"2025-12-24T09:00:55.211Z","extraction_method":"api_direct_v1"},{"question_id":"DKw7HShP18VJOJa4470j","question_number":165,"page":33,"question_text":"A company deploys a photo-processing application to an Amazon EC2 instance. The application needs to process each photo in less than 5 seconds. If processing takes longer than 5 seconds, the company\u2019s development team must receive a notification.\\n\\nHow can a developer implement the required time measurement and notification with the LEAST operational overhead?","choices":{"D":"Create an Amazon Kinesis data stream. Each time a photo is processed, publish the processing time to the data stream. Create an Amazon CloudWatch alarm that enters ALARM state if any values are more than 5 seconds. Notify the development team by using an Amazon Simple Notification Service (Amazon SNS) topic.","C":"Create an Amazon CloudWatch custom metric. Each time a photo is processed, publish the processing time as a metric value. Create a CloudWatch alarm that enters ALARM state if the average of values is greater than 5 seconds. Notify the development team by sending an Amazon Simple Email Service (Amazon SES) message.","A":"Create an Amazon CloudWatch custom metric. Each time a photo is processed, publish the processing time as a metric value. Create a CloudWatch alarm that is based on a static threshold of 5 seconds. Notify the development team by using an Amazon Simple Notification Service (Amazon SNS) topic.","B":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Each time a photo is processed, publish the processing time to the queue. Create an application to consume from the queue and to determine whether any values are more than 5 seconds. Notify the development team by using an Amazon Simple Notification Service (Amazon SNS) topic."},"correct_answer":"A","answer_ET":"A","answers_community":["A (85%)","C (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124858-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 01:56:00","unix_timestamp":1698537360,"discussion_count":5,"discussion":[{"content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/88805-exam-aws-certified-developer-associate-topic-1-question-263/","poster":"tapan666","upvote_count":"7","timestamp":"1698553080.0","comment_id":"1056571"},{"upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217001","timestamp":"1716496140.0"},{"comment_id":"1167698","timestamp":"1709790780.0","upvote_count":"2","poster":"KarBiswa","content":"Selected Answer: C\\nThe values exceeds then changes the alarm from OK to Alarm.\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html#:~:text=A%20metric%20alarm%20has,determine%20the%20alarm%20state.","comments":[{"comment_id":"1292168","upvote_count":"1","poster":"albert_kuo","content":"Option C is incorrect.\\nCloudWatch alarm should be triggered based on \\"each photo in less than 5 seconds\\" not \\"average\\"","timestamp":"1727834040.0"},{"comment_id":"1288042","content":"Opton C is wrong: CloudWantch action may not use SES, only SNS\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","poster":"preachr","upvote_count":"2","timestamp":"1727081940.0"}]},{"upvote_count":"3","comment_id":"1132750","poster":"SerialiDr","timestamp":"1706293800.0","content":"Selected Answer: A\\nThis approach directly leverages AWS services for monitoring and notification with minimal setup and maintenance. CloudWatch custom metrics can be used to track the processing time for each photo. A CloudWatch alarm can then be configured to trigger when any metric value exceeds the threshold of 5 seconds, sending a notification to the development team via an SNS topic."},{"upvote_count":"2","content":"A. Create an Amazon CloudWatch custom metric. Each time a photo is processed, publish the processing time as a metric value. Create a CloudWatch alarm that is based on a static threshold of 5 seconds. Notify the development team by using an Amazon Simple Notification Service (Amazon SNS) topic.","poster":"Claire_KMT","timestamp":"1698537360.0","comment_id":"1056493"}],"answer_description":"","extracted_at":"2025-12-24T09:00:55.211Z","extraction_method":"api_direct_v1"},{"question_id":"kVHZ8MVNLcZtBMeKiWTJ","question_number":166,"page":34,"question_text":"A company is using AWS Elastic Beanstalk to manage web applications that are running on Amazon EC2 instances. A developer needs to make configuration changes. The developer must deploy the changes to new instances only.\\n\\nWhich types of deployment can the developer use to meet this requirement? (Choose two.)","choices":{"E":"Rolling with additional batch","D":"Blue/green","A":"All at once","B":"Immutable","C":"Rolling"},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (85%)","BE (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124859-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 01:57:00","unix_timestamp":1698537420,"discussion_count":8,"discussion":[{"poster":"tapan666","timestamp":"1698553140.0","comment_id":"1056572","content":"Selected Answer: BD\\nhttps://www.examtopics.com/discussions/amazon/view/88855-exam-aws-certified-developer-associate-topic-1-question-289/","upvote_count":"8"},{"comment_id":"1132751","timestamp":"1706293920.0","upvote_count":"5","content":"Selected Answer: BD\\nB. Immutable: In an immutable deployment, AWS Elastic Beanstalk deploys the application version to a fresh group of instances in a new Auto Scaling group. Once the new instances pass health checks, they are moved to the existing Auto Scaling group, and the old instances are terminated. This approach ensures that new instances are used for the deployment, minimizing the impact on the existing environment.\\n\\nD. Blue/Green: Blue/green deployment involves deploying the new version of the application to a separate environment (the \\"green\\" environment). Once the new environment is ready and tested, the traffic is switched from the old environment (the \\"blue\\" environment) to the new one. This type of deployment is effective for ensuring that the new version is deployed on new instances and provides a straightforward way to rollback if needed.","poster":"SerialiDr"},{"comment_id":"1402345","upvote_count":"1","poster":"otabek94_30","timestamp":"1742744580.0","content":"Selected Answer: BE\\nWhy BD? As Blue/Green is related to CodeDeploy, must not it be BE?"},{"timestamp":"1727083080.0","poster":"preachr","comment_id":"1288048","content":"Selected Answer: BD\\ncorrect options : B and D","upvote_count":"1"},{"comments":[{"comment_id":"1288046","upvote_count":"1","poster":"preachr","content":"did you check the link: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html\\nthere is a table at the bottom: \\"The following table compares deployment method properties.\\"","timestamp":"1727082960.0"},{"upvote_count":"1","comment_id":"1288047","content":"option E is wong:\\n\\nRolling with an additional batch --\x3e New **and** existing instances","timestamp":"1727083020.0","poster":"preachr"}],"poster":"Saurabh04","comment_id":"1266083","content":"Selected Answer: BE\\nImmutable:\\nAn immutable deployment launches a full set of new instances running the updated version of the application alongside the existing instances.\\nIt ensures that the old instances remain untouched until the new ones pass health checks.\\nOnce validated, the old instances are terminated, resulting in minimal downtime.\\nRolling with additional batch:\\nIn a rolling deployment with an additional batch, Elastic Beanstalk launches a new batch of instances before taking any existing instances out of service.\\nThis maintains full capacity during deployments.\\nAfter successful deployment, the additional batch of instances is terminated.","upvote_count":"2","timestamp":"1723679940.0"},{"upvote_count":"1","timestamp":"1716496320.0","comment_id":"1217005","content":"Selected Answer: BD\\nBD is the correct answer.","poster":"65703c1"},{"comment_id":"1098457","poster":"Certified101","content":"Selected Answer: BD\\nBD - https://www.examtopics.com/discussions/amazon/view/88855-exam-aws-certified-developer-associate-topic-1-question-289/","upvote_count":"2","timestamp":"1702754220.0"},{"poster":"Claire_KMT","upvote_count":"2","content":"B. Immutable\\nD. Blue/green","timestamp":"1698537420.0","comment_id":"1056495"}],"answer_description":"","extracted_at":"2025-12-24T09:01:06.263Z","extraction_method":"api_direct_v1"},{"question_id":"bKwtO5rRGYoPSL9FZQ18","question_number":167,"page":34,"question_text":"A developer needs to use Amazon DynamoDB to store customer orders. The developer\u2019s company requires all customer data to be encrypted at rest with a key that the company generates.\\n\\nWhat should the developer do to meet these requirements?","choices":{"A":"Create the DynamoDB table with encryption set to None. Code the application to use the key to decrypt the data when the application reads from the table. Code the application to use the key to encrypt the data when the application writes to the table.","D":"Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS AWS managed key during creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key.","C":"Store the key by using AWS Key Management Service (AWS KMS). Create the DynamoDB table with default encryption. Include the kms:Encrypt parameter with the Amazon Resource Name (ARN) of the AWS KMS key when using the DynamoDB software development kit (SDK).","B":"Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS customer managed key during creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124860-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 01:59:00","unix_timestamp":1698537540,"discussion_count":6,"discussion":[{"timestamp":"1730549760.0","poster":"Saudis","content":"B is correct, yes it is seems D from the first look but the keyword is a \\"customer\\" not \\"aws\\" because says the key compony generated","upvote_count":"1","comment_id":"1306164"},{"comment_id":"1217007","upvote_count":"2","poster":"65703c1","timestamp":"1716496380.0","content":"Selected Answer: B\\nB is the correct answer."},{"content":"Selected Answer: B\\nhttps://aws.amazon.com/blogs/database/bring-your-own-encryption-keys-to-amazon-dynamodb/","comment_id":"1140720","poster":"joshnort","upvote_count":"2","timestamp":"1707115620.0"},{"timestamp":"1706294280.0","comment_id":"1132758","poster":"SerialiDr","upvote_count":"4","content":"Selected Answer: B\\nThis option allows the developer to use a customer-managed key in AWS KMS for encryption at rest in DynamoDB. The customer-managed key offers more flexibility and control over the key management compared to AWS managed keys. When creating the DynamoDB table, the developer can specify the KMS key to be used for encryption."},{"content":"Selected Answer: B\\nhttps://www.examtopics.com/discussions/amazon/view/78943-exam-aws-certified-developer-associate-topic-1-question-23/","comment_id":"1056573","poster":"tapan666","upvote_count":"3","timestamp":"1698553260.0"},{"content":"B. Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS customer managed key during the creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key.","comment_id":"1056497","timestamp":"1698537540.0","poster":"Claire_KMT","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:01:06.263Z","extraction_method":"api_direct_v1"},{"question_id":"aGOMiOXYpO7YLm4Rv3Xg","question_number":168,"page":34,"question_text":"A company is migrating an on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads. The company wants to refactor the code to achieve optimum read performance for queries.\\nWhich solution will meet this requirement with LEAST current and future effort?","choices":{"A":"Use a multi-AZ Amazon RDS deployment. Increase the number of connections that the code makes to the database or increase the connection pool size if a connection pool is in use.","D":"Use open source replication software to create a copy of the MySQL database on an Amazon EC2 instance. Modify the application code so that queries use the IP address of the EC2 instance.","B":"Use a multi-AZ Amazon RDS deployment. Modify the code so that queries access the secondary RDS instance.","C":"Deploy Amazon RDS with one or more read replicas. Modify the application code so that queries use the URL for the read replicas."},"correct_answer":"C","answer_ET":"C","answers_community":["C (96%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103510-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:07:00","unix_timestamp":1679432820,"discussion_count":26,"discussion":[{"content":"Selected Answer: C\\nMulti-AZ is for disaster recovery, not read scalability or performance.","upvote_count":"8","timestamp":"1683650340.0","comment_id":"893300","poster":"Devon_Fazekas"},{"upvote_count":"1","timestamp":"1748153940.0","poster":"gordilloedwin","comment_id":"1572083","content":"Selected Answer: C\\nI think is C"},{"content":"Selected Answer: C\\nA) & B) - Eliminated - Multi-AZ deployments are designed for high availability and failover, not for scaling read performance.\\n\\nD) Eliminated - significant operational overhead to set up and maintain replication between the primary database and the EC2 instance","timestamp":"1734781080.0","poster":"sumanshu","upvote_count":"2","comment_id":"1329973"},{"poster":"trieudo","comment_id":"1326309","upvote_count":"3","content":"Selected Answer: C\\nkeyword: read-heavy workloads, LEAST current and future effort\\n\\n==> discard A, B: multiAZ, just only make high availibity, option A: it make you can handler bigger cocurency request, option B you can access to secondary RDS in normal case by modifying code. Both are not help for \'read-heavy workloads\'\\n==> discard D: take time to execute, maintain, ... when use not-intergated source, violate \'LEAST current and future effort\'\\n\\nC is best choice","timestamp":"1734139980.0"},{"poster":"Piku2","comment_id":"1325432","timestamp":"1733985000.0","upvote_count":"1","content":"Selected Answer: C\\nIt should be C as we need to update the URL of the rds endpoint as it is needed to connect the application to use the read replicas for read queries."},{"timestamp":"1720367400.0","comment_id":"1243911","upvote_count":"3","content":"Option C provides the most straightforward and effective solution for improving read performance with minimal changes to the current application code and the least ongoing maintenance effort. Deploying read replicas allows for scaling read capacity and distributing read traffic efficiently.","poster":"tomchandler077"},{"timestamp":"1720115820.0","comment_id":"1242227","comments":[{"upvote_count":"1","timestamp":"1731422940.0","poster":"JonasKahnwald","comment_id":"1310658","content":"No, multi AZ is vor desaster recovery."}],"content":"Option C is wrong because deploying a read replica will be more effort then just enabling the multi-AZ with RDS and also the multi-AZ is meant for high availability that\'s why option B is correct.","poster":"nkroker","upvote_count":"1"},{"upvote_count":"1","comment_id":"1215038","timestamp":"1716303000.0","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer."},{"content":"Option A and B are both talking about Multi AZ RDS instance which gives Primary and Secondary(Non Read Replica). This is good for high availability but will not help in reads. Read replica or Multi AZ Cluster deployment is the only option to achieve high reads.","upvote_count":"1","timestamp":"1713990060.0","comment_id":"1201622","poster":"Vaibs099"},{"poster":"Dikshika","comment_id":"1198141","timestamp":"1713469620.0","upvote_count":"2","content":"C it is as it clearly mentions they want to achieve optimum read performance"},{"content":"Selected Answer: C\\nC forever","timestamp":"1712769000.0","poster":"dan_bj","comment_id":"1193176","upvote_count":"1"},{"content":"Selected Answer: C\\nC... No Question","poster":"badsati","upvote_count":"1","timestamp":"1712602980.0","comment_id":"1191782"},{"timestamp":"1712443500.0","comment_id":"1190649","upvote_count":"1","content":"Selected Answer: C\\nC. El uso de replicas de lectura, aliviana las consultas intensivas sobre la BD principal","poster":"vinfo"},{"content":"Selected Answer: B\\neasiest solution is to use multi-az rds deployment with 2 readable standby instances\\nsetting up read replica is more effort than checking a single option","comment_id":"1102568","upvote_count":"2","comments":[{"timestamp":"1711537320.0","upvote_count":"1","poster":"mghectorenjoyer69","comment_id":"1184014","content":"ni mada ra"}],"timestamp":"1703166240.0","poster":"xdkonorek2"},{"content":"Selected Answer: C\\nRead heavy access need read replicas as the right solution.","poster":"Skywalker23","comment_id":"1015673","timestamp":"1695550980.0","upvote_count":"4"},{"comment_id":"997599","upvote_count":"3","content":"Selected Answer: C\\nKeyword: heavy read","timestamp":"1693743540.0","poster":"Tony88"},{"poster":"Akash619","content":"Selected Answer: C\\nRead Replicas for high performance read operations","comment_id":"987831","upvote_count":"2","timestamp":"1692749220.0"},{"timestamp":"1691615820.0","upvote_count":"2","poster":"jayvarma","comment_id":"977028","content":"Keyword: Achieve Optimum read performance for queries.\\nAnswer: Use Read Replicas and use that specific URL for read queries."},{"upvote_count":"1","comment_id":"889821","content":"Selected Answer: C\\nC answer","timestamp":"1683266940.0","poster":"Malkia"},{"comment_id":"876283","content":"Selected Answer: C\\nC answer","poster":"Rpod","upvote_count":"3","timestamp":"1682065020.0"},{"upvote_count":"2","content":"Selected Answer: C\\nIt\'s C.","poster":"Krok","timestamp":"1680694680.0","comment_id":"862050"},{"comment_id":"848679","timestamp":"1679606100.0","poster":"Dun6","content":"Selected Answer: C\\nHeavy reads, use read replica","upvote_count":"3"},{"poster":"Untamables","timestamp":"1679556660.0","upvote_count":"4","content":"Selected Answer: C\\nC\\nhttps://aws.amazon.com/rds/features/read-replicas/","comment_id":"847932"},{"poster":"March2023","content":"Selected Answer: C\\nIt is C","timestamp":"1679545740.0","upvote_count":"2","comment_id":"847795"},{"poster":"Ajaykumarlp","upvote_count":"2","comment_id":"846935","content":"It is C","timestamp":"1679481120.0"},{"poster":"svrnvtr","upvote_count":"2","comment_id":"846351","timestamp":"1679432820.0","content":"Selected Answer: C\\nSeems like it is C"}],"answer_description":"","extracted_at":"2025-12-24T09:01:06.263Z","extraction_method":"api_direct_v1"},{"question_id":"TF8wbQ83MedZTaBAxAHA","question_number":169,"page":34,"question_text":"A company uses AWS CloudFormation to deploy an application that uses an Amazon API Gateway REST API with AWS Lambda function integration. The application uses Amazon DynamoDB for data persistence. The application has three stages: development, testing, and production. Each stage uses its own DynamoDB table.\\n\\nThe company has encountered unexpected issues when promoting changes to the production stage. The changes were successful in the development and testing stages. A developer needs to route 20% of the traffic to the new production stage API with the next production release. The developer needs to route the remaining 80% of the traffic to the existing production stage. The solution must minimize the number of errors that any single customer experiences.\\n\\nWhich approach should the developer take to meet these requirements?","choices":{"A":"Update 20% of the planned changes to the production stage. Deploy the new production stage. Monitor the results. Repeat this process five times to test all planned changes.","D":"Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes","C":"Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.","B":"Update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. Set the weight to a value of 80. Add a second record for the production domain name. Change the second routing policy to a weighted routing policy. Set the weight of the second policy to a value of 20. Change the alias of the second policy to use the testing stage API."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124861-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 02:02:00","unix_timestamp":1698537720,"discussion_count":4,"discussion":[{"upvote_count":"2","timestamp":"1732401360.0","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1217008","poster":"65703c1"},{"content":"Selected Answer: D\\nAmazon API Gateway supports canary release deployments, which are specifically designed for this type of scenario. By configuring canary settings, the developer can gradually roll out changes to a small percentage of users (20% in this case) while still serving the majority of users (80%) with the current production stage. This approach helps in minimizing the impact of potential issues with new deployments.","comment_id":"1133196","poster":"SerialiDr","timestamp":"1722063840.0","upvote_count":"3"},{"upvote_count":"3","poster":"ansobimat","content":"Selected Answer: D\\nD is correct","timestamp":"1716204720.0","comment_id":"1075429"},{"poster":"Claire_KMT","upvote_count":"2","timestamp":"1714345320.0","content":"D. Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes","comment_id":"1056499"}],"answer_description":"","extracted_at":"2025-12-24T09:01:06.263Z","extraction_method":"api_direct_v1"},{"question_id":"dFO7q90jtxzUpkeGDaY3","question_number":170,"page":34,"question_text":"A developer has created a data collection application that uses Amazon API Gateway, AWS Lambda, and Amazon S3. The application\u2019s users periodically upload data files and wait for the validation status to be reflected on a processing dashboard. The validation process is complex and time-consuming for large files.\\n\\nSome users are uploading dozens of large files and have to wait and refresh the processing dashboard to see if the files have been validated. The developer must refactor the application to immediately update the validation result on the user\u2019s dashboard without reloading the full dashboard.\\n\\nWhat is the MOST operationally efficient solution that meets these requirements?","choices":{"D":"Save the user-uploaded file and user detail to Amazon DynamoDB. Use Amazon DynamoDB Streams with Amazon Simple Notification Service (Amazon SNS) push notifications to send updates to the browser to update the user interface.","A":"Integrate the client with an API Gateway WebSocket API. Save the user-uploaded files with the WebSocket connection ID. Push the validation status to the connection ID when the processing is complete to initiate an update of the user interface.","C":"Save the user\u2019s email address along with the user-uploaded file. When the validation process is complete, send an email notification through Amazon Simple Notification Service (Amazon SNS) to the user who uploaded the file.","B":"Launch an Amazon EC2 micro instance, and set up a WebSocket server. Send the user-uploaded file and user detail to the EC2 instance after the user uploads the file. Use the WebSocket server to send updates to the user interface when the uploaded file is processed."},"correct_answer":"A","answer_ET":"A","answers_community":["A (85%)","D (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124862-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 02:05:00","unix_timestamp":1698537900,"discussion_count":9,"discussion":[{"timestamp":"1714551120.0","comment_id":"1059555","poster":"PrakashM14","content":"Selected Answer: A\\nOption B involves setting up a WebSocket server on an EC2 instance, which is more manual and may require additional management overhead. Option C relies on email notifications, which might introduce delays and may not provide the desired real-time updates. Option D involves DynamoDB and SNS, which may add complexity without the direct support for real-time updates that WebSocket provides.\\n\\nSo, Option A","upvote_count":"8"},{"poster":"AlmeroSenior","timestamp":"1747037880.0","upvote_count":"1","content":"Selected Answer: A\\nAlso had D is the best option , but looks like Dynamo Steams can directly integrate with SNS ( needs lambda ) , so A","comment_id":"1568395","comments":[{"content":"Typo There , CANT intergrate directly with SNS","timestamp":"1747037880.0","comment_id":"1568396","poster":"AlmeroSenior","upvote_count":"1"}]},{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732409160.0","poster":"65703c1","upvote_count":"1","comment_id":"1217071"},{"timestamp":"1725349860.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html\\nThe use case says the option","upvote_count":"1","poster":"KarBiswa","comment_id":"1164676"},{"poster":"SerialiDr","comment_id":"1133365","upvote_count":"3","content":"Selected Answer: A\\nThis approach leverages the real-time capabilities of WebSocket connections managed by Amazon API Gateway. When a user uploads a file, the application can associate the file with the user\'s WebSocket connection ID. Once the file validation process completes, the application can send the status directly to the connected client, allowing immediate updates to the dashboard without the need for manual refreshes.","timestamp":"1722079200.0"},{"upvote_count":"1","content":"Selected Answer: D\\nBased on ChatGPT: D.","poster":"tqiu654","comment_id":"1094033","timestamp":"1718153100.0"},{"content":"Selected Answer: A\\nA. Integrate the client with an API Gateway WebSocket API. Save the user-uploaded files with the WebSocket connection ID. Push the validation status to the connection ID when the processing is complete to initiate an update of the user interface.","upvote_count":"3","poster":"ansobimat","comment_id":"1075434","timestamp":"1716204960.0"},{"upvote_count":"2","poster":"tapan666","content":"Selected Answer: D\\nOption C could work for notifying users, it doesn\'t provide immediate updates on the user\'s dashboard. Users would need to check their email to see the validation status, which may not be as user-friendly as real-time updates on the dashboard.\\nIt adds complexity with email notifications and may result in longer delays before users see the validation results.\\n\\nOption D (using DynamoDB Streams and Amazon SNS) is preferred because it offers a more operationally efficient and real-time solution without the need for WebSocket management, email notifications, or a constantly running EC2 instance. It provides immediate updates on the user\'s dashboard while keeping operational complexity and costs to a minimum.","comment_id":"1056576","timestamp":"1714357800.0"},{"comment_id":"1056502","content":"B. Launch an Amazon EC2 micro instance, and set up a WebSocket server. Send the user-uploaded file and user detail to the EC2 instance after the user uploads the file. Use the WebSocket server to send updates to the user interface when the uploaded file is processed.\\nOR\\nD. Save the user-uploaded file and user detail to Amazon DynamoDB. Use Amazon DynamoDB Streams with Amazon Simple Notification Service (Amazon SNS) push notifications to send updates to the browser to update the user interface.","poster":"Claire_KMT","upvote_count":"1","timestamp":"1714345500.0"}],"answer_description":"","extracted_at":"2025-12-24T09:01:06.263Z","extraction_method":"api_direct_v1"},{"question_id":"caa1dSxP0JJ2qXI25axZ","question_number":171,"page":35,"question_text":"A company\u2019s developer is creating an application that uses Amazon API Gateway. The company wants to ensure that only users in the Sales department can use the application. The users authenticate to the application by using federated credentials from a third-party identity provider (IdP) through Amazon Cognito. The developer has set up an attribute mapping to map an attribute that is named Department and to pass the attribute to a custom AWS Lambda authorizer.\\n\\nTo test the access limitation, the developer sets their department to Engineering in the IdP and attempts to log in to the application. The developer is denied access. The developer then updates their department to Sales in the IdP and attempts to log in. Again, the developer is denied access. The developer checks the logs and discovers that access is being denied because the developer\u2019s access token has a department value of Engineering.\\n\\nWhich of the following is a possible reason that the developer\u2019s department is still being reported as Engineering instead of Sales?","choices":{"C":"The IAM role for the custom Lambda authorizer does not have a Department tag.","D":"The IAM role for the Amazon Cognito user pool does not have a Department tag.","A":"Authorization caching is enabled in the custom Lambda authorizer.","B":"Authorization caching is enabled on the Amazon Cognito user pool."},"correct_answer":"A","answer_ET":"A","answers_community":["A (88%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124863-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 02:09:00","unix_timestamp":1698538140,"discussion_count":12,"discussion":[{"content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/88914-exam-aws-certified-developer-associate-topic-1-question-294/","timestamp":"1698553920.0","poster":"tapan666","upvote_count":"6","comment_id":"1056579"},{"timestamp":"1731736380.0","comment_id":"1312960","poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: A\\nSet authorizerResultTtlInSeconds to 0 in API gateway"},{"upvote_count":"1","poster":"65703c1","comment_id":"1217074","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716504600.0"},{"upvote_count":"2","comment_id":"1186389","poster":"ethanluvsbooks","timestamp":"1711833900.0","content":"A is correct"},{"poster":"KarBiswa","timestamp":"1709459760.0","comment_id":"1164681","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html#:~:text=If%20access%20is%20allowed%2C%20API%20Gateway%20invokes%20the%20method.%20If%20caching%20is%20enabled%20in%20the%20authorizer%20settings%2C%20API%20Gateway%20also%20caches%20the%20policy%20so%20that%20the%20Lambda%20authorizer%20function%20doesn%27t%20need%20to%20be%20invoked%20again.","upvote_count":"3"},{"comment_id":"1141272","upvote_count":"2","timestamp":"1707149760.0","poster":"joshnort","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/configure-api-gateway-lambda-authorization-with-console.html"},{"upvote_count":"4","comment_id":"1133367","timestamp":"1706361780.0","content":"Selected Answer: A\\nWhen authorization caching is enabled in a custom Lambda authorizer, the authorizer can cache the policy associated with an access token. This caching is designed to improve performance by reducing the number of calls to the Lambda function. However, it can also lead to outdated authorization information being used if the user\'s attributes change in the identity provider (IdP) but the cached policy in the Lambda authorizer is still based on the old attributes.\\n\\nIn this case, when the developer initially logged in with the department set to Engineering, the custom Lambda authorizer created and cached a policy based on this information. Subsequently, even after the developer updated their department to Sales in the IdP, the cached policy (which still reflects the Engineering department) was used, leading to the access denial.","poster":"SerialiDr"},{"upvote_count":"1","timestamp":"1706361540.0","content":"Selected Answer: A\\nThis approach leverages the real-time capabilities of WebSocket connections managed by Amazon API Gateway. When a user uploads a file, the application can associate the file with the user\'s WebSocket connection ID. Once the file validation process completes, the application can send the status directly to the connected client, allowing immediate updates to the dashboard without the need for manual refreshes.","comment_id":"1133363","comments":[{"content":"wrongly added here, please delete","poster":"SerialiDr","timestamp":"1706361840.0","comment_id":"1133369","upvote_count":"1"}],"poster":"SerialiDr"},{"timestamp":"1702349280.0","poster":"tqiu654","upvote_count":"1","comment_id":"1094037","content":"Selected Answer: D\\nBased on ChatGPT:D"},{"timestamp":"1700065980.0","comment_id":"1071636","content":"Selected Answer: A\\nA is Correct","poster":"anasbakla","upvote_count":"3"},{"poster":"PrakashM14","content":"Selected Answer: B\\nOptions A, C, and D do not directly address the caching of user attributes in the context of Amazon Cognito. Option A refers to caching in the custom Lambda authorizer, but the issue seems more likely to be related to the Cognito user pool\'s caching mechanism. Options C and D mention IAM roles and tags, which may be relevant for other aspects of access control but are not the primary cause of the reported department value in this scenario.","timestamp":"1698833700.0","upvote_count":"2","comment_id":"1059558"},{"timestamp":"1698538140.0","content":"B. Authorization caching is enabled on the Amazon Cognito user pool.","poster":"Claire_KMT","comment_id":"1056505","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:01:17.146Z","extraction_method":"api_direct_v1"},{"question_id":"JNllk398usrMhaZLQppQ","question_number":172,"page":35,"question_text":"A company has migrated an application to Amazon EC2 instances. Automatic scaling is working well for the application user interface. However, the process to deliver shipping requests to the company\u2019s warehouse staff is encountering issues. Duplicate shipping requests are arriving, and some requests are lost or arrive out of order.\\n\\nThe company must avoid duplicate shipping requests and must process the requests in the order that the requests arrive. Requests are never more than 250 KB in size and take 5-10 minutes to process. A developer needs to rearchitect the application to improve the reliability of the delivery and processing of the requests.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda function to the SNS topic. Modify the application to write the requests to the SNS topic.","C":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) standard queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue.","A":"Create an Amazon Kinesis Data Firehose delivery stream to process the requests. Create an Amazon Kinesis data stream. Modify the application to write the requests to the Kinesis data stream.","D":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124864-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 02:12:00","unix_timestamp":1698538320,"discussion_count":6,"discussion":[{"comment_id":"1231720","poster":"tsangckl","upvote_count":"1","content":"This appear at 17 Jun exam","timestamp":"1718598480.0"},{"comment_id":"1217077","timestamp":"1716504780.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer."},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-exactly-once-processing.html\\n\\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-message-order.html","poster":"joshnort","timestamp":"1707802380.0","comment_id":"1148899","upvote_count":"3"},{"upvote_count":"4","content":"Selected Answer: D\\nAmazon SQS FIFO (First-In-First-Out) queues are designed to ensure that messages are processed exactly once and in the exact order that they are sent. This characteristic makes FIFO queues suitable for scenarios where order and uniqueness are critical. By integrating the FIFO queue with an AWS Lambda function, the developer can automate the processing of the shipping requests as they arrive in the queue.","timestamp":"1706362680.0","poster":"SerialiDr","comment_id":"1133383"},{"content":"Selected Answer: D\\nhttps://www.examtopics.com/discussions/amazon/view/88667-exam-aws-certified-developer-associate-topic-1-question-209/","timestamp":"1698554040.0","upvote_count":"3","poster":"tapan666","comment_id":"1056580"},{"poster":"Claire_KMT","timestamp":"1698538320.0","upvote_count":"3","comment_id":"1056506","content":"D. Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue."}],"answer_description":"","extracted_at":"2025-12-24T09:01:17.146Z","extraction_method":"api_direct_v1"},{"question_id":"MXdBOm6Xr2Z0VXzApMEO","question_number":173,"page":35,"question_text":"A developer is creating a machine learning (ML) pipeline in AWS Step Functions that contains AWS Lambda functions. The developer has configured an Amazon Simple Queue Service (Amazon SQS) queue to deliver ML model parameters to the ML pipeline to train ML models. The developer uploads the trained models are uploaded to an Amazon S3 bucket.\\n\\nThe developer needs a solution that can locally test the ML pipeline without making service integration calls to Amazon SQS and Amazon S3.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Use AWS Step Functions Local with mocked service integrations.","C":"Use the AWS Serverless Application Model (AWS SAM) CLI to run and locally test the Lambda functions.","A":"Use the Amazon CodeGuru Profiler to analyze the Lambda functions used in the AWS Step Functions pipeline.","B":"Use the AWS Step Functions Local Docker Image to run and locally test the Lambda functions."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/124865-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-10-29 02:13:00","unix_timestamp":1698538380,"discussion_count":8,"discussion":[{"content":"Selected Answer: D\\nAWS Step Functions Local allows developers to test Step Functions workflows on their local machines, without the need to deploy them to AWS. By using Step Functions Local, developers can simulate Step Functions and mock the integration with AWS services such as Amazon SQS and Amazon S3. This approach is ideal for testing the flow of the ML pipeline, including the interaction of Lambda functions, without actually triggering external AWS services.","comment_id":"1133423","upvote_count":"5","poster":"SerialiDr","timestamp":"1706367420.0"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/sfn-local-test-sm-exec.html","upvote_count":"2","comment_id":"1248082","timestamp":"1721019900.0","poster":"Anandesh"},{"comment_id":"1231721","upvote_count":"1","poster":"tsangckl","content":"This appear at 17 Jun exam","timestamp":"1718598480.0"},{"upvote_count":"1","comment_id":"1217087","content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","timestamp":"1716505380.0"},{"comment_id":"1164686","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/sfn-local-test-sm-exec.html","upvote_count":"1","timestamp":"1709460000.0","poster":"KarBiswa"},{"timestamp":"1701260220.0","upvote_count":"2","poster":"deepak547","content":"Step Functions Local, specifically allows mocking AWS services like SQS and S3. This enables end-to-end local testing of the state machine while simulating external calls.\\n\\nTherefore, AWS Step Functions Local with mocked integrations meets the requirements to test the pipeline offline without relying on live AWS services. This is the simplest way to achieve local testing.","comment_id":"1083413"},{"comment_id":"1056582","timestamp":"1698554160.0","upvote_count":"3","poster":"tapan666","content":"Selected Answer: D\\nD. Use AWS Step Functions Local with mocked service integrations.\\nHide Solution"},{"content":"D. Use AWS Step Functions Local with mocked service integrations.","poster":"Claire_KMT","comment_id":"1056507","timestamp":"1698538380.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:01:17.146Z","extraction_method":"api_direct_v1"},{"question_id":"Iq9jQxEmY37OagrMUMJV","question_number":174,"page":35,"question_text":"A company runs a batch processing application by using AWS Lambda functions and Amazon API Gateway APIs with deployment stages for development, user acceptance testing, and production. A development team needs to configure the APIs in the deployment stages to connect to third-party service endpoints.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Store the third-party service endpoints in Lambda layers that correspond to the stage.","D":"Store the third-party service endpoint for each environment in AWS AppConfig.","B":"Store the third-party service endpoints in API Gateway stage variables that correspond to the stage.","C":"Encode the third-party service endpoints as query parameters in the API Gateway request URL."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134248-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-20 16:24:00","unix_timestamp":1708442640,"discussion_count":4,"discussion":[{"timestamp":"1732410540.0","poster":"65703c1","upvote_count":"2","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217089"},{"timestamp":"1725350640.0","poster":"KarBiswa","upvote_count":"3","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/amazon-api-gateway-using-stage-variables.html","comment_id":"1164690"},{"comment_id":"1161063","poster":"ANDRES715","timestamp":"1724796720.0","upvote_count":"2","content":"Selected Answer: B\\nYou.com y chatGpt"},{"content":"Selected Answer: B\\nD: additional complex\\nC: this is typically used to send data to the end point. Not to configure the endpoint itself. Less secure.","upvote_count":"1","timestamp":"1724160240.0","comment_id":"1154817","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:01:17.146Z","extraction_method":"api_direct_v1"},{"question_id":"7ePq9yD5KVB7zLUDZSjb","question_number":175,"page":35,"question_text":"A developer is building a serverless application that runs on AWS. The developer wants to create an accelerated development workflow that deploys incremental changes to AWS for testing. The developer wants to deploy the incremental changes but does not want to fully deploy the entire application to AWS for every code commit.\\n\\nWhat should the developer do to meet these requirements?","choices":{"A":"Use the AWS Serverless Application Model (AWS SAM) to build the application. Use the sam sync command to deploy the incremental changes.","C":"Use the AWS Cloud Development Kit (AWS CDK) to build the application. Use the cdk synth command to deploy the incremental changes.","D":"Use the AWS Cloud Development Kit (AWS CDK) to build the application. Use the cdk bootstrap command to deploy the incremental changes.","B":"Use the AWS Serverless Application Model (AWS SAM) to build the application. Use the sam init command to deploy the incremental changes."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134067-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-17 17:17:00","unix_timestamp":1708186620,"discussion_count":5,"discussion":[{"upvote_count":"6","content":"Selected Answer: A\\nHere the answer is A - sam sync. \\nAccording to my research: \\n- cdk synth: only constructs your CloudFormation template. It does not deploy (create actual resources) it to AWS. You can take the template constructed, deploy it manually in CFN console, edit or inspect.\\n- sam init: used to initialize a new serverless application\\n- cdk bootstrap: the main purpose of cdk bootstrap is to provision a set of resources required to support the deployment of AWS CDK applications","poster":"tgv","timestamp":"1723904220.0","comment_id":"1152679"},{"comment_id":"1217161","poster":"65703c1","upvote_count":"2","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732418820.0"},{"timestamp":"1725351000.0","poster":"KarBiswa","comment_id":"1164692","content":"Selected Answer: A\\nhttps://aws.amazon.com/blogs/compute/speeding-up-incremental-changes-with-aws-sam-accelerate-and-nested-stacks/#:~:text=AWS%20SAM%20Accelerate%20enhances%20the%20development%20experience.%20It%20automatically%20observes%20local%20code%20changes%20and%20synchronizes%20them%20to%20AWS%20without%20building%20and%20deploying%20every%20function%20in%20my%20project.","upvote_count":"2"},{"poster":"ANDRES715","comment_id":"1161064","upvote_count":"1","timestamp":"1724797020.0","content":"Selected Answer: A\\nYou.com"},{"content":"Selected Answer: A\\nServerless\\ncdk synth command is not used for deploying changes. Instead, cdk synth generates an AWS CloudFormation template from the CDK app\'s code, which describes the cloud resources that need to be created or updated. It does not actually deploy those changes to AWS.","timestamp":"1724160540.0","upvote_count":"1","poster":"CrescentShared","comment_id":"1154820"}],"answer_description":"","extracted_at":"2025-12-24T09:01:17.146Z","extraction_method":"api_direct_v1"},{"question_id":"g1VSDebWrUiWy0vTZNrE","question_number":176,"page":36,"question_text":"A developer is building an application that will use an Amazon API Gateway API with an AWS Lambda backend. The team that will develop the frontend requires immediate access to the API endpoints to build the UI. To prepare the backend application for integration, the developer needs to set up endpoints. The endpoints need to return predefined HTTP status codes and JSON responses for the frontend team. The developer creates a method for an API resource.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Set the integration type to MOCK. Configure the method\'s integration request and integration response to associate a JSON responses with specific HTTP status codes.","D":"Set the integration type to MOCK. Use a method request to define HTTP status codes. Use an integration request to define JSON responses.","C":"Set the integration type to HTTP_PROXY. Configure API Gateway to pass all requests to an external placeholder API. which the team will build.","A":"Set the integration type to AWS_PROXY. Provision Lambda functions to return hardcoded JSON data."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134068-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-17 17:21:00","unix_timestamp":1708186860,"discussion_count":4,"discussion":[{"content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217164","upvote_count":"2","poster":"65703c1","timestamp":"1732419060.0"},{"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html#:~:text=MOCK%3A%20This%20type,of%20an%20API.","comment_id":"1164695","upvote_count":"2","poster":"KarBiswa","timestamp":"1725351180.0"},{"upvote_count":"1","comment_id":"1161067","poster":"ANDRES715","content":"Selected Answer: B\\nYou.com","timestamp":"1724797140.0"},{"timestamp":"1723904460.0","poster":"tgv","upvote_count":"4","comment_id":"1152683","content":"Selected Answer: B\\nthe correct answer is B"}],"answer_description":"","extracted_at":"2025-12-24T09:01:28.176Z","extraction_method":"api_direct_v1"},{"question_id":"2S8R6Bz8DRLGSeplFtVB","question_number":177,"page":36,"question_text":"A developer is migrating an application to Amazon Elastic Kubernetes Service (Amazon EKS). The developer migrates the application to Amazon Elastic Container Registry (Amazon ECR) with an EKS cluster. As part of the application migration to a new backend, the developer creates a new AWS account. The developer makes configuration changes to the application to point the application to the new AWS account and to use new backend resources. The developer successfully tests the changes within the application by deploying the pipeline.\\n\\nThe Docker image build and the pipeline deployment are successful, but the application is still connecting to the old backend. The developer finds that the application\'s configuration is still referencing the original EKS cluster and not referencing the new backend resources.\\n\\nWhich reason can explain why the application is not connecting to the new resources?","choices":{"A":"The developer did not successfully create the new AWS account.","B":"The developer added a new tag to the Docker image.","C":"The developer did not update the Docker image tag to a new version.","D":"The developer pushed the changes to a new Docker image tag."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134259-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:06:00","unix_timestamp":1708481160,"discussion_count":3,"discussion":[{"upvote_count":"1","timestamp":"1732419240.0","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","comment_id":"1217167"},{"upvote_count":"3","timestamp":"1725351600.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html#:~:text=You%20can%20identify%20an%20image%20with%20the%20repository%3Atag%20value%20or%20the%20image%20ID%20in%20the%20resulting%20command%20output","comment_id":"1164699","poster":"KarBiswa"},{"timestamp":"1724198760.0","poster":"CrescentShared","upvote_count":"3","content":"Selected Answer: C\\nB probably intended to say \'a wrong tag\' but not as clear as C.","comment_id":"1155151"}],"answer_description":"","extracted_at":"2025-12-24T09:01:28.176Z","extraction_method":"api_direct_v1"},{"question_id":"OO9KJ1ZelGBQqliUBlq8","question_number":178,"page":36,"question_text":"A developer is creating an application that reads and writes to multiple Amazon S3 buckets. The application will be deployed to an Amazon EC2 instance. The developer wants to make secure API requests from the EC2 instances without the need to manage the security credentials for the application. The developer needs to apply the principle of least privilege.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Associate the EC2 instance with an IAM role that has an AmazonS3FullAccess AWS managed policy.","A":"Create an IAM user. Create access keys and secret keys for the user. Associate the user with an IAM policy that allows s3:* permissions.","D":"Create a bucket policy on the S3 bucket that allows s3:ListBucket and s3:*Object permissions to the EC2 instance.","B":"Associate the EC2 instance with an IAM role that has an IAM policy that allows s3:ListBucket and s3:*Object permissions for specific S3 buckets."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134260-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:09:00","unix_timestamp":1708481340,"discussion_count":3,"discussion":[{"content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217174","poster":"65703c1","timestamp":"1732419720.0","upvote_count":"3"},{"content":"Habla de varios depositos S3 por eso la opcion correcta es la B ya que C no especifica cada deposito, habla de solo uno.","timestamp":"1724797620.0","poster":"ANDRES715","comment_id":"1161077","upvote_count":"1"},{"comment_id":"1155153","upvote_count":"3","content":"Selected Answer: B\\nB is correct.","poster":"CrescentShared","timestamp":"1724198940.0"}],"answer_description":"","extracted_at":"2025-12-24T09:01:28.176Z","extraction_method":"api_direct_v1"},{"question_id":"sCOMDmFzGAp1OYEj5IBQ","question_number":179,"page":36,"question_text":"A developer is creating an application that will be deployed on IoT devices. The application will send data to a RESTful API that is deployed as an AWS Lambda function. The application will assign each API request a unique identifier. The volume of API requests from the application can randomly increase at any given time of day.\\nDuring periods of request throttling, the application might need to retry requests. The API must be able to handle duplicate requests without inconsistencies or data loss.\\nWhich solution will meet these requirements?","choices":{"A":"Create an Amazon RDS for MySQL DB instance. Store the unique identifier for each request in a database table. Modify the Lambda function to check the table for the identifier before processing the request.","B":"Create an Amazon DynamoDB table. Store the unique identifier for each request in the table. Modify the Lambda function to check the table for the identifier before processing the request.","C":"Create an Amazon DynamoDB table. Store the unique identifier for each request in the table. Modify the Lambda function to return a client error response when the function receives a duplicate request.","D":"Create an Amazon ElastiCache for Memcached instance. Store the unique identifier for each request in the cache. Modify the Lambda function to check the cache for the identifier before processing the request."},"correct_answer":"B","answer_ET":"B","answers_community":["B (98%)","2%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103656-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 11:48:00","unix_timestamp":1679568480,"discussion_count":10,"discussion":[{"poster":"Devon_Fazekas","timestamp":"1683651180.0","content":"Selected Answer: B\\nI originally thought ElastiCache would provide the sufficient session management of the unique identifiers with the least latency. But apparently, the scope of this question revolves around durability, not latency. Hence, a persistent storage is better suited. And while RDS is a viable solution for durability and performance, the question specifies IoT devices which typically produce unstructured data that is better handled by No-SQL services like DynamoDB.","comment_id":"893311","upvote_count":"31"},{"comment_id":"848083","content":"Selected Answer: B\\nB\\nThe resolution is to make the Lambda function idempotent.\\nhttps://repost.aws/knowledge-center/lambda-function-idempotent\\nhttps://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/","upvote_count":"9","timestamp":"1679568480.0","poster":"Untamables"},{"timestamp":"1748154300.0","poster":"gordilloedwin","comment_id":"1572084","content":"Selected Answer: B\\nYeah, I thought of C as well... but the cache entries will be evicted sooner rather than later, and thus the new entry will be processed again. Cache is just temporary","upvote_count":"1"},{"comments":[{"content":"C) Eliminated - Returning a client error response for duplicate requests is not a good approach","comment_id":"1329983","timestamp":"1734781800.0","poster":"sumanshu","upvote_count":"2"}],"upvote_count":"4","timestamp":"1734781740.0","comment_id":"1329982","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - RDS is not as scalable as DynamoDB for handling unpredictable spikes in traffic.\\n\\nD) Eliminated - Memcached is an in-memory cache that is not designed for persistence or durability. If the instance is restarted or the data is evicted due to memory constraints, the identifiers could be lost"},{"poster":"trieudo","content":"Selected Answer: B\\nkeyword:\\n- AWS Lambda function\\n- increase at any given time\\n- retry requests\\n- handle duplicate requests\\n\\n==> Discard A, D: violate \'increase at any given time\', it is not automatically, because it is not fit with serverless service \'AWS Lambda function\'\\n==> Discard C: violate \'retry requests + handle duplicate requests\', => different response from success vs. error error, make it is non-idempotency \\n=> Discard D: violate \'inconsistencies or data loss.\' it doest not store persistent data.\\n\\nB is best solution","upvote_count":"3","comment_id":"1326315","timestamp":"1734141900.0"},{"poster":"f271c23","upvote_count":"1","timestamp":"1733458920.0","comment_id":"1322612","content":"Selected Answer: C\\nI think C has the merits to be a right answer. It has more specific handling to duplicate requests . The answer B does the same but the langugage is more explicite in option C"},{"comment_id":"1223925","upvote_count":"3","content":"Why not C?\\nAccording to the question \\"During periods of request throttling, the application might need to retry requests\\", this indicate that lambda should returns client error, so the application can make another retry request to fix the problem","comments":[{"poster":"queekao","upvote_count":"1","timestamp":"1721459520.0","comment_id":"1251587","content":"because c don\'t mention about retry actions"},{"content":"same doubt","poster":"cocolavayen","timestamp":"1720105200.0","upvote_count":"1","comment_id":"1242160"}],"timestamp":"1717478700.0","poster":"ElFaramawi"},{"comment_id":"1215040","upvote_count":"1","timestamp":"1716303180.0","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"content":"Selected Answer: B\\nConsistency: Memcached does not provide built-in support for atomic operations or conditional writes like DynamoDB does. Handling duplicate requests and ensuring consistency would require additional application logic and complexity.","timestamp":"1710176640.0","upvote_count":"1","comment_id":"1171168","poster":"Abdullah22"},{"content":"Selected Answer: B\\nCache topic.\\nSo Elastic Redis and DynamoDB both can be used as a cache solution. \\nIf you want high performance, low latency, go with Redis\\nIf you want persistent storage, go with DyanmoDB.","upvote_count":"5","comment_id":"997601","timestamp":"1693743780.0","poster":"Tony88"}],"answer_description":"","extracted_at":"2025-12-24T09:01:28.176Z","extraction_method":"api_direct_v1"},{"question_id":"eyB2Qv2OGiPUCKcdqANy","question_number":180,"page":36,"question_text":"A developer is writing an application that will retrieve sensitive data from a third-party system. The application will format the data into a PDF file. The PDF file could be more than 1 MB. The application will encrypt the data to disk by using AWS Key Management Service (AWS KMS). The application will decrypt the file when a user requests to download it. The retrieval and formatting portions of the application are complete.\\n\\nThe developer needs to use the GenerateDataKey API to encrypt the PDF file so that the PDF file can be decrypted later. The developer needs to use an AWS KMS symmetric customer managed key for encryption.\\n\\nWhich solutions will meet these requirements?","choices":{"D":"Write the plain text key from the GenerateDataKey API to disk for later use. Use the encrypted key from the GenerateDataKey API to encrypt the file by using the KMS Encrypt API.","B":"Write the plain text key from the GenerateDataKey API to disk for later use. Use the encrypted key from the GenerateDataKey API and a symmetric encryption algorithm to encrypt the file.","C":"Write the encrypted key from the GenerateDataKey API to disk for later use. Use the plaintext key from the GenerateDataKey API to encrypt the file by using the KMS Encrypt API.","A":"Write the encrypted key from the GenerateDataKey API to disk for later use. Use the plaintext key from the GenerateDataKey API and a symmetric encryption algorithm to encrypt the file."},"correct_answer":"A","answer_ET":"A","answers_community":["A (61%)","C (33%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134261-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:17:00","unix_timestamp":1708481820,"discussion_count":11,"discussion":[{"content":"Selected Answer: A\\nUsing the KMS Encrypt API to encrypt large amounts of data, such as a PDF file that could be more than 1 MB, is not efficient and can be costly. AWS KMS is designed for encrypting small amounts of data, such as encryption keys or short strings. For larger data, it\'s recommended to use a client-side encryption library with a data key generated by KMS.","upvote_count":"6","poster":"CrescentShared","timestamp":"1708481820.0","comment_id":"1155161"},{"upvote_count":"1","content":"Selected Answer: C\\nC. We use KMS Encrypt API and this method is called envelope encyrption. KMS will generate plaintext key which we have to store on the disk. We use it to encrypt file by calling KMS API","comment_id":"1395566","poster":"0bdf3af","timestamp":"1741946520.0"},{"content":"Selected Answer: A\\nTo encrypt data outside of AWS KMS:\\n\\n1) Use the GenerateDataKey operation to get a data key.\\n\\n2) Use the plaintext data key (in the Plaintext field of the response) to encrypt your data outside of AWS KMS. Then erase the plaintext data key from memory.\\n\\n3) Store the encrypted data key (in the CiphertextBlob field of the response) with the encrypted data.","poster":"preachr","timestamp":"1727181720.0","upvote_count":"1","comment_id":"1288601"},{"comment_id":"1274618","content":"Selected Answer: C\\nWhere is the KMS key element on A?","poster":"wh1t4k3r","upvote_count":"1","timestamp":"1724948580.0"},{"upvote_count":"2","timestamp":"1721525940.0","content":"The question clearly says using KMS so why would you even consider A and B","comment_id":"1252118","poster":"jyrajan69"},{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716516120.0","poster":"65703c1","upvote_count":"2","comment_id":"1217180"},{"timestamp":"1711365720.0","content":"Selected Answer: C\\nGoing with my gut.","poster":"DeaconStJohn","upvote_count":"1","comment_id":"1182424"},{"content":"Selected Answer: A\\nOption A is the most appropriate method for encrypting a PDF file using AWS KMS, where the plaintext key is used for encryption operations, and the encrypted key (not the plaintext key) is stored or managed externally for later decryption use.","poster":"SerialiDr","timestamp":"1709666280.0","comment_id":"1166700","upvote_count":"2"},{"upvote_count":"1","poster":"Abdullah22","comment_id":"1166602","content":"going with C","timestamp":"1709655180.0"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateDataKey.html","comment_id":"1164708","poster":"KarBiswa","timestamp":"1709462820.0","upvote_count":"3","comments":[{"comment_id":"1164709","poster":"KarBiswa","upvote_count":"1","comments":[{"timestamp":"1711186440.0","poster":"KarBiswa","content":"C is the option final decision","comment_id":"1180747","upvote_count":"1"}],"content":"Sorry changing it to A as C is not about saying using plain text data as customized. Though the algorithm word is confusing","timestamp":"1709463060.0"}]},{"timestamp":"1709080260.0","content":"Selected Answer: D\\nSeg\xfan la documentaci\xf3n de AWS, cuando se utiliza la API GenerateDataKey, se obtiene una clave de texto sin formato y una clave cifrada. La clave de texto sin formato se puede escribir en el disco para su uso posterior, mientras que la clave cifrada se utiliza para cifrar los datos. En este caso, el desarrollador debe escribir la clave de texto sin formato en el disco para su uso posterior y utilizar la clave cifrada para cifrar el archivo PDF mediante la API de cifrado KMS.","comment_id":"1161083","poster":"ANDRES715","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:01:28.176Z","extraction_method":"api_direct_v1"},{"question_id":"9bEqgE9jPeRW6M1znU8j","question_number":181,"page":37,"question_text":"A company runs an application on Amazon EC2 instances. The EC2 instances open connections to an Amazon RDS for SQL Server database. A developer needs to store and access the credentials and wants to automatically rotate the credentials. The developer does not want to store the credentials for the database in the code.\\n\\nWhich solution will meet these requirements in the MOST secure way?","choices":{"B":"Store the credentials as secrets in AWS Secrets Manager. Create an AWS Lambda function to update the secrets and the database. Retrieve the credentials from Secrets Manager as needed.","C":"Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance launch template to download the credentials from Amazon S3 as the instance launches. Create an AWS Lambda function to update the secrets and the database.","A":"Create an IAM role that has permissions to access the database. Attach the IAM role to the EC2 instances.","D":"Store the credentials in an Amazon DynamoDB table. Configure an Amazon CloudWatch Events rule to invoke an AWS Lambda function to periodically update the secrets and database."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133069-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-06 17:18:00","unix_timestamp":1707236280,"discussion_count":5,"discussion":[{"poster":"wh1t4k3r","timestamp":"1724949120.0","comment_id":"1274628","content":"Selected Answer: B\\nB is the only one that makes sense, but it is not practical at all.","upvote_count":"3"},{"upvote_count":"2","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","timestamp":"1716532440.0","comment_id":"1217245"},{"content":"Selected Answer: B\\nB is correct","comment_id":"1155162","poster":"CrescentShared","timestamp":"1708481820.0","upvote_count":"3"},{"comment_id":"1152694","poster":"tgv","timestamp":"1708187520.0","content":"rotation --\x3e Secrets Manager","upvote_count":"3"},{"content":"The ans is B","upvote_count":"4","poster":"VKG0507","timestamp":"1707236280.0","comment_id":"1142357"}],"answer_description":"","extracted_at":"2025-12-24T09:01:39.141Z","extraction_method":"api_direct_v1"},{"question_id":"Rxqp99FWZVRv1amxvSBP","question_number":182,"page":37,"question_text":"A company wants to test its web application more frequently. The company deploys the application by using a separate AWS CloudFormation stack for each environment. The company deploys the same CloudFormation template to each stack as the application progresses through the development lifecycle.\\n\\nA developer needs to build in notifications for the quality assurance (QA) team. The developer wants the notifications to occur for new deployments in the final preproduction environment.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create an Amazon CloudWatch alarm that monitors the metrics from CloudFormation. Filter the metrics on the stack name and the stack status. Configure the CloudWatch alarm to notify the QA team.","A":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the QA team to the Amazon SNS topic. Update the CloudFormation stack options to point to the SNS topic in the pre-production environment.","B":"Create an AWS Lambda function that notifies the QA team. Create an Amazon EventBridge rule to invoke the Lambda function on the default event bus. Filter the events on the CloudFormation service and on the CloudFormation stack Amazon Resource Name (ARN).","D":"Create an AWS Lambda function that notifies the QA team. Configure the event source mapping to receive events from CloudFormation. Specify the filtering values to limit invocations to the desired CloudFormation stack."},"correct_answer":"A","answer_ET":"A","answers_community":["A (50%)","B (50%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134262-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:37:00","unix_timestamp":1708483020,"discussion_count":10,"discussion":[{"poster":"08dc0cf","comment_id":"1578234","content":"Selected Answer: B\\nNot A: CloudFormation doesn\'t support built-in SNS notifications directly tied to stack events without using stack-level custom resources or tooling.\\nB: EventBridge allows you to monitor AWS service events, including CloudFormation stack changes","timestamp":"1750145040.0","upvote_count":"1"},{"poster":"AlmeroSenior","comment_id":"1577862","upvote_count":"1","content":"Selected Answer: B\\nSNS integration with CloudFormation is limited to stack failure notifications, not general deployment events.","timestamp":"1750051680.0"},{"comment_id":"1575426","upvote_count":"1","poster":"AlmeroSenior","content":"Selected Answer: B\\nIts B, not A - SNS topic with CloudFormation stack options: CloudFormation does not natively support sending notifications to SNS topics based on stack events unless you use custom resources or additional automation.","timestamp":"1749275040.0"},{"comment_id":"1572190","timestamp":"1748183400.0","content":"Selected Answer: B\\nThis solution is more flexible","poster":"egosselin","upvote_count":"1"},{"poster":"albert_kuo","upvote_count":"1","timestamp":"1721873220.0","content":"Selected Answer: B\\nB is the correct answer.\\nHere\'s why:\\n\\nIt uses EventBridge to capture CloudFormation stack events.\\nIt allows filtering based on the CloudFormation service and the specific stack ARN, which can be used to identify the pre-production environment.\\nThe Lambda function can be customized to send notifications to the QA team in any desired format (email, Slack, etc.).\\nThis setup will automatically trigger for new deployments in the specified environment.","comment_id":"1254652","comments":[{"content":"{\\n \\"source\\": [\\"aws.cloudformation\\"],\\n \\"detail-type\\": [\\"CloudFormation Stack Status Change\\"],\\n \\"detail\\": {\\n \\"stack-id\\": [\\"arn:aws:cloudformation:your-region:your-account-id:stack/your-stack-name/*\\"],\\n \\"status\\": [\\"CREATE_COMPLETE\\", \\"UPDATE_COMPLETE\\"]\\n }\\n}","timestamp":"1727842380.0","poster":"albert_kuo","comment_id":"1292202","upvote_count":"1"}]},{"poster":"65703c1","upvote_count":"2","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217248","timestamp":"1716532680.0"},{"timestamp":"1711866000.0","content":"Answer: A\\nSo I was also confused about this. But you can add an SNS topic to cloud formation: \\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-sns-topic.html (The AWS::SNS::Topic resource creates a topic to which notifications can be published.)\\nhttps://stackoverflow.com/questions/34792724/adding-cloudformation-stack-events-to-sns","poster":"ethanluvsbooks","comment_id":"1186624","upvote_count":"3"},{"poster":"SerialiDr","upvote_count":"4","content":"Selected Answer: A\\nA. This option involves creating an SNS topic to which the QA team subscribes. CloudFormation can indeed integrate with SNS to send notifications about stack events, making this a viable way to notify the QA team of deployment updates specifically in the pre-production environment if the CloudFormation stack in that environment is configured to publish events to this SNS topic.\\n\\nBased on these considerations, options A and B are the most directly relevant and practical solutions for the given requirements, with option A (SNS topic for direct CloudFormation notifications) being the most straightforward to implement for notifying the QA team of new deployments in the pre-production environment, and option B (Lambda and EventBridge) offering a more customizable solution that can filter and handle notifications based on specific criteria related to CloudFormation events.","comment_id":"1167380","timestamp":"1709747520.0"},{"comment_id":"1164716","upvote_count":"3","timestamp":"1709463660.0","content":"Selected Answer: B\\nhttps://aws.amazon.com/about-aws/whats-new/2022/07/aws-cloudformation-event-notifications-amazon-eventbridge-event-driven-applications/","poster":"KarBiswa"},{"upvote_count":"2","poster":"CrescentShared","timestamp":"1708483020.0","comment_id":"1155177","content":"Selected Answer: A\\nA is correct."}],"answer_description":"","extracted_at":"2025-12-24T09:01:39.141Z","extraction_method":"api_direct_v1"},{"question_id":"5iuot2sJkoPLnZiV55Lf","question_number":183,"page":37,"question_text":"A developer manages three AWS accounts. Each account contains an Amazon RDS DB instance in a private subnet. The developer needs to define users in each database in a consistent way. The developer must ensure that the same users are created and updated later in all three accounts.\\n\\nWhich solution will meet these requirements with the MOST operational efficiency?","choices":{"D":"Implement an AWS Lambda function that creates the users in the database. Provide the function with the details of all three accounts.","B":"Create an AWS CloudFormation template that contains a custom resource to create the users in the database. Deploy the template in each account.","C":"Write a script that creates the users. Deploy an Amazon EC2 instance in each account to run the script on the databases. Run the script in each account.","A":"Create an AWS CloudFormation template. Declare the users in the template. Attach the users to the database. Deploy the template in each account."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134263-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:43:00","unix_timestamp":1708483380,"discussion_count":3,"discussion":[{"timestamp":"1732437660.0","comment_id":"1217250","poster":"65703c1","upvote_count":"2","content":"Selected Answer: B\\nB is the correct answer."},{"comment_id":"1164720","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html#:~:text=For%20example%2C%20you%20might%20want%20to%20include%20resources%20that%20aren%27t%20available%20as%20AWS%20CloudFormation%20resource%20types.%20You%20can%20include%20those%20resources%20by%20using%20custom%20resources.%20That%20way%20you%20can%20still%20manage%20all%20your%20related%20resources%20in%20a%20single%20stack.","poster":"KarBiswa","timestamp":"1725354660.0","upvote_count":"2"},{"poster":"CrescentShared","timestamp":"1724200980.0","upvote_count":"4","comment_id":"1155181","content":"Selected Answer: B\\nCloudFormation itself does not natively manage database users within RDS. You would need a custom resource or some additional automation to create users within the RDS instance."}],"answer_description":"","extracted_at":"2025-12-24T09:01:39.141Z","extraction_method":"api_direct_v1"},{"question_id":"oyMdOfFx2akcATeZHN5Z","question_number":184,"page":37,"question_text":"A company is building a new application that runs on AWS and uses Amazon API Gateway to expose APIs. Teams of developers are working on separate components of the application in parallel. The company wants to publish an API without an integrated backend so that teams that depend on the application backend can continue the development work before the API backend development is complete.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create API Gateway resources and set the integration type value set to HTTP_PROXY. Add mapping templates and deploy the API. Create an AWS Lambda layer that returns various HTTP status codes. Associate the Lambda layer with the API deployment.","C":"Create an EC2 application that returns mocked HTTP responses. Create API Gateway resources and set the integration type value to AWS. Create an API Gateway stage and deploy the API.","B":"Create an AWS Lambda function that returns mocked responses and various HTTP status codes. Create API Gateway resources and set the integration type value to AWS_PROXY. Deploy the API.","A":"Create API Gateway resources and set the integration type value to MOCK. Configure the method integration request and integration response to associate a response with an HTTP status code. Create an API Gateway stage and deploy the API."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134264-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:44:00","unix_timestamp":1708483440,"discussion_count":3,"discussion":[{"timestamp":"1732437840.0","upvote_count":"2","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217254"},{"content":"Selected Answer: A\\nAl crear recursos de API Gateway y establecer el tipo de integraci\xf3n en MOCK, se puede simular la respuesta de la API sin necesidad de un backend real. Esto permite que los equipos de desarrollo trabajen en paralelo en componentes separados de la aplicaci\xf3n y contin\xfaen el trabajo de desarrollo antes de que se complete el backend de la API.","comment_id":"1161104","timestamp":"1724798520.0","poster":"ANDRES715","upvote_count":"3"},{"comment_id":"1155182","poster":"CrescentShared","upvote_count":"4","content":"Selected Answer: A\\nDuplicated question.","timestamp":"1724201040.0"}],"answer_description":"","extracted_at":"2025-12-24T09:01:39.141Z","extraction_method":"api_direct_v1"},{"question_id":"2so7sUAXrD2y1EMqdl7R","question_number":185,"page":37,"question_text":"An application that runs on AWS receives messages from an Amazon Simple Queue Service (Amazon SQS) queue and processes the messages in batches. The application sends the data to another SQS queue to be consumed by another legacy application. The legacy system can take up to 5 minutes to process some transaction data.\\n\\nA developer wants to ensure that there are no out-of-order updates in the legacy system. The developer cannot alter the behavior of the legacy system.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Use an SQS standard queue with a SendMessageBatchRequestEntry data type. Configure the DelaySeconds values.","D":"Use an SQS FIFO queue. Configure the DelaySeconds value.","C":"Use an SQS standard queue with a SendMessageBatchRequestEntry data type. Configure the visibility timeout value.","A":"Use an SQS FIFO queue. Configure the visibility timeout value."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134265-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 03:53:00","unix_timestamp":1708483980,"discussion_count":4,"discussion":[{"upvote_count":"2","comment_id":"1217256","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732438020.0"},{"poster":"KarBiswa","content":"Selected Answer: A\\nEmphasizes on the order so A is best","timestamp":"1725354840.0","comment_id":"1164722","upvote_count":"4"},{"poster":"ANDRES715","timestamp":"1724798640.0","comment_id":"1161112","upvote_count":"4","content":"Selected Answer: A\\nAl utilizar una cola SQS FIFO, se garantiza que los mensajes se procesen en el orden en que se reciben. Esto evita actualizaciones desordenadas en el sistema heredado y asegura la coherencia en el procesamiento de los datos de transacciones.\\n\\n\\nAdem\xe1s, al configurar el valor del tiempo de espera de visibilidad, se puede controlar el tiempo durante el cual un mensaje permanece invisible para otros consumidores despu\xe9s de que un consumidor lo recibe. Esto permite que el sistema heredado tenga hasta 5 minutos para procesar algunos datos de transacciones antes de que est\xe9n disponibles para otros consumidores."},{"timestamp":"1724201580.0","content":"Selected Answer: A\\nA is correct","upvote_count":"2","poster":"CrescentShared","comment_id":"1155186"}],"answer_description":"","extracted_at":"2025-12-24T09:01:39.141Z","extraction_method":"api_direct_v1"},{"question_id":"Vjx7V0YSoAn32NDGbWqH","question_number":186,"page":38,"question_text":"A company is building a compute-intensive application that will run on a fleet of Amazon EC2 instances. The application uses attached Amazon Elastic Block Store (Amazon EBS) volumes for storing data. The Amazon EBS volumes will be created at time of initial deployment. The application will process sensitive information. All of the data must be encrypted. The solution should not impact the application\'s performance.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Configure the application to write all data to an encrypted Amazon S3 bucket.","C":"Configure a custom encryption algorithm for the application that will encrypt and decrypt all data.","A":"Configure the fleet of EC2 instances to use encrypted EBS volumes to store data.","D":"Configure an Amazon Machine Image (AMI) that has an encrypted root volume and store the data to ephemeral disks."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134266-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 04:03:00","unix_timestamp":1708484580,"discussion_count":3,"discussion":[{"poster":"CrescentShared","upvote_count":"6","comment_id":"1155197","content":"Selected Answer: A\\nOption B is not ideal because writing all data to an S3 bucket would introduce network latency and might impact performance.\\nBy default, Amazon EBS volumes can only be attached to one EC2 instance at a time, and they cannot be mounted to multiple instances simultaneously. However, AWS does offer a feature called Amazon EBS Multi-Attach, which allows you to attach a Provisioned IOPS SSD (io1 or io2) EBS volume to up to 16 Nitro-based EC2 instances within the same Availability Zone. This feature is designed for applications that require concurrent access to the same data from multiple instances, such as clustered databases or parallel file systems.","timestamp":"1724202180.0"},{"comment_id":"1217260","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","upvote_count":"1","timestamp":"1732438740.0"},{"timestamp":"1725639480.0","poster":"SerialiDr","comment_id":"1167392","content":"Selected Answer: A\\nThis approach directly meets the requirement for encryption without impacting performance significantly. AWS EBS encryption offers encryption at rest and integrates with AWS Key Management Service (AWS KMS) for managing encryption keys. This encryption happens transparently to the applications using the EBS volumes, thus not affecting performance in a manner that would be significant for most compute-intensive applications.","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:01:50.161Z","extraction_method":"api_direct_v1"},{"question_id":"pPs6Un1Tu0EnY6IVMTqg","question_number":187,"page":38,"question_text":"A developer is updating the production version of an AWS Lambda function to fix a defect. The developer has tested the updated code in a test environment. The developer wants to slowly roll out the updates to a small subset of production users before rolling out the changes to all users. Only 10% of the users should be initially exposed to the new code in production.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Update the Lambda code and create a new version of the Lambda function. Create a Lambda function alias. Configure the traffic weights in the Lambda alias between the two Lambda function versions. Send 90% of the traffic to the production version, and send 10% of the traffic to the new version.","A":"Update the Lambda code and create a new version of the Lambda function. Create a Lambda function trigger. Configure the traffic weights in the trigger between the two Lambda function versions. Send 90% of the traffic to the production version, and send 10% of the traffic to the new version.","B":"Create a new Lambda function that uses the updated code. Create a Lambda alias for the production Lambda function. Configure the Lambda alias to send 90% of the traffic to the production Lambda function, and send 10% of the traffic to the test Lambda function.","C":"Update the Lambda code and create a new version of the Lambda function. Create a Lambda proxy integration. Configure the Lambda proxy to split traffic between the two Lambda function versions. Send 90% of the traffic to the production version, and send 10% of the traffic to the new version."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134267-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 04:09:00","unix_timestamp":1708484940,"discussion_count":4,"discussion":[{"comment_id":"1217263","upvote_count":"2","timestamp":"1732439100.0","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer."},{"comment_id":"1168858","poster":"KarBiswa","timestamp":"1725797580.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html","upvote_count":"3"},{"poster":"koltysh","comment_id":"1168211","timestamp":"1725722280.0","upvote_count":"2","content":"answer is D"},{"content":"Selected Answer: D\\nD is correct.","upvote_count":"4","comment_id":"1155200","timestamp":"1724202540.0","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:01:50.161Z","extraction_method":"api_direct_v1"},{"question_id":"IR30R3wvyzXQDxG4JjvW","question_number":188,"page":38,"question_text":"A developer is creating an AWS Lambda function that consumes messages from an Amazon Simple Queue Service (Amazon SQS) standard queue. The developer notices that the Lambda function processes some messages multiple times.\\n\\nHow should developer resolve this issue MOST cost-effectively?","choices":{"B":"Set up a dead-letter queue.","D":"Change the message processing to use Amazon Kinesis Data Streams instead of Amazon SQS.","A":"Change the Amazon SQS standard queue to an Amazon SQS FIFO queue by using the Amazon SQS message deduplication ID.","C":"Set the maximum concurrency limit of the AWS Lambda function to 1."},"correct_answer":"A","answer_ET":"A","answers_community":["A (73%)","C (27%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134268-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 04:26:00","unix_timestamp":1708485960,"discussion_count":7,"discussion":[{"timestamp":"1723448880.0","content":"Selected Answer: C\\nThe problem is the Lambda processes the message multiple times. This is due to Lambda concurrency mixed with VisibilityTimeout of the SQS queue.\\n\\nVisibilityTimeout defaults to 30 seconds. Using this default, if the Lambda takes longer than 30 seconds to process the message, then the message will become available again in the Queue for consumers. This means a second Lambda can come along and dequeue the same message - leading to duplicate processing. \\n\\nThis problem can be solved with A or C\\n\\nHowever - the question is asking for MOST cost effective\\n\\nThe answer MUST be C then: using Lambda Reserved Concurrency (totally free).","poster":"BrainFried","comment_id":"1264534","upvote_count":"3"},{"upvote_count":"3","timestamp":"1716534540.0","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","comment_id":"1217267"},{"upvote_count":"1","content":"The actual answers are not mentioned into the options as most cost effective remedy\\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#services-sqs-batchfailurereporting:~:text=To%20prevent%20Lambda,successfully%20processes%20them.","poster":"KarBiswa","timestamp":"1710402720.0","comment_id":"1173222"},{"comment_id":"1169474","timestamp":"1709987820.0","upvote_count":"1","content":"B is correct Because of Cost","poster":"Tchie"},{"upvote_count":"4","timestamp":"1709749260.0","comment_id":"1167393","poster":"SerialiDr","content":"Selected Answer: A\\nGiven this, based on AWS best practices, changing the Amazon SQS standard queue to an Amazon SQS FIFO (First-In, First-Out) queue using the Amazon SQS message deduplication ID (Option A) is the most effective way to ensure messages are processed once and in the order they are sent. FIFO queues are designed to prevent duplicate processing and maintain the order of messages, which aligns with the requirement to resolve the issue of Lambda functions processing some messages multiple times."},{"content":"Selected Answer: C\\nIn this case most cost effective option","comment_id":"1164723","timestamp":"1709464980.0","poster":"KarBiswa","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1709465280.0","comments":[{"comment_id":"1168870","timestamp":"1709908260.0","content":"Ideally none of the options are correct based on the documentaion","poster":"KarBiswa","upvote_count":"1"}],"comment_id":"1164724","content":"Changing it to A after consulting https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#:~:text=To%20prevent%20Lambda,successfully%20processes%20them.","poster":"KarBiswa"}]},{"content":"Selected Answer: A\\nA is correct.","poster":"CrescentShared","comment_id":"1155207","timestamp":"1708485960.0","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:01:50.161Z","extraction_method":"api_direct_v1"},{"question_id":"HBMvN5yXeBuo4X5UATIg","question_number":189,"page":38,"question_text":"A developer is optimizing an AWS Lambda function and wants to test the changes in production on a small percentage of all traffic. The Lambda function serves requests to a RE ST API in Amazon API Gateway. The developer needs to deploy their changes and perform a test in production without changing the API Gateway URL.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Define a function version for the currently deployed production Lambda function. Update the API Gateway endpoint to reference the new Lambda function version. Upload and publish the optimized Lambda function code. On the production API Gateway stage, define a canary release and set the percentage of traffic to direct to the canary release. Update the API Gateway endpoint to use the $LATEST version of the Lambda function. Publish the API to the canary stage.","B":"Define a function version for the currently deployed production Lambda function. Update the API Gateway endpoint to reference the new Lambda function version. Upload and publish the optimized Lambda function code. Update the API Gateway endpoint to use the $LATEST version of the Lambda function. Deploy a new API Gateway stage.","D":"Define a function version for the currently deployed production Lambda function. Update the API Gateway endpoint to reference the new Lambda function version. Upload and publish the optimized Lambda function code. Update the API Gateway endpoint to use the $LATEST version of the Lambda function. Deploy the API to the production API Gateway stage.","C":"Define an alias on the $LATEST version of the Lambda function. Update the API Gateway endpoint to reference the new Lambda function alias. Upload and publish the optimized Lambda function code. On the production API Gateway stage, define a canary release and set the percentage of traffic to direct to the canary release. Update the API Gateway endpoint to use the $LATEST version of the Lambda function. Publish to the canary stage."},"correct_answer":"C","answer_ET":"C","answers_community":["C (65%)","A (35%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134269-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 04:36:00","unix_timestamp":1708486560,"discussion_count":8,"discussion":[{"poster":"08dc0cf","comment_id":"1578228","timestamp":"1750143900.0","content":"Selected Answer: A\\nIncorrect use of alias on $LATEST","upvote_count":"1"},{"timestamp":"1742202900.0","upvote_count":"1","comment_id":"1399581","content":"Selected Answer: A\\nA. \\nAPI Gateway Canary deployment by using versions","poster":"0bdf3af"},{"content":"Selected Answer: A\\nThe answer is A. If you read carefully, in option C, the endpoint is going to be printed to the $LATEST version all the time. So caranr would not be in effective","comment_id":"1387764","timestamp":"1741766100.0","upvote_count":"2","poster":"Shamalka"},{"timestamp":"1731740040.0","poster":"albert_kuo","comment_id":"1312967","upvote_count":"2","content":"Selected Answer: A\\n# create Lambda version\\naws lambda publish-version --function-name myFunction\\n\\n# Update API Gateway\\naws apigateway update-integration --rest-api-id api-id --resource-id resource-id --http-method GET --patch-operations op=replace,path=/uri,value=arn:aws:lambda:region:account-id:function:myFunction:1\\n\\n# Canary Deployments\\n{\\n \\"percentTraffic\\": 10,\\n \\"useStageCache\\": false\\n}"},{"timestamp":"1716534840.0","upvote_count":"2","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217271","poster":"65703c1"},{"upvote_count":"3","poster":"KarBiswa","comment_id":"1164728","timestamp":"1709465520.0","content":"Selected Answer: C\\nC looks more perfect"},{"poster":"ANDRES715","upvote_count":"3","content":"Selected Answer: C\\nAl definir un alias en la versi\xf3n $LATEST de la funci\xf3n Lambda, el desarrollador puede referenciar este alias en el punto final de API Gateway. Luego, al cargar y publicar el c\xf3digo de funci\xf3n Lambda optimizado, se asegura de que la API Gateway haga referencia al nuevo alias de la funci\xf3n Lambda.\\n\\n\\nDespu\xe9s, en la etapa de producci\xf3n de API Gateway, se puede definir una versi\xf3n canary y establecer el porcentaje de tr\xe1fico que se dirigir\xe1 a la versi\xf3n canary. Esto permite probar los cambios en producci\xf3n en un peque\xf1o porcentaje del tr\xe1fico sin cambiar la URL de API Gateway.","comment_id":"1161133","timestamp":"1709081700.0"},{"content":"Selected Answer: C\\nA also looks good, C has an alias created and more like a practical way.","timestamp":"1708486560.0","poster":"CrescentShared","upvote_count":"3","comment_id":"1155212"}],"answer_description":"","extracted_at":"2025-12-24T09:01:50.161Z","extraction_method":"api_direct_v1"},{"question_id":"75GG4bGtcNam3RbtkMnb","question_number":190,"page":38,"question_text":"A developer wants to expand an application to run in multiple AWS Regions. The developer wants to copy Amazon Machine Images (AMIs) with the latest changes and create a new application stack in the destination Region. According to company requirements, all AMIs must be encrypted in all Regions. However, not all the AMIs that the company uses are encrypted.\\nHow can the developer expand the application to run in the destination Region while meeting the encryption requirement?","choices":{"A":"Create new AMIs, and specify encryption parameters. Copy the encrypted AMIs to the destination Region. Delete the unencrypted AMIs.","C":"Use AWS Certificate Manager (ACM) to enable encryption on the unencrypted AMIs. Copy the encrypted AMIs to the destination Region.","B":"Use AWS Key Management Service (AWS KMS) to enable encryption on the unencrypted AMIs. Copy the encrypted AMIs to the destination Region.","D":"Copy the unencrypted AMIs to the destination Region. Enable encryption by default in the destination Region."},"correct_answer":"A","answer_ET":"A","answers_community":["A (78%)","B (22%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102901-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-17 09:48:00","unix_timestamp":1679042880,"discussion_count":27,"discussion":[{"upvote_count":"26","poster":"Bibay","comment_id":"897319","content":"A. Create new AMIs, and specify encryption parameters. Copy the encrypted AMIs to the destination Region. Delete the unencrypted AMIs.\\n\\nThe best solution for meeting the encryption requirement is to create new AMIs with encryption enabled and copy them to the destination Region. By default, when an AMI is copied to another Region, it is not encrypted in the destination Region even if it is encrypted in the source Region. Therefore, the developer must create new encrypted AMIs that can be used in the destination Region. Once the new encrypted AMIs have been created, they can be copied to the destination Region. The unencrypted AMIs can then be deleted to ensure that all instances running in all Regions are using only encrypted AMIs.","timestamp":"1684046640.0"},{"content":"Selected Answer: A\\nA is correct. \\nUnencrypted AMI can\'t be encrypted after creation. Need to create new encrypted AMI then it can be copied to other regions.","timestamp":"1697139960.0","upvote_count":"11","comment_id":"1042059","poster":"Rameez1"},{"upvote_count":"3","comment_id":"1330346","content":"Selected Answer: A\\nA) Amazon Machine Images (AMIs) can be encrypted at creation time\\n\\nB) Eliminated - AWS KMS does not allow you to encrypt an existing unencrypted AMI directly.\\n\\nC) Eliminated - AWS Certificate Manager (ACM) is used for managing SSL/TLS certificates, not for encrypting AMIs.\\n\\nD) Eliminated - It does not retroactively encrypt existing AMIs.","poster":"sumanshu","comments":[{"upvote_count":"1","poster":"sumanshu","timestamp":"1738223880.0","comment_id":"1348945","content":"D) Eliminated - Though we have the option while copying the AMI to different region , we can encrypt at that time. But It will only encrypt in destination region. What about the Source region. As per question - It should be encrypted in all regions."}],"timestamp":"1734864360.0"},{"content":"Selected Answer: A\\n==> Discard B: Once an AMI is created, encryption configuration cannot be changed,\\n==> Discard C: ACM use for SSL/ TLS connection manager\\n==> Discard D: Even if assumed that \\"encryption by default\\" is enabled in the destination before copy, original AMI is still not encrypted, so condition \\"AMIs must be encrypted in all Regions\\" is not met.\\n\\nA is popular pattern:\\n1. Create a snapshot from the original AMI.\\n2. Encrypt the snapshot using an AWS KMS key.\\n3. Create a new AMI from the encrypted snapshot.\\n4. Copy the encrypted AMI to the destination region","upvote_count":"1","timestamp":"1734142860.0","comment_id":"1326320","poster":"trieudo"},{"poster":"Venky786","timestamp":"1730772180.0","comment_id":"1307171","content":"Answer is A\\nWhile AWS KMS is used to manage encryption keys, it cannot retroactively encrypt an existing unencrypted AMI. Encryption must be specified when creating or copying the AMI.","upvote_count":"1"},{"upvote_count":"1","poster":"wh1t4k3r","content":"Selected Answer: A\\nRegarding B: Once an AMI is created, encryption configuration cannot be changed, you need to create a new one and enable encryption. Another point: if you are planning to share the AMI between accounts, you cannot use AWS managed keys","timestamp":"1723810740.0","comment_id":"1267040"},{"content":"Option A ensures all AMIs are encrypted before they are copied to the destination region, meeting the encryption requirement and providing a clear and compliant process for expanding the application to multiple AWS Regions.","timestamp":"1720377600.0","comment_id":"1243972","upvote_count":"1","poster":"tomchandler077"},{"timestamp":"1716303360.0","comment_id":"1215043","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer."},{"comment_id":"1165725","timestamp":"1709563680.0","content":"Selected Answer: A\\nEncryption of an Amazon Machine Image (AMI) is typically tied to the underlying Amazon Elastic Block Store (EBS) snapshots that are associated with the AMI.\\n\\nWhen you create an AMI, you have the option to specify encryption parameters. If you choose to encrypt the root volume, the resulting AMI will be encrypted. This encryption setting applies to both the root volume and any additional EBS volumes attached to the instance.\\n\\nThe encryption status of an EBS snapshot is determined at the time of snapshot creation. Once a snapshot is created, its encryption status remains constant. If you want to encrypt a snapshot, you typically need to create a new snapshot from an encrypted volume.\\n\\nOnce an AMI is created, you generally cannot modify its encryption status directly. If you need to change the encryption status, you might need to create a new AMI from an encrypted snapshot.","poster":"TheFivePips","upvote_count":"4"},{"comment_id":"1158431","upvote_count":"1","poster":"SerialiDr","content":"Selected Answer: A\\nA.This approach ensures that all AMIs are encrypted using specified encryption parameters before they are copied to the destination Region, aligning with the company\'s encryption requirement. AWS provides the capability to encrypt AMIs during the AMI creation process and when copying AMIs between Regions. You can specify an AWS Key Management Service (AWS KMS) customer master key (CMK) during these processes to use for encryption, meeting the requirement to use a company-generated key.","timestamp":"1708842840.0"},{"upvote_count":"2","comment_id":"1100997","poster":"gqs3119","timestamp":"1703019900.0","content":"C ACM is about SSL/TLS\\nD Even if assumed that \\"encryption by default\\" is enabled in the destination before copy, original AMI is still not encrypted, so condition \\"AMIs must be encrypted in all Regions\\" is not met.\\nB I don\'t see any option in AWS Console or docs to encrypt in place existing AMI. It can be done when copying it. Option B doesn\'t handle existing unencrypted AMIs.\\nA I think, A is the best description of the procedure."},{"comment_id":"1084817","poster":"BluntFarmer","timestamp":"1701383220.0","upvote_count":"2","content":"I would go with D: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default\\nSolves must be encrypted issue once and for all plus you can copy unencrypted to encrypted","comments":[{"content":"it still keeps the unencrypted AMI untouched. You have to delete them but not mentioned as explicit as A","poster":"maurice2005","upvote_count":"2","timestamp":"1707852900.0","comment_id":"1149524"}]},{"comment_id":"1080696","timestamp":"1701007980.0","content":"Selected Answer: A\\nkms keys is regional,so when you use kms before you copy to another region,the second region still has the unencryed AMIs.so B is not correct","upvote_count":"1","poster":"walala97"},{"comment_id":"1062205","poster":"ronn555","timestamp":"1699111020.0","upvote_count":"3","content":"A\\nWhen you create an encrypted AMI and do not specify the KMS key, AWS will use the default Customer Managed Key which is the only multi-region key. If you select a KMS key from the origin region it will not work in the destination region (presently) so B is not correct."},{"timestamp":"1697093700.0","content":"Selected Answer: B\\nAnswer is B\\ncheck this link\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html#ami-copy-encryption","comment_id":"1041439","poster":"Cerakoted","comments":[{"upvote_count":"1","content":"If you read this link carefully it actually proves that B is wrong. The correct answer is A. You cannot enable encryption on an unencrypted AMI. ---\x3e an AMI backed by an unencrypted root snapshot is copied to an AMI with an encrypted root snapshot. The CopyImage action is invoked with two encryption parameters, including a customer managed key. As a result, the encryption status of the root snapshot changes, so that the target AMI is backed by a root snapshot containing the same data as the source snapshot, but encrypted using the specified key.","timestamp":"1701910980.0","comment_id":"1089881","poster":"[Removed]"}],"upvote_count":"2"},{"comment_id":"1028131","timestamp":"1696780980.0","content":"Selected Answer: B\\nHere\'s why option B is the appropriate choice:\\n\\nAWS KMS Encryption: AWS KMS is a service that allows you to easily enable encryption for your resources, including Amazon Machine Images (AMIs). You can create a customer managed key (CMK) in AWS KMS and use it to encrypt your AMIs.\\n\\nEnable Encryption on Unencrypted AMIs: You can enable encryption for unencrypted AMIs by creating a copy of the AMI and specifying the AWS KMS key to use for encryption during the copy process. This ensures that your new AMIs in the destination Region are encrypted.\\n\\nMaintain Data Integrity: This approach allows you to maintain data integrity and ensure that all AMIs are encrypted in compliance with company requirements.","poster":"manikantaJ","upvote_count":"2"},{"timestamp":"1695247020.0","comment_id":"1012627","poster":"sofiatian","content":"Selected Answer: B\\nCopy an unencrypted source AMI to an encrypted target AMI\\n\\nIn this scenario, an AMI backed by an unencrypted root snapshot is copied to an AMI with an encrypted root snapshot. The CopyImage action is invoked with two encryption parameters, including a customer managed key. As a result, the encryption status of the root snapshot changes, so that the target AMI is backed by a root snapshot containing the same data as the source snapshot, but encrypted using the specified key. \\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","upvote_count":"2"},{"comment_id":"994859","poster":"Ap1011","upvote_count":"3","content":"Answer A\\nFor any AMI copy to be encrypted the source AMI should be Encrypted first , You cant encrypt the copy of the AMI if the source Is not Encrypted","timestamp":"1693464780.0"},{"comments":[{"comment_id":"986217","timestamp":"1692595500.0","content":"B is wrong. Going with A\\n\\nYou just cant use KMS to encrypt and unencrypted snapshot, you\'ll need to first create a vol from the snapshot and select the option to encrypt it. Making A the correct answer.","upvote_count":"2","poster":"Naj_64"}],"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html#AMI-encryption-copy\\n\\n\\"Copy-image behaviors with both Encrypted and KmsKeyId set:\\nAn unencrypted snapshot is copied to a snapshot encrypted by the specified KMS key.\\"","poster":"Naj_64","timestamp":"1692419460.0","comment_id":"984940","upvote_count":"2"},{"upvote_count":"1","timestamp":"1680709980.0","poster":"sanjoysarkar","comment_id":"862256","content":"A. Is the correct answer."},{"content":"Selected Answer: A\\nI think it\'s A.\\nOption D is also correct, but in this case, your source AMI stay unencrypted.\\nOptions B and C - are incorrect, you can\'t just encrypt existing unencrypted AMI or create encrypted AMI from unencrypted EC2.","poster":"Krok","upvote_count":"2","comment_id":"862211","timestamp":"1680706740.0"},{"upvote_count":"4","timestamp":"1680587700.0","comment_id":"860691","poster":"5aga","content":"Selected Answer: A\\nread the question carefully. yes, we can use kms to encrypt ami and use in multiple regions. but you cannot direct applying kms encryption on non encrypted AMI. Answer B is wrong."},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html\\nEncrypt an unencrypted image during copy\\nIn this scenario, an AMI backed by an unencrypted root snapshot is copied to an AMI with an encrypted root snapshot. The CopyImage action is invoked with two encryption parameters, including a customer managed key.\\n\\nA is the only logical answer.","poster":"anhike","upvote_count":"6","comment_id":"852783","timestamp":"1679979060.0"},{"comment_id":"850444","content":"Selected Answer: B\\nMy vote is B","poster":"March2023","timestamp":"1679776140.0","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: A\\nyou cannot encrypt an existing unencrypted AMI. you need to create an ami with encryption enabled and change its region, so answer is B","poster":"srikanth923","comment_id":"850077","comments":[{"poster":"srikanth923","comments":[{"content":"Just looked this up you\'re right. A is the only logical answer.","comment_id":"850539","upvote_count":"1","timestamp":"1679785260.0","poster":"March2023"}],"content":"I mean A","comment_id":"850078","timestamp":"1679744040.0","upvote_count":"4"}],"timestamp":"1679744040.0"},{"comment_id":"848115","upvote_count":"2","poster":"Untamables","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html\\nOption D is wrong. You must enable the default encryption before copying the unencrypted AMIs.","timestamp":"1679570580.0"},{"poster":"aragon_saa","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/88812-exam-aws-certified-developer-associate-topic-1-question-266/","comment_id":"841806","upvote_count":"2","timestamp":"1679042880.0"}],"answer_description":"","extracted_at":"2025-12-24T09:01:50.161Z","extraction_method":"api_direct_v1"},{"question_id":"0rktX1d7GrIoklvwDYSr","question_number":191,"page":39,"question_text":"A company notices that credentials that the company uses to connect to an external software as a service (SaaS) vendor are stored in a configuration file as plaintext.\\n\\nThe developer needs to secure the API credentials and enforce automatic credentials rotation on a quarterly basis.\\n\\nWhich solution will meet these requirements MOST securely?","choices":{"C":"Store the credentials in AWS Secrets Manager and enable rotation. Configure the API to have Secrets Manager access.","B":"Retrieve temporary credentials from AWS Security Token Service (AWS STS) every 15 minutes. Use the temporary credentials when users make API calls to the SaaS vendor.","A":"Use AWS Key Management Service (AWS KMS) to encrypt the configuration file. Decrypt the configuration file when users make API calls to the SaaS vendor. Enable rotation.","D":"Store the credentials in AWS Systems Manager Parameter Store and enable rotation. Retrieve the credentials when users make API calls to the SaaS vendor."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134270-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 04:59:00","unix_timestamp":1708487940,"discussion_count":3,"discussion":[{"comment_id":"1217275","poster":"65703c1","timestamp":"1732440480.0","upvote_count":"3","content":"Selected Answer: C\\nC is the correct answer."},{"content":"answer C","comment_id":"1168225","upvote_count":"2","timestamp":"1725722940.0","poster":"koltysh"},{"timestamp":"1724205540.0","content":"Selected Answer: C\\nA too much effort.","comment_id":"1155220","upvote_count":"3","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:02:01.180Z","extraction_method":"api_direct_v1"},{"question_id":"bc4CMF8BlRAiyG0J6mCi","question_number":192,"page":39,"question_text":"A company has an application that is hosted on Amazon EC2 instances. The application stores objects in an Amazon S3 bucket and allows users to download objects from the S3 bucket. A developer turns on S3 Block Public Access for the S3 bucket. After this change, users report errors when they attempt to download objects. The developer needs to implement a solution so that only users who are signed in to the application can access objects in the S3 bucket.\\n\\nWhich combination of steps will meet these requirements in the MOST secure way? (Choose two.)","choices":{"B":"Create an IAM user with an appropriate policy. Store the access key ID and secret access key on the EC2 instances.","D":"Modify the application to use the S3 GetObject API call and to return the object handle to the user.","E":"Modify the application to delegate requests to the S3 bucket.","C":"Modify the application to use the S3 GeneratePresignedUrl API call.","A":"Create an EC2 instance profile and role with an appropriate policy. Associate the role with the EC2 instances."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (87%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134271-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:13:00","unix_timestamp":1708488780,"discussion_count":7,"discussion":[{"timestamp":"1709805000.0","content":"Selected Answer: AC\\nA. Creating an EC2 instance profile and role with an appropriate policy and associating the role with the EC2 instances follows the principle of least privilege. The EC2 instances will have temporary security credentials provided by the role, and the permissions granted to the role can be tightly controlled using IAM policies. This approach eliminates the need to manage and store long-term access keys on the EC2 instances, which can be a security risk.\\n\\nC. Using the S3 GeneratePresignedUrl API call allows the application to generate time-limited URLs that provide temporary access to objects in the S3 bucket. These pre-signed URLs can be generated for authenticated users, ensuring that only authorized users can access the objects. This approach ensures that the objects in the S3 bucket remain private and are not publicly accessible.","poster":"SerialiDr","upvote_count":"6","comment_id":"1167855"},{"comment_id":"1274639","upvote_count":"2","content":"A is correct. No doubt about it. \\nMy problem with C is this: ok, ive generated the presigned URL... now what? You need to update the app to USE de generated url, and there is no mention of that.\\nIm going with E.","poster":"wh1t4k3r","timestamp":"1724951340.0"},{"content":"Selected Answer: CE\\nOption C: Modify the application to use the S3 GeneratePresignedUrl API call:\\nGenerate a pre-signed URL for each object in the S3 bucket.\\nProvide the pre-signed URL to authenticated users.\\nUsers can use the pre-signed URL to download objects directly from S3 without exposing the bucket publicly.\\nOption E: Modify the application to delegate requests to the S3 bucket:\\nEnsure that the application handles authentication and authorization.\\nWhen a user requests an object, the application verifies their credentials and then retrieves the object from S3.\\nThis approach allows fine-grained control over access.","upvote_count":"1","timestamp":"1723689300.0","comment_id":"1266144","poster":"Saurabh04"},{"content":"Selected Answer: AC\\nAC is the correct answer.","poster":"65703c1","comment_id":"1217281","timestamp":"1716536100.0","upvote_count":"2"},{"timestamp":"1709467080.0","upvote_count":"3","poster":"KarBiswa","content":"Selected Answer: AC\\nPresigned Url and appropriate policy","comments":[{"poster":"KarBiswa","comment_id":"1164746","content":"Key ID and secret key id is the not the best of options","upvote_count":"1","timestamp":"1709467200.0"}],"comment_id":"1164744"},{"upvote_count":"1","poster":"ANDRES715","comment_id":"1161145","timestamp":"1709082000.0","content":"Selected Answer: BC\\nCree un usuario de IAM con una pol\xedtica adecuada (opci\xf3n B): El desarrollador debe crear un usuario de IAM en AWS con una pol\xedtica que permita el acceso a los objetos del dep\xf3sito S3 solo a los usuarios autenticados en la aplicaci\xf3n. Esta pol\xedtica debe tener permisos adecuados para acceder y descargar objetos del dep\xf3sito S3.\\n\\nModifique la aplicaci\xf3n para utilizar la llamada API S3 GeneratePresignedUrl (opci\xf3n C): El desarrollador debe modificar la aplicaci\xf3n para utilizar la llamada API S3 GeneratePresignedUrl. Esta llamada generar\xe1 una URL prefirmada que contiene una firma de seguridad y un tiempo de expiraci\xf3n. Solo los usuarios autenticados que tengan acceso a esta URL prefirmada podr\xe1n descargar los objetos del dep\xf3sito S3."},{"poster":"CrescentShared","timestamp":"1708488780.0","comment_id":"1155227","upvote_count":"2","content":"Selected Answer: AC\\nOption E: Modifying the application to delegate requests to the S3 bucket is less secure than using pre-signed URLs. If the application acts as a proxy for S3 requests, it would need to handle the data transfer from S3 to the user, which can increase the load on the application and potentially expose the application to additional security risks."}],"answer_description":"","extracted_at":"2025-12-24T09:02:01.180Z","extraction_method":"api_direct_v1"},{"question_id":"xSVK3ihyMPOcfNGZh1nk","question_number":193,"page":39,"question_text":"An Amazon Simple Queue Service (Amazon SQS) queue serves as an event source for an AWS Lambda function. In the SQS queue, each item corresponds to a video file that the Lambda function must convert to a smaller resolution. The Lambda function is timing out on longer video files, but the Lambda function\'s timeout is already configured to its maximum value.\\n\\nWhat should a developer do to avoid the timeouts without additional code changes?","choices":{"A":"Increase the memory configuration of the Lambda function.","D":"Use multi-threading for the conversion.","B":"Increase the visibility timeout on the SQS queue.","C":"Increase the instance size of the host that runs the Lambda function."},"correct_answer":"A","answer_ET":"A","answers_community":["A (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134272-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:23:00","unix_timestamp":1708489380,"discussion_count":5,"discussion":[{"timestamp":"1724206980.0","poster":"CrescentShared","content":"Selected Answer: A\\n\u201cWithout any additional code changes.\u201d","comment_id":"1155234","upvote_count":"9"},{"upvote_count":"1","timestamp":"1732441140.0","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","comment_id":"1217282"},{"timestamp":"1725695760.0","content":"Selected Answer: B\\nB. Increase the visibility timeout on the SQS queue.\\n\\nIncreasing the visibility timeout on the SQS queue is the most direct way to ensure that messages corresponding to longer video files are not prematurely made available for processing by another instance of the Lambda function or returned to the queue due to processing timeouts. This approach, however, does not directly address the Lambda function\'s timeout issue but rather helps manage the reprocessing of message","upvote_count":"1","comment_id":"1167863","poster":"SerialiDr"},{"timestamp":"1725357780.0","content":"Selected Answer: A\\nchanging memory configuration","poster":"KarBiswa","comment_id":"1164749","upvote_count":"2"},{"upvote_count":"4","timestamp":"1724880900.0","poster":"monishvster","comment_id":"1162046","content":"Selected Answer: A\\nIncreasing memory will also increase CPU, thereby optimizing performance of Lambda function"}],"answer_description":"","extracted_at":"2025-12-24T09:02:01.180Z","extraction_method":"api_direct_v1"},{"question_id":"DDtfYKxt6QeQJ4V9TG7a","question_number":194,"page":39,"question_text":"A company is building an application on AWS. The application\'s backend includes an Amazon API Gateway REST API. The company\'s frontend application developers cannot continue work until the backend API is ready for integration. The company needs a solution that will allow the frontend application developers to continue their work.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"B":"Integrate a Lambda function with API Gateway and return a mocked response.","D":"Configure a proxy resource for API Gateway API methods.","A":"Configure mock integrations for API Gateway API methods.","C":"Add new API endpoints to the API Gateway stage and returns a mocked response."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134273-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:25:00","unix_timestamp":1708489500,"discussion_count":5,"discussion":[{"content":"Selected Answer: A\\nA. Configure mock integrations for API Gateway API methods.\\n\\nMock integrations in Amazon API Gateway allow you to return a fixed response without sending the request further to the backend. This approach enables frontend developers to work with a predetermined response structure and data, facilitating parallel development without waiting for the backend services to be fully implemented. This solution does not require additional code changes or the deployment of placeholder backend services, making it operationally efficient and straightforward to implement for temporary use during the development phase.","comment_id":"1167865","upvote_count":"6","timestamp":"1725695880.0","poster":"SerialiDr"},{"upvote_count":"2","comment_id":"1217283","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","timestamp":"1732441320.0"},{"poster":"KarBiswa","content":"Mock integration","timestamp":"1725357840.0","upvote_count":"2","comment_id":"1164751"},{"comment_id":"1162047","poster":"monishvster","timestamp":"1724880960.0","content":"Selected Answer: A\\nmock integration","upvote_count":"1"},{"poster":"CrescentShared","upvote_count":"1","timestamp":"1724207100.0","comment_id":"1155235","content":"Selected Answer: A\\nDuplicated questions."}],"answer_description":"","extracted_at":"2025-12-24T09:02:01.180Z","extraction_method":"api_direct_v1"},{"question_id":"WJtOBA65799cggfXv8YM","question_number":195,"page":39,"question_text":"A company is preparing to migrate an application to the company\'s first AWS environment. Before this migration, a developer is creating a proof-of-concept application to validate a model for building and deploying container-based applications on AWS.\\n\\nWhich combination of steps should the developer take to deploy the containerized proof-of-concept application with the LEAST operational effort? (Choose two.)","choices":{"D":"Deploy the application to Amazon Elastic Kubernetes Service (Amazon EKS) on AWS Fargate.","A":"Package the application into a .zip file by using a command line tool. Upload the package to Amazon S3.","E":"Deploy the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.","C":"Deploy the application to an Amazon EC2 instance by using AWS CodeDeploy.","B":"Package the application into a container image by using the Docker CLI. Upload the image to Amazon Elastic Container Registry (Amazon ECR)."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134274-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:29:00","unix_timestamp":1708489740,"discussion_count":7,"discussion":[{"upvote_count":"1","content":"Selected Answer: BE\\nBE is the correct answer.","timestamp":"1716537120.0","poster":"65703c1","comment_id":"1217289"},{"poster":"Tchie","comment_id":"1169490","comments":[{"comment_id":"1274653","poster":"wh1t4k3r","upvote_count":"1","content":"No, its not.\\nYou are assuming the developer have intermediate to advanced knowledge on kubernetes. ECS is way easier if you are at a starting point from containers and it is going cloud native. Plus the only valid packaging options is the ECR one, that is WAY MORE easy to integrate to ECS then EKS...","timestamp":"1724952060.0"}],"upvote_count":"1","timestamp":"1709988540.0","content":"B&D Using EKS is least operational overhead"},{"upvote_count":"2","comment_id":"1169328","content":"Selected Answer: BE\\nECR -> ECS","poster":"nder","timestamp":"1709971020.0"},{"content":"Selected Answer: BE\\nBE - ecs much easer than eks .","comment_id":"1167263","upvote_count":"2","poster":"Abdullah22","timestamp":"1709737500.0"},{"upvote_count":"2","comment_id":"1164760","poster":"KarBiswa","timestamp":"1709468400.0","content":"Selected Answer: BE\\nhttps://aws.amazon.com/getting-started/hands-on/deploy-docker-containers/"},{"poster":"monishvster","timestamp":"1709163420.0","comment_id":"1162048","content":"Selected Answer: BE\\nE corresponds to actions in B","upvote_count":"2"},{"poster":"CrescentShared","timestamp":"1708489740.0","upvote_count":"4","comment_id":"1155237","content":"Selected Answer: BE\\nWhy D? Is EKS necessary?"}],"answer_description":"","extracted_at":"2025-12-24T09:02:01.180Z","extraction_method":"api_direct_v1"},{"question_id":"AwcRh8titietFbge8GGF","question_number":196,"page":40,"question_text":"A developer supports an application that accesses data in an Amazon DynamoDB table. One of the item attributes is expirationDate in the timestamp format. The application uses this attribute to find items, archive them, and remove them from the table based on the timestamp value.\\n\\nThe application will be decommissioned soon, and the developer must find another way to implement this functionality. The developer needs a solution that will require the least amount of code to write.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create an Amazon EventBridge scheduled rule to invoke the Lambda functions. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB table and process them.","A":"Enable TTL on the expirationDate attribute in the table. Create a DynamoDB stream. Create an AWS Lambda function to process the deleted items. Create a DynamoDB trigger for the Lambda function.","B":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create a DynamoDB stream. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB stream and process them.","D":"Enable TTL on the expirationDate attribute in the table. Specify an Amazon Simple Queue Service (Amazon SQS) dead-letter queue as the target to delete the items. Create an AWS Lambda function to process the items."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134275-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:31:00","unix_timestamp":1708489860,"discussion_count":5,"discussion":[{"poster":"65703c1","upvote_count":"2","comment_id":"1217297","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732442640.0"},{"timestamp":"1725696840.0","upvote_count":"3","poster":"SerialiDr","content":"Selected Answer: A\\nA. Enable TTL (Time to Live) on the expirationDate attribute in the table. Create a DynamoDB stream. Create an AWS Lambda function to process the deleted items. Create a DynamoDB trigger for the Lambda function.\\n\\nThis approach leverages DynamoDB\'s TTL feature to automatically delete items past their expiration date, minimizing the need for custom code to manage this process. The use of a DynamoDB stream and a Lambda function triggered by this stream allows for processing or archiving the items just before they are deleted, without the need to manually scan and delete expired items, thereby significantly reducing operational complexity and code maintenance.","comment_id":"1167885"},{"timestamp":"1725628680.0","poster":"Abdullah22","upvote_count":"1","content":"Selected Answer: A\\ngoing with A","comment_id":"1167276"},{"timestamp":"1725358980.0","comment_id":"1164762","content":"Selected Answer: A\\nIt is TTL and stream combination. It will be utilized by the Lambda","poster":"KarBiswa","upvote_count":"1"},{"poster":"CrescentShared","comment_id":"1155239","upvote_count":"3","timestamp":"1724207460.0","content":"Selected Answer: A\\nNot sure why C. A can totally handle this."}],"answer_description":"","extracted_at":"2025-12-24T09:02:12.186Z","extraction_method":"api_direct_v1"},{"question_id":"xOpci2I4A8Svo8WwmQfA","question_number":197,"page":40,"question_text":"A developer needs to implement a custom machine learning (ML) library in an application. The size of the library is 15 GB. The size of the library is increasing. The application uses AWS Lambda functions. All the Lambda functions must have access to the library.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Save the library in Amazon S3. Download the library from Amazon S3 inside the Lambda function.","D":"Save the library in an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all the Lambda functions.","A":"Save the library in Lambda layers. Attach the layers to all Lambda functions.","C":"Save the library as a Lambda container image. Redeploy the Lambda functions with the new image."},"correct_answer":"D","answer_ET":"D","answers_community":["D (76%)","A (24%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134276-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:32:00","unix_timestamp":1708489920,"discussion_count":9,"discussion":[{"comment_id":"1169334","upvote_count":"13","content":"Selected Answer: D\\nQuick google will tell you the max size of a lambda layer is 250mb.","poster":"nder","timestamp":"1709971620.0"},{"poster":"preachr","upvote_count":"1","content":"Selected Answer: D\\nhttps://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/\\n\\nSharing large code packages with Lambda\\nEFS is useful for sharing software packages or binaries that are otherwise too large for Lambda layers. You can copy these to EFS and have Lambda use these packages as if there are installed in the Lambda deployment package.","comment_id":"1288988","timestamp":"1727268000.0"},{"timestamp":"1716537960.0","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1217298","upvote_count":"2","poster":"65703c1"},{"comment_id":"1185377","poster":"DeaconStJohn","timestamp":"1711710840.0","upvote_count":"3","content":"Selected Answer: D\\nI\'ve been going back and forward on this one for a few days. I have settled for EFS primarily based off a blog I read from an AWS community builder who specializes in lambda.\\nhttps://betterdev.blog/serverless-ml-on-aws-lambda/#overcoming_lambda_size_limitations:~:text=the%20DynamoDB%20table.-,Overcoming%20Lambda%20size%20limitations,-If%20we%20package\\n\\n250mb limit per lambda, although the layers capacity is 75gb this covers your whole environment and breaches the single lambda limit.\\nThe blog uses a container solution, the limit here is 10GB which is still to small for our use case.\\nEFS fits this use case even though it is a tad more troublesome to implement.\\n\\nGranted the blog is 2 years old, I\'m hoping not much has changed since."},{"timestamp":"1709806560.0","content":"Selected Answer: D\\nD. Save the library in an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all the Lambda functions.\\n\\nThis approach allows Lambda functions to access large libraries or datasets that exceed the size limits of Lambda\'s deployment package. By using Amazon EFS, a fully managed elastic file storage, the library can be stored once and mounted onto multiple Lambda functions simultaneously. This eliminates the need to package the library with each Lambda function, which would not be feasible given the size constraints of Lambda layers and deployment packages. Additionally, this method requires minimal code changes, focusing only on configuring the Lambda functions to mount the EFS file system, providing a scalable and efficient solution for making large libraries available to serverless applications.","upvote_count":"3","comment_id":"1167887","poster":"SerialiDr"},{"poster":"Abdullah22","content":"Selected Answer: D\\njust the layer limitation 250 mb .","timestamp":"1709740260.0","upvote_count":"2","comment_id":"1167315"},{"upvote_count":"4","timestamp":"1709468820.0","content":"Selected Answer: A\\nUpto 75 GB can be accommodated. \\nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html","poster":"KarBiswa","comment_id":"1164766"},{"upvote_count":"4","timestamp":"1709168040.0","poster":"ANDRES715","content":"Selected Answer: A\\nLa soluci\xf3n recomendada para este caso es guardar la biblioteca en capas Lambda y adjuntar esas capas a todas las funciones Lambda. Esto permitir\xe1 que todas las funciones Lambda tengan acceso a la biblioteca sin necesidad de duplicarla en cada funci\xf3n.\\n\\n\\nLas capas Lambda son una forma de compartir c\xf3digo y bibliotecas comunes entre varias funciones Lambda. Puedes crear una capa Lambda que contenga la biblioteca de aprendizaje autom\xe1tico y luego adjuntar esa capa a todas las funciones Lambda que necesiten acceder a ella.\\n\\n\\nAl utilizar capas Lambda, puedes reducir el tama\xf1o de las funciones Lambda y simplificar su mantenimiento. Adem\xe1s, si el tama\xf1o de la biblioteca est\xe1 aumentando, puedes actualizar la capa Lambda sin tener que modificar y volver a implementar todas las funciones Lambda.","comment_id":"1162104"},{"content":"Selected Answer: D\\nS3 takes too long.","upvote_count":"2","poster":"CrescentShared","comment_id":"1155240","timestamp":"1708489920.0"}],"answer_description":"","extracted_at":"2025-12-24T09:02:12.186Z","extraction_method":"api_direct_v1"},{"question_id":"kUeBknz6sSCBHOoccps1","question_number":198,"page":40,"question_text":"A developer is designing a serverless application for a game in which users register and log in through a web browser. The application makes requests on behalf of users to a set of AWS Lambda functions that run behind an Amazon API Gateway HTTP API.\\n\\nThe developer needs to implement a solution to register and log in users on the application\'s sign-in page. The solution must minimize operational overhead and must minimize ongoing management of user identities.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create Amazon Cognito user pools for external social identity providers. Configure IAM roles for the identity pools.","B":"Program the sign-in page to create users\' IAM groups with the IAM roles attached to the groups.","D":"Configure the sign-in page to register and store the users and their passwords in an Amazon DynamoDB table with an attached IAM policy.","C":"Create an Amazon RDS for SQL Server DB instance to store the users and manage the permissions to the backend resources in AWS."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134277-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:38:00","unix_timestamp":1708490280,"discussion_count":5,"discussion":[{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217300","poster":"65703c1","upvote_count":"2","timestamp":"1732443000.0"},{"poster":"KarBiswa","upvote_count":"3","content":"Selected Answer: A\\nCognito is the option","comment_id":"1164769","timestamp":"1725359400.0"},{"timestamp":"1724885760.0","content":"Selected Answer: A\\nAmazon Cognito es un servicio de AWS que permite agregar f\xe1cilmente la funcionalidad de registro e inicio de sesi\xf3n a las aplicaciones. Puedes utilizar proveedores de identidades sociales externos, como Google, Facebook o Amazon, para permitir que los usuarios se registren e inicien sesi\xf3n en tu aplicaci\xf3n.\\n\\n\\nAl crear grupos de usuarios en Amazon Cognito y asignar roles de IAM a esos grupos, puedes gestionar de manera eficiente los permisos y accesos de los usuarios a los recursos backend en AWS. Esto te permite minimizar los gastos operativos y la gesti\xf3n continua de las identidades de los usuarios.","comment_id":"1162105","upvote_count":"3","poster":"ANDRES715"},{"timestamp":"1724881200.0","upvote_count":"3","poster":"monishvster","content":"Selected Answer: A\\nCognito is the answer","comment_id":"1162051"},{"content":"Selected Answer: A\\nAnybody has an idea why it is C?","comment_id":"1155241","timestamp":"1724207880.0","poster":"CrescentShared","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:02:12.186Z","extraction_method":"api_direct_v1"},{"question_id":"FBxjiliFpHjPyHwt8oNo","question_number":199,"page":40,"question_text":"A company has a web application that is hosted on Amazon EC2 instances. The EC2 instances are configured to stream logs to Amazon CloudWatch Logs. The company needs to receive an Amazon Simple Notification Service (Amazon SNS) notification when the number of application error messages exceeds a defined threshold within a 5-minute period.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Rewrite the application code to stream application logs to Amazon SNS. Configure an SNS topic to send a notification when the number of errors exceeds the defined threshold within a 5-minute period.","C":"Install and configure the Amazon Inspector agent on the EC2 instances to monitor for errors. Configure Amazon Inspector to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period.","B":"Configure a subscription filter on the CloudWatch Logs log group. Configure the filter to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period.","D":"Create a CloudWatch metric filter to match the application error pattern in the log data. Set up a CloudWatch alarm based on the new custom metric. Configure the alarm to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133406-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-09 01:12:00","unix_timestamp":1707437520,"discussion_count":6,"discussion":[{"content":"Correct Answer is D","poster":"Moumita","comment_id":"1145116","upvote_count":"7","timestamp":"1707437520.0"},{"timestamp":"1708490340.0","upvote_count":"5","comment_id":"1155242","content":"Selected Answer: D\\nShould be D","poster":"CrescentShared"},{"upvote_count":"1","timestamp":"1718598600.0","comment_id":"1231722","content":"This appear at 17 Jun exam","poster":"tsangckl"},{"timestamp":"1716538740.0","comment_id":"1217308","poster":"65703c1","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer."},{"upvote_count":"3","timestamp":"1709469180.0","poster":"KarBiswa","content":"Selected Answer: D\\nD is the option","comment_id":"1164771"},{"poster":"monishvster","content":"Selected Answer: D\\nShould be D","timestamp":"1709163660.0","comment_id":"1162053","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:02:12.186Z","extraction_method":"api_direct_v1"},{"question_id":"mkXbG67ib14FvrgWGdlS","question_number":200,"page":40,"question_text":"A photo sharing application uses Amazon S3 to store image files. All user images are manually audited for inappropriate content by a third-party company. The audits are completed 1-24 hours after user upload and the results are written to an Amazon DynamoDB table, which uses the S3 object key as a primary key. The database items can be queried by using a REST API created by the third-party company.\\n\\nAn application developer needs to implement an automated process to tag all S3 objects with the results of the content audit.\\n\\nWhat should the developer do to meet these requirements in the MOST operationally efficient way?","choices":{"D":"Launch an Amazon EC2 instance. Deploy a script to the EC2 instance to use the external database results to tag the S3 objects accordingly. Configure a crontab file to run the script at regular intervals.","A":"Create an AWS Lambda function to run in response to the s3:ObjectCreated event type. Write the S3 key to an Amazon Simple Queue Service (Amazon SQS) queue with a visibility timeout of 24 hours. Create and configure a second Lambda function to read items from the queue. Retrieve the results for each item from the DynamoDB table. Tag each S3 object accordingly.","B":"Create an AWS Lambda function to run in response to the s3:ObjectCreated event type. Integrate the function into an AWS Step Functions standard workflow. Define an AWS Step Functions Wait state and set the value to 24 hours. Create and configure a second Lambda function to retrieve the audit results and tag the S3 objects accordingly after the Wait state is over.","C":"Create an AWS Lambda function to load all untagged S3 objects. Retrieve the results for each item from the REST API and tag each S3 object accordingly. Create and configure an Amazon EventBridge rule to run at regular intervals. Set the Lambda function as a target for the EventBridge rule."},"correct_answer":"B","answer_ET":"B","answers_community":["B (50%)","C (47%)","3%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134278-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:40:00","unix_timestamp":1708490400,"discussion_count":16,"discussion":[{"upvote_count":"8","comment_id":"1177324","poster":"AssessmentKing","timestamp":"1710852900.0","content":"Selected Answer: B\\nImages are first uploaded to S3 bucket.\\nThen, manual audit is performed that lasts 1-24 hours.\\nOnly after the audit of the image is finished we can run our Lambda function.\\nIf we run event at regular intervals (what does it mean?) should we run it every hour and then we would have bunch of untagged objects that haven\'t been audited and we would add a tag to them which doesn\'t make sense.\\n\\n- In option B they explicitly mention that the Wait period will be 24 hours thus insuring that the audit of those objects has been completed. Only then we run the Lambda function."},{"comment_id":"1167895","upvote_count":"6","content":"Selected Answer: C\\nC. Create an AWS Lambda function to load all untagged S3 objects. Retrieve the results for each item from the REST API and tag each S3 object accordingly. Create and configure an Amazon EventBridge rule to run at regular intervals. Set the Lambda function as a target for the EventBridge rule.\\n\\nThis solution leverages AWS Lambda for processing and tagging S3 objects based on the audit results available through the REST API. By using Amazon EventBridge to trigger the Lambda function at regular intervals, the developer ensures that the process runs automatically without manual intervention, efficiently handling the tagging of S3 objects once the audit results are available. This approach minimizes operational effort and does not require the continuous monitoring of S3 object creation or the management of complex workflows.","timestamp":"1709807220.0","poster":"SerialiDr"},{"comment_id":"1572247","upvote_count":"1","poster":"egosselin","content":"Selected Answer: C\\nC is the best anwser. B is wrong, because it induce unnecessary latency, if the image is audited after an hour, the app will still wait for 23 hours to tag the image.","timestamp":"1748195700.0"},{"timestamp":"1737860580.0","upvote_count":"1","content":"Selected Answer: B\\nC will take too long... Each img will takd 24 hrs, and it will wait for all imgs. I do not understand why people are confused.. It needs to be triggered when the img is uploaded.","poster":"mooncake1","comments":[{"timestamp":"1737860700.0","content":"Also SQS max VT is 12 hr. 24 hr is impossible, A not right","comment_id":"1346779","upvote_count":"1","poster":"mooncake1"}],"comment_id":"1346777"},{"upvote_count":"1","content":"Selected Answer: C\\nC is the right answer.\\nLambda+EvenBridge is operationally more efficient than Step Function.","comment_id":"1338104","timestamp":"1736373600.0","poster":"Arad"},{"poster":"ShakthiGCP","timestamp":"1733784480.0","content":"Selected Answer: B\\nAns: B . We have to wait for 1- 24 hrs .we cant just run the lambda functions to get untagged objects .","upvote_count":"1","comment_id":"1324257"},{"comment_id":"1306236","poster":"Saudis","timestamp":"1730564400.0","upvote_count":"1","content":"Selected Answer: C\\nI am confuse because the chatGPT Says C"},{"comment_id":"1305208","comments":[{"poster":"devmo","upvote_count":"1","content":"Changing my mind to B as a lambda might time out if number of untagged items are a lot. Good use case for dynamodb streams.","timestamp":"1730326980.0","comment_id":"1305213"}],"upvote_count":"1","content":"Selected Answer: C\\nWith option B, what if the external company doesn\'t complete the audit in 24 hours Least operational over head and long term solution would be going with 1 lambda and event bridge is what I feel.","poster":"devmo","timestamp":"1730326440.0"},{"content":"C coz of operationally efficient words","upvote_count":"3","comment_id":"1298921","timestamp":"1729107000.0","poster":"MasoudK"},{"upvote_count":"3","comment_id":"1228238","timestamp":"1718080320.0","poster":"tsangckl","content":"Selected Answer: C\\nThis solution leverages AWS Lambda, which is a serverless compute service that runs your code in response to events and automatically manages the underlying compute resources for you1. By using Lambda in conjunction with Amazon EventBridge, which can trigger events at regular intervals, you can create a system that periodically checks for new audit results and applies tags to S3 objects without the need for managing server instances or handling queue visibility timeouts. This approach is not only operationally efficient but also cost-effective, as you pay only for the compute time you consume with Lambda21."},{"upvote_count":"2","timestamp":"1716539040.0","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1","comment_id":"1217310"},{"poster":"DeaconStJohn","content":"Selected Answer: B\\nI\'m still not sure if B is correct. \\nHowever, I think this use case is very similar to a feature that exists in step functions. Although the wording doesn\'t answer the question directly and I think waiting 24 hours is the opposite of operationally efficient. The GetTaskToken feature that is part of service integration in step functions would be a perfect match for this scenario, removing the 24 hour wait while maintaining operational efficiency using AWS Step functions.\\nI can only hope this is what they are getting at when I answer this on the exam.\\n\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/connect-to-resource.html","timestamp":"1711371420.0","upvote_count":"4","comment_id":"1182475"},{"comment_id":"1170914","poster":"KarBiswa","timestamp":"1710148980.0","upvote_count":"2","content":"Selected Answer: C\\nBest option considering the question conditions. Reading from Rest API"},{"content":"Selected Answer: A\\nShould be A","upvote_count":"1","poster":"monishvster","timestamp":"1709163840.0","comment_id":"1162054"},{"timestamp":"1709122860.0","content":"Selected Answer: B\\nI may choose B.","comment_id":"1161611","upvote_count":"3","poster":"Jisking"},{"poster":"CrescentShared","comment_id":"1155244","timestamp":"1708490400.0","content":"Selected Answer: C\\nA does not make any sense.","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:02:12.186Z","extraction_method":"api_direct_v1"},{"question_id":"MKKx7n4MPgJhb3Z4RgsS","question_number":201,"page":41,"question_text":"A company hosts a client-side web application for one of its subsidiaries on Amazon S3. The web application can be accessed through Amazon CloudFront from https://www.example.com. After a successful rollout, the company wants to host three more client-side web applications for its remaining subsidiaries on three separate S3 buckets.\\nTo achieve this goal, a developer moves all the common JavaScript files and web fonts to a central S3 bucket that serves the web applications. However, during testing, the developer notices that the browser blocks the JavaScript files and web fonts.\\nWhat should the developer do to prevent the browser from blocking the JavaScript files and web fonts?","choices":{"B":"Create a bucket policy that allows access to the central S3 bucket. Attach the bucket policy to the central S3 bucket","A":"Create four access points that allow access to the central S3 bucket. Assign an access point to each web application bucket.","D":"Create a Content-MD5 header that provides a message integrity check for the central S3 bucket. Insert the Content-MD5 header for each web application request.","C":"Create a cross-origin resource sharing (CORS) configuration that allows access to the central S3 bucket. Add the CORS configuration to the central S3 bucket."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102902-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-17 09:49:00","unix_timestamp":1679042940,"discussion_count":8,"discussion":[{"poster":"Untamables","upvote_count":"6","timestamp":"1679571600.0","content":"Selected Answer: C\\nC\\nThis is a frequent trouble. Web applications cannot access the resources in other domains by default, except some exceptions. You must configure CORS on the resources to be accessed.\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html","comment_id":"848134"},{"upvote_count":"2","content":"Selected Answer: C\\nThe issue described is related to Cross-Origin Resource Sharing (CORS).\\n\\nA) Eliminated - S3 access points deals with permissions, not with resolving cross-origin issues.\\n\\nB) Eliminated - A bucket policy defines access rules for an S3 bucket (e.g., which users or accounts can access it).Bucket policies define access permissions, but they do not address the cross-origin issue.\\n\\nC) By adding a CORS configuration to the central bucket, you instruct the browser to allow requests from the web application\u2019s domains (origins).\\n\\nD) Eliminated - Content-MD5 is a header used to ensure that data was not corrupted during transmission. it is unrelated to the browser\u2019s blocking behavior due to CORS.","comment_id":"1330350","poster":"sumanshu","timestamp":"1734864840.0"},{"content":"Selected Answer: C\\n==> Discard A. Access points manage S3 access but don\'t address browser\'s cross-origin restrictions.\\n==> Discard B. Bucket policies control permissions but don\'t override browser Same-Origin Policy.\\n==> Discard D. Content-MD5 ensures data integrity but doesn\'t affect cross-origin resource sharing.\\n\\nC is useful when cross site access","poster":"trieudo","comment_id":"1326322","upvote_count":"1","timestamp":"1734143400.0"},{"content":"C\\nThe question described is a classic case of Cross-Origin Resource Sharing (CORS) where the browser blocks resources (like JavaScript files and web fonts) that are loaded from a different origin (the central S3 bucket) than the web application. To resolve this, a CORS configuration needs to be added to the central S3 bucket to allow these resources to be accessed from the different origins of the web applications.","upvote_count":"1","poster":"tomchandler077","comment_id":"1243974","timestamp":"1720377840.0"},{"timestamp":"1716303480.0","comment_id":"1215044","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1"},{"content":"Selected Answer: C\\nThe answer is C for cat","upvote_count":"1","comment_id":"1191787","poster":"badsati","timestamp":"1712603640.0"},{"poster":"svrnvtr","content":"Selected Answer: C\\nIt is C","timestamp":"1679433180.0","upvote_count":"3","comment_id":"846356"},{"timestamp":"1679042940.0","content":"C\\nhttps://www.examtopics.com/discussions/amazon/view/88856-exam-aws-certified-developer-associate-topic-1-question-302/","poster":"aragon_saa","upvote_count":"3","comment_id":"841808"}],"answer_description":"","extracted_at":"2025-12-24T09:02:23.165Z","extraction_method":"api_direct_v1"},{"question_id":"f3ABt2FotierL5qczsZp","question_number":202,"page":41,"question_text":"A company has built an AWS Lambda function to convert large image files into output files that can be used in a third-party viewer application. The company recently added a new module to the function to improve the output of the generated files. However, the new module has increased the bundle size and has increased the time that is needed to deploy changes to the function code.\\n\\nHow can a developer increase the speed of the Lambda function deployment?","choices":{"A":"Use AWS CodeDeploy to deploy the function code.","B":"Use Lambda layers to package and load dependencies.","C":"Increase the memory size of the function.","D":"Use Amazon S3 to host the function dependencies."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134279-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:44:00","unix_timestamp":1708490640,"discussion_count":6,"discussion":[{"content":"Selected Answer: B\\nKeyword => increased the bundle size","timestamp":"1730564580.0","upvote_count":"1","poster":"Saudis","comment_id":"1306237"},{"content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"3","timestamp":"1716539160.0","poster":"65703c1","comment_id":"1217311"},{"comment_id":"1167892","content":"Selected Answer: B\\nB. Use Lambda layers to package and load dependencies.\\n\\nLambda layers are a way to manage your function\'s dependencies separately, reducing the size of the deployment package that needs to be uploaded when the function\'s code changes. By moving the large module or other dependencies to a Lambda layer, only changes to the function\'s own code need to be uploaded during deployment, which can significantly speed up the deployment process. This approach allows for more efficient management of libraries and dependencies, making deployments quicker and more streamlined without altering the function\'s memory size, which would not directly impact deployment speed, or relying on external services like Amazon S3 or AWS CodeDeploy in a way that doesn\'t specifically address deployment speed for large dependencies.","timestamp":"1709806980.0","upvote_count":"2","poster":"SerialiDr"},{"comment_id":"1167342","content":"Selected Answer: B\\nLambda layers allow packaging shared dependencies outside the function code, resulting in smaller deployment packages for subsequent updates. This significantly reduces the time required to upload the code to AWS during deployment.","upvote_count":"2","timestamp":"1709742180.0","poster":"Abdullah22"},{"poster":"KarBiswa","timestamp":"1709469600.0","content":"Selected Answer: B\\nIts a lambda layer scenario","upvote_count":"1","comment_id":"1164777"},{"upvote_count":"3","poster":"CrescentShared","timestamp":"1708490640.0","comment_id":"1155248","content":"Selected Answer: B\\nMust be B"}],"answer_description":"","extracted_at":"2025-12-24T09:02:23.165Z","extraction_method":"api_direct_v1"},{"question_id":"95Mh99RC57t4rM9KaI7Q","question_number":203,"page":41,"question_text":"A developer creates a static website for their department. The developer deploys the static assets for the website to an Amazon S3 bucket and serves the assets with Amazon CloudFront. The developer uses origin access control (OAC) on the CloudFront distribution to access the S3 bucket.\\n\\nThe developer notices users can access the root URL and specific pages but cannot access directories without specifying a file name. For example, /products/index.html works, but /products/ returns an error. The developer needs to enable accessing directories without specifying a file name without exposing the S3 bucket publicly.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create a CloudFront function that examines the request URL and appends index.html when directories are being accessed. Add the function as a viewer request CloudFront function to the CloudFront distribution\'s behavior.","B":"Update the Amazon S3 bucket settings and enable static website hosting. Specify index.html as the Index document. Update the S3 bucket policy to enable access. Update the CloudFront distribution\'s origin to use the S3 website endpoint.","D":"Create a custom error response on the CloudFront distribution with the HTTP error code set to the HTTP 404 Not Found response code and the response page path to /index.html. Set the HTTP response code to the HTTP 200 OK response code.","A":"Update the CloudFront distribution\'s settings to index.html as the default root object is set."},"correct_answer":"C","answer_ET":"C","answers_community":["C (73%)","B (20%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134280-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:53:00","unix_timestamp":1708491180,"discussion_count":9,"discussion":[{"poster":"examuserss","content":"Selected Answer: A\\nThe best solution is Option A: Update the CloudFront distribution\'s settings to index.html as the default root object. This is the simplest and most operationally efficient way to ensure that CloudFront automatically serves the index.html file when a user requests a directory, without needing to expose the S3 bucket publicly or implement complex logic.","upvote_count":"1","comment_id":"1330874","timestamp":"1734970440.0"},{"poster":"Saurabh04","comment_id":"1266177","content":"Selected Answer: B\\nEnable static website hosting on the S3 bucket.\\nSpecify index.html as the Index document.\\nUpdate the S3 bucket policy to allow access.\\nConfigure the CloudFront distribution\u2019s origin to use the S3 website endpoint.\\nPros:\\nHandles both root and subdirectories.\\nKeeps the S3 bucket private.\\nCons:\\nRequires S3 bucket policy adjustments.","timestamp":"1723693680.0","upvote_count":"1"},{"poster":"65703c1","upvote_count":"2","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217321","timestamp":"1716540540.0"},{"timestamp":"1710162600.0","comment_id":"1171029","poster":"KarBiswa","upvote_count":"4","content":"Selected Answer: C\\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/implementing-default-directory-indexes-in-amazon-s3-backed-amazon-cloudfront-origins-using-cloudfront-functions/"},{"timestamp":"1709821020.0","upvote_count":"2","poster":"Abdullah22","content":"going with B.","comment_id":"1168076"},{"content":"Selected Answer: C\\nThis solution allows for the dynamic handling of requests to directories by automatically appending index.html to the path when a directory is requested. This approach does not require exposing the S3 bucket publicly or modifying S3 bucket settings for static website hosting. It leverages CloudFront\'s capabilities to manipulate the request at the edge location before it reaches the origin, ensuring that users can access directories without specifying a file name in the most secure and efficient manner.","upvote_count":"3","timestamp":"1709814480.0","comment_id":"1167969","poster":"SerialiDr"},{"comment_id":"1163344","timestamp":"1709284080.0","content":"C is the right option","upvote_count":"1","poster":"HD98"},{"comment_id":"1162110","poster":"ANDRES715","content":"Selected Answer: B\\nAl habilitar el alojamiento de sitios web est\xe1ticos en el dep\xf3sito de Amazon S3 y especificar index.html como documento de \xedndice, se permite el acceso a los directorios sin especificar un nombre de archivo. Al mismo tiempo, al actualizar la pol\xedtica del dep\xf3sito S3 para habilitar el acceso y el origen de la distribuci\xf3n de CloudFront para utilizar el punto final del sitio web de S3, se garantiza que el acceso se gestione de manera segura sin exponer p\xfablicamente el dep\xf3sito de S3.","upvote_count":"2","timestamp":"1709169000.0"},{"comment_id":"1155250","poster":"CrescentShared","upvote_count":"2","content":"Selected Answer: C\\nWhen you enable static website hosting on an S3 bucket, you can specify an index document, which S3 automatically returns when a user requests a directory. However, changing the CloudFront origin to the S3 website endpoint would expose the S3 bucket publicly, which contradicts the requirement to keep the S3 bucket private.","timestamp":"1708491180.0","comments":[]}],"answer_description":"","extracted_at":"2025-12-24T09:02:23.165Z","extraction_method":"api_direct_v1"},{"question_id":"zEy4FeTGWG2nchApkNSd","question_number":204,"page":41,"question_text":"A developer is testing a RESTful application that is deployed by using Amazon API Gateway and AWS Lambda. When the developer tests the user login by using credentials that are not valid, the developer receives an HTTP 405: METHOD_NOT_ALLOWED error. The developer has verified that the test is sending the correct request for the resource.\\n\\nWhich HTTP error should the application return in response to the request?","choices":{"B":"HTTP 404","C":"HTTP 503","A":"HTTP 401","D":"HTTP 505"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134281-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:56:00","unix_timestamp":1708491360,"discussion_count":4,"discussion":[{"poster":"CrescentShared","upvote_count":"7","timestamp":"1708491360.0","comment_id":"1155251","content":"Selected Answer: A\\nC. HTTP 503: Service Unavailable - This status code indicates that the server is not ready to handle the request. It is usually a temporary state, often due to maintenance or overloading.\\n\\nD. HTTP 505: HTTP Version Not Supported - This status code means that the server does not support the HTTP protocol version used in the request. It is a rare occurrence and typically indicates that the client is using an outdated or unsupported version of HTTP."},{"poster":"Saudis","upvote_count":"1","comment_id":"1306252","content":"Selected Answer: A\\nUnauthorized 401","timestamp":"1730566500.0"},{"upvote_count":"1","poster":"65703c1","timestamp":"1716540720.0","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217322"},{"comment_id":"1164800","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html","upvote_count":"3","timestamp":"1709472420.0","poster":"KarBiswa"}],"answer_description":"","extracted_at":"2025-12-24T09:02:23.165Z","extraction_method":"api_direct_v1"},{"question_id":"FSnEin7O6tyl3TQd3WnQ","question_number":205,"page":41,"question_text":"A developer must use multi-factor authentication (MFA) to access data in an Amazon S3 bucket that is in another AWS account.\\n\\nWhich AWS Security Token Service (AWS STS) API operation should the developer use with the MFA information to meet this requirement?","choices":{"B":"GetFederationToken","C":"AssumeRoleWithSAML","D":"AssumeRole","A":"AssumeRoleWithWebIdentity"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134282-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:57:00","unix_timestamp":1708491420,"discussion_count":6,"discussion":[{"content":"Selected Answer: D\\nUsing MFA with AssumeRole\\n(Optional) You can include multi-factor authentication (MFA) information when you call AssumeRole. This is useful for cross-account scenarios to ensure that the user that assumes the role has been authenticated with an AWS MFA device. In that scenario, the trust policy of the role being assumed includes a condition that tests for MFA authentication. If the caller does not include valid MFA information, the request to assume the role is denied.","poster":"Abdullah22","timestamp":"1709822520.0","comment_id":"1168099","upvote_count":"6"},{"content":"Selected Answer: D\\nMFA with AssumeRole always","timestamp":"1730566620.0","comment_id":"1306253","poster":"Saudis","upvote_count":"1"},{"timestamp":"1716540840.0","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1217323","upvote_count":"3","poster":"65703c1"},{"poster":"koltysh","comment_id":"1168248","timestamp":"1709834700.0","content":"answer D","upvote_count":"1"},{"poster":"KarBiswa","timestamp":"1709472600.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_configure-api-require.html#:~:text=Call%20API%20operations%20that%20access%20resources%20in%20the%20same%20or,to%20restrict%20access%20to%20resources%20protected%20by%20resource%2Dbased%20policies.","comment_id":"1164802","upvote_count":"4"},{"timestamp":"1708491420.0","upvote_count":"3","comment_id":"1155252","poster":"CrescentShared","content":"Selected Answer: D\\nanswer Is D"}],"answer_description":"","extracted_at":"2025-12-24T09:02:23.165Z","extraction_method":"api_direct_v1"},{"question_id":"0N45UVYX5szAnjRqYnmW","question_number":206,"page":42,"question_text":"A developer designed an application on an Amazon EC2 instance. The application makes API requests to objects in an Amazon S3 bucket.\\n\\nWhich combination of steps will ensure that the application makes the API requests in the MOST secure manner? (Choose two.)","choices":{"E":"Store the credentials of the IAM user in the environment variables on the EC2 instance.","A":"Create an IAM user that has permissions to the S3 bucket. Add the user to an IAM group.","B":"Create an IAM role that has permissions to the S3 bucket.","D":"Create an IAM role that has permissions to the S3 bucket. Assign the role to an IAM group.","C":"Add the IAM role to an instance profile. Attach the instance profile to the EC2 instance."},"correct_answer":"BC","answer_ET":"BC","answers_community":["BC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134283-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 05:58:00","unix_timestamp":1708491480,"discussion_count":3,"discussion":[{"timestamp":"1723694340.0","comment_id":"1266184","poster":"Saurabh04","upvote_count":"2","content":"Selected Answer: BC\\nOption B (Amazon S3 Static Website Hosting):\\nEnable static website hosting on the S3 bucket.\\nSpecify index.html as the Index document.\\nUpdate the S3 bucket policy to allow access.\\nConfigure the CloudFront distribution\u2019s origin to use the S3 website endpoint.\\nPros:\\nHandles both root and subdirectories.\\nKeeps the S3 bucket private.\\nCons:\\nRequires S3 bucket policy adjustments.\\nVerdict: Recommended solution.\\nOption C (CloudFront Function for Directory Indexes):\\nCreate a CloudFront function that appends index.html to request URLs for directories.\\nAdd this function as a viewer request CloudFront function.\\nPros:\\nCustomizable behavior.\\nWorks for subdirectories.\\nCons:\\nAdds complexity.\\nVerdict: Suitable if you need custom logic"},{"content":"Selected Answer: BC\\nBC is the correct answer.","poster":"65703c1","comment_id":"1217324","timestamp":"1716540960.0","upvote_count":"1"},{"timestamp":"1708491480.0","comment_id":"1155253","upvote_count":"3","content":"Selected Answer: BC\\nBC is correct","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:02:34.161Z","extraction_method":"api_direct_v1"},{"question_id":"9OsznhTa0P2RqGDL2T8E","question_number":207,"page":42,"question_text":"An AWS Lambda function requires read access to an Amazon S3 bucket and requires read/write access to an Amazon DynamoDB table. The correct IAM policy already exists.\\n\\nWhat is the MOST secure way to grant the Lambda function access to the S3 bucket and the DynamoDB table?","choices":{"D":"Add the AWS account root user access key ID and secret access key as encrypted environment variables in the Lambda function.","C":"Create an IAM user with programmatic access. Attach the existing IAM policy to the user. Add the user access key ID and secret access key as environment variables in the Lambda function.","B":"Create an IAM role for the Lambda function. Attach the existing IAM policy to the role. Attach the role to the Lambda function.","A":"Attach the existing IAM policy to the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134284-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 06:37:00","unix_timestamp":1708493820,"discussion_count":2,"discussion":[{"upvote_count":"2","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217325","poster":"65703c1","timestamp":"1732445820.0"},{"content":"Selected Answer: B\\nmust be b","poster":"CrescentShared","timestamp":"1724211420.0","upvote_count":"3","comment_id":"1155268"}],"answer_description":"","extracted_at":"2025-12-24T09:02:34.161Z","extraction_method":"api_direct_v1"},{"question_id":"BwPJAD2gzRw6wS4Dj67k","question_number":208,"page":42,"question_text":"A developer is using AWS Step Functions to automate a workflow. The workflow defines each step as an AWS Lambda function task. The developer notices that runs of the Step Functions state machine fail in the GetResource task with either an IllegalArgumentException error or a TooManyRequestsException error.\\n\\nThe developer wants the state machine to stop running when the state machine encounters an IllegalArgumentException error. The state machine needs to retry the GetResource task one additional time after 10 seconds if the state machine encounters a TooManyRequestsException error. If the second attempt fails, the developer wants the state machine to stop running.\\n\\nHow can the developer implement the Lambda retry functionality without adding unnecessary complexity to the state machine?","choices":{"A":"Add a Delay task after the GetResource task. Add a catcher to the GetResource task. Configure the catcher with an error type of TooManyRequestsException. Configure the next step to be the Delay task. Configure the Delay task to wait for an interval of 10 seconds. Configure the next step to be the GetResource task.","B":"Add a catcher to the GetResource task. Configure the catcher with an error type of TooManyRequestsException, an interval of 10 seconds, and a maximum attempts value of 1. Configure the next step to be the GetResource task.","D":"Duplicate the GetResource task. Rename the new GetResource task to TryAgain. Add a catcher to the original GetResource task. Configure the catcher with an error type of TooManyRequestsException. Configure the next step to be TryAgain.","C":"Add a retrier to the GetResource task. Configure the retrier with an error type of TooManyRequestsException, an interval of 10 seconds, and a maximum attempts value of 1."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134285-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 06:52:00","unix_timestamp":1708494720,"discussion_count":4,"discussion":[{"poster":"65703c1","upvote_count":"2","timestamp":"1732457700.0","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217431"},{"poster":"KarBiswa","upvote_count":"3","comment_id":"1164812","timestamp":"1725363600.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-error-handling.html#:~:text=Task%2C%20Parallel,the%20Retry%20field."},{"comment_id":"1162058","poster":"monishvster","content":"Selected Answer: C\\nShould be C","timestamp":"1724881980.0","upvote_count":"2"},{"content":"Selected Answer: C\\nShould be C","poster":"CrescentShared","upvote_count":"2","comment_id":"1155278","timestamp":"1724212320.0"}],"answer_description":"","extracted_at":"2025-12-24T09:02:34.161Z","extraction_method":"api_direct_v1"},{"question_id":"BCiLOdCHZ5Qw69wgirGw","question_number":209,"page":42,"question_text":"A developer is creating a serverless application that uses an AWS Lambda function. The developer will use AWS CloudFormation to deploy the application. The application will write logs to Amazon CloudWatch Logs. The developer has created a log group in a CloudFormation template for the application to use. The developer needs to modify the CloudFormation template to make the name of the log group available to the application at runtime.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Use the CloudFormation template\'s Mappings section to specify the log group\'s name for the application.","B":"Pass the log group\'s name to the application in the user data section of the CloudFormation template.","D":"Pass the log group\'s Amazon Resource Name (ARN) as an environment variable to the Lambda function.","A":"Use the AWS::Include transform in CloudFormation to provide the log group\'s name to the application."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134286-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 06:58:00","unix_timestamp":1708495080,"discussion_count":6,"discussion":[{"timestamp":"1727850960.0","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: D\\nResources:\\n MyLogGroup:\\n Type: AWS::Logs::LogGroup\\n Properties:\\n LogGroupName: !Sub \\"/aws/lambda/${AWS::StackName}-log-group\\"\\n \\n MyLambdaFunction:\\n Type: AWS::Lambda::Function\\n Properties:\\n FunctionName: MyFunction\\n Handler: index.handler\\n Runtime: nodejs14.x\\n Role: arn:aws:iam::123456789012:role/service-role/MyLambdaRole\\n Environment:\\n Variables:\\n LOG_GROUP_ARN: !GetAtt MyLogGroup.Arn","comment_id":"1292243"},{"content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1217435","timestamp":"1716553500.0","upvote_count":"2","poster":"65703c1"},{"comment_id":"1168124","content":"Selected Answer: D\\nExplanation of why other options are less suitable:\\n\\nA. AWS::Include transform: While the AWS::Include transform allows importing values from other templates, it\'s generally used for larger configurations and not ideal for this specific purpose of passing a single value to the application.\\nB. User data: The user data section in CloudFormation is typically used for one-time configuration scripts and not intended for passing sensitive information like log group names or ARNs, raising security concerns.\\nC. CloudFormation Mappings: While mappings can store key-value pairs within the template, they are not directly accessible as environment variables within the application code.","timestamp":"1709824080.0","poster":"Abdullah22","upvote_count":"4"},{"upvote_count":"2","poster":"SerialiDr","timestamp":"1709818260.0","comment_id":"1168031","content":"Selected Answer: D\\nBy specifying the log group\'s ARN as an environment variable in the CloudFormation template for the Lambda function, the developer can easily access this information within the application code at runtime. This method provides a straightforward way to pass dynamic configuration or resource references to AWS Lambda functions without hardcoding values, thereby maintaining flexibility and ensuring that the application can utilize the correct resources after deployment."},{"timestamp":"1709474040.0","content":"Selected Answer: D\\nVery nice question totally confusing. D is correct","comment_id":"1164817","poster":"KarBiswa","upvote_count":"1"},{"upvote_count":"4","poster":"CrescentShared","comment_id":"1155283","timestamp":"1708495080.0","content":"Selected Answer: D\\nUser data is typically used to pass startup scripts to EC2 instances, not Lambda functions. This would not be the appropriate mechanism for a serverless application using Lambda. The Mappings section in a CloudFormation template is used to define sets of key-value pairs that can be used to specify conditional parameter values based on region or other criteria. It doesn\'t provide a direct way to make the log group\'s name available to the Lambda function at runtime."}],"answer_description":"","extracted_at":"2025-12-24T09:02:34.161Z","extraction_method":"api_direct_v1"},{"question_id":"LbgIcng1cHXkND5gecfJ","question_number":210,"page":42,"question_text":"A developer is creating an Amazon DynamoDB table by using the AWS CLI. The DynamoDB table must use server-side encryption with an AWS owned encryption key.\\n\\nHow should the developer create the DynamoDB table to meet these requirements?","choices":{"A":"Create an AWS Key Management Service (AWS KMS) customer managed key. Provide the key\'s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table.","D":"Create the DynamoDB table with the default encryption options.","C":"Create an AWS owned key. Provide the key\'s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table.","B":"Create an AWS Key Management Service (AWS KMS) AWS managed key. Provide the key\'s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134287-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:02:00","unix_timestamp":1708495320,"discussion_count":6,"discussion":[{"upvote_count":"1","content":"Selected Answer: D\\naws dynamodb create-table \\\\\\n --table-name MyTable \\\\\\n --attribute-definitions AttributeName=Id,AttributeType=S \\\\\\n --key-schema AttributeName=Id,KeyType=HASH \\\\\\n --billing-mode PAY_PER_REQUEST","comment_id":"1313344","timestamp":"1731808860.0","poster":"albert_kuo"},{"comment_id":"1252170","timestamp":"1721530080.0","upvote_count":"2","poster":"Anandesh","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html\\nYou can switch between key types at any time"},{"content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1217437","timestamp":"1716553620.0"},{"upvote_count":"3","comment_id":"1168036","poster":"SerialiDr","timestamp":"1709818680.0","content":"Selected Answer: D\\nWhen creating a DynamoDB table, if no specific encryption options are provided, it uses the default encryption setting which is server-side encryption with AWS managed keys (SSE with AWS owned key). This option does not require specifying a key ARN in the creation process, making it the simplest and most straightforward way to ensure data at rest is encrypted using keys managed by AWS."},{"comment_id":"1164826","upvote_count":"2","poster":"KarBiswa","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html","timestamp":"1709474760.0"},{"timestamp":"1708495320.0","poster":"CrescentShared","upvote_count":"2","content":"Selected Answer: D\\nD is good enough to meet the requirement.","comment_id":"1155287"}],"answer_description":"","extracted_at":"2025-12-24T09:02:34.161Z","extraction_method":"api_direct_v1"},{"question_id":"cx93KOIdExXHjZtWstNx","question_number":211,"page":43,"question_text":"A company has an application that runs across multiple AWS Regions. The application is experiencing performance issues at irregular intervals. A developer must use AWS X-Ray to implement distributed tracing for the application to troubleshoot the root cause of the performance issues.\\n\\nWhat should the developer do to meet this requirement?","choices":{"A":"Use the X-Ray console to add annotations for AWS services and user-defined services.","D":"Use Region annotation that X-Ray adds automatically for user-defined services. Configure X-Ray to add Region annotation for AWS services.","C":"Use the X-Ray daemon to add annotations for AWS services and user-defined services.","B":"Use Region annotation that X-Ray adds automatically for AWS services. Add Region annotation for user-defined services."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134288-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:04:00","unix_timestamp":1708495440,"discussion_count":4,"discussion":[{"content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217439","upvote_count":"1","timestamp":"1732458480.0","poster":"65703c1"},{"upvote_count":"3","comment_id":"1168142","timestamp":"1725716820.0","content":"Selected Answer: B\\nUser-defined services:\\nDeveloped by users: These services are applications, microservices, or any software components specifically built and deployed by the user or organization using AWS. They can be written in any programming language and deployed on various platforms, including EC2 instances, Lambda functions, or containers on platforms like Amazon ECS or EKS.","poster":"Abdullah22"},{"timestamp":"1725365400.0","content":"Selected Answer: B\\nhttps://aws.amazon.com/xray/faqs/#:~:text=Region%20annotation%20for%20AWS%20services%20will%20be%20added%20automatically%2C%20however%2C%20customers%20will%20need%20to%20instrument%20custom%20services%20to%20add%20the%20regional%20annotation%20to%20make%20use%20of%20the%20cross%2Dregion%20support.","comment_id":"1164830","upvote_count":"2","poster":"KarBiswa"},{"comment_id":"1155289","upvote_count":"4","content":"Selected Answer: B\\nUser defined has to be in sdk.","poster":"CrescentShared","timestamp":"1724213040.0"}],"answer_description":"","extracted_at":"2025-12-24T09:02:45.193Z","extraction_method":"api_direct_v1"},{"question_id":"soiRABlFBVkhnd9QnkRx","question_number":212,"page":43,"question_text":"An application is processing clickstream data using Amazon Kinesis. The clickstream data feed into Kinesis experiences periodic spikes. The PutRecords API call occasionally fails and the logs show that the failed call returns the response shown below:\\n//IMG//\\n\\nWhich techniques will help mitigate this exception? (Choose two.)","choices":{"D":"Use Amazon SNS instead of Kinesis.","B":"Use a PutRecord API instead of PutRecords.","E":"Reduce the number of KCL consumers.","C":"Reduce the frequency and/or size of the requests.","A":"Implement retries with exponential backoff."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (85%)","BC (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102903-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image1.png"],"answer_images":[],"timestamp":"2023-03-17 09:50:00","unix_timestamp":1679043000,"discussion_count":9,"discussion":[{"content":"Selected Answer: AC\\n100% AC as per AWS : ProvisionedThroughputExceededException\\nThe request rate for the stream is too high, or the requested data is too large for the available throughput. Reduce the frequency or size of your requests. For more information, see Streams Limits in the Amazon Kinesis Data Streams Developer Guide, and Error Retries and Exponential Backoff in AWS in the AWS General Reference.\\n\\nhttps://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html","timestamp":"1686702960.0","upvote_count":"8","poster":"eboehm2","comment_id":"922634"},{"upvote_count":"2","comments":[{"timestamp":"1734865380.0","content":"E) Eliminated - KCL consumers consume data from Kinesis streams; reducing their number will not address the write throughput limits causing the ProvisionedThroughputExceededException","upvote_count":"2","comment_id":"1330354","poster":"sumanshu"}],"timestamp":"1734865320.0","content":"Selected Answer: AC\\nA) Correct - Retries with exponential backoff help manage temporary spikes by delaying subsequent retry attempts progressively\\n\\nB) Eliminated - Switching to PutRecord would increase API calls, worsening the throughput issue\\n\\nC) Correct - Reducing request size or frequency directly addresses the throughput limits by spreading out the data more evenly.\\n\\nD) Eliminated - Amazon SNS is a messaging service, not designed for streaming data with high throughput like Kinesis.","poster":"sumanshu","comment_id":"1330353"},{"poster":"trieudo","comment_id":"1326329","upvote_count":"1","content":"Selected Answer: AC\\n==> Discard B: PutRecord doesn\'t reduce throughput issues as it sends one record at a time, increasing API calls.\\n==> Discard D: SNS isn\'t designed for streaming data; it handles pub/sub messaging.\\n==> Discard E: Reducing KCL consumers affects reading, not writing throughput.\\n\\n- A: Exponential backoff reduces retries during peak usage, easing shard throughput pressure. \\n- C: Lowering request frequency or size directly mitigates throughput exceedance on shards.","timestamp":"1734144720.0"},{"timestamp":"1730772540.0","comment_id":"1307172","upvote_count":"2","content":"Answer is A and C\\nBatch Efficiency: The `PutRecords` API allows you to send multiple records in a single request, which is generally more efficient than sending individual records with `PutRecord`. Using `PutRecords` can help optimize throughput by reducing the number of API calls and better utilizing the available capacity.","poster":"Venky786"},{"comment_id":"1215046","timestamp":"1716303600.0","poster":"65703c1","content":"Selected Answer: AC\\nAC is the correct answer.","upvote_count":"1"},{"timestamp":"1685867880.0","comment_id":"914255","upvote_count":"1","content":"Selected Answer: AC\\nAC is the best answer. When there is throttling, it is best practise to implement retries with exponential backoff.","poster":"Baba_Eni"},{"poster":"ezredame","comment_id":"910157","upvote_count":"3","comments":[{"poster":"eboehm2","comment_id":"922633","content":"I thought this at first too, but I was doing some additional reading and using the PutRecord API over PutRecords is wrong as it could actually make the problem worse as producers may make too many rapid requests to write to the stream\\nhttps://repost.aws/knowledge-center/kinesis-data-stream-throttling","upvote_count":"4","timestamp":"1686702720.0"},{"poster":"Majong","comment_id":"910959","content":"Can you please add a link where I can find this information. From what I can read on AWS is that you can implement exponential backoff but it is not by default.","timestamp":"1685517540.0","upvote_count":"1"}],"content":"Selected Answer: BC\\nI think this is really tricky question. To get this exception, the request rate for the stream is too high, or the requested data is too large for the available throughput. Reduce the frequency or size of your requests. So we can \\"Reduce the frequency and/or size of the requests\\" also decrease the size with \\"Use a PutRecord API instead of PutRecords\\"\\n\\nThe API already implements retries with exponential backoff. So there is no need for A.","timestamp":"1685443020.0"},{"upvote_count":"4","poster":"Untamables","content":"Selected Answer: AC\\nA and C\\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kinesis-data-stream-throttling-errors/","comment_id":"848174","timestamp":"1679573880.0"},{"poster":"aragon_saa","comments":[{"upvote_count":"1","poster":"yashika2005","content":"thanks a lotttt!","comment_id":"913258","timestamp":"1685766480.0"}],"timestamp":"1679043000.0","upvote_count":"4","comment_id":"841809","content":"AC\\nhttps://www.examtopics.com/discussions/amazon/view/69142-exam-aws-certified-developer-associate-topic-1-question-370/"}],"answer_description":"","extracted_at":"2025-12-24T09:02:45.193Z","extraction_method":"api_direct_v1"},{"question_id":"zK5nkkzaTd6etsI7is5G","question_number":213,"page":43,"question_text":"A company runs an application on AWS. The application uses an AWS Lambda function that is configured with an Amazon Simple Queue Service (Amazon SQS) queue called high priority queue as the event source. A developer is updating the Lambda function with another SQS queue called low priority queue as the event source. The Lambda function must always read up to 10 simultaneous messages from the high priority queue before processing messages from low priority queue. The Lambda function must be limited to 100 simultaneous invocations.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Set the event source mapping batch size to 10 for the high priority queue and to 90 for the low priority queue.","D":"Set the event source mapping batch window to 10 for the high priority queue and to 90 for the low priority queue.","B":"Set the delivery delay to 0 seconds for the high priority queue and to 10 seconds for the low priority queue.","C":"Set the event source mapping maximum concurrency to 10 for the high priority queue and to 90 for the low priority queue."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134289-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:07:00","unix_timestamp":1708495620,"discussion_count":6,"discussion":[{"comment_id":"1313347","timestamp":"1731809760.0","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: C\\nResources:\\n HighPriorityEventSourceMapping:\\n Type: AWS::Lambda::EventSourceMapping\\n Properties:\\n BatchSize: 10\\n MaximumConcurrency: 10\\n EventSourceArn: arn:aws:sqs:region:account-id:high-priority-queue\\n FunctionName: myLambdaFunction\\n\\n LowPriorityEventSourceMapping:\\n Type: AWS::Lambda::EventSourceMapping\\n Properties:\\n BatchSize: 10\\n MaximumConcurrency: 90\\n EventSourceArn: arn:aws:sqs:region:account-id:low-priority-queue\\n FunctionName: myLambdaFunction"},{"timestamp":"1727367480.0","poster":"preachr","upvote_count":"2","comment_id":"1289594","content":"Selected Answer: C\\nYou can use the maximum concurrency setting to control scaling behavior for your SQS event sources. The maximum concurrency setting limits the number of concurrent instances of the function that an Amazon SQS event source can invoke. Maximum concurrency is an event source-level setting. If you have multiple Amazon SQS event sources mapped to one function, each event source can have a separate maximum concurrency setting. You can use maximum concurrency to prevent one queue from using all of the function\'s reserved concurrency or the rest of the account\'s concurrency quota. There is no charge for configuring maximum concurrency on an Amazon SQS event source."},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716553800.0","comment_id":"1217440"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency","comment_id":"1164839","upvote_count":"2","timestamp":"1709475720.0","poster":"KarBiswa"},{"timestamp":"1709164560.0","comment_id":"1162059","poster":"monishvster","upvote_count":"2","content":"Selected Answer: C\\nShould be C"},{"upvote_count":"2","poster":"CrescentShared","content":"Selected Answer: C\\nNone of them seems to be guarantee the requirement. \\nSet the reserved concurrency on the Lambda function to 100 to limit the total invocations across all triggers.\\nConfigure the event source mapping for the high priority queue to use a maximum concurrency that ensures its messages are processed first. This could be most of the reserved concurrency (but not all, to allow for some processing of the low priority queue).\\nConfigure the event source mapping for the low priority queue with a smaller maximum concurrency to ensure it doesn\'t starve the high priority queue of Lambda resources.","comment_id":"1155291","timestamp":"1708495620.0"}],"answer_description":"","extracted_at":"2025-12-24T09:02:45.193Z","extraction_method":"api_direct_v1"},{"question_id":"YFonpC5o5a2BHTR8yi14","question_number":214,"page":43,"question_text":"A data visualization company wants to strengthen the security of its core applications. The applications are deployed on AWS across its development, staging, pre-production, and production environments. The company needs to encrypt all of its stored sensitive credentials. The sensitive credentials need to be automatically rotated. A version of the sensitive credentials need to be stored for each environment.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"A":"Configure AWS Secrets Manager versions to store different copies of the same credentials across multiple environments.","B":"Create a new parameter version in AWS Systems Manager Parameter Store for each environment. Store the environment-specific credentials in the parameter version.","D":"Configure AWS Secrets Manager to create a new secret for each environment type. Store the environment-specific credentials in the secret.","C":"Configure the environment variables in the application code. Use different names for each environment type."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134290-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:09:00","unix_timestamp":1708495740,"discussion_count":6,"discussion":[{"comment_id":"1217445","poster":"65703c1","timestamp":"1732459140.0","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2"},{"timestamp":"1729938120.0","content":"A comprehensive guide to help you navigate the landscape and find the perfect <a href=\\"https://keensolution.in/data-visualization-services/\\">data visualization agencies in India</a> for your business","comment_id":"1202533","upvote_count":"1","poster":"keensolution"},{"poster":"SerialiDr","content":"Selected Answer: D\\nD. Configure AWS Secrets Manager to create a new secret for each environment type. Store the environment-specific credentials in the secret.\\n\\nAWS Secrets Manager supports the encryption of secrets (including sensitive credentials) and allows for automatic rotation of these secrets. By creating a new secret for each environment (development, staging, pre-production, and production), you can manage and access the environment-specific credentials securely. This approach facilitates operational efficiency by leveraging AWS Secrets Manager\'s built-in capabilities for encryption and rotation, without the need for manual intervention or complex configurations. Secrets Manager also provides a straightforward way to retrieve the correct version of the credentials for each specific environment, simplifying the management of sensitive data across different stages of application deployment.","timestamp":"1725717180.0","comment_id":"1168150","upvote_count":"3"},{"poster":"KarBiswa","upvote_count":"1","comment_id":"1164843","timestamp":"1725366420.0","content":"Selected Answer: D\\nDifferent credentials"},{"upvote_count":"1","content":"Selected Answer: D\\nShould be D","comment_id":"1162062","timestamp":"1724882400.0","poster":"monishvster"},{"content":"Selected Answer: D\\nC does not make sense.","poster":"CrescentShared","comment_id":"1155292","upvote_count":"2","timestamp":"1724213340.0"}],"answer_description":"","extracted_at":"2025-12-24T09:02:45.193Z","extraction_method":"api_direct_v1"},{"question_id":"s55cZ4v2OAJrulG4EP1C","question_number":215,"page":43,"question_text":"A developer is investigating an issue in part of a company\'s application. In the application, messages are sent to an Amazon Simple Queue Service (Amazon SQS) queue. The AWS Lambda function polls messages from the SQS queue and sends email messages by using Amazon Simple Email Service (Amazon SES). Users have been receiving duplicate email messages during periods of high traffic.\\n\\nWhich reasons could explain the duplicate email messages? (Choose two.)","choices":{"B":"Standard SQS queues support exactly-once processing, so the duplicate email messages are because of user error.","A":"Standard SQS queues support at-least-once message delivery.","D":"The SQS queue\'s visibility timeout is lower than or the same as the Lambda function\'s timeout.","C":"Amazon SES has the DomainKeys Identified Mail (DKIM) authentication incorrectly configured.","E":"The Amazon SES bounce rate metric is too high."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134291-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:10:00","unix_timestamp":1708495800,"discussion_count":4,"discussion":[{"timestamp":"1708495800.0","comment_id":"1155293","content":"Selected Answer: AD\\nAD is correct.","poster":"CrescentShared","upvote_count":"6"},{"comment_id":"1237402","upvote_count":"1","timestamp":"1719399000.0","content":"Selected Answer: AD\\nAD for sure","poster":"Alabi"},{"content":"Selected Answer: AD\\nAD is the correct answer.","comment_id":"1217450","poster":"65703c1","upvote_count":"1","timestamp":"1716554580.0"},{"timestamp":"1709476560.0","comment_id":"1164849","poster":"KarBiswa","content":"Selected Answer: AD\\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:02:45.193Z","extraction_method":"api_direct_v1"},{"question_id":"P6GgLpSXbZvspn6psoBd","question_number":216,"page":44,"question_text":"A developer is deploying a company\'s application to Amazon EC2 instances. The application generates gigabytes of data files each day. The files are rarely accessed, but the files must be available to the application\'s users within minutes of a request during the first year of storage. The company must retain the files for 7 years.\\n\\nHow can the developer implement the application to meet these requirements MOST cost-effectively?","choices":{"D":"Store the files on an Amazon Elastic File System (Amazon EFS) mount. Configure EFS lifecycle management to transition the files to the EFS Standard- Infrequent Access (Standard-IA) storage class after 1 year.","B":"Store the files in an Amazon S3 bucket. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition the files to the S3 Glacier Flexible Retrieval storage class after 1 year.","C":"Store the files on an Amazon Elastic Block Store (Amazon EBS) volume. Use Amazon Data Lifecycle Manager (Amazon DLM) to create snapshots of the EBS volumes and to store those snapshots in Amazon S3.","A":"Store the files in an Amazon S3 bucket. Use the S3 Glacier Instant Retrieval storage class. Create an S3 Lifecycle policy to transition the files to the S3 Glacier Deep Archive storage class after 1 year."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134292-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:11:00","unix_timestamp":1708495860,"discussion_count":5,"discussion":[{"comment_id":"1306301","timestamp":"1730575320.0","poster":"Saudis","content":"Selected Answer: A\\nGlacier for archiving = long time storge","upvote_count":"1"},{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1217456","timestamp":"1716554880.0","upvote_count":"3","poster":"65703c1"},{"upvote_count":"3","comment_id":"1164856","content":"Selected Answer: A\\nhttps://aws.amazon.com/s3/storage-classes/","timestamp":"1709477160.0","poster":"KarBiswa"},{"poster":"monishvster","upvote_count":"3","comment_id":"1162063","content":"Selected Answer: A\\nShould be A","timestamp":"1709164920.0"},{"timestamp":"1708495860.0","comment_id":"1155295","content":"Selected Answer: A\\nMust be A","upvote_count":"4","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:02:56.153Z","extraction_method":"api_direct_v1"},{"question_id":"fKGPQq4pQUvoqSycr66u","question_number":217,"page":44,"question_text":"A company\'s developer has deployed an application in AWS by using AWS CloudFormation. The CloudFormation stack includes parameters in AWS Systems Manager Parameter Store that the application uses as configuration settings. The application can modify the parameter values.\\n\\nWhen the developer updated the stack to create additional resources with tags, the developer noted that the parameter values were reset and that the values ignored the latest changes made by the application. The developer needs to change the way the company deploys the CloudFormation stack. The developer also needs to avoid resetting the parameter values outside the stack.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"D":"Modify the CloudFormation stack policy to deny updates on Parameter Store parameters.","A":"Modify the CloudFormation stack to set the deletion policy to Retain for the Parameter Store parameters.","C":"Create an Amazon RDS DB instance as a resource in the CloudFormation stack. Create a table in the database for parameter configuration. Migrate the parameters that the application is modifying from Parameter Store to the configuration table.","B":"Create an Amazon DynamoDB table as a resource in the CloudFormation stack to hold configuration data for the application. Migrate the parameters that the application is modifying from Parameter Store to the DynamoDB table."},"correct_answer":"A","answer_ET":"A","answers_community":["A (56%)","D (37%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134293-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:12:00","unix_timestamp":1708495920,"discussion_count":12,"discussion":[{"content":"Selected Answer: D\\nLa opci\xf3n de DeletionPolicy: Retain aplica solo para la eliminacion de los recursos, la pregunta habla de la actualizaci\xf3n del valor de SSM Parameter, una politica que haga el deny de poder actualizar los valores, permitir\xe1 proteger el cloudformation","poster":"teban0130","timestamp":"1741691460.0","upvote_count":"2","comment_id":"1387356"},{"poster":"albert_kuo","timestamp":"1727868300.0","upvote_count":"1","content":"Selected Answer: A\\nResources:\\n MyAppParameter:\\n Type: \\"AWS::SSM::Parameter\\"\\n Properties:\\n Name: \\"MyAppParameter\\"\\n Type: \\"String\\"\\n Value: \\"InitialValue\\"\\n DeletionPolicy: Retain","comment_id":"1292381"},{"content":"Selected Answer: B\\nOption B (Use Amazon DynamoDB for Configuration Data):\\nCreate a DynamoDB table as a resource in the CloudFormation stack.\\nMigrate the parameters from Parameter Store to the DynamoDB table.\\nAllows the application to modify parameter values without affecting the stack.","poster":"Saurabh04","upvote_count":"2","timestamp":"1723696620.0","comment_id":"1266202"},{"comments":[{"poster":"BrainFried","timestamp":"1723462500.0","upvote_count":"1","comment_id":"1264628","content":"The stack deletes resources on updates. See https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html\\n\\nThe wording in the question states \\"The application can modify the parameter values\\"\\n\\nGiven this, it is unlikely that Option D would be suitable. It would prevent the application from making updates to the parameter store, leading to potential errors. \\n\\nOption D is also unsuitable as it as it would mean the parameter store would still be reset for any future stack updates - which is precisely the root cause of the original issue stated in this question. D does not solve the problem here. A does."}],"content":"Selected Answer: D\\nThere is no evidence from the wording in question that resources have been deleted from outside. Also, resetting the values does not mean factory reset wherein, somebody deleted the resource from outside and recreated it with default values. There is no evidence of that either. So, as per https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#stack-policy-reference I would choose D","timestamp":"1721537820.0","poster":"Anandesh","upvote_count":"2","comment_id":"1252228"},{"poster":"ahadh7621","upvote_count":"1","comment_id":"1251707","content":"I don\'t understand why it would be A. Reading the question again, \\"The developer \\"updated the stack to create additional resources with tags...noted that the parameter values were reset\\". A deletion policy only protects resources when a stack is deleted or \\"This capability also applies to stack update operations that lead to resources being deleted from stacks.\\" (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html) The parameters aren\'t being deleted but simply overwritten.\\n\\nIn this case, to prevent the parameter store values from being overwritten, we can use a stack policy to prevent updates to a stack resource. \\"You can prevent stack resources from being unintentionally updated or deleted during a stack update by using a stack policy.\\" (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#stack-policy-intro-example)","timestamp":"1721473020.0"},{"timestamp":"1716555780.0","upvote_count":"1","comment_id":"1217473","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1"},{"upvote_count":"3","content":"Selected Answer: A\\nOption A is the most straightforward approach to ensure that the parameters are not deleted or reset to their original values when the stack is deleted or updated. \\n\\nOption D Modifying the stack policy to deny updates on Parameter Store parameters could prevent necessary updates and is not recommended as it could lead to stack update failures.","comment_id":"1175819","poster":"yingying920928","timestamp":"1710679020.0"},{"timestamp":"1710175680.0","content":"Selected Answer: A\\nThis solution allows the developer to avoid resetting the parameter values stored in AWS Systems Manager Parameter Store when updating the CloudFormation stack. By setting the deletion policy to Retain for those parameters, CloudFormation will preserve their values during stack updates instead of deleting and recreating them.","comment_id":"1171150","poster":"KarBiswa","upvote_count":"3"},{"upvote_count":"4","comment_id":"1168291","content":"Selected Answer: A\\nA. Modify the CloudFormation stack to set the deletion policy to Retain for the Parameter Store parameters.\\n\\nThis solution allows the developer to avoid resetting the parameter values stored in AWS Systems Manager Parameter Store when updating the CloudFormation stack. By setting the deletion policy to Retain for those parameters, CloudFormation will preserve their values during stack updates instead of deleting and recreating them.\\n\\nIt changes the way the company deploys the CloudFormation stack by modifying the deletion policy for the relevant parameters.\\nIt avoids resetting the parameter values outside the stack, as the values modified by the application will be retained during stack updates.","poster":"SerialiDr","timestamp":"1709838480.0"},{"poster":"Abdullah22","upvote_count":"2","timestamp":"1709831400.0","comment_id":"1168203","content":"Selected Answer: D\\nI am going with D."},{"poster":"monishvster","upvote_count":"3","timestamp":"1709165040.0","comment_id":"1162065","content":"Selected Answer: A\\nShould be A. As the developer also needs to avoid resetting the parameter values outside the stack."},{"poster":"CrescentShared","comment_id":"1155296","content":"Selected Answer: D\\nIt is D","timestamp":"1708495920.0","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:02:56.153Z","extraction_method":"api_direct_v1"},{"question_id":"CigJWcoySusdYkEmf4Tr","question_number":218,"page":44,"question_text":"A company has a social media application that receives large amounts of traffic. User posts and interactions are continuously updated in an Amazon RDS database. The data changes frequently, and the data types can be complex. The application must serve read requests with minimal latency.\\n\\nThe application\'s current architecture struggles to deliver these rapid data updates efficiently. The company needs a solution to improve the application\'s performance.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Add an Amazon CloudFront distribution in front of the RDS database to provide a caching layer for the high volume of rapidly changing data.","B":"Set up Amazon S3 Transfer Acceleration on the RDS database to enhance the speed of data transfer from the databases to the application.","A":"Use Amazon DynamoDB Accelerator (DAX) in front of the RDS database to provide a caching layer for the high volume of rapidly changing data.","D":"Create an Amazon ElastiCache for Redis cluster. Update the application code to use a write-through caching strategy and read the data from Redis."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134294-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:14:00","unix_timestamp":1708496040,"discussion_count":10,"discussion":[{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","comment_id":"1217486","timestamp":"1732461240.0","poster":"65703c1"},{"upvote_count":"2","content":"D\\nCloud Front is generally used to distribute static content such as images, stylesheets, and scripts. CloudFront is not typically used for caching database queries or dynamic data directly from databases like RDS.","comment_id":"1194355","timestamp":"1728739080.0","poster":"be1dca8"},{"upvote_count":"1","timestamp":"1728739020.0","poster":"be1dca8","content":"D\\n is generally used to distribute static content such as images, stylesheets, and scripts. CloudFront is not typically used for caching database queries or dynamic data directly from databases like RDS.","comment_id":"1194354"},{"comment_id":"1179379","timestamp":"1726927140.0","upvote_count":"1","content":"cash , complex = redis","poster":"Abdullah22"},{"upvote_count":"3","timestamp":"1725729360.0","poster":"SerialiDr","content":"Selected Answer: D\\nThis option is the most suitable for the described scenario. Amazon ElastiCache for Redis can act as a high-performance, in-memory data store and cache, which is ideal for applications that require fast access to data. Implementing a write-through caching strategy ensures that data is written to the cache and the primary data store (RDS) simultaneously, keeping the cache up to date. Reading data from the cache can significantly reduce latency and the load on the RDS database, making it an optimal solution for applications with high read demand.","comment_id":"1168299"},{"comment_id":"1168210","timestamp":"1725722220.0","upvote_count":"2","poster":"Abdullah22","content":"Selected Answer: D\\ngoing with cash D"},{"poster":"KarBiswa","timestamp":"1725368160.0","comment_id":"1164863","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/whitepapers/latest/database-caching-strategies-using-redis/caching-patterns.html","upvote_count":"1"},{"poster":"ANDRES715","comment_id":"1162120","content":"R. Utilice Amazon DynamoDB Accelerator (DAX) frente a la base de datos RDS para proporcionar una capa de almacenamiento en cach\xe9 para el gran volumen de datos que cambian r\xe1pidamente.\\n\\n\\nAl utilizar Amazon DynamoDB Accelerator (DAX) frente a la base de datos RDS, se puede proporcionar una capa de almacenamiento en cach\xe9 para el gran volumen de datos que cambian r\xe1pidamente. DAX mejora el rendimiento de las consultas de lectura al almacenar en cach\xe9 los resultados de las consultas m\xe1s frecuentes, lo que reduce la latencia y mejora la capacidad de respuesta de la aplicaci\xf3n.\\n\\n\\nEs importante tener en cuenta que DynamoDB Accelerator (DAX) es una opci\xf3n eficiente para mejorar el rendimiento de aplicaciones que requieren un acceso r\xe1pido a datos que cambian con frecuencia, como en el caso de una aplicaci\xf3n de redes sociales.","upvote_count":"1","timestamp":"1724889000.0"},{"comment_id":"1162066","content":"Selected Answer: D\\nShould be D","timestamp":"1724882760.0","poster":"monishvster","upvote_count":"1"},{"upvote_count":"1","poster":"CrescentShared","timestamp":"1724213640.0","comment_id":"1155299","content":"Selected Answer: D\\nhesitate between C and D."}],"answer_description":"","extracted_at":"2025-12-24T09:02:56.153Z","extraction_method":"api_direct_v1"},{"question_id":"rQX7R9xaVhSN2SRwkssM","question_number":219,"page":44,"question_text":"A developer created an AWS Lambda function that performs a series of operations that involve multiple AWS services. The function\'s duration time is higher than normal. To determine the cause of the issue, the developer must investigate traffic between the services without changing the function code.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Enable AWS X-Ray active tracing in the Lambda function. Review the logs in X-Ray.","D":"Review the Amazon CloudWatch logs that are associated with the Lambda function.","B":"Configure AWS CloudTrail. View the trail logs that are associated with the Lambda function.","C":"Review the AWS Config logs in Amazon CloudWatch."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134295-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:17:00","unix_timestamp":1708496220,"discussion_count":5,"discussion":[{"poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"2","comment_id":"1217489","timestamp":"1732461420.0"},{"timestamp":"1725368280.0","upvote_count":"2","poster":"KarBiswa","comment_id":"1164865","content":"Selected Answer: A\\nX ray option"},{"upvote_count":"2","poster":"monishvster","content":"Selected Answer: A\\nShould be A","timestamp":"1724882760.0","comment_id":"1162067"},{"upvote_count":"4","comment_id":"1158296","timestamp":"1724545740.0","content":"Selected Answer: A\\nA. Enable AWS X-Ray active tracing in the Lambda function. Review the logs in X-Ray.\\nX-Ray provides insights into the duration and performance of each component, helping you identify the root cause of performance issues without modifying the function code.","poster":"hungnv6_rikkei"},{"content":"Selected Answer: A\\nbetween the services","timestamp":"1724213820.0","poster":"CrescentShared","comment_id":"1155301","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:02:56.153Z","extraction_method":"api_direct_v1"},{"question_id":"zv521Acs422Tap2mkrcq","question_number":220,"page":44,"question_text":"A company has on-premises data centers that run an image processing service. The service consists of containerized applications that run on Kubernetes clusters. All the applications have access to the same NFS share for files and data storage.\\n\\nThe company is running out of NFS capacity in the data centers and needs to migrate to AWS as soon as possible. The Kubernetes clusters must be highly available on AWS.\\n\\nWhich combination of actions will meet these requirements? (Choose two.)","choices":{"D":"Create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to run the applications. Configure each node of the cluster to mount the Amazon Elastic Block Store (Amazon EBS) volume at the required path for the container images.","C":"Create an Amazon Elastic Container Service (Amazon ECS) cluster to run the applications. Configure each node of the cluster to mount the Amazon Elastic Block Store (Amazon EBS) volume at the required path for the container images.","A":"Transfer the information that is in the NFS share to an Amazon Elastic Block Store (Amazon EBS) volume. Upload the container images to Amazon Elastic Container Registry (Amazon ECR).","B":"Transfer the information that is in the NFS share to an Amazon Elastic File System (Amazon EFS) volume. Upload the container images to Amazon Elastic Container Registry (Amazon ECR).","E":"Create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to run the applications. Configure each node of the cluster to mount the Amazon Elastic File System (Amazon EFS) volume at the required path for the container images."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134296-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:17:00","unix_timestamp":1708496220,"discussion_count":5,"discussion":[{"timestamp":"1732461660.0","comment_id":"1217494","upvote_count":"2","poster":"65703c1","content":"Selected Answer: BE\\nBE is the correct answer."},{"upvote_count":"4","comment_id":"1171423","content":"Selected Answer: BE\\nhttps://docs.aws.amazon.com/efs/latest/ug/efs-onpremises.html for NFS to EFS mounting and the question itself demands EKS.","poster":"KarBiswa","timestamp":"1726107960.0"},{"content":"Selected Answer: BE\\nEFS is the key here","timestamp":"1724882880.0","poster":"monishvster","upvote_count":"3","comment_id":"1162068"},{"upvote_count":"2","content":"Selected Answer: BE\\nAmazon Elastic File System (Amazon EFS) volume and Amazon Elastic Kubernetes Service (Amazon EKS)","poster":"hungnv6_rikkei","comment_id":"1158298","timestamp":"1724545920.0"},{"poster":"CrescentShared","content":"Selected Answer: BE\\nEBS cannot be multi mounted.","upvote_count":"3","timestamp":"1724213820.0","comment_id":"1155302"}],"answer_description":"","extracted_at":"2025-12-24T09:02:56.153Z","extraction_method":"api_direct_v1"},{"question_id":"pi2Tnalti3IelwAhrZ43","question_number":221,"page":45,"question_text":"A company has an analytics application that uses an AWS Lambda function to process transaction data asynchronously. A developer notices that asynchronous invocations of the Lambda function sometimes fail. When failed Lambda function invocations occur, the developer wants to invoke a second Lambda function to handle errors and log details.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create a status check alarm on the initial Lambda function. Configure the alarm to invoke the error-handling Lambda function when the alarm is initiated. Ensure that the alarm passes the stack trace in the event object.","C":"Configure a Lambda function trigger with a failure condition. Specify Lambda function as the destination type. Specify the error-handling Lambda function\'s Amazon Resource Name (ARN) as the resource.","B":"Enable AWS X-Ray active tracing on the initial Lambda function. Configure X-Ray to capture stack traces of the failed invocations. Invoke the error-handling Lambda function by including the stack traces in the event object.","A":"Configure a Lambda function destination with a failure condition. Specify Lambda function as the destination type. Specify the error-handling Lambda function\'s Amazon Resource Name (ARN) as the resource."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134297-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:19:00","unix_timestamp":1708496340,"discussion_count":5,"discussion":[{"poster":"65703c1","timestamp":"1732461840.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"2","comment_id":"1217498"},{"content":"Selected Answer: A\\nLambda destinations allow you to configure what happens to Lambda function invocation records when an invocation is successful or, in this case, when it fails. By setting a destination for failed invocations, you can specify another Lambda function to handle errors. This setup enables automatic error handling without requiring changes to the application code or the use of additional services for monitoring and triggering error-handling mechanisms. The error-handling Lambda function can then log details, send notifications, or take corrective actions as needed.","upvote_count":"3","poster":"SerialiDr","timestamp":"1725730200.0","comment_id":"1168310"},{"poster":"KarBiswa","upvote_count":"1","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations","timestamp":"1725368760.0","comment_id":"1164873"},{"upvote_count":"1","timestamp":"1724882940.0","poster":"monishvster","comment_id":"1162071","content":"Selected Answer: A\\nShould be A since Trigger is before execution"},{"content":"Selected Answer: A\\nis not a valid approach because Lambda does not have a direct configuration for triggers based on failure conditions in the way described. The concept of a trigger is generally used for starting an invocation, not handling failures.","timestamp":"1724213940.0","comment_id":"1155304","poster":"CrescentShared","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:03:07.185Z","extraction_method":"api_direct_v1"},{"question_id":"cVriWzVwWZX25MbjvEcH","question_number":222,"page":45,"question_text":"A company introduced a new feature that should be accessible to only a specific group of premium customers. A developer needs the ability to turn the feature on and off in response to performance and feedback. The developer needs a solution to validate and deploy these configurations quickly without causing any disruptions.\\n\\nWhat should the developer do to meet these requirements?","choices":{"D":"Use AWS Systems Manager Parameter Store to store and validate the configuration settings for the feature. Enable lifecycle rules to turn the feature on and off.","B":"Use AWS Secrets Manager to securely manage and validate the feature configurations. Enable lifecycle rules to turn the feature on and off.","A":"Use AWS AppConfig to manage the feature configuration and to validate and deploy changes. Use feature flags to turn the feature on and off.","C":"Use AWS Config to manage the feature configuration and validation. Set up AWS Config rules to turn the feature on and off based on predefined conditions."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134298-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-21 07:20:00","unix_timestamp":1708496400,"discussion_count":4,"discussion":[{"content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","upvote_count":"2","timestamp":"1732462080.0","comment_id":"1217505"},{"poster":"SerialiDr","comment_id":"1168307","upvote_count":"4","timestamp":"1725729900.0","content":"Selected Answer: A\\nAWS AppConfig is part of AWS Systems Manager and is designed specifically for managing application configurations and feature toggles in a safe and controlled manner. It allows developers to validate changes before deployment, minimizing the risk of impacting application stability and user experience. Using feature flags with AppConfig enables the developer to turn features on or off without deploying new code, making it an ideal solution for controlling access to new features based on various criteria, including user groups or performance metrics. This method provides a quick and non-disruptive way to manage application features."},{"comment_id":"1164876","timestamp":"1725369000.0","upvote_count":"3","poster":"KarBiswa","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/appconfig/latest/userguide/what-is-appconfig.html"},{"poster":"CrescentShared","timestamp":"1724214000.0","comment_id":"1155305","upvote_count":"2","content":"Selected Answer: A\\nApp COnfig is the one"}],"answer_description":"","extracted_at":"2025-12-24T09:03:07.185Z","extraction_method":"api_direct_v1"},{"question_id":"NAzDbiCIqIkmGianOuA3","question_number":223,"page":45,"question_text":"An application is using Amazon Cognito user pools and identity pools for secure access. A developer wants to integrate the user-specific file upload and download features in the application with Amazon S3. The developer must ensure that the files are saved and retrieved in a secure manner and that users can access only their own files. The file sizes range from 3 KB to 300 MB.\\nWhich option will meet these requirements with the HIGHEST level of security?","choices":{"D":"Use an IAM policy within the Amazon Cognito identity prefix to restrict users to use their own folders in Amazon S3.","B":"Save the details of the uploaded files in a separate Amazon DynamoDB table. Filter the list of files in the user interface (UI) by comparing the current user ID with the user ID associated with the file in the table.","A":"Use S3 Event Notifications to validate the file upload and download requests and update the user interface (UI).","C":"Use Amazon API Gateway and an AWS Lambda function to upload and download files. Validate each request in the Lambda function before performing the requested operation."},"correct_answer":"D","answer_ET":"D","answers_community":["D (93%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102788-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 10:16:00","unix_timestamp":1678958160,"discussion_count":14,"discussion":[{"upvote_count":"12","timestamp":"1679360640.0","poster":"Untamables","comment_id":"845417","content":"Selected Answer: D\\nD\\nI actually apply this solution the production applications.\\nExamples\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_s3_cognito-bucket.html\\nhttps://docs.amplify.aws/lib/storage/getting-started/q/platform/js/"},{"content":"Selected Answer: D\\nThis solution provides the highest level of security by ensuring that each user can only access their own files in Amazon S3 based on their identity.","comment_id":"1329450","poster":"sumanshu","upvote_count":"1","timestamp":"1734700440.0","comments":[{"comments":[{"comments":[{"content":"C) Eliminated - Lambda would need to handle the file transfer and validation, which could introduce scaling issues for large file sizes (300 MB).","comment_id":"1329472","upvote_count":"1","poster":"sumanshu","timestamp":"1734701760.0"}],"upvote_count":"1","content":"B) Eliminated - Storing file details in DynamoDB and using it to filter access in the UI could be helpful for organizing and tracking files. However, this does not address the core security concern of restricting direct access to S3 objects themselves. Even though DynamoDB can help track files, it still doesn\'t enforce access control on the S3 objects themselves","timestamp":"1734701700.0","poster":"sumanshu","comment_id":"1329471"}],"comment_id":"1329470","timestamp":"1734701640.0","upvote_count":"1","content":"A) Eliminated - S3 Event Notifications are typically used for triggering processes when an object is uploaded or modified in S3, but they don\'t directly validate or enforce security controls on user-specific access","poster":"sumanshu"}]},{"comment_id":"1324977","poster":"trieudo","upvote_count":"2","content":"Selected Answer: D\\nHighest secure\\n\\n=> discard A: S3 Event Notifications, it act on notify with event, not blocking risk\\n=> discard B: You can\'t handle by UI or BE code by User ID, but hacker can try to access directly into storage s3 \\n=> discard C: I would have said C but that is kind of a custom solution that is both more overhead and more prone to error\\n\\nD ==> The identity prefix in Amazon Cognito allows you to create a unique identity for each user. This prefix can be used as part of the IAM policy to control access at a more granular level.","timestamp":"1733913300.0"},{"comment_id":"890676","upvote_count":"1","comments":[{"comment_id":"897615","poster":"grzess","upvote_count":"3","content":"Implementing custom authentication / authorization solution is extremely bad practice. Any developers is prone to mistakes. It\'s always better to trust the dedicated solution. Thus option C is definitely not the correct one.","timestamp":"1684074900.0"}],"content":"Selected Answer: C\\nD is not the best option as IAM policies only apply to actions taken through AWS Management Console, SDKs, and CLI. It does not apply to direct access to S3 from the application.\\n\\nOption B is a good approach, but it requires additional overhead to manage the DynamoDB table.\\n\\nOption A is also a possible solution but only provides limited security as it only validates the upload and download requests, and it does not provide user-level authorization.\\n\\nOption C is the best choice as it allows the developer to implement a custom authentication mechanism in the Lambda function, providing the highest level of security. The authentication mechanism can be integrated with Amazon Cognito user pools and identity pools to authenticate users and ensure that only the owner of the file can upload and download it.","poster":"Bibay","timestamp":"1727237760.0"},{"upvote_count":"1","timestamp":"1722290700.0","comment_id":"1257716","poster":"ACurryDeveloper","content":"D you benchods. It says cognito in the question motherchods"},{"poster":"NagaoShingo","content":"Selected Answer: D\\nD is correct answer.","upvote_count":"2","comment_id":"1222764","timestamp":"1717257360.0"},{"upvote_count":"1","timestamp":"1716295560.0","comment_id":"1214947","poster":"65703c1","content":"D is the correct answer."},{"timestamp":"1709558760.0","poster":"TheFivePips","comment_id":"1165595","content":"Selected Answer: D\\nThe identity prefix in Amazon Cognito allows you to create a unique identity for each user. This prefix can be used as part of the IAM policy to control access at a more granular level.\\n\\nI would have said C but that is kind of a custom solution that is both more overhead and more prone to error","upvote_count":"2"},{"timestamp":"1706637120.0","content":"Selected Answer: D\\nD is the answer","upvote_count":"1","poster":"tfmzworld","comment_id":"1136003"},{"poster":"Chimzi","content":"Selected Answer: D\\nB can work but does not provide the same level of security as D","timestamp":"1704303420.0","upvote_count":"1","comment_id":"1112979"},{"comment_id":"1061928","timestamp":"1699078800.0","content":"Selected Answer: B\\nI consider between B & D","upvote_count":"1","poster":"dongocanh272"},{"comment_id":"1027587","upvote_count":"1","content":"Selected Answer: D\\nAnswer D is correct","poster":"Digo30sp","timestamp":"1696703700.0"},{"comment_id":"879765","timestamp":"1682378100.0","poster":"MrTee","content":"Selected Answer: D\\nThis solution ensures that users can access only their own files in a secure manner.","upvote_count":"3"},{"timestamp":"1678958160.0","comment_id":"840742","poster":"haaris786","upvote_count":"3","content":"Answer D: \\n\\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-integrating-user-pools-with-identity-pools.html"}],"answer_description":"","extracted_at":"2025-12-24T09:03:07.185Z","extraction_method":"api_direct_v1"},{"question_id":"8tFRn9TEv6i1wGvs4zEJ","question_number":224,"page":45,"question_text":"A company has an application that uses Amazon Cognito user pools as an identity provider. The company must secure access to user records. The company has set up multi-factor authentication (MFA). The company also wants to send a login activity notification by email every time a user logs in.\\nWhat is the MOST operationally efficient solution that meets this requirement?","choices":{"C":"Create an AWS Lambda function that uses Amazon Simple Email Service (Amazon SES) to send the email notification. Create an Amazon CloudWatch Logs log subscription filter to invoke the function based on the login status.","B":"Create an AWS Lambda function that uses Amazon Simple Email Service (Amazon SES) to send the email notification. Add an Amazon Cognito post authentication Lambda trigger for the function.","A":"Create an AWS Lambda function that uses Amazon Simple Email Service (Amazon SES) to send the email notification. Add an Amazon API Gateway API to invoke the function. Call the API from the client side when login confirmation is received.","D":"Configure Amazon Cognito to stream all logs to Amazon Kinesis Data Firehose. Create an AWS Lambda function to process the streamed logs and to send the email notification based on the login status of each user."},"correct_answer":"B","answer_ET":"B","answers_community":["B (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102904-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-17 09:51:00","unix_timestamp":1679043060,"discussion_count":10,"discussion":[{"comment_id":"897339","content":"B. Create an AWS Lambda function that uses Amazon Simple Email Service (Amazon SES) to send the email notification. Add an Amazon Cognito post authentication Lambda trigger for the function.\\n\\nThe most operationally efficient solution for sending login activity notifications by email for Amazon Cognito user pools is to use a Lambda trigger that is automatically invoked by Amazon Cognito every time a user logs in. This eliminates the need for client-side calls to an API or log subscription filter. A Lambda function can be used to send email notifications using Amazon SES.\\n\\nOption B satisfies these requirements and is the most operationally efficient solution.","poster":"Bibay","upvote_count":"14","timestamp":"1684048560.0"},{"poster":"Untamables","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-post-authentication.html","timestamp":"1679574240.0","comment_id":"848180","upvote_count":"9"},{"poster":"ravi_01","upvote_count":"1","content":"Selected Answer: B\\npost authentication trigger","comment_id":"1584698","timestamp":"1752025260.0"},{"poster":"wmv__","content":"Selected Answer: B\\n\\"Trigger\\"","comment_id":"1444524","timestamp":"1743737700.0","upvote_count":"1"},{"upvote_count":"1","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - the API Gateway needs to be explicitly invoked from the client. not operationally efficient\\n\\nB) Correct - Post-authentication triggers are built-in Cognito features that automatically execute a Lambda function after a user logs in.\\n\\nC) Eliminated - less efficient because it requires setting up CloudWatch Logs for Cognito, creating subscription filters, and maintaining log processing infrastructure\\n\\nD) Eliminated - highly complex and introduces multiple components (Kinesis, Firehose, Lambda),","timestamp":"1734865800.0","comment_id":"1330358"},{"content":"Selected Answer: B\\n==> Discard A: Requires client-side API calls, which are less secure and operationally inefficient (enhance security, validate in BE, ...) compared to server-side triggers. \\n==> Discard C: Relies on CloudWatch Logs and filters, which add unnecessary complexity and are not directly tied to Cognito\'s login events. \\n==> Discard D: Involves Kinesis Data Firehose for log streaming, which is over-engineered and introduces additional cost and latency for a simple notification task.\\n\\nB: Uses Cognito\'s native post-authentication trigger, which is the most secure, integrated, and operationally efficient method for sending email notifications after successful logins.","upvote_count":"2","poster":"trieudo","timestamp":"1734145620.0","comment_id":"1326332"},{"poster":"serverlessme","upvote_count":"1","comment_id":"1302051","content":"Option B is absolutely correct. \\nThe Lambda function is triggered by Coginito whenever a user log in. The Lambda function then sends email notification to the user using Amazon SES.","timestamp":"1729686360.0"},{"timestamp":"1716303720.0","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1","poster":"65703c1","comment_id":"1215047"},{"poster":"Melisa202401","content":"Selected Answer: A\\nAmazon Cognito user pools integrate with API Gateway or ALB\\nProcess is: user athenticate with CUP, receive JWT (token), then pass to API Gateway\\nAPI Gateway will evaluate JWT wwith CUP, if it is valid, allow access to Lambda (have a duty to send email)","comment_id":"1191436","upvote_count":"1","comments":[{"timestamp":"1712646000.0","poster":"Melisa202401","comment_id":"1192072","content":"sorry I change to B\\nBecause the question have the presence of MFA","upvote_count":"1"}],"timestamp":"1712560800.0"},{"upvote_count":"3","timestamp":"1679043060.0","comment_id":"841812","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/78944-exam-aws-certified-developer-associate-topic-1-question-9/","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T09:03:07.185Z","extraction_method":"api_direct_v1"},{"question_id":"NkRU5eQpuWyYjursGH9u","question_number":225,"page":45,"question_text":"A developer needs approval from a product owner before the developer can deploy code for an application to production. The developer uses AWS CodePipeline to deploy the application. The developer configures an Amazon Simple Notification Service (Amazon SNS) topic to send notifications to the product owner.\\n\\nWhich solution is the MOST operationally efficient way for the developer to receive approval from the product owner?","choices":{"A":"Add a new stage to CodePipeline before the production deployment. Add a manual approval action to the new stage. Add a new notification rule in the pipeline settings. Specify manual approval as the event that initiates the notification. Specify the SNS topic\'s Amazon Resource Name (ARN) to notify the product owner.","C":"Add a manual approval action to the existing production deployment stage in CodePipeline. Specify the SNS topic\'s Amazon Resource Name (ARN) while configuring the new manual approval action.","D":"Edit the settings in CodePipeline. Create a new notification rule. Specify manual approval as the event that initiates the notification. Create a new notification target. Specify the SNS topic to notify the product owner. Save the notification rule.","B":"Develop an AWS Step Functions state machine that sends a notification to the product owner and accepts an approval. Add a new stage to CodePipeline before the production deployment. Add the state machine as a Step Functions action to the new stage."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134336-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 06:26:00","unix_timestamp":1708579560,"discussion_count":4,"discussion":[{"upvote_count":"1","timestamp":"1732462440.0","comment_id":"1217510","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer."},{"timestamp":"1725730440.0","poster":"SerialiDr","content":"Selected Answer: A\\nThis solution directly integrates a manual approval process into the CI/CD pipeline. By adding a specific stage for manual approval before the deployment can proceed to production, it ensures that no changes are deployed without explicit consent. The integration of Amazon SNS for notifications automates the communication process, informing the product owner when their input is needed. This setup not only enforces a governance check but also streamlines the approval process, making it both efficient and auditable.","comment_id":"1168313","upvote_count":"4"},{"upvote_count":"2","poster":"monishvster","timestamp":"1724883060.0","comment_id":"1162075","content":"Selected Answer: A\\nshould be A"},{"poster":"CrescentShared","upvote_count":"3","timestamp":"1724297160.0","content":"Selected Answer: A\\nAdding a manual approval action to a pipeline stage, which is necessary for halting the pipeline to wait for approval.","comment_id":"1156144"}],"answer_description":"","extracted_at":"2025-12-24T09:03:07.185Z","extraction_method":"api_direct_v1"},{"question_id":"WuBZKTBRFdHaapDz1cKl","question_number":226,"page":46,"question_text":"A developer is building a serverless application on AWS for a workflow that processes high volumes of data. In the workflow, an AWS Step Functions state machine invokes several AWS Lambda functions.\\n\\nOne of the Lambda functions occasionally fails because of timeout errors during periods of high demand. The developer must ensure that the workflow automatically retries the failed function invocation if a timeout error occurs.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Add a Fail state to the Step Functions state machine definition. Configure the state machine with the maximum number of retry attempts.","B":"Add a Timeout field in the Step Functions state machine definition. Configure the state machine with the maximum number of retry attempts.","D":"Update the Step Functions state machine to pass the invocation request to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe a Lambda function to the SNS topic. Configure the Lambda function with the maximum number of retry attempts for a timeout error type.","A":"Add a Retry field in the Step Functions state machine definition. Configure the state machine with the maximum number of retry attempts and the timeout error type to retry on."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134337-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 06:27:00","unix_timestamp":1708579620,"discussion_count":6,"discussion":[{"comment_id":"1171430","upvote_count":"5","poster":"KarBiswa","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-error-handling.html#:~:text=Task%2C%20Parallel%2C%20and%20Map%20states%20can%20have%20a%20field%20named%20Retry%2C%20whose%20value%20must%20be%20an%20array%20of%20objects%20known%20as%20retriers.%20An%20individual%20retrier%20represents%20a%20certain%20number%20of%20retries%2C%20usually%20at%20increasing%20time%20intervals.","timestamp":"1710218880.0"},{"comment_id":"1156145","poster":"CrescentShared","upvote_count":"5","timestamp":"1708579620.0","content":"Selected Answer: A\\nA is correct."},{"content":"Selected Answer: A\\n{\\n \\"Type\\": \\"Task\\",\\n \\"Resource\\": \\"arn:aws:lambda:region:account-id:function:function-name\\",\\n \\"Retry\\": [\\n {\\n \\"ErrorEquals\\": [\\"States.Timeout\\"],\\n \\"IntervalSeconds\\": 2,\\n \\"MaxAttempts\\": 3,\\n \\"BackoffRate\\": 2.0\\n }\\n ],\\n \\"End\\": true\\n}","poster":"albert_kuo","timestamp":"1727915580.0","upvote_count":"1","comment_id":"1292566"},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-error-handling.html#error-handling-examples","timestamp":"1727458200.0","poster":"preachr","upvote_count":"1","comment_id":"1290191"},{"timestamp":"1716558000.0","poster":"65703c1","comment_id":"1217514","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer."},{"timestamp":"1709901780.0","upvote_count":"4","comment_id":"1168785","content":"Selected Answer: A\\nAWS Step Functions allows you to handle errors and automate retry policies directly within your state machine definition. By adding a Retry field to the state definition of the Lambda function within the Step Functions state machine, you can specify the error types for which retries should occur, including timeout errors. You can also configure the maximum number of retry attempts, the interval between retries, backoff rate, and more. This solution directly addresses the need for automatic retry in case of specific errors such as timeouts, making it an efficient way to enhance the resilience of serverless workflows.","poster":"SerialiDr"}],"answer_description":"","extracted_at":"2025-12-24T09:03:18.215Z","extraction_method":"api_direct_v1"},{"question_id":"PNQc6HC4nrQfoAXZNety","question_number":227,"page":46,"question_text":"A company runs a serverless application on AWS. The application includes an AWS Lambda function. The Lambda function processes data and stores the data in an Amazon RDS for PostgreSQL database. A developer created a user credentials in the database for the application.\\n\\nThe developer needs to use AWS Secrets Manager to manage the user credentials. The password must to be rotated on a regular basis. The solution needs to ensure that there is high availability and no downtime for the application during secret rotation.\\n\\nWhat should the developer do to meet these requirements?","choices":{"C":"Configure automatic rotation with the single user rotation strategy.","D":"Configure automatic rotation with the alternating users rotation strategy.","A":"Configure managed rotation with the single user rotation strategy.","B":"Configure managed rotation with the alternating users rotation strategy."},"correct_answer":"D","answer_ET":"D","answers_community":["D (65%)","B (35%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134124-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 10:39:00","unix_timestamp":1708249140,"discussion_count":12,"discussion":[{"content":"Selected Answer: D\\nManaged rotation vs. automatic rotation:\\nManaged rotation requires manual intervention to specify when a secret should be rotated. This doesn\'t meet the requirement of automated password rotation on a regular basis.\\nAutomatic rotation automatically rotates secrets based on a defined schedule, meeting the requirement for regular password changes.\\nSingle user vs. alternating users:\\nSingle user rotation means there is only one set of credentials. Rotating this would cause downtime as the application needs to update its connection information.\\nAlternating users rotation uses two sets of credentials. Only one is active at a time. When it\'s time to rotate, the inactive set is rotated, and then the application switches to using that set, avoiding downtime","upvote_count":"15","timestamp":"1708249140.0","comment_id":"1153155","poster":"tgv"},{"timestamp":"1750156200.0","poster":"08dc0cf","content":"Selected Answer: B\\nB: Managed rotation alternating users","comment_id":"1578268","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\\nI think the term \\"automatic rotation\\" is confusing here. The right term in the AWS documentation is \\"Managed rotation\\". The managed rotation is available for RDS and it automate the rotation process on a regular basis.","timestamp":"1748503980.0","comment_id":"1573252","poster":"egosselin"},{"upvote_count":"1","comment_id":"1341004","timestamp":"1736948040.0","content":"Selected Answer: B\\nB is the correct answer.\\nD is wrong because automatic rotation requires the developer to write and manage custom rotation logic. Using managed rotation is simpler and more operationally efficient.","poster":"Arad"},{"content":"Selected Answer: B\\n\\"Automatic rotation\\" is not a distinct concept in AWS Secrets Manager; rotation is always \\"managed.\\" This option likely refers to the alternating strategy but does not add clarity compared to managed rotation.","upvote_count":"1","comment_id":"1338920","timestamp":"1736534160.0","poster":"bp07"},{"poster":"Saurabh04","timestamp":"1723699800.0","upvote_count":"1","comment_id":"1266233","comments":[{"content":"\\"managed rotation\\" is not the correct terminology in AWS Secrets Manager","timestamp":"1727916480.0","comment_id":"1292577","poster":"albert_kuo","upvote_count":"1"}],"content":"Selected Answer: B\\nAutomatic rotation does not address the high availability requirement. If the rotation process causes downtime, it could impact our application\'s stability"},{"poster":"albert_kuo","upvote_count":"1","timestamp":"1721974380.0","comments":[],"content":"Selected Answer: B\\nB. Configure managed rotation with the alternating users rotation strategy.","comment_id":"1255504"},{"content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","upvote_count":"1","timestamp":"1716558180.0","comment_id":"1217518"},{"upvote_count":"2","content":"Selected Answer: D\\nAutomatic Rotation\\n\\nWe strongly recommend that you use automatic rotation instead of managed rotation. Automatic rotation simplifies the rotation process and offers several advantages over managed rotation, including:\\n\\nIt eliminates the need to create and manage Lambda functions to update the secret in AWS Secrets Manager or the database.\\nIt supports the alternating users rotation strategy, which is no longer supported for managed rotation.\\n(Source: AWS Secrets Manager documentation: https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html)","comment_id":"1168964","poster":"Abdullah22","timestamp":"1709916600.0"},{"content":"Selected Answer: B\\nUsing AWS Secrets Manager\'s managed rotation with the alternating users rotation strategy is ideal for databases like Amazon RDS for PostgreSQL. This strategy involves creating a second user in the database with the same permissions as the original user. During rotation, Secrets Manager switches between these two users, updating the credentials for the inactive user and then making it the active user for subsequent connections. This approach minimizes the risk of downtime because the application can continue to use the currently active credentials while the other set is being rotated. It also ensures that credentials are regularly updated, enhancing security without disrupting database access.","poster":"SerialiDr","upvote_count":"2","comment_id":"1168793","timestamp":"1709902740.0"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/tutorials_rotation-alternating.html#:~:text=This%20strategy%20is%20a%20good%20choice%20if%20you%20need%20high%20availability%20for%20your%20secret%2C%20because%20one%20of%20the%20alternating%20users%20has%20current%20credentials%20to%20the%20database%20while%20the%20other%20one%20is%20being%20updated.%20For%20more","poster":"KarBiswa","comment_id":"1164882","timestamp":"1709479260.0","upvote_count":"2"},{"content":"Selected Answer: B\\nBoth B and D options involve using the alternating users rotation strategy, which is suitable for ensuring high availability and no downtime during secret rotation. The difference between \\"managed rotation\\" and \\"automatic rotation\\" is mostly semantic in this context, as both terms refer to the capability of AWS Secrets Manager to automatically rotate the secret. The more common terminology used in the context of AWS Secrets Manager is \\"managed rotation,\\" so option B is often preferred.","poster":"CrescentShared","upvote_count":"3","timestamp":"1708580280.0","comment_id":"1156147"}],"answer_description":"","extracted_at":"2025-12-24T09:03:18.215Z","extraction_method":"api_direct_v1"},{"question_id":"2Cg70TJ2TdLrvnLu1OXJ","question_number":228,"page":46,"question_text":"A company runs an application on AWS. The application consists of a static website that is hosted on Amazon S3. The application includes Amazon API Gateway APIs that invoke AWS Lambda functions. During a period of high traffic on the application, application users reported that the application was slow at irregular intervals. There were no failed requests.\\n\\nA developer needs to find the slow executions across all the Lambda functions.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Enable AWS CloudTrail Insights on the account where the Lambda functions are running. After CloudTrail Insights has finished processing, review CloudTrail Insights to find the anomalous functions.","D":"Set up AWS Glue to crawl through the logs in Amazon CloudWatch Logs for the Lambda functions. Configure an AWS Glue job to transform the logs into a structured format and to output the logs into Amazon S3. Use the Amazon CloudWatch dashboard to visualize the slowest functions based on the duration.","A":"Perform a query across all the Lambda function log groups by using Amazon CloudWatch Logs Insights. Filter on type of report and sort descending by Lambda function execution duration.","C":"Enable AWS X-Ray for all the Lambda functions. Configure an X-Ray insight on a new group that includes all the Lambda functions. After the X-Ray insight has finished processing, review the X-Ray logs."},"correct_answer":"C","answer_ET":"C","answers_community":["C (64%)","A (36%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134339-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 06:54:00","unix_timestamp":1708581240,"discussion_count":10,"discussion":[{"comment_id":"1162076","timestamp":"1709165760.0","upvote_count":"6","poster":"monishvster","content":"Selected Answer: C\\nX-ray will provide better insights for performance"},{"timestamp":"1750156140.0","comment_id":"1578267","poster":"08dc0cf","upvote_count":"1","content":"Selected Answer: A\\nCorrect answer is A. C is n sufficient"},{"upvote_count":"1","timestamp":"1748505000.0","poster":"egosselin","content":"Selected Answer: A\\nFor this specific case, i think the answer is A","comment_id":"1573253"},{"content":"Selected Answer: C\\nX-Ray for performance","comment_id":"1315605","poster":"ShakthiGCP","timestamp":"1732154880.0","upvote_count":"1"},{"upvote_count":"2","poster":"BrainFried","content":"Selected Answer: A\\nI think the answer is A\\n\\nThe goal is to analysis past executions of the Lambda functions, to isolate and identity the slow Lambda functions. This can be done with option A. \\n\\nOption D does not retroactively analyse past executions of Lambda functions - therefore it\'s not as effective as option A ~~","timestamp":"1723466160.0","comment_id":"1264646"},{"comment_id":"1217528","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716558660.0","upvote_count":"1"},{"poster":"KarBiswa","comment_id":"1171439","timestamp":"1710219600.0","upvote_count":"4","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/general-approach.html#:~:text=Use%20X%2DRay%20to%20find%20all%20the%20services%20involved%20in%20a%20request.%20For%20larger%20serverless%20applications%2C%20this%20is%20the%20fastest%20way%20to%20locate%20all%20of%20the%20interactions%20involved%20in%20the%20request.%20From%20X%2DRay%2C%20isolate%20the%20service%20where%20latency%20or%20errors%20are%20occurring%20then%20drill%20down%20further. It clearly an interaction issues among the services no failure has occurred"},{"content":"Selected Answer: C\\nnot sure between A and C but going with C.","timestamp":"1709917260.0","comment_id":"1168972","poster":"Abdullah22","upvote_count":"2"},{"comment_id":"1168815","upvote_count":"2","timestamp":"1709903760.0","content":"Selected Answer: A\\nA. Perform a query across all the Lambda function log groups by using Amazon CloudWatch Logs Insights. Filter on type of report and sort descending by Lambda function execution duration.\\n\\nHere\'s why this approach is most efficient:\\n\\nCentralized Logs: CloudWatch Logs Insights allows you to query logs across all your Lambda function log groups in a single location.\\nTargeted Filtering: You can filter the query to focus on specific time periods of high traffic, pinpointing anomalies during those times.\\nSorting by Duration: By sorting the results descending by execution duration, you can easily identify Lambda functions with the slowest execution times.\\nFast Insights: CloudWatch Logs Insights offers near real-time analysis, enabling you to quickly identify performance bottlenecks.","comments":[],"poster":"SerialiDr"},{"content":"Selected Answer: A\\nHesitate. A or C?","comment_id":"1156155","poster":"CrescentShared","timestamp":"1708581240.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:03:18.215Z","extraction_method":"api_direct_v1"},{"question_id":"sQBedCbMQBEHWitYJZvY","question_number":229,"page":46,"question_text":"A company is building a serverless application on AWS. The application uses Amazon API Gateway and AWS Lambda. The company wants to deploy the application to its development, test, and production environments.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"C":"Duplicate the code for each environment. Deploy the code to a separate API Gateway stage.","A":"Use API Gateway stage variables and create Lambda aliases to reference environment-specific resources.","B":"Use Amazon Elastic Container Service (Amazon ECS) to deploy the application to the environments.","D":"Use AWS Elastic Beanstalk to deploy the application to the environments."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134340-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 07:00:00","unix_timestamp":1708581600,"discussion_count":4,"discussion":[{"content":"Selected Answer: A\\nThis approach allows for easy management of multiple environments within the same AWS infrastructure. API Gateway stage variables can be used to manage configurations that differ between environments, such as endpoint URLs or configuration settings. Similarly, Lambda aliases can point to different versions of Lambda functions, making it possible to deploy different versions of the codebase to different environments (e.g., development, test, production) without duplicating the code. This solution is both efficient and scalable, enabling quick updates and minimal overhead in managing environment-specific configurations.","upvote_count":"6","poster":"SerialiDr","comment_id":"1168819","timestamp":"1725794340.0"},{"upvote_count":"1","comment_id":"1217531","poster":"65703c1","timestamp":"1732463580.0","content":"Selected Answer: A\\nA is the correct answer."},{"comment_id":"1168976","poster":"Abdullah22","content":"Selected Answer: A\\ngoing with A","timestamp":"1725807840.0","upvote_count":"4"},{"timestamp":"1724299200.0","comment_id":"1156158","content":"Selected Answer: A\\nD: not for serverless.","upvote_count":"4","poster":"CrescentShared"}],"answer_description":"","extracted_at":"2025-12-24T09:03:18.215Z","extraction_method":"api_direct_v1"},{"question_id":"reZOg0FmgztU1yb0j7ED","question_number":230,"page":46,"question_text":"A developer uses AWS CloudFormation to deploy an Amazon API Gateway API and an AWS Step Functions state machine. The state machine must reference the API Gateway API after the CloudFormation template is deployed. The developer needs a solution that uses the state machine to reference the API Gateway endpoint.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"D":"Configure the CloudFormation template to store the API endpoint in a standard AWS::AppConfig::ConfigurationProfile resource. Configure the state machine to reference the resource.","C":"Configure the CloudFormation template to store the API endpoint in a standard AWS::SecretsManager::Secret resource. Configure the state machine to reference the resource.","A":"Configure the CloudFormation template to reference the API endpoint in the DefinitionSubstitutions property for the AWS::StepFunctions::StateMachine resource.","B":"Configure the CloudFormation template to store the API endpoint in an environment variable for the AWS::StepFunctions::StateMachine resource. Configure the state machine to reference the environment variable."},"correct_answer":"A","answer_ET":"A","answers_community":["A (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134341-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 07:10:00","unix_timestamp":1708582200,"discussion_count":8,"discussion":[{"content":"Selected Answer: A\\nResources:\\n MyApi:\\n Type: AWS::ApiGateway::RestApi\\n Properties:\\n Name: MyApi\\n\\n MyStateMachine:\\n Type: AWS::StepFunctions::StateMachine\\n Properties: \\n DefinitionString: \\n !Sub |\\n {\\n \\"StartAt\\": \\"CallAPI\\",\\n \\"States\\": {\\n \\"CallAPI\\": {\\n \\"Type\\": \\"Task\\",\\n \\"Resource\\": \\"${ApiEndpoint}\\",\\n \\"End\\": true\\n }\\n }\\n }\\n DefinitionSubstitutions:\\n ApiEndpoint: !Sub \\"https://${MyApi}.execute-api.${AWS::Region}.amazonaws.com/prod\\"\\n RoleArn: arn:aws:iam::123456789012:role/service-role/MyStateMachineRole","poster":"albert_kuo","upvote_count":"1","comment_id":"1292586","timestamp":"1727917860.0"},{"poster":"Saurabh04","content":"Selected Answer: B\\nThis approach is cost-effective","timestamp":"1723700340.0","upvote_count":"1","comment_id":"1266240"},{"timestamp":"1721119500.0","content":"Step Functions does not have a Definitions substitution property or feature, so that throws A out. The most cost effective has to be B","upvote_count":"1","poster":"jyrajan69","comment_id":"1248774"},{"poster":"65703c1","comment_id":"1217536","timestamp":"1716558960.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1"},{"timestamp":"1710219960.0","upvote_count":"2","poster":"KarBiswa","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-stepfunctions-statemachine.html#:~:text=A%20map%20(string,key%2Dvalue%20map.","comment_id":"1171444"},{"poster":"Abdullah22","upvote_count":"2","content":"Selected Answer: A\\ngoing with A .","timestamp":"1709918100.0","comment_id":"1168988"},{"upvote_count":"4","poster":"SerialiDr","comment_id":"1168826","content":"Selected Answer: A\\nThis approach leverages CloudFormation\'s ability to dynamically substitute values within the definition of AWS resources. By using the DefinitionSubstitutions property for the AWS::StepFunctions::StateMachine resource, you can directly insert the API Gateway endpoint or other necessary parameters into the state machine\'s definition. This enables the state machine to reference the API Gateway API without hard-coding values, allowing for flexibility and reusability of the CloudFormation template across different deployments. It\'s also a cost-effective solution because it uses native CloudFormation capabilities without the need for additional resources or services.","timestamp":"1709904180.0"},{"content":"Selected Answer: A\\nThe other options (B, C, and D) involve using additional resources or services that are not necessary for this requirement and would therefore be less cost-effective.","poster":"CrescentShared","upvote_count":"2","comment_id":"1156166","timestamp":"1708582200.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:18.215Z","extraction_method":"api_direct_v1"},{"question_id":"RqTMGw08PWNYR3cSqUyJ","question_number":231,"page":47,"question_text":"A developer is building an application on AWS. The application includes an AWS Lambda function that processes messages from an Amazon Simple Queue Service (Amazon SQS) queue.\\n\\nThe Lambda function sometimes fails or times out. The developer needs to figure out why the Lambda function fails to process some messages.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"B":"Increase the visibility timeout of the SQS queue. Check logs in Amazon CloudWatch Logs for error details.","C":"Create a dead-letter queue. Configure the Lambda function to send the failed messages to the dead-letter queue.","A":"Increase the maximum timeout of the Lambda function to 15 minutes. Check the AWS CloudTrail event history for error details.","D":"Create an Amazon DynamoDB table. Update the Lambda function to send the failed messages to the DynamoDB table."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134125-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 10:44:00","unix_timestamp":1708249440,"discussion_count":4,"discussion":[{"upvote_count":"7","timestamp":"1723967040.0","poster":"tgv","content":"Selected Answer: C\\nAlways DLQ for checking failed processed messaged in Lambda.","comment_id":"1153159"},{"upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1732464060.0","comment_id":"1217545","poster":"65703c1"},{"upvote_count":"3","comment_id":"1193974","timestamp":"1728672120.0","poster":"be1dca8","content":"B, the question is asking how the developer can figure out the issue. it is not asking about where to put the failed messages to."},{"timestamp":"1725885720.0","poster":"Abdullah22","content":"Selected Answer: C\\nhttps://aws.amazon.com/blogs/compute/implementing-aws-lambda-error-handling-patterns/","comment_id":"1169563","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:03:29.152Z","extraction_method":"api_direct_v1"},{"question_id":"h2Vkxjs79eDSPISDDIh6","question_number":232,"page":47,"question_text":"A developer needs to deploy an application in three AWS Regions by using AWS CloudFormation. Each Region will use an AWS Elastic Beanstalk environment with an Application Load Balancer (ALB). The developer wants to use AWS Certificate Manager (ACM) to deploy SSL certificates to each ALB.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create a global certificate in ACM. Update the CloudFormation template to deploy the global certificate to each ALB.","A":"Create a certificate in ACM in any one of the Regions. Import the certificate into the ALB that is in each Region.","C":"Create a certificate in ACM in each Region. Import the certificate into the ALB for each Region.","D":"Create a certificate in ACM in the us-east-1 Region. Update the CloudFormation template to deploy the certificate to each ALB."},"correct_answer":"C","answer_ET":"C","answers_community":["C (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134126-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 10:45:00","unix_timestamp":1708249500,"discussion_count":7,"discussion":[{"content":"Selected Answer: C\\nRegional Certificates: ACM certificates are regional resources. They cannot be shared across different Regions. Creating a certificate in each Region ensures proper certificate management and association with the ALBs.\\nCloudFormation Integration: CloudFormation allows you to define resources and their configurations for individual Regions. Creating certificates within the template for each Region aligns well with this approach.","upvote_count":"6","timestamp":"1709968920.0","comment_id":"1169319","poster":"SerialiDr"},{"timestamp":"1731812160.0","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: C\\nACM is a regional service","comment_id":"1313360"},{"content":"Selected Answer: D\\nGiven the requirements and cost-effectiveness, I recommend Option D\u2014create a certificate in ACM in the us-east-1 Region and update the CloudFormation template to deploy the certificate to each ALB. This way, you maintain consistency while minimizing certificate management overhead.","comment_id":"1266243","upvote_count":"1","poster":"Saurabh04","timestamp":"1723700520.0"},{"comment_id":"1217553","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716559440.0","upvote_count":"1","poster":"65703c1"},{"upvote_count":"2","poster":"KarBiswa","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html","comment_id":"1171486","timestamp":"1710225960.0"},{"content":"Selected Answer: C\\nCertificates in ACM are regional resources. To use a certificate with Elastic Load Balancing for the same fully qualified domain name (FQDN) or set of FQDNs in more than one AWS region, you must request or import a certificate for each region.","comment_id":"1162991","timestamp":"1709238840.0","upvote_count":"2","poster":"nder"},{"poster":"tgv","upvote_count":"4","timestamp":"1708249500.0","content":"Selected Answer: C\\nThe correct solution is to create a certificate in each Region and to assign it to each ALB.","comment_id":"1153160"}],"answer_description":"","extracted_at":"2025-12-24T09:03:29.152Z","extraction_method":"api_direct_v1"},{"question_id":"QM26GbenxEAt9vMTVmc5","question_number":233,"page":47,"question_text":"A company needs to deploy all its cloud resources by using AWS CloudFormation templates. A developer must create an Amazon Simple Notification Service (Amazon SNS) automatic notification to help enforce this rule. The developer creates an SNS topic and subscribes the email address of the company\'s security team to the SNS topic.\\n\\nThe security team must receive a notification immediately if an IAM role is created without the use of CloudFormation.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Launch an Amazon EC2 instance that includes a script to filter events from CloudTrail if a role was created without CloudFormation. Configure the script to publish to the SNS topic. Create a cron job to run the script on tile EC2 instance every 15 minutes.","A":"Create an AWS Lambda function to filter events from CloudTrail if a role was created without CloudFormation. Configure the Lambda function to publish to the SNS topic. Create an Amazon EventBridge schedule to invoke the Lambda function every 15 minutes.","D":"Create an Amazon EventBridge rule to filter events from CloudTrail if a role was created without CloudFormation. Specify the SNS topic as the target of the EventBridge rule.","B":"Create an AWS Fargate task in Amazon Elastic Container Service (Amazon ECS) to filter events from CloudTrail if a role was created without CloudFormation. Configure the Fargate task to publish to the SNS topic. Create an Amazon EventBridge schedule to run the Fargate task every 15 minutes."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134342-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 07:19:00","unix_timestamp":1708582740,"discussion_count":5,"discussion":[{"content":"Selected Answer: D\\n(ABC) eliminated. every 15 minutes is not immediate notification.\\n(D) is correct.\\n\\nAmazon EventBridge rule - specifies what EventBridge does with the events delivered to each event bus. A rule specifies which events to send to which targets for processing. A single rule can send an event to multiple targets, which then run in parallel. There are two types of rules: rules that match on event data as events are delivered, and rules that run on a defined schedule. In addition, certain AWS services may create and manage rules in your account as well.\\n\\nAmazon EventBridge rule that match on event data - match against incoming events based on event data criteria,an event pattern. An event pattern defines the event structure and the fields that a rule matches. If an event matches the criteria defined in the event pattern, EventBridge sends it to the target(s) you specify.","upvote_count":"1","poster":"NSA_Poker","comment_id":"1283936","timestamp":"1726382160.0"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","timestamp":"1716559860.0","comment_id":"1217563","poster":"65703c1"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html#:~:text=ENABLED_WITH_ALL_CLOUDTRAIL_MANAGEMENT_EVENTS%3A%20The%20rule,User%20Guide.","upvote_count":"4","timestamp":"1710227460.0","comment_id":"1171495","poster":"KarBiswa"},{"timestamp":"1709996220.0","comment_id":"1169572","content":"Selected Answer: D\\ngoing with D","poster":"Abdullah22","upvote_count":"3"},{"upvote_count":"3","content":"Selected Answer: D\\nEl desarrollador debe crear una regla de Amazon EventBridge para filtrar eventos de CloudTrail si se crea un rol sin el uso de CloudFormation. Luego, debe especificar el tema de SNS como destino de la regla de EventBridge. Esto permitir\xe1 que el equipo de seguridad reciba una notificaci\xf3n inmediata a trav\xe9s del tema de SNS cuando se cree una funci\xf3n de IAM sin el uso de CloudFormation.","timestamp":"1709251440.0","comment_id":"1163109","poster":"ANDRES715"}],"answer_description":"","extracted_at":"2025-12-24T09:03:29.152Z","extraction_method":"api_direct_v1"},{"question_id":"AZTIrJhIlibo20mbW5Vb","question_number":234,"page":47,"question_text":"A company is adopting serverless computing for some of its new services. A development team needs to create a serverless infrastructure by using AWS Serverless Application Model (AWS SAM). All infrastructure must be deployed by using AWS CloudFormation templates.\\n\\nWhat should the development team do to meet these requirements?","choices":{"B":"Add a Mappings section to the CloudFormation templates that contains AWS::Serverless::Function and AWS::Serverless::API.","C":"Add a Transform section to the CloudFormation templates. Use the AWS SAM syntax to define the resources.","D":"Add a Parameters section to the CloudFormation templates that specifies the relevant AWS SAM Globals section.","A":"Add a Resources section to the CloudFormation templates that contains AWS::Lambda::Function resources."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133607-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 13:28:00","unix_timestamp":1707740880,"discussion_count":8,"discussion":[{"comment_id":"1292589","timestamp":"1727918520.0","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: C\\nAWSTemplateFormatVersion: \'2010-09-09\'\\nTransform: \'AWS::Serverless-2016-10-31\'\\nResources:\\n MyFunction:\\n Type: AWS::Serverless::Function\\n Properties:\\n Handler: index.handler\\n Runtime: nodejs14.x\\n CodeUri: s3://my-bucket/my-function.zip\\n Events:\\n ApiEvent:\\n Type: Api\\n Properties:\\n Path: /myfunction\\n Method: get"},{"poster":"65703c1","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217572","timestamp":"1716560220.0"},{"timestamp":"1710228540.0","upvote_count":"4","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/codecatalyst/latest/userguide/deploy-tut-lambda.html#:~:text=AWSTemplateFormatVersion%3A%20%272010%2D09%2D09%27%0ATransform%3A%20AWS%3A%3AServerless%2D2016%2D10%2D31","comment_id":"1171501","poster":"KarBiswa"},{"poster":"koltysh","content":"it will be C","timestamp":"1710003480.0","upvote_count":"3","comment_id":"1169668"},{"upvote_count":"3","content":"Selected Answer: C\\nUsing SAM to define the CF templates","timestamp":"1709979540.0","poster":"nder","comment_id":"1169404"},{"content":"Selected Answer: C\\nShould be C","timestamp":"1709166000.0","upvote_count":"4","comment_id":"1162079","poster":"monishvster"},{"content":"Selected Answer: C\\nGot this question in exam.","upvote_count":"4","comment_id":"1156171","timestamp":"1708582800.0","poster":"CrescentShared"},{"poster":"tgv","content":"the correct answer is C","timestamp":"1708069620.0","comment_id":"1151806","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:03:29.152Z","extraction_method":"api_direct_v1"},{"question_id":"xMd1aZ83pDG8sinKcaLM","question_number":235,"page":47,"question_text":"A developer has an application that stores data in an Amazon S3 bucket. The application uses an HTTP API to store and retrieve objects. When the PutObject API operation adds objects to the S3 bucket the developer must encrypt these objects at rest by using server-side encryption with Amazon S3 managed keys (SSE-S3).\\nWhich solution will meet this requirement?","choices":{"D":"Apply TLS to encrypt the traffic to the S3 bucket.","A":"Create an AWS Key Management Service (AWS KMS) key. Assign the KMS key to the S3 bucket.","C":"Provide the encryption key in the HTTP header of every request.","B":"Set the x-amz-server-side-encryption header when invoking the PutObject API operation."},"correct_answer":"B","answer_ET":"B","answers_community":["B (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103513-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:20:00","unix_timestamp":1679433600,"discussion_count":10,"discussion":[{"timestamp":"1699953540.0","comment_id":"897343","poster":"Bibay","content":"B. Set the x-amz-server-side-encryption header when invoking the PutObject API operation.\\n\\nWhen using the PutObject API operation to store objects in an S3 bucket, the x-amz-server-side-encryption header can be set to specify the server-side encryption algorithm used to encrypt the object. Setting this header to \\"AES256\\" or \\"aws:kms\\" enables server-side encryption with SSE-S3 or SSE-KMS respectively.\\n\\nOption A is incorrect because assigning a KMS key to the S3 bucket will not enable SSE-S3 encryption.\\n\\nOption C is incorrect because providing the encryption key in the HTTP header of every request is not a valid way to enable SSE-S3 encryption.\\n\\nOption D is incorrect because applying TLS encryption to the traffic to the S3 bucket only encrypts the data in transit, but does not encrypt the objects at rest in the bucket.","comments":[{"content":"I now got to know \'KMS key to S3 bucket will not enable S3 encryption\'","poster":"jipark","timestamp":"1707037680.0","upvote_count":"1","comment_id":"971766"},{"poster":"beekeeper0101","comment_id":"1226811","upvote_count":"1","timestamp":"1733680500.0","content":"Thank you!\\nSetting the x-amz-server-side-encryption header to:\\n- AES256 => SSE-S3\\n- AWS:KMS => SSE-KMS"}],"upvote_count":"15"},{"comment_id":"846363","upvote_count":"10","timestamp":"1695324000.0","poster":"svrnvtr","content":"Selected Answer: B\\nB https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html"},{"content":"Selected Answer: B\\nA) Eliminated - While AWS Key Management Service (KMS) keys can be used for encryption in S3 (SSE-KMS), this option refers to creating a custom KMS key, which is not required when using SSE-S3.\\nB) Correct - The x-amz-server-side-encryption header is the correct way to specify the use of SSE-S3 when uploading objects to S3 via the PutObject API.\\nC) Eliminated - Providing an encryption key in the HTTP header refers to client-side encryption or SSE-C\\nD) Eliminated - TLS (Transport Layer Security) encrypts data in transit, not at rest.","upvote_count":"1","comment_id":"1330458","poster":"sumanshu","timestamp":"1734885240.0"},{"comment_id":"1326334","content":"Selected Answer: B\\n==> Discard A: SSE-KMS uses AWS KMS keys, not Amazon S3-managed keys required for SSE-S3. \\n==> Discard C: SSE-C requires customer-provided keys, not Amazon S3-managed keys for SSE-S3. \\n==> Discard D: TLS encrypts data in transit, not at rest as required by SSE-S3.\\n\\nB is correct because setting `x-amz-server-side-encryption: AES256` ensures Amazon S3 uses SSE-S3 to encrypt objects at rest automatically.","upvote_count":"1","poster":"trieudo","timestamp":"1734146580.0"},{"timestamp":"1732208940.0","upvote_count":"1","comment_id":"1215049","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"timestamp":"1728558540.0","poster":"badsati","comment_id":"1192906","content":"Selected Answer: B\\nAnswer is B","upvote_count":"1"},{"poster":"nderitunick","upvote_count":"1","comment_id":"1084530","comments":[{"timestamp":"1717078500.0","poster":"nderitunick","upvote_count":"1","comment_id":"1084533","content":"I misread the question. It\'s all good."}],"timestamp":"1717078140.0","content":"Aren\'t objects on s3 encrypted using SSE-S3 by default? I don\'t understand why D is not the answer."},{"comments":[{"comments":[{"comment_id":"1101697","upvote_count":"1","timestamp":"1718890800.0","poster":"cucuff","content":"because it takes some time for exam questions to be updated"}],"poster":"fordiscussionstwo","content":"what is correct answer then?","upvote_count":"2","comment_id":"1025986","timestamp":"1712351880.0"}],"poster":"aanataliya","comment_id":"987703","upvote_count":"8","content":"Answer for this question is changed starting January 5, 2023. Amazon S3 now applies server-side encryption with Amazon S3 managed keys (SSE-S3) as the base level of encryption for every bucket in Amazon S3.\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/default-encryption-faq.html","timestamp":"1708636020.0"},{"comment_id":"952029","content":"Selected Answer: B\\nC is a way to use customer-provided keys not S3-managed keys.","poster":"tttamtttam","timestamp":"1705304700.0","upvote_count":"2"},{"timestamp":"1703096700.0","upvote_count":"1","comment_id":"928588","poster":"CisconAWSGURU","content":"Selected Answer: C\\nC is correct and hear is the reason from AWS docs.\\nVisit AWS Regions and Endpoints in the AWS General Reference or the AWS Region Table to see the regional availability for ACM.\\n\\nCertificates in ACM are regional resources. To use a certificate with Elastic Load Balancing for the same fully qualified domain name (FQDN) or set of FQDNs in more than one AWS region, you must request or import a certificate for each region. For certificates provided by ACM, this means you must revalidate each domain name in the certificate for each region. You cannot copy a certificate between regions.\\n\\nTo use an ACM certificate with Amazon CloudFront, you must request or import the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution."}],"answer_description":"","extracted_at":"2025-12-24T09:03:29.152Z","extraction_method":"api_direct_v1"},{"question_id":"MXHjk0PrJpPfZPVdRis8","question_number":236,"page":48,"question_text":"A developer is building an application that invokes AWS Lambda functions asynchronously to process events. The developer notices that a Lambda function fails to process some events at random times. The developer needs to investigate the failed events and capture the events that the Lambda function fails to process.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Configure the Lambda function with a dead-letter queue based in Amazon Kinesis. Update the Lambda function\'s execution role with the required permissions.","C":"Configure the Lambda function with an Amazon Simple Queue Service (Amazon SQS) dead-letter queue. Update the Lambda function\'s execution role with the required permissions.","A":"Add an Amazon EventBridge rule for the Lambda function. Configure the EventBridge rule to react to failed events and to store the events in an Amazon DynamoDB table.","D":"Configure the Lambda function with an Amazon Simple Queue Service (Amazon SQS) FIFO dead-letter queue. Update the Lambda function\'s execution role with the required permissions."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133608-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 13:31:00","unix_timestamp":1707741060,"discussion_count":5,"discussion":[{"upvote_count":"10","comment_id":"1153201","timestamp":"1723972020.0","poster":"tgv","content":"The standard SQS dead-letter queue should capture the failed events and let the developer debug them, so C is the right solution. \\nB - There\'s no such thing as a DLQ in Kinesis. \\nD - SQS FIFO DLQ would be too much overkill for this task because you don\'t need ordering or deduplication. \\nA - This would involve additional costs and too much complexity to use a DynamoDB table for this."},{"upvote_count":"1","comment_id":"1217582","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1732465500.0"},{"timestamp":"1726119300.0","upvote_count":"3","poster":"KarBiswa","comment_id":"1171509","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html#:~:text=You%20can%20configure%20a%20dead%2Dletter%20queue%20on%20the%20function%20to%20capture%20events%20that%20weren%27t%20successfully%20processed."},{"upvote_count":"3","content":"Selected Answer: C\\ngpoing with C","poster":"Abdullah22","timestamp":"1725887460.0","comment_id":"1169584"},{"poster":"CrescentShared","timestamp":"1724300580.0","comment_id":"1156173","content":"Selected Answer: C\\nUsing an SQS queue for a DLQ is simpler than using Amazon Kinesis. Kinesis is a more complex service designed for real-time data streaming, which might be overkill for simply capturing failed Lambda events.","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:03:40.162Z","extraction_method":"api_direct_v1"},{"question_id":"suHWsRD2bJDoCccngpEG","question_number":237,"page":48,"question_text":"A company has built a serverless application for its ecommerce website. The application includes a REST API in Amazon API Gateway that invokes an AWS Lambda function. The Lambda function processes data and stores the data in Amazon DynamoDB table. The Lambda function calls a third-party stock application API to process the order. After the ordered is processed, the Lambda function returns an HTTP 200 status code with no body to the client.\\n\\nDuring peak usage when the API calls exceeds a certain threshold, the third-party stock application sometimes fails to process the data and responds with error messages. The company needs a solution that will not overwhelm the third-party stock application.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Configure the REST API in API Gateway to write the requests directly into DynamoDB. Configure a DynamoDB intrinsic function to perform the transformation. Set up a DynamoDB stream to call the third-party stock application API with each new row. Delete the Lambda function.","C":"Configure the REST API in API Gateway to write the requests directly into an Amazon Simple Notification Service (Amazon SNS) topic. Configure the Lambda function with a provisioned concurrency equal to the third-party stock application\'s threshold. Set the Lambda function to process the messages from the SNS topic.","D":"Configure the REST API in API Gateway to write the requests directly into Amazon Athena. Configure the transformation of the data by using SQL with multiple query result locations set up to point to the DynamoDB table and the third-party stock fulfilment application API. Delete the Lambda function.","B":"Configure the REST API in API Gateway to write the requests directly into an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda function with a reserved concurrency equal to the third-party stock application\'s threshold. Set Lambda function to process the messages from the SQS queue."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133609-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 14:10:00","unix_timestamp":1707743400,"discussion_count":4,"discussion":[{"comment_id":"1153203","upvote_count":"11","timestamp":"1723972200.0","poster":"tgv","content":"B should do it: API Gateway --\x3e SQS <-- Lambda poll"},{"content":"Selected Answer: B\\nno doubt.","upvote_count":"5","timestamp":"1724300820.0","comment_id":"1156175","poster":"CrescentShared"},{"poster":"65703c1","timestamp":"1732466700.0","upvote_count":"1","comment_id":"1217607","content":"Selected Answer: B\\nB is the correct answer."},{"timestamp":"1727721960.0","upvote_count":"2","comment_id":"1186368","content":"Selected Answer: B\\nB is right","poster":"seetpt"}],"answer_description":"","extracted_at":"2025-12-24T09:03:40.162Z","extraction_method":"api_direct_v1"},{"question_id":"AqcBWrc3XGee5jihGwST","question_number":238,"page":48,"question_text":"A company hosts its application on AWS. The application runs on an Amazon Elastic Container Service (Amazon ECS) cluster that uses AWS Fargate. The cluster runs behind an Application Load Balancer. The application stores data in an Amazon Aurora database. A developer encrypts and manages database credentials inside the application.\\n\\nThe company wants to use a more secure credential storage method and implement periodic credential rotation.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"B":"Migrate the credentials to AWS Systems Manager Parameter Store. Encrypt the parameter by using an AWS Key Management Service (AWS KMS) key. Turn on secret rotation. Use IAM policies and roles to grant Amazon ECS Fargate permissions to access to AWS Secrets Manager.","C":"Migrate the credentials to ECS Fargate environment variables. Encrypt the credentials by using an AWS Key Management Service (AWS KMS) key. Turn on secret rotation. Use IAM policies and roles to grant Amazon ECS Fargate permissions to access to AWS Secrets Manager.","A":"Migrate the secret credentials to Amazon RDS parameter groups. Encrypt the parameter by using an AWS Key Management Service (AWS KMS) key. Turn on secret rotation. Use IAM policies and roles to grant AWS KMS permissions to access Amazon RDS.","D":"Migrate the credentials to AWS Secrets Manager. Encrypt the credentials by using an AWS Key Management Service (AWS KMS) key. Turn on secret rotation. Use IAM policies and roles to grant Amazon ECS Fargate permissions to access to AWS Secrets Manager by using keys."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133610-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 14:11:00","unix_timestamp":1707743460,"discussion_count":6,"discussion":[{"comment_id":"1217630","timestamp":"1716562740.0","upvote_count":"2","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer."},{"comments":[{"content":"Not always. Depends on cost. SSM PS is cheaper.","poster":"BrainFried","comment_id":"1264864","upvote_count":"1","timestamp":"1723506360.0"}],"comment_id":"1165304","poster":"KarBiswa","upvote_count":"4","content":"Selected Answer: D\\nAlways secrets manager for credential","timestamp":"1709526960.0"},{"comment_id":"1163005","poster":"nder","timestamp":"1709239500.0","content":"Selected Answer: D\\nIf it\'s secrets manager its for db","upvote_count":"3"},{"comment_id":"1162081","timestamp":"1709166180.0","upvote_count":"3","content":"Selected Answer: D\\nSecrets Manager","poster":"monishvster"},{"upvote_count":"3","content":"Selected Answer: D\\nC is not correct.","comment_id":"1156177","timestamp":"1708583580.0","poster":"CrescentShared"},{"comment_id":"1153205","content":"the most secure + secrets rotation --\x3e Secrets Manager","upvote_count":"4","poster":"tgv","timestamp":"1708254720.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:40.162Z","extraction_method":"api_direct_v1"},{"question_id":"2Q8pZBc5w5ANFDe2cwGH","question_number":239,"page":48,"question_text":"A company has a mobile app. The app includes an Amazon API Gateway REST API that invokes AWS Lambda functions. The Lambda functions process data from the app.\\n\\nThe company needs to test updated Lambda functions that have new features. The company must conduct these tests with a subset of users before deployment. The tests must not affect other users of the app.\\n\\nWhich solution will meet these requirements with the LEAST amount of operational effort?","choices":{"A":"Create a new version of each Lambda function with a weighted alias. Configure a weight value for each version of the Lambda function. Update the new weighted alias Amazon Resource Name (ARN) in the REST API.","D":"Create a new REST API in API Gateway. Set up a Lambda non-proxy integration to connect to multiple Lambda functions. Specify the necessary parameters and properties in API Gateway. Enable canary settings on the deployment stage. Specify a smaller percentage of API traffic to go to the new version of the Lambda function.","B":"Create a new REST API in API Gateway. Set up a Lambda proxy integration to connect to multiple Lambda functions. Enable canary settings on the deployment stage. Specify a smaller percentage of API traffic to go to the new version of the Lambda function.","C":"Create a new version of each Lambda function. Integrate a predefined canary deployment in AWS CodeDeploy to slowly shift the traffic to the new versions automatically."},"correct_answer":"A","answer_ET":"A","answers_community":["A (51%)","B (47%)","2%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133611-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 14:16:00","unix_timestamp":1707743760,"discussion_count":19,"discussion":[{"comment_id":"1183144","poster":"DeaconStJohn","comments":[{"timestamp":"1722049680.0","poster":"albert_kuo","upvote_count":"2","content":"1. create new version\\naws lambda publish-version --function-name MyFunction\\n\\n2. create weighted alias\\naws lambda create-alias --function-name MyFunction \\\\\\n --name MyAlias \\\\\\n --function-version 1 \\\\\\n --routing-config \'{\\"AdditionalVersionWeights\\": {\\"2\\": 0.1}}\'","comment_id":"1255971"}],"upvote_count":"10","content":"Selected Answer: A\\nThe wording is screaming out weighted alias. During a canary deployment, we are moving code from testing to prod. We can define a subset of users i.e. 10% for a set period of time. After this the other users will be impacted as the percentage will increment or the deployment will push new code to 100% of users.\\n\\nWith a weighted alias we can define a subset of users and use this as our guinea pigs to test new code. As this isn\'t a canary deployment we have no risk of more users becoming impacted. Operational overhead is minimal as we only need to point to a new alias.\\n\\nWith weighted alias we can deploy for testing purposes. From my understanding lambda proxy is grouping lambda functions. the traffic splitting would need to be set at the lambda level as this is testing prior to deployment.","timestamp":"1711442880.0"},{"timestamp":"1711882560.0","poster":"ethanluvsbooks","upvote_count":"5","content":"Selected Answer: B\\nThis is the least amount of effort.\\nI originally thought answer A but then you will have more effort because will have to update API Gateway configuration to use new ARN etc. Unless there are other thoughts on this?","comment_id":"1186723"},{"poster":"Shamalka","upvote_count":"1","timestamp":"1741936140.0","content":"Selected Answer: A\\nThe simple answer is A. The Simple reason for the answer to not be D is why you would need to create a new Rest API endpoint.?","comment_id":"1395541"},{"comment_id":"1330889","poster":"examuserss","upvote_count":"1","content":"Selected Answer: A\\nBest Solution:\\nOption A: Create a new version of each Lambda function with a weighted alias. Configure a weight value for each version of the Lambda function. Update the new weighted alias Amazon Resource Name (ARN) in the REST API.\\n\\nThis is the least complex and most efficient solution. By using weighted aliases for Lambda versions, you can control the traffic sent to the new version of the function, and it can be done with minimal operational overhead, without the need to create a new API or involve other services like AWS CodeDeploy.","timestamp":"1734973920.0"},{"upvote_count":"1","comment_id":"1316084","content":"Selected Answer: A\\nWeight ed alias","timestamp":"1732236780.0","poster":"ShakthiGCP"},{"poster":"ShakthiGCP","upvote_count":"1","content":"Selected Answer: A\\nYes. Answer is Option A. B will eventually push all users to new alias as part of canary deployment.","comment_id":"1311672","timestamp":"1731545880.0"},{"content":"Selected Answer: B\\nB provides the least operational effort","upvote_count":"1","poster":"Saudis","timestamp":"1730653680.0","comment_id":"1306581"},{"upvote_count":"1","timestamp":"1727615340.0","content":"Selected Answer: A\\nI think A is direct","poster":"abdulla203","comment_id":"1291148"},{"timestamp":"1725021240.0","content":"I am going with A, not sure if creating a new rest api is less effort then just managing the existing API config for the weight.","upvote_count":"2","comment_id":"1275071","poster":"wh1t4k3r"},{"upvote_count":"1","content":"Option A is typically the most straightforward and requires the least operational effort while providing high control over traffic distribution directly from the Lambda configuration. This method avoids the overhead of managing additional services or creating new APIs and is directly supported by AWS services for testing purposes with actual users.","poster":"tomchandler077","comment_id":"1249960","timestamp":"1721247060.0"},{"timestamp":"1716563640.0","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1217642"},{"timestamp":"1713626520.0","comment_id":"1199210","poster":"a1971h","content":"Selected Answer: B\\nIt says: with the LEAST amount of operational effort \\nB --- NEVER A!!!","upvote_count":"3"},{"poster":"yingying920928","content":"Selected Answer: A\\nPrefer A, because creating a new REST API (B) involves more operational overhead and complexity compared to using weighted aliases. Moreover, setting up a Lambda proxy integration to connect to multiple Lambda functions can increase complexity, especially when handling different versions for canary testing.","timestamp":"1710681120.0","comment_id":"1175840","upvote_count":"4"},{"poster":"KarBiswa","upvote_count":"3","timestamp":"1709527920.0","comments":[{"timestamp":"1712858340.0","content":"This is possible but the question stated less operational effort.","comment_id":"1193953","poster":"be1dca8","upvote_count":"1"}],"comment_id":"1165308","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html"},{"content":"Selected Answer: D\\n}\\nEl desarrollador debe crear una nueva API REST en Amazon API Gateway y configurar una integraci\xf3n Lambda sin proxy para conectarse a m\xfaltiples funciones Lambda. Luego, debe especificar los par\xe1metros y propiedades necesarios en API Gateway y habilitar la configuraci\xf3n canary en la etapa de implementaci\xf3n. Especifique un porcentaje menor de tr\xe1fico API para ir a la nueva versi\xf3n de la funci\xf3n Lambda.\\n\\n\\nAl utilizar una nueva API REST en API Gateway con una configuraci\xf3n canary, el desarrollador puede probar las funciones Lambda actualizadas con nuevas caracter\xedsticas con un subconjunto de usuarios antes de la implementaci\xf3n completa. Esto permite realizar pruebas sin afectar a otros usuarios de la aplicaci\xf3n y con un menor esfuerzo operativo.","upvote_count":"1","poster":"ANDRES715","timestamp":"1709252520.0","comment_id":"1163117"},{"timestamp":"1709166300.0","poster":"monishvster","upvote_count":"5","comment_id":"1162083","content":"Selected Answer: B\\nShould be B"},{"content":"Selected Answer: B\\nOption A involves using weighted aliases for Lambda functions, which is a valid approach but requires more effort to manage and update the aliases in the API Gateway configuration.","upvote_count":"5","comment_id":"1156179","poster":"CrescentShared","timestamp":"1708583880.0"},{"content":"Selected Answer: A\\nLambda with weighted alias with weight configured for each version of the function. \\nThe canary situation is much suitable for deployments.","timestamp":"1708254840.0","poster":"tgv","comment_id":"1153207","upvote_count":"4"},{"poster":"Americo32","content":"Op\xe7\xe3o A","upvote_count":"2","comment_id":"1148123","timestamp":"1707743760.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:40.162Z","extraction_method":"api_direct_v1"},{"question_id":"aIFhzBgywOZFusrMfNFi","question_number":240,"page":48,"question_text":"A developer works for a company that only has a single pre-production AWS account with an AWS CloudFormation AWS Serverless Application Model (AWS SAM) stack. The developer made changes to an existing AWS Lambda function specified in the AWS SAM template and additional Amazon Simple Notification service (Amazon SNS) topics.\\n\\nThe developer wants to do a one-time deploy of the changes to test if the changes are working. The developer does not want to impact the existing pre-production application that is currently being used by other team members as part of the release pipeline.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Use the AWS SAM CLI to package and create a change set against the pre-production AWS account. Execute the change set in a new AWS account designated for a development environment.","D":"Update the CloudFormation stack in the pre-production account. Add a separate stage that points to a new AWS account designated for a development environment.","A":"Use the AWS SAM CLI to package and deploy the SAM application to the pre-production AWS account. Specify the debug parameter.","C":"Use the AWS SAM CLI to package and deploy the SAM application to a new AWS account designated for a development environment."},"correct_answer":"C","answer_ET":"C","answers_community":["C (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133612-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 14:25:00","unix_timestamp":1707744300,"discussion_count":6,"discussion":[{"timestamp":"1709978640.0","comment_id":"1169394","content":"Selected Answer: C\\nThis option meets the requirements by deploying the changes to a completely separate AWS account, ensuring that the pre-production application is not impacted. This approach allows the developer to test the changes in isolation.","poster":"SerialiDr","upvote_count":"6"},{"upvote_count":"1","comment_id":"1266266","poster":"Saurabh04","content":"Selected Answer: B\\nI recommend Option B\u2014create a change set in a separate development environment. This way, you can test your changes without affecting other team members.","timestamp":"1723703520.0"},{"content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716563820.0","upvote_count":"1","poster":"65703c1","comment_id":"1217643"},{"upvote_count":"2","comment_id":"1165313","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/using-sam-cli-deploy.html B option seems to be by default","poster":"KarBiswa","timestamp":"1709528640.0"},{"timestamp":"1708584240.0","upvote_count":"2","poster":"CrescentShared","content":"Selected Answer: C\\nC is correct.","comment_id":"1156182"},{"upvote_count":"2","timestamp":"1708070700.0","poster":"tgv","comment_id":"1151816","content":"best practice here is to sam pack and sam deploy to a new AWS account dedicated to development so in this case the developer wouldn\'t impact whatsoever the existing pre-prod application. option C"}],"answer_description":"","extracted_at":"2025-12-24T09:03:40.162Z","extraction_method":"api_direct_v1"},{"question_id":"pTEKXHjkZFuWi4nXDPzp","question_number":241,"page":49,"question_text":"A company built an online event platform. For each event, the company organizes quizzes and generates leaderboards that are based on the quiz scores. The company stores the leaderboard data in Amazon DynamoDB and retains the data for 30 days after an event is complete. The company then uses a scheduled job to delete the old leaderboard data.\\n\\nThe DynamoDB table is configured with a fixed write capacity. During the months when many events occur, the DynamoDB write API requests are throttled when the scheduled delete job runs.\\n\\nA developer must create a long-term solution that deletes the old leaderboard data and optimizes write throughput.\\n\\nWhich solution meets these requirements?","choices":{"B":"Use DynamoDB Streams to schedule and delete the leaderboard data.","A":"Configure a TTL attribute for the leaderboard data.","C":"Use AWS Step Functions to schedule and delete the leaderboard data.","D":"Set a higher write capacity when the scheduled delete job runs."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134133-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:17:00","unix_timestamp":1708255020,"discussion_count":5,"discussion":[{"upvote_count":"7","poster":"tgv","comment_id":"1153210","timestamp":"1723972620.0","content":"Selected Answer: A\\nAlways consider TTL when trying to ditch from DynamoDB."},{"content":"Selected Answer: A\\nTime To Live","comment_id":"1226289","upvote_count":"2","poster":"vkovilam","timestamp":"1733598840.0"},{"upvote_count":"2","comment_id":"1217646","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732468980.0"},{"timestamp":"1725419280.0","poster":"KarBiswa","comment_id":"1165314","upvote_count":"2","content":"Selected Answer: A\\nIt should be TTL enabled"},{"upvote_count":"2","poster":"CrescentShared","comment_id":"1156184","content":"Selected Answer: A\\nA is right","timestamp":"1724302020.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:51.125Z","extraction_method":"api_direct_v1"},{"question_id":"ZlpJ9LR6l6QZudvWQtZf","question_number":242,"page":49,"question_text":"A company uses an AWS Lambda function that reads messages from an Amazon Simple Queue Service (Amazon SQS) standard queue. The Lambda function makes an HTTP call to a third-party API for each message. The company wants to ensure that the Lambda function does not overwhelm the third-party API with more than two concurrent requests.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Configure a maximum concurrency of two on the Amazon SQS event source mapping for the Lambda function.","B":"Configure a batch size of two on the Amazon SQS event source mapping for the Lambda function.","C":"Configure Lambda event filtering to process two messages from Amazon SQS at every invocations.","A":"Configure a provisioned concurrency of two on the Lambda function."},"correct_answer":"D","answer_ET":"D","answers_community":["D (88%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134135-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:18:00","unix_timestamp":1708255080,"discussion_count":8,"discussion":[{"poster":"monishvster","timestamp":"1709166600.0","upvote_count":"7","comment_id":"1162086","content":"Selected Answer: D\\nShould be D. Source: https://aws.amazon.com/blogs/compute/introducing-maximum-concurrency-of-aws-lambda-functions-when-using-amazon-sqs-as-an-event-source/"},{"timestamp":"1711444440.0","comment_id":"1183155","poster":"DeaconStJohn","content":"Selected Answer: D\\nDidn\'t like the wording.\\n\\nA - provisioned concurrency keeps 2 functions on warm standby for critical work. this is a minimum. question is asking about a maximum of 2.\\nB - Batch of 2 is fine. latency could see this fall flat on it\'s face though. lambda invocations between function and SQS are limited to 2, not strictly between lambda and vendor API.\\nC - event filtering is completely irrelevant here.\\nD - Maximum is what the question is asking for. this will limit the amount of requests made to the vendor API. I would much prefer to set the reserved concurrency at the lambda level but this can be overridden at the SQS event source mapping level so I guess this is the best answer.","comments":[{"content":"aws lambda create-event-source-mapping \\\\\\n --function-name YourLambdaFunctionName \\\\\\n --batch-size 2 \\\\\\n --maximum-batching-window-in-seconds 5 \\\\\\n --event-source-arn arn:aws:sqs:region:account-id:queue-name \\\\\\n --maximum-concurrency 2","upvote_count":"2","timestamp":"1722050280.0","comment_id":"1255979","poster":"albert_kuo"}],"upvote_count":"5"},{"upvote_count":"1","poster":"ShakthiGCP","comment_id":"1316094","timestamp":"1732237620.0","content":"Selected Answer: D\\nSqs event source mapping"},{"comment_id":"1217647","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","timestamp":"1716564540.0"},{"upvote_count":"3","comment_id":"1169635","poster":"Abdullah22","content":"Selected Answer: D\\ngoing with D","timestamp":"1710000720.0"},{"poster":"SerialiDr","timestamp":"1709979300.0","upvote_count":"2","content":"Selected Answer: A\\nControlled Execution: Provisioned concurrency ensures that a minimum number of Lambda execution environments are always available. Setting it to two guarantees that only two Lambda function instances can process messages from the SQS queue concurrently.\\nIndependent of Message Batch Size: Even if the SQS event source mapping delivers a batch of messages exceeding two, the provisioned concurrency limits the number of Lambda invocations happening simultaneously.","comment_id":"1169402"},{"content":"Selected Answer: B\\nconfiguring a maximum concurrency of two on the SQS event source mapping, is not a valid option. The concept of maximum concurrency is not directly applicable to SQS event source mappings. Concurrency in the context of Lambda functions and SQS is controlled by the batch size and the function\'s reserved concurrency settings.","timestamp":"1708584660.0","comment_id":"1156186","poster":"CrescentShared","upvote_count":"1"},{"content":"Selected Answer: D\\nCorrect answer is D. The maximum concurrency setting on the Amazon SQS event source mapping for the Lambda function controls how many messages are sent to the Lambda function concurrently. By setting it to two, you ensure that only two messages are processed concurrently, preventing the Lambda function from overwhelming the third-party API with more than two concurrent requests.","comment_id":"1153213","poster":"tgv","timestamp":"1708255080.0","upvote_count":"5"}],"answer_description":"","extracted_at":"2025-12-24T09:03:51.125Z","extraction_method":"api_direct_v1"},{"question_id":"KL7lGiEVlMlXSdPW5hux","question_number":243,"page":49,"question_text":"A company is using Amazon API Gateway to develop an API for its application on AWS. A developer needs to test and generate API responses. Other teams are required to test the API immediately.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Set up the request validators in the API\'s OpenAPI definition file. Import the OpenAPI definitions into API Gateway to test the API.","A":"Set up a mock integration request in API Gateway. Configure the method\'s integration request and integration response to associate a response with a given status code.","D":"Set up a request parameter-based Lambda authorizer to control access to the API. Configure the Lambda function with the necessary mapping template.","C":"Set up a gateway response for the API in API Gateway. Configure response headers with hardcoded HTTP status codes and responses."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134136-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:20:00","unix_timestamp":1708255200,"discussion_count":2,"discussion":[{"timestamp":"1723972800.0","content":"Selected Answer: A\\nThe mock integration should do it here","poster":"tgv","comment_id":"1153215","upvote_count":"9"},{"poster":"65703c1","comment_id":"1217648","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732469460.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:51.125Z","extraction_method":"api_direct_v1"},{"question_id":"ozJMppte0SwhdY7SEL1N","question_number":244,"page":49,"question_text":"A company is releasing a new feature. Users can request early access to the new feature by using an application form. The company expects a surge of requests when the application form becomes available. Each request will be stored as an item in an Amazon DynamoDB table.\\n\\nEach item will contain the user\'s username, the submission date, and a validation status of UNVALIDATED. VALID, or NOT VALID. Each item also will contain the user\'s rating of the process on a scale of 1 to 5.\\n\\nEach user can submit one request. For the DynamoDB table, the developer must choose a partition key that will give the workload well-distributed records across partitions.\\n\\nWhich DynamoDB attribute will meet these requirements?","choices":{"A":"Username","B":"Submission date","C":"Validation status","D":"Rating of the process on a scale of 1 to 5"},"correct_answer":"A","answer_ET":"A","answers_community":["A (93%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134343-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 07:53:00","unix_timestamp":1708584780,"discussion_count":7,"discussion":[{"poster":"Dzok5050","upvote_count":"5","comment_id":"1215663","content":"Selected Answer: A\\nIt\'s A of course. This question got me wondering, who choses default right answers here","timestamp":"1716373680.0"},{"comment_id":"1306766","timestamp":"1730693700.0","poster":"Saudis","upvote_count":"1","content":"Selected Answer: A\\npartition key should be Unique so the A is a best choice"},{"content":"Selected Answer: B\\nThe submission date could be a good choice if it has high cardinality (many distinct values).\\nHowever, if multiple requests occur simultaneously (e.g., during the surge), it might still lead to hot partitions","comment_id":"1266269","poster":"Saurabh04","timestamp":"1723704180.0","upvote_count":"1"},{"comment_id":"1217649","timestamp":"1716564720.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"2"},{"comment_id":"1165321","timestamp":"1709529300.0","poster":"KarBiswa","upvote_count":"1","content":"Selected Answer: A\\nUsername beyond doubt"},{"poster":"nder","timestamp":"1709240880.0","upvote_count":"3","content":"Selected Answer: A\\nUsername avoids a hot partition key","comment_id":"1163020"},{"poster":"CrescentShared","upvote_count":"2","content":"Selected Answer: A\\nrest is not even distributed.","comment_id":"1156188","timestamp":"1708584780.0"}],"answer_description":"","extracted_at":"2025-12-24T09:03:51.125Z","extraction_method":"api_direct_v1"},{"question_id":"DffxtIZwuNECNAA6PVRI","question_number":245,"page":49,"question_text":"A developer is creating a publicly accessible enterprise website consisting of only static assets. The developer is hosting the website in Amazon S3 and serving the website to users through an Amazon CloudFront distribution. The users of this application must not be able to access the application content directly from an S3 bucket. All content must be served through the Amazon CloudFront distribution.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Update the S3 bucket\'s static website settings. Enable static website hosting and specifying index and error documents. Update the CloudFront origin to use the S3 bucket\'s website endpoint.","B":"Update the S3 bucket settings. Enable the block all public access setting in Amazon S3. Configure the CloudFront distribution\'s with Amazon S3 as the origin. Update the S3 bucket policy to allow CloudFront write access.","A":"Create a new origin access control (OAC) in CloudFront. Configure the CloudFront distribution\'s origin to use the new OAC. Update the S3 bucket policy to allow CloudFront OAC with read and write access to access Amazon S3 as the origin.","D":"Update the CloudFront distribution\'s origin to send a custom header. Update the S3 bucket policy with a condition by using the aws:RequestTag/tag-key key. Configure the tag-key as the custom header name, and the value being matched is the header\'s value."},"correct_answer":"A","answer_ET":"A","answers_community":["A (86%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134344-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 07:54:00","unix_timestamp":1708584840,"discussion_count":7,"discussion":[{"timestamp":"1730693880.0","poster":"Saudis","comment_id":"1306767","content":"Selected Answer: A\\nthe access to S3 Always by two ways OAC or OAI \\nIn cloud front we access by OAC","upvote_count":"1"},{"upvote_count":"1","comment_id":"1217652","poster":"65703c1","timestamp":"1716565140.0","content":"Selected Answer: A\\nA is the correct answer."},{"comment_id":"1183157","poster":"DeaconStJohn","timestamp":"1711444620.0","content":"Selected Answer: A\\nThink back to every beginner cloud project you have completed/read about/ignored.","upvote_count":"3"},{"timestamp":"1710003180.0","comments":[{"timestamp":"1710003480.0","poster":"Abdullah22","upvote_count":"2","content":"changing to A. Origin access identity is now considered a legacy solution. The official AWS documentation now recommends that Origin Access Control is used instead.","comment_id":"1169666"}],"upvote_count":"1","poster":"Abdullah22","content":"Selected Answer: B\\nwhy not B","comment_id":"1169664"},{"timestamp":"1709241540.0","upvote_count":"4","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html","poster":"nder","comment_id":"1163027"},{"comment_id":"1162089","timestamp":"1709166900.0","content":"Selected Answer: C\\nWe don\'t want to provide write access to CloudFront since it\'s a static website. S3 should suffice","poster":"monishvster","comments":[{"comment_id":"1183159","upvote_count":"1","timestamp":"1711444740.0","poster":"DeaconStJohn","content":"Option C requires public access to the bucket to be allowed.\\n\\n\\"The users of this application must not be able to access the application content directly from an S3 bucket. All content must be served through the Amazon CloudFront distribution.\\"\\n\\nOAC allows us to turn this feature off and still access the bucket contents via cloudfront."}],"upvote_count":"1"},{"comment_id":"1156191","poster":"CrescentShared","content":"Selected Answer: A\\nWhile enabling the block all public access setting in Amazon S3 is a good security practice and necessary for this scenario, simply allowing CloudFront \\"write access\\" is not relevant since the scenario involves serving static assets, not writing to the S3 bucket. This option also doesn\'t specify using an OAC or a similar method to ensure exclusive access through CloudFront.","timestamp":"1708584840.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:03:51.125Z","extraction_method":"api_direct_v1"},{"question_id":"A97ohM3OiWvppZJE6L8j","question_number":246,"page":50,"question_text":"A developer needs to perform geographic load testing of an API. The developer must deploy resources to multiple AWS Regions to support the load testing of the API.\\nHow can the developer meet these requirements without additional application code?","choices":{"A":"Create and deploy an AWS Lambda function in each desired Region. Configure the Lambda function to create a stack from an AWS CloudFormation template in that Region when the function is invoked.","D":"Create an AWS CloudFormation template that defines the load test resources. Use the AWS CLI deploy command to create a stack from the template in each Region.","B":"Create an AWS CloudFormation template that defines the load test resources. Use the AWS CLI create-stack-set command to create a stack set in the desired Regions.","C":"Create an AWS Systems Manager document that defines the resources. Use the document to create the resources in the desired Regions."},"correct_answer":"B","answer_ET":"B","answers_community":["B (97%)","3%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103515-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:23:00","unix_timestamp":1679433780,"discussion_count":9,"discussion":[{"upvote_count":"13","comment_id":"897348","content":"Selected Answer: B\\nB. Create an AWS CloudFormation template that defines the load test resources. Use the AWS CLI create-stack-set command to create a stack set in the desired Regions.\\n\\nAWS CloudFormation StackSets allow developers to deploy CloudFormation stacks across multiple AWS accounts and regions with a single CloudFormation template. By using the AWS CLI create-stack-set command, the developer can deploy the same CloudFormation stack to multiple regions without additional application code, thereby meeting the requirement for geographic load testing of an API.","timestamp":"1684049040.0","poster":"Bibay"},{"comment_id":"848208","poster":"Untamables","timestamp":"1679575680.0","upvote_count":"8","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-concepts.html\\nhttps://awscli.amazonaws.com/v2/documentation/api/2.1.30/reference/cloudformation/create-stack-set.html"},{"poster":"sumanshu","timestamp":"1734885780.0","content":"Selected Answer: B\\nA) Eliminated: Requires extra steps (deploying Lambda functions) and additional code, making it not optimal.\\n\\nB) Correct - CloudFormation stack sets are specifically designed for deploying resources across multiple Regions and accounts.\\n\\nC) Eliminated - AWS Systems Manager documents are used to automate tasks and manage instances, not specifically for deploying infrastructure across multiple Regions.","upvote_count":"2","comments":[{"poster":"sumanshu","upvote_count":"2","comments":[{"timestamp":"1738408680.0","content":"D) Eliminated - the deploy command is designed for deploying a single CloudFormation stack in a specific region. If you need to deploy the same stack in multiple regions, you would have to run the deploy command separately for each region, specifying the appropriate region each time","comment_id":"1349839","comments":[{"poster":"sumanshu","content":"B) Correct - Using the create-stack-set command in AWS CloudFormation allows you to deploy resources across multiple AWS Regions with a single command. This is achieved by creating a stack set, which is a collection of AWS CloudFormation stacks that can be managed as a single unit across multiple accounts and regions. Once the stack set is created, you can add stack instances in the desired regions,","comment_id":"1349840","upvote_count":"2","timestamp":"1738408800.0"}],"upvote_count":"2","poster":"sumanshu"}],"timestamp":"1734885900.0","content":"D) Eliminated - Requires you to manually deploy the CloudFormation stack in each Region individually using the deploy command.","comment_id":"1330465"}],"comment_id":"1330464"},{"content":"Selected Answer: B\\n==> Discard A: Requires additional application code (Lambda), violating \\"without additional application code.\\". Beside, Creating and managing multiple Lambda functions increases workload and is inefficient for large-scale deployment.\\n==> Discard C: AWS Systems Manager is not designed for infrastructure deployment, violating \\"deploy resources to multiple AWS Regions.\\"\\n==> Discard D: Requires manual deployment per Region, violating \\"deploy resources to multiple AWS Regions\\" efficiently. This means you have to repeat the deployment process manually for each region, which is time-consuming and error-prone.\\n\\nB: CloudFormation StackSet automates multi-region deployments, meeting \\"deploy resources to multiple AWS Regions\\" efficiently without additional application code.","comment_id":"1326336","poster":"trieudo","upvote_count":"1","timestamp":"1734147720.0"},{"poster":"ltfalcon","comment_id":"1284086","upvote_count":"1","content":"B according to chatgpt :)","timestamp":"1726401600.0"},{"upvote_count":"1","timestamp":"1716304440.0","poster":"65703c1","comment_id":"1215053","content":"Selected Answer: B\\nB is the correct answer."},{"content":"in desired Regions better than in each Region.","poster":"hsinchang","comment_id":"1003189","upvote_count":"3","timestamp":"1694262360.0"},{"comment_id":"980043","timestamp":"1691932560.0","poster":"rlnd2000","upvote_count":"1","content":"Selected Answer: C\\nIf using Edge-Optimized endpoint, then the certificate must be in us-east-1\\nIf using Regional endpoint, the certificate must be in the API Gateway region"},{"content":"Selected Answer: B\\nB\\nhttps://aws.amazon.com/ru/about-aws/whats-new/2021/04/deploy-cloudformation-stacks-concurrently-across-multiple-aws-regions-using-aws-cloudformation-stacksets/","upvote_count":"3","poster":"svrnvtr","timestamp":"1679433780.0","comment_id":"846367"}],"answer_description":"","extracted_at":"2025-12-24T09:04:02.147Z","extraction_method":"api_direct_v1"},{"question_id":"qctzXVuIA9EvIlyhNv4g","question_number":247,"page":50,"question_text":"A developer built an application that calls an external API to obtain data, processes the data, and saves the result to Amazon S3. The developer built a container image with all of the necessary dependencies to run the application as a container.\\n\\nThe application runs locally and requires minimal CPU and RAM resources. The developer has created an Amazon ECS cluster. The developer needs to run the application hourly in Amazon Elastic Container Service (Amazon ECS).\\n\\nWhich solution will meet these requirements with the LEAST amount of infrastructure management overhead?","choices":{"C":"Define a task definition with an AWS Fargate launch type.","A":"Add a capacity provider to manage instances.","D":"Create an Amazon ECS cluster and add the managed node groups feature to run the application.","B":"Add an Amazon EC2 instance that runs the application."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134139-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:29:00","unix_timestamp":1708255740,"discussion_count":6,"discussion":[{"content":"Selected Answer: C\\nAlways ECS with Fargate for the least management.","poster":"tgv","comment_id":"1153219","upvote_count":"10","timestamp":"1708255740.0"},{"poster":"Saudis","upvote_count":"1","timestamp":"1730694000.0","content":"Selected Answer: C\\nAWS Fargate Serverless Container management","comment_id":"1306768"},{"timestamp":"1727630700.0","poster":"preachr","content":"Selected Answer: C\\nFargate is suitable for the following workloads:\\n- Large workloads that require low operational overhead\\n- Small workloads that have an occasional burst\\n- Tiny workloads\\n- Batch workloads","comment_id":"1291247","upvote_count":"1"},{"comment_id":"1217653","poster":"65703c1","timestamp":"1716565380.0","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1"},{"upvote_count":"3","poster":"KarBiswa","timestamp":"1709529600.0","comment_id":"1165323","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/launch_types.html"},{"content":"Selected Answer: C\\nEl desarrollador debe definir una definici\xf3n de tarea con un tipo de lanzamiento de AWS Fargate. Al utilizar AWS Fargate, el desarrollador puede ejecutar la aplicaci\xf3n en un cl\xfaster de Amazon ECS sin tener que administrar la infraestructura subyacente. Fargate se encarga de aprovisionar y escalar autom\xe1ticamente los recursos necesarios para ejecutar la tarea de la aplicaci\xf3n, lo que reduce la carga operativa y los gastos generales de administraci\xf3n.\\n\\n\\nAl ejecutar la aplicaci\xf3n en AWS Fargate, el desarrollador puede aprovechar los recursos m\xednimos de CPU y RAM necesarios para la aplicaci\xf3n, lo que garantiza un uso eficiente de los recursos y minimiza los costos.","upvote_count":"4","comment_id":"1163129","timestamp":"1709253720.0","poster":"ANDRES715"}],"answer_description":"","extracted_at":"2025-12-24T09:04:02.147Z","extraction_method":"api_direct_v1"},{"question_id":"uxdl89Urg6RWy5frEcoD","question_number":248,"page":50,"question_text":"A company runs its website on AWS. The company posts daily polls on its website and publishes the poll results next day. The website stores user responses in an Amazon DynamoDB table. After the poll results are published, the company does not need to keep the user responses.\\n\\nA developer needs to implement a solution that will automatically remove old user responses from the DynamoDB table. The developer adds a new expiration_date attribute to the DynamoDB table. The developer plans to use the expiration_date attribute for the automation.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"C":"Create an AWS Glue job to delete old user responses based on the expiration_date attribute. Create an AWS Glue trigger schedule to run the job daily.","A":"Create an AWS Lambda function to delete old user responses based on the expiration_date attribute. Create an Amazon EventBridge schedule to run the Lambda function daily.","D":"Enable TTL on the DynamoDB table and specify the expiration_date attribute. Expire old user responses by using DynamoDB TTL.","B":"Create an AWS Fargate task in Amazon Elastic Container Service (Amazon ECS) to delete old user responses based on the expiration_date attribute. Create an Amazon EventBridge schedule to run the Fargate task daily."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133631-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 18:08:00","unix_timestamp":1707757680,"discussion_count":6,"discussion":[{"upvote_count":"1","content":"Selected Answer: D\\n1. enable ttl\\naws dynamodb update-time-to-live \\\\\\n --table-name <your-table-name> \\\\\\n --time-to-live-specification \\"Enabled=true, AttributeName=expiration_date\\"\\n\\n2.Set TTL\\naws dynamodb describe-time-to-live --table-name <your-table-name>","poster":"albert_kuo","comment_id":"1255984","timestamp":"1722050940.0"},{"upvote_count":"1","poster":"tomchandler077","content":"To deploy an AWS Lambda function using AWS CloudFormation, especially when the function code is stored in an Amazon S3 bucket, the developer should reference the S3 location directly in the CloudFormation template. The best option to achieve this with the least development effort is:\\n\\nOption D directly links the Lambda function\'s deployment package stored in S3 to the CloudFormation template, which automates the deployment process without requiring additional steps for handling the function code.","timestamp":"1721248920.0","comment_id":"1249977"},{"comment_id":"1217654","upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716565980.0"},{"timestamp":"1709167020.0","poster":"monishvster","upvote_count":"4","comment_id":"1162091","content":"Selected Answer: D\\nAlways TTL"},{"content":"Selected Answer: D\\nIt\'s D.","timestamp":"1708585020.0","comment_id":"1156194","upvote_count":"3","poster":"CrescentShared"},{"poster":"Americo32","comment_id":"1148421","timestamp":"1707757680.0","content":"Op\xe7\xe3o A","upvote_count":"1","comments":[{"upvote_count":"5","poster":"tgv","timestamp":"1708072140.0","content":"it says \\"the least development effort\\". in this case the TTL would be best practice","comment_id":"1151826"}]}],"answer_description":"","extracted_at":"2025-12-24T09:04:02.147Z","extraction_method":"api_direct_v1"},{"question_id":"v1MzRgGpa8jbewzOxp4e","question_number":249,"page":50,"question_text":"A developer is creating a simple proof-of-concept demo by using AWS CloudFormation and AWS Lambda functions. The demo will use a CloudFormation template to deploy an existing Lambda function. The Lambda function uses deployment packages and dependencies stored in Amazon S3. The developer defined an AWS::Lambda::Function resource in a CloudFormation template. The developer needs to add the S3 bucket to the CloudFormation template.\\n\\nWhat should the developer do to meet these requirements with the LEAST development effort?","choices":{"C":"Find the S3 key for the Lambda function. Add the S3 key as the ZipFile property in the CloudFormation template.","B":"Add the function code in the CloudFormation template as the ZipFile property.","A":"Add the function code in the CloudFormation template inline as the code property.","D":"Add the relevant key and bucket to the S3Bucket and S3Key properties in the CloudFormation template."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133632-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 18:11:00","unix_timestamp":1707757860,"discussion_count":4,"discussion":[{"timestamp":"1708255980.0","content":"Selected Answer: D\\nThe correct solution would be D, to add the S3Bucket and S3Key properties in the CloudFormation template.","poster":"tgv","upvote_count":"8","comment_id":"1153223"},{"upvote_count":"3","content":"Selected Answer: D\\nAWSTemplateFormatVersion: \'2010-09-09\'\\nResources:\\n MyLambdaFunction:\\n Type: \'AWS::Lambda::Function\'\\n Properties:\\n FunctionName: MyLambdaFunction\\n Handler: index.handler\\n Role: arn:aws:iam::123456789012:role/execution_role\\n Code:\\n S3Bucket: my-lambda-functions-bucket\\n S3Key: path/to/my-deployment-package.zip\\n Runtime: python3.8\\n Timeout: 300\\n MemorySize: 128","timestamp":"1722051000.0","poster":"albert_kuo","comment_id":"1255986"},{"comment_id":"1217655","upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716566040.0"},{"poster":"KarBiswa","timestamp":"1709530020.0","comment_id":"1165324","upvote_count":"4","content":"Selected Answer: D\\nhttps://aws.amazon.com/blogs/infrastructure-and-automation/deploying-aws-lambda-functions-using-aws-cloudformation-the-portable-way/"}],"answer_description":"","extracted_at":"2025-12-24T09:04:02.147Z","extraction_method":"api_direct_v1"},{"question_id":"JCQRLrrLR4HbBTpunkkK","question_number":250,"page":50,"question_text":"A developer is building a microservices-based application by using Python on AWS and several AWS services. The developer must use AWS X-Ray. The developer views the service map by using the console to view the service dependencies. During testing, the developer notices that some services are missing from the service map.\\n\\nWhat can the developer do to ensure that all services appear in the X-Ray service map?","choices":{"C":"Enable X-Ray data aggregation in Amazon CloudWatch Logs for all the services that the application uses.","D":"Increase the X-Ray service map timeout value in the X-Ray console.","A":"Modify the X-Ray Python agent configuration in each service to increase the sampling rate.","B":"Instrument the application by using the X-Ray SDK for Python. Install the X-Ray SDK for all the services that the application uses."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133633-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 18:14:00","unix_timestamp":1707758040,"discussion_count":4,"discussion":[{"poster":"Americo32","upvote_count":"7","timestamp":"1707758040.0","comment_id":"1148427","content":"Op\xe7\xe3o B"},{"timestamp":"1708256100.0","upvote_count":"7","poster":"tgv","content":"Selected Answer: B\\nInstrument the application by using the X-Ray SDK for Python","comment_id":"1153225"},{"timestamp":"1721248980.0","content":"B ----\x3e>> To ensure that all services appear in the AWS X-Ray service map, it\'s essential that each component of the application is properly instrumented to send data to X-Ray. The X-Ray SDK must be used within the application to capture and send the necessary telemetry data to X-Ray.","comment_id":"1249979","upvote_count":"3","poster":"tomchandler077"},{"content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716574140.0","upvote_count":"1","poster":"65703c1","comment_id":"1217705"}],"answer_description":"","extracted_at":"2025-12-24T09:04:02.147Z","extraction_method":"api_direct_v1"},{"question_id":"UhwUlvCZK6rllf76MdBl","question_number":251,"page":51,"question_text":"A developer is building a containerized application on AWS. The application communicates with a third-party service by using API keys. The developer needs a secure way to store the API keys and pass the API keys to the containerized application.\\n\\nWhich solutions will meet these requirements? (Choose two.)","choices":{"E":"Store the API keys as a SecretString parameter in AWS Secrets Manager. Grant the application access to retrieve the value from Secrets Manager.","C":"Add a new AWS CloudFormation parameter to the CloudFormation template. Pass the API keys to the application by using the container definition environment variables.","D":"Embed the API keys in the application. Build the container image on-premises. Upload the container image to Amazon Elastic Container Registry (Amazon ECR).","A":"Store the API keys as a SecureString parameter in AWS Systems Manager Parameter Store. Grant the application access to retrieve the value from Parameter Store.","B":"Store the API keys in AWS CloudFormation templates by using base64 encoding. Pass the API keys to the application through container definition environment variables."},"correct_answer":"AE","answer_ET":"AE","answers_community":["AE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133634-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 18:16:00","unix_timestamp":1707758160,"discussion_count":5,"discussion":[{"comment_id":"1151829","content":"A and E would be correct in this case.","poster":"tgv","timestamp":"1723790280.0","upvote_count":"5"},{"content":"Selected Answer: AE\\nAE is the correct answer.","timestamp":"1732484760.0","upvote_count":"1","comment_id":"1217775","poster":"65703c1"},{"upvote_count":"2","content":"Selected Answer: AE\\nhttps://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/security-secrets-management.html#:~:text=Use%20AWS%20Secrets%20Manager%20or%20Amazon%20EC2%20Systems%20Manager%20Parameter%20Store%20for%20storing%20secret%20materials","timestamp":"1726139040.0","poster":"KarBiswa","comment_id":"1171706"},{"poster":"monishvster","content":"Selected Answer: AE\\nI have used Secrets Manager to store API Key","timestamp":"1724884800.0","comment_id":"1162092","upvote_count":"4"},{"comment_id":"1156196","content":"Selected Answer: AE\\nC is not right.","poster":"CrescentShared","timestamp":"1724302860.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:04:13.191Z","extraction_method":"api_direct_v1"},{"question_id":"fuLCmFfKMu2k5Bq1Vize","question_number":252,"page":51,"question_text":"A company runs an application on AWS. The application stores data in an Amazon DynamoDB table. Some queries are taking a long time to run. These slow queries involve an attribute that is not the table\'s partition key or sort key.\\n\\nThe amount of data that the application stores in the DynamoDB table is expected to increase significantly. A developer must increase the performance of the queries.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Perform a parallel scan operation by issuing individual scan requests. In the parameters, specify the segment for the scan requests and the total number of segments for the parallel scan.","D":"Turn on read capacity auto scaling for the DynamoDB table. Increase the maximum read capacity units (RCUs).","B":"Create a global secondary index (GSI). Set query attribute to be the partition key of the index.","A":"Increase the page size for each request by setting the Limit parameter to be higher than the default value. Configure the application to retry any request that exceeds the provisioned throughput."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134141-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:37:00","unix_timestamp":1708256220,"discussion_count":6,"discussion":[{"timestamp":"1708256220.0","content":"Selected Answer: B\\nCreating a GSI would be more cost efficient than increasing the RCU in this case.","comment_id":"1153229","upvote_count":"10","poster":"tgv"},{"upvote_count":"1","poster":"albert_kuo","timestamp":"1727928540.0","comment_id":"1292626","content":"Selected Answer: B\\nan attribute that is not the table\'s partition key or sort key => create GSI to solve this problem"},{"content":"To improve the performance of queries that involve an attribute that is neither the table\'s partition key nor sort key, and anticipating an increase in data volume, the most effective solution is to utilize a global secondary index (GSI). This allows for efficient querying based on different attributes that are critical for performance but not originally designed as keys in the main table structure.","timestamp":"1721249340.0","comment_id":"1249984","upvote_count":"3","poster":"tomchandler077"},{"poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1217777","timestamp":"1716580140.0","upvote_count":"1"},{"upvote_count":"2","poster":"be1dca8","content":"B Parallel scan operations can be useful for scanning large tables, but they may not necessarily improve performance for specific queries involving non-key attributes.","comment_id":"1193876","timestamp":"1712846880.0"},{"content":"Selected Answer: B\\nGSI :)","comment_id":"1164706","poster":"nder","timestamp":"1709462340.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:04:13.191Z","extraction_method":"api_direct_v1"},{"question_id":"1tFQjXR7nT4M8FiVi3LO","question_number":253,"page":51,"question_text":"A company runs a payment application on Amazon EC2 instances behind an Application Load Balance. The EC2 instances run in an Auto Scaling group across multiple Availability Zones. The application needs to retrieve application secrets during the application startup and export the secrets as environment variables. These secrets must be encrypted at rest and need to be rotated every month.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"C":"Save the secrets as base64 encoded environment variables in the application properties. Retrieve the secrets during the application startup. Reference the secrets in the application code. Write a script to rotate the secrets saved as environment variables.","D":"Store the secrets in AWS Secrets Manager. Provision a new customer master key. Use the key to encrypt the secrets. Enable automatic rotation. Configure an Amazon EC2 user data script to programmatically retrieve the secrets during the startup and export as environment variables.","A":"Save the secrets in a text file and store the text file in Amazon S3. Provision a customer managed key. Use the key for secret encryption in Amazon S3. Read the contents of the text file and read the export as environment variables. Configure S3 Object Lambda to rotate the text file every month.","B":"Save the secrets as strings in AWS Systems Manager Parameter Store and use the default AWS Key Management Service (AWS KMS) key. Configure an Amazon EC2 user data script to retrieve the secrets during the startup and export as environment variables. Configure an AWS Lambda function to rotate the secrets in Parameter Store every month."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/133636-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-12 18:27:00","unix_timestamp":1707758820,"discussion_count":6,"discussion":[{"poster":"tgv","content":"rotation --\x3e AWS Secrets Manager","upvote_count":"6","comment_id":"1151835","timestamp":"1708072980.0"},{"timestamp":"1708585500.0","comment_id":"1156197","poster":"CrescentShared","content":"Selected Answer: D\\nD is right","upvote_count":"6"},{"comment_id":"1306771","poster":"Saudis","timestamp":"1730695380.0","content":"Selected Answer: D\\nrotated is key word :)","upvote_count":"1"},{"upvote_count":"1","comment_id":"1292627","content":"Selected Answer: D\\n#!/bin/bash\\nsecret_value=$(aws secretsmanager get-secret-value --secret-id your-secret-id --query SecretString --output text)\\nexport SECRET_ENV_VAR=$secret_value","poster":"albert_kuo","timestamp":"1727928660.0"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","comment_id":"1217789","poster":"65703c1","timestamp":"1716580740.0"},{"timestamp":"1711831680.0","comment_id":"1186369","poster":"seetpt","content":"Selected Answer: D\\nD is right","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:04:13.191Z","extraction_method":"api_direct_v1"},{"question_id":"WRJWtz6MOZJosxuqKBwY","question_number":254,"page":51,"question_text":"A company is using Amazon API Gateway to invoke a new AWS Lambda function. The company has Lambda function versions in its PROD and DEV environments. In each environment, there is a Lambda function alias pointing to the corresponding Lambda function version. API Gateway has one stage that is configured to point at the PROD alias.\\n\\nThe company wants to configure API Gateway to enable the PROD and DEV Lambda function versions to be simultaneously and distinctly available.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Use an environment variable for the Lambda function alias in API Gateway. Republish PROD and create a new stage for development. Create API gateway environment variables for PROD and DEV stages. Point each stage variable to the PROD Lambda function alias to the DEV Lambda function alias.","A":"Enable a Lambda authorizer for the Lambda function alias in API Gateway. Republish PROD and create a new stage for DEV. Create API Gateway stage variables for the PROD and DEV stages. Point each stage variable to the PROD Lambda authorizer to the DEV Lambda authorizer.","D":"Use an API Gateway stage variable to configure the Lambda function alias. Republish PROD and create a new stage for development. Create API Gateway stage variables for PROD and DEV stages. Point each stage variable to the PROD Lambda function alias and to the DEV Lambda function alias.","B":"Set up a gateway response in API Gateway for the Lambda function alias. Republish PROD and create a new stage for DEV. Create gateway responses in API Gateway for PROD and DEV Lambda aliases."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134142-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-18 12:41:00","unix_timestamp":1708256460,"discussion_count":4,"discussion":[{"timestamp":"1723974060.0","upvote_count":"11","content":"Selected Answer: D\\nUse an API Gateway stage variable to configure the Lambda function alias.","poster":"tgv","comment_id":"1153231"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","poster":"65703c1","comment_id":"1217786","timestamp":"1732485480.0"},{"content":"Selected Answer: D\\nhttps://datanextsolutions.com/blog/managing-in-production-aws-lambda-functions-with-api-gateway/","poster":"KarBiswa","upvote_count":"3","timestamp":"1726744920.0","comment_id":"1177348"},{"upvote_count":"4","content":"Selected Answer: D\\nstage variable in API Gateway","poster":"monishvster","comment_id":"1162094","timestamp":"1724884920.0"}],"answer_description":"","extracted_at":"2025-12-24T09:04:13.191Z","extraction_method":"api_direct_v1"},{"question_id":"s377UatdQJwzAcYrNdZL","question_number":255,"page":51,"question_text":"A developer is working on an ecommerce platform that communicates with several third-party payment processing APIs. The third-party payment services do not provide a test environment.\\n\\nThe developer needs to validate the ecommerce platform\'s integration with the third-party payment processing APIs. The developer must test the API integration code without invoking the third-party payment processing APIs.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create an AWS Lambda function for each third-party API. Embed responses captured from the real third-party API. Configure Amazon Route 53 Resolver with an inbound endpoint for each Lambda function\'s Amazon Resource Name (ARN).","D":"Set up an Amazon API Gateway REST API for each third-party API. Specify an integration request type of Mock. Configure integration responses by using sample responses captured from the real third-party API.","B":"Set up an AWS AppSync GraphQL API with a data source configured for each third-party API. Specify an integration type of Mock. Configure integration responses by using sample responses captured from the real third-party API.","A":"Set up an Amazon API Gateway REST API with a gateway response configured for status code 200. Add response templates that contain sample responses captured from the real third-party API."},"correct_answer":"D","answer_ET":"D","answers_community":["D (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/134345-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-02-22 08:08:00","unix_timestamp":1708585680,"discussion_count":7,"discussion":[{"timestamp":"1708585680.0","comment_id":"1156198","upvote_count":"6","poster":"CrescentShared","content":"Selected Answer: D\\nD is right"},{"timestamp":"1729586760.0","upvote_count":"1","poster":"MasoudK","comment_id":"1301496","content":"I will go with A. You can manage all mock responses within a single API Gateway, simplifying the setup and reducing costs."},{"comment_id":"1217782","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","timestamp":"1716580500.0"},{"comment_id":"1170462","content":"anyone know way the questions end by this question which is 328 and there is no rest of the 337 questions?","timestamp":"1710088680.0","poster":"Abdullah22","upvote_count":"1"},{"comment_id":"1170450","upvote_count":"2","content":"Selected Answer: D\\nA. Response Templates for Status Code 200: While API Gateway supports response templates, simply configuring a 200 status code doesn\'t simulate the specific responses expected from the third-party APIs. The developer needs to define more detailed response structures to effectively test the integration logic.","poster":"Abdullah22","timestamp":"1710088140.0"},{"comment_id":"1165594","timestamp":"1709558580.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html","upvote_count":"2","poster":"KarBiswa"},{"content":"Selected Answer: A\\nA. Configure una API REST de Amazon API Gateway con una respuesta de puerta de enlace configurada para el c\xf3digo de estado 200. Agregue plantillas de respuesta que contengan respuestas de muestra capturadas de la API real de terceros.\\n\\n\\nAl configurar una API REST de Amazon API Gateway con una respuesta de puerta de enlace configurada para el c\xf3digo de estado 200, el desarrollador puede simular las respuestas de las API de procesamiento de pagos de terceros sin invocar realmente las API reales. Al agregar plantillas de respuesta que contengan respuestas de muestra capturadas de la API real de terceros, el desarrollador puede validar la integraci\xf3n de la plataforma de comercio electr\xf3nico con las API de procesamiento de pagos de terceros sin tener que interactuar directamente con las API reales.","poster":"ANDRES715","timestamp":"1709255160.0","comment_id":"1163144","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:04:13.191Z","extraction_method":"api_direct_v1"},{"question_id":"aoBn6B0AFA4tLWZe5jOF","question_number":256,"page":52,"question_text":"A developer is storing many objects in a single Amazon S3 bucket. The developer needs to optimize the S3 bucket for high request rates.\\n\\nHow should the developer store the objects to meet this requirement?","choices":{"C":"Store the objects by using object key names distributed across multiple prefixes.","A":"Store the objects by using S3 Intelligent-Tiering.","B":"Store the objects at the root of the S3 bucket.","D":"Store each object with an object tag named \\"prefix\\" that contains a unique value."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136628-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 14:27:00","unix_timestamp":1710854820,"discussion_count":3,"discussion":[{"poster":"cachac","content":"Selected Answer: C\\nBy distributing object key names across multiple prefixes, you can ensure that the load is spread across many partitions.","timestamp":"1719832020.0","upvote_count":"3","comment_id":"1240119"},{"comment_id":"1217779","poster":"65703c1","timestamp":"1716580260.0","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1"},{"upvote_count":"3","timestamp":"1710854820.0","comment_id":"1177353","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html","poster":"KarBiswa"}],"answer_description":"","extracted_at":"2025-12-24T09:04:24.152Z","extraction_method":"api_direct_v1"},{"question_id":"Y6V34ejciqIxfolBrimA","question_number":257,"page":52,"question_text":"A developer is creating an application that includes an Amazon API Gateway REST API in the us-east-2 Region. The developer wants to use Amazon CloudFront and a custom domain name for the API. The developer has acquired an SSL/TLS certificate for the domain from a third-party provider.\\nHow should the developer configure the custom domain for the application?","choices":{"D":"Import the SSL/TLS certificate into AWS Certificate Manager (ACM) in the us-east-1 Region. Create a DNS CNAME record for the custom domain.","B":"Import the SSL/TLS certificate into CloudFront. Create a DNS CNAME record for the custom domain.","C":"Import the SSL/TLS certificate into AWS Certificate Manager (ACM) in the same Region as the API. Create a DNS CNAME record for the custom domain.","A":"Import the SSL/TLS certificate into AWS Certificate Manager (ACM) in the same Region as the API. Create a DNS A record for the custom domain."},"correct_answer":"D","answer_ET":"D","answers_community":["D (87%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103664-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 13:57:00","unix_timestamp":1679576220,"discussion_count":17,"discussion":[{"timestamp":"1696303140.0","comment_id":"859516","content":"Selected Answer: D\\nTo use a certificate in AWS Certificate Manager (ACM) to require HTTPS between viewers and CloudFront, make sure you request (or import) the certificate in the US East (N. Virginia) Region (us-east-1).\\n\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-requirements.html\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html","poster":"brandon87","upvote_count":"31"},{"comment_id":"955136","content":"Selected Answer: D\\nI have checked at various places\\nAnswer is D\\nReason: ACM just can only import certificate in us-east-1 and we need to associate the imported certificate with us-east-2\\nThe caused confusion regarding it is because of import and associate\\nCrux: we will import in us-east-1 but use in us-east-2","timestamp":"1705572900.0","poster":"ancomedian","upvote_count":"9"},{"timestamp":"1734886320.0","upvote_count":"1","comment_id":"1330470","poster":"sumanshu","content":"Selected Answer: D\\nACM certificates must reside in us-east-1 for CloudFront, not the same Region as the API (us-east-2 in this case)."},{"upvote_count":"1","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","comment_id":"1215054","timestamp":"1732209420.0"},{"poster":"fhuadeen","upvote_count":"1","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-requirements.html","comment_id":"1191565","timestamp":"1728388620.0"},{"timestamp":"1720828500.0","comment_id":"1121209","upvote_count":"1","poster":"AjeshA1990","content":"Import cert in the same region"},{"content":"D. Importe o certificado SSL/TLS para o AWS Certificate Manager (ACM) na regi\xe3o us-east-1. Crie um registro DNS CNAME para o dom\xednio personalizado.","timestamp":"1714102740.0","poster":"Jonalb","upvote_count":"1","comment_id":"1054262"},{"poster":"fossil123","timestamp":"1709163480.0","comment_id":"993535","content":"Selected Answer: D\\nAWS Region for AWS Certificate Manager\\nTo use a certificate in AWS Certificate Manager (ACM) to require HTTPS between viewers and CloudFront, make sure you request (or import) the certificate in the US East (N. Virginia) Region (us-east-1).","upvote_count":"2"},{"comment_id":"953774","content":"Selected Answer: D\\nD\\nIf you need to use CloudFront, then, you must import it into ue-east-1.\\nhttps://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html","timestamp":"1705463640.0","upvote_count":"3","poster":"acordovam"},{"content":"Selected Answer: D\\nA is not right because for cloudfront you create a CNMA not a DNS A https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html\\nC is not right because ACM cannot import certificates in us-east-2 https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-requirements.html\\nB is not right. The certificate is for an external CA but can be uploaded to ACM or you must request a public certificate from AWS certificate Manager https://repost.aws/knowledge-center/install-ssl-cloudfront but you cannot import the certificate into CloudFront","comment_id":"943176","upvote_count":"3","poster":"Pupina","timestamp":"1704414180.0"},{"poster":"rlnd2000","content":"Selected Answer: C\\nC\\nThe first statement of the question: A developer is creating an application that includes an Amazon API Gateway REST API in the us-east-2 Region. ... it is a Regional API, when using a Regional endpoint, the SSL/TLS certificate for the custom domain must be imported into AWS Certificate Manager (ACM) in the same Region as the API, only if we use g Edge-Optimized endpoint, the certificate must be in us-east-1.","comment_id":"925881","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1718594100.0","comment_id":"1098672","content":"Initially I also thought but it is a specific hard core requirement \\"To use an ACM certificate with CloudFront, make sure you request (or import) the certificate in the US East (N. Virginia) Region (us-east-1).\\"","poster":"KarBiswa"}],"timestamp":"1702812420.0"},{"upvote_count":"3","comment_id":"905391","poster":"peterpain","timestamp":"1700795700.0","content":"Selected Answer: D\\nThe ACM has to be implemented at US-East-1"},{"poster":"Bibay","content":"Selected Answer: C\\nTo use Amazon CloudFront and a custom domain name for an Amazon API Gateway REST API, the developer should import the SSL/TLS certificate into AWS Certificate Manager (ACM) in the same Region as the API, and create a DNS CNAME record for the custom domain. This is because AWS Certificate Manager can only issue SSL/TLS certificates in the same Region as the API, and a DNS CNAME record maps the custom domain to the CloudFront distribution.\\n\\nOption A is incorrect because a DNS A record is not sufficient to map the custom domain to the CloudFront distribution.\\n\\nOption B is incorrect because AWS Certificate Manager must issue the SSL/TLS certificate in the same Region as the API.\\n\\nOption D is incorrect because the SSL/TLS certificate must be issued in the same Region as the API, and a DNS CNAME record is required to map the custom domain to the CloudFront distribution.","comment_id":"897359","timestamp":"1699954440.0","upvote_count":"5"},{"poster":"KhyatiChhajed","timestamp":"1699346040.0","content":"Selected Answer: C\\nC. Import the SSL/TLS certificate into AWS Certificate Manager (ACM) in the same Region as the API. Create a DNS CNAME record for the custom domain.\\nExplanation:\\nAmazon CloudFront can use SSL/TLS certificates stored in AWS Certificate Manager (ACM) to provide secure HTTPS connections for custom domain names. In this scenario, the developer should import the SSL/TLS certificate acquired from a third-party provider into ACM in the same Region as the API (us-east-2 in this case). This allows the certificate to be used by CloudFront.","upvote_count":"1","comment_id":"891192"},{"upvote_count":"1","poster":"hanJR","timestamp":"1698377700.0","content":"It\'s D. It is trying to integrate with CloudFront, therefore it must upload certificates in us-east-1. If it was a regional API, then certificates must be uploaded in the same region of the API Gateway.","comment_id":"882192"},{"upvote_count":"1","timestamp":"1695480000.0","content":"Selected Answer: C\\nI was thinking this answer would be C","poster":"March2023","comment_id":"848454"},{"comment_id":"848220","content":"Selected Answer: D\\nThe correct answer is D.\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-requirements.html\\nhttps://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html","poster":"Untamables","timestamp":"1695466620.0","upvote_count":"8"}],"answer_description":"","extracted_at":"2025-12-24T09:04:24.152Z","extraction_method":"api_direct_v1"},{"question_id":"xiDV0wsF8vjTk7z0Pjms","question_number":258,"page":52,"question_text":"A company deploys a new application to AWS. The company is streaming application logs to Amazon CloudWatch Logs. The company\'s development team must receive notification by email when the word \\"ERROR\\" appears in any log lines. A developer sets up an Amazon Simple Notification Service (Amazon SNS) topic and subscribes the development team to the topic.\\n\\nWhat should the developer do next to meet the requirements?","choices":{"D":"Create a CloudWatch alarm that includes \\"ERROR\\" as a filter pattern, a log group dimension that defines the appropriate log group, and a destination that notifies the SNS topic.","C":"Select the appropriate log group. Create an SNS subscription filter with \\"ERROR\\" as the filter pattern. Select the SNS topic as the destination.","B":"In CloudWatch Logs Insights, select the appropriate log group. Create a metric query to search for the term \\"ERROR\\" in the logs. Create an alarm on this metric that notifies the SNS topic when the metric is 1 or higher.","A":"Select the appropriate log group. Create a CloudWatch metric filter with \\"ERROR\\" as the search term. Create an alarm on this metric that notifies the SNS topic when the metric is 1 or higher."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136632-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 14:32:00","unix_timestamp":1710855120,"discussion_count":4,"discussion":[{"timestamp":"1711449780.0","comment_id":"1183223","upvote_count":"6","content":"Selected Answer: A\\nJust clicked through the console to achieve this. \\nC. SNS subscription filtering is not supported on cloudwatch log groups.\\nB. Log insights lets me jump into the logs and not create a metric that can be pushed to SNS.\\nD. Cloudwatch alarm works off a predefined metric and not a pattern such as ERROR. We need to create the metric to create the alarm","poster":"DeaconStJohn"},{"upvote_count":"1","content":"Selected Answer: A\\naws logs put-metric-filter --log-group-name /aws/lambda/my-log-group \\\\\\n--filter-name ErrorFilter --filter-pattern \\"ERROR\\" \\\\\\n--metric-transformations metricName=ErrorCount,metricNamespace=MyAppNamespace,metricValue=1","poster":"albert_kuo","timestamp":"1727929200.0","comment_id":"1292628"},{"timestamp":"1716580380.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","poster":"65703c1","comment_id":"1217781"},{"upvote_count":"3","poster":"KarBiswa","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-monitoring-using-cloudwatch.html","timestamp":"1710855120.0","comment_id":"1177364"}],"answer_description":"","extracted_at":"2025-12-24T09:04:24.152Z","extraction_method":"api_direct_v1"},{"question_id":"JafcNBXlY9PdXeusaF6W","question_number":259,"page":52,"question_text":"A company uses Amazon Simple Queue Service (Amazon SQS) to decouple its microservices architecture. Some messages in an SQS queue contain sensitive information. A developer must implement a solution that encrypts all the data at rest.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Use AWS Certificate Manager (ACM) to generate an SSL/TLS certificate. Reference the certificate when messages are sent to the queue.","A":"Enable server-side encryption for the SQS queue by using an SQS managed encryption key (SSE-SQS).","D":"Set a message attribute in the SQS SendMessage request for messages that are sent to the queue. Set the Name to ENCRYPT. Set the Value to TRUE.","B":"Use the aws:SecureTransport condition in the queue policy to ensure that only HTTPS (TLS) is used for all requests to the SQS queue."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136633-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 14:37:00","unix_timestamp":1710855420,"discussion_count":4,"discussion":[{"poster":"preachr","upvote_count":"1","content":"Selected Answer: A\\nServer-side encryption (SSE) lets you transmit sensitive data in encrypted queues. SSE protects the contents of messages in queues using SQS-managed encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS).","comment_id":"1291522","timestamp":"1727691840.0"},{"content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","comment_id":"1217811","upvote_count":"3","timestamp":"1716583500.0"},{"upvote_count":"3","poster":"Dzok5050","content":"Selected Answer: A\\nIt\'s A it\'s a valid option to enable.\\nC, D is related to in transit","comment_id":"1215684","timestamp":"1716375960.0"},{"upvote_count":"4","comment_id":"1177367","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html","poster":"KarBiswa","timestamp":"1710855420.0"}],"answer_description":"","extracted_at":"2025-12-24T09:04:24.152Z","extraction_method":"api_direct_v1"},{"question_id":"BWpfSHX12cqe1j9MLpzW","question_number":260,"page":52,"question_text":"A company recently deployed a new serverless user portal. Users have reported that part of the portal is slow. The initial analysis found a single Amazon API Gateway endpoint that is responsible for the performance issues. The endpoint integrates with an AWS Lambda function. However, the Lambda function interacts with other APIs and AWS services.\\n\\nHow can a developer find the source of the increased response time by using operational best practices?","choices":{"B":"Instrument the Lambda function with the AWS X-Ray SDK. Add HTTP and HTTPS interceptors and SDK client handlers. Deploy the updated Lambda function. Turn on X-Ray tracing. After accumulating enough usage data, use the X-Ray service map to examine the average response times to determine the likely sources.","D":"Use Amazon CloudWatch Synthetics to create a new canary. Turn on AWS X-Ray tracing on the canary. Configure the canary to scan the user portal. After accumulating enough usage data, use the CloudWatch Synthetics canary dashboard to view the metrics from the canary.","A":"Update the Lambda function by adding logging statements with high-precision timestamps before and after each external request. Deploy the updated Lambda function. After accumulating enough usage data, examine the Amazon CloudWatch logs for the Lambda function to determine the likely sources for the increased response time.","C":"Review the Lambda function\'s Amazon CloudWatch metrics by using the metrics explorer. Apply anomaly detection to the Duration metric and the Throttles metric. Review the anomalies to determine the likely sources."},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","D (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136634-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 14:46:00","unix_timestamp":1710855960,"discussion_count":6,"discussion":[{"comment_id":"1306773","upvote_count":"2","timestamp":"1730696340.0","poster":"Saudis","content":"Selected Answer: B\\nincreased response => Tracing so B is the best choice"},{"timestamp":"1716583740.0","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"3","comment_id":"1217814"},{"timestamp":"1711450920.0","upvote_count":"3","poster":"DeaconStJohn","comment_id":"1183235","content":"Selected Answer: B\\nI have to agree B for this one and not because chatGPT told me so.\\n\\nupon research the canary seems to be the best option to capture issues before your customer sees them. As we already have reports of performance issues here I think the more long winded canary option is less feasible. \\nthe canary checks for broken links and compares screenshots to baseline images, it also checks for heart beats and whether API\'s read/write functionality is working.\\nI feel like Xray would be the better tool as the SDK with provide higher quality metrics and highlight latency, bottlenecks or other performance issues at any point in the service map. It is a single tool as opposed to option D\'s needing two tools and ultimately if option D requires X-ray to add granularity to canary results why not just start with X-ray."},{"poster":"Prastuti55","content":"Selected Answer: B\\nX-Ray for investigating performance issues.","comment_id":"1181784","timestamp":"1711294260.0","upvote_count":"1"},{"content":"Selected Answer: B\\ngpt & makes sense","timestamp":"1711293960.0","comment_id":"1181776","poster":"outrageous7","upvote_count":"1"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries.html","poster":"KarBiswa","comment_id":"1180472","timestamp":"1711160820.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:04:24.152Z","extraction_method":"api_direct_v1"},{"question_id":"osI7s7IjFsoBxonG7a6z","question_number":261,"page":53,"question_text":"A developer is building an event-driven application by using AWS Lambda and Amazon EventBridge. The Lambda function needs to push events to an EventBridge event bus. The developer uses an SDK to run the PutEvents EventBridge action and specifies no credentials in the code. After deploying the Lambda function, the developer notices that the function is failing and there are AccessDeniedException errors in the logs.\\n\\nHow should the developer resolve this issue?","choices":{"B":"Modify their AWS credentials to include permissions for the PutEvents EventBridge action.","C":"Modify the Lambda function execution role to include permissions for the PutEvents EventBridge action.","D":"Add a resource-based policy to the Lambda function to include permissions for the PutEvents EventBridge action.","A":"Configure a VPC peering connection between the Lambda function and EventBridge."},"correct_answer":"C","answer_ET":"C","answers_community":["C (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136958-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 03:34:00","unix_timestamp":1711161240,"discussion_count":6,"discussion":[{"upvote_count":"1","timestamp":"1735050720.0","poster":"examuserss","content":"Selected Answer: C\\nCorrect Answer:\\nC. Modify the Lambda function execution role to include permissions for the PutEvents EventBridge action.\\n\\nThe developer should update the Lambda function\'s execution role to include the necessary permissions for the PutEvents action on the EventBridge event bus. This will resolve the AccessDeniedException errors and allow the Lambda function to push events to EventBridge.","comment_id":"1331150"},{"timestamp":"1716584040.0","comment_id":"1217818","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1"},{"comment_id":"1193820","timestamp":"1712840880.0","content":"C\\nyou use IAM roles on the sender event bus to give the sender event bus permission to send events to the receiver event bus. You use Resource-based policies on the receiver event bus to give the receiver event bus permission to receive events from the sender event bus.\\n\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-bus-to-bus.html","poster":"be1dca8","comments":[{"comment_id":"1256016","upvote_count":"1","timestamp":"1722055740.0","content":"{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": \\"events:PutEvents\\",\\n \\"Resource\\": \\"*\\"\\n }\\n ]\\n}","poster":"albert_kuo"}],"upvote_count":"3"},{"content":"Selected Answer: C\\nAs lambda is initiating the action (push), permission must be attached the the execution role.","upvote_count":"2","poster":"DeaconStJohn","timestamp":"1711451100.0","comment_id":"1183237"},{"upvote_count":"2","timestamp":"1711294200.0","comment_id":"1181783","content":"Selected Answer: C\\nLambda Execution Role (IAM Role)\\n\u2022 Grants the Lambda function permissions to AWS services / resources","poster":"outrageous7"},{"comment_id":"1180473","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-bus-perms.html","upvote_count":"1","timestamp":"1711161240.0","poster":"KarBiswa"}],"answer_description":"","extracted_at":"2025-12-24T09:04:35.139Z","extraction_method":"api_direct_v1"},{"question_id":"CZfgzplgnQAm7FYZcrHM","question_number":262,"page":53,"question_text":"A company\'s application has an AWS Lambda function that processes messages from IoT devices. The company wants to monitor the Lambda function to ensure that the Lambda function is meeting its required service level agreement (SLA).\\n\\nA developer must implement a solution to determine the application\'s throughput in near real time. The throughput must be based on the number of messages that the Lambda function receives and processes in a given time period. The Lambda function performs initialization and post-processing steps that must not factor into the throughput measurement.\\n\\nWhat should the developer do to meet these requirements?","choices":{"C":"Modify the application to publish custom Amazon CloudWatch metrics when the Lambda function receives and processes each message. Use the metrics to calculate the throughput.","D":"Use the Lambda function\'s Invocations metric and Duration metric to calculate the throughput in Amazon CloudWatch.","B":"Modify the application to log the calculated throughput to Amazon CloudWatch Logs. Use Amazon EventBridge to invoke a separate Lambda function to process the logs on a schedule.","A":"Use the Lambda function\'s ConcurrentExecutions metric in Amazon CloudWatch to measure the throughput."},"correct_answer":"C","answer_ET":"C","answers_community":["C (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136640-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 15:05:00","unix_timestamp":1710857100,"discussion_count":7,"discussion":[{"upvote_count":"5","content":"Selected Answer: C\\nUse the metrics to calculate the throughput. This is because custom metrics can provide a more accurate measure of throughput, as they can be configured to only increment when a message is received and processed by the Lambda function. This would exclude the time spent on initialization and post-processing, which are not part of the throughput measurement.","comment_id":"1182260","poster":"Alagong","timestamp":"1711348860.0"},{"content":"Selected Answer: C\\nCorrect Answer:\\nC. Modify the application to publish custom Amazon CloudWatch metrics when the Lambda function receives and processes each message. Use the metrics to calculate the throughput.\\n\\nThis solution allows the developer to focus on the specific parts of the Lambda function that are responsible for processing messages, providing the most accurate and real-time measurement of throughput. By publishing custom metrics, the developer can ensure the throughput is tracked exactly as required, excluding any irrelevant steps.","poster":"examuserss","upvote_count":"1","timestamp":"1735050840.0","comment_id":"1331151"},{"comment_id":"1292634","poster":"albert_kuo","timestamp":"1727930220.0","content":"Selected Answer: C\\nimport boto3\\nimport time\\n\\ncloudwatch = boto3.client(\'cloudwatch\')\\n\\ndef lambda_handler(event, context):\\n # Process the IoT message\\n process_message(event)\\n \\n # Publish custom CloudWatch metric for throughput\\n cloudwatch.put_metric_data(\\n Namespace=\'IoTMessageProcessing\',\\n MetricData=[\\n {\\n \'MetricName\': \'MessagesProcessed\',\\n \'Timestamp\': time.time(),\\n \'Value\': 1,\\n \'Unit\': \'Count\'\\n },\\n ]\\n )","upvote_count":"1"},{"content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217820","upvote_count":"1","poster":"65703c1","timestamp":"1716584400.0"},{"poster":"trungtd","timestamp":"1712291040.0","content":"Selected Answer: C\\nBecause this requirement provides its own definition of how throughput is measured, you must use custom metrics.","upvote_count":"2","comment_id":"1189648"},{"upvote_count":"2","comment_id":"1185651","poster":"seetpt","content":"Selected Answer: C\\nI think C","timestamp":"1711742640.0"},{"upvote_count":"2","poster":"KarBiswa","content":"Selected Answer: A\\nhttps://aws.amazon.com/blogs/compute/understanding-aws-lambda-scaling-and-throughput/","timestamp":"1710857100.0","comment_id":"1177391"}],"answer_description":"","extracted_at":"2025-12-24T09:04:35.139Z","extraction_method":"api_direct_v1"},{"question_id":"woSo1uwj6tDmjztzAp8A","question_number":263,"page":53,"question_text":"A developer is using an AWS CodePipeline pipeline to provide continuous integration and continuous delivery (CI/CD) support for a Java application. The developer needs to update the pipeline to support the introduction of a new application dependency .jar file. The pipeline must start a build when a new version of the .jar file becomes available.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create an Amazon S3 bucket to store the dependency .jar file. Publish the dependency .jar file to the S3 bucket. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.","B":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an ECR source action to start a CodePipeline pipeline build.","D":"Create an AWS CodeArtifact repository. Publish the dependency .jar file to the repository. Use an Amazon EventBridge rule to start a CodePipeline pipeline build.","C":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136644-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 15:21:00","unix_timestamp":1710858060,"discussion_count":5,"discussion":[{"timestamp":"1721523240.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/codeartifact/latest/ug/configure-service-events-codepipeline.html","poster":"Anandesh","upvote_count":"1","comment_id":"1252096"},{"content":"Selected Answer: D\\nD is correct\\nKeyword for using CodeArtifact is Dependency","upvote_count":"1","poster":"Alabi","timestamp":"1718731140.0","comment_id":"1232545"},{"content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716584520.0","comment_id":"1217822","poster":"65703c1","upvote_count":"1"},{"timestamp":"1712291340.0","content":"Selected Answer: D\\nAWS CodeArtifact is a managed artifact repository service that lets you securely store, publish, and share software packages.","comment_id":"1189651","upvote_count":"3","poster":"trungtd"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/codeartifact/latest/ug/configure-service-events-codepipeline.html#configure-service-events-codepipeline-create-rule","comment_id":"1177406","upvote_count":"3","timestamp":"1710858060.0","poster":"KarBiswa"}],"answer_description":"","extracted_at":"2025-12-24T09:04:35.139Z","extraction_method":"api_direct_v1"},{"question_id":"RNymbGZHtvxb9JASgT8V","question_number":264,"page":53,"question_text":"A company with multiple branch locations has an analytics and reporting application. Each branch office pushes a sales report to a shared Amazon S3 bucket at a predefined time each day. The company has developed an AWS Lambda function that analyzes the reports from all branch offices in a single pass. The Lambda function stores the results in a database.\\n\\nThe company needs to start the analysis once each day at a specific time.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"C":"Configure the Lambda function to run continuously and to begin analysis only at the predefined time each day.","D":"Create an Amazon EventBridge scheduled rule that invokes the Lambda function once each day at the predefined time.","B":"Create an AWS Step Functions state machine that invokes the Lambda function once each day at the predefined time.","A":"Configure an S3 event notification to invoke the Lambda function when a branch office uploads a sales report."},"correct_answer":"D","answer_ET":"D","answers_community":["D (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136959-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 03:40:00","unix_timestamp":1711161600,"discussion_count":6,"discussion":[{"upvote_count":"1","poster":"examuserss","comment_id":"1331157","timestamp":"1735051560.0","content":"Selected Answer: D\\nCorrect Answer:\\nD. Create an Amazon EventBridge scheduled rule that invokes the Lambda function once each day at the predefined time.\\n\\nThis solution allows you to trigger the Lambda function at the desired time each day without unnecessary compute usage and cost. EventBridge is ideal for time-based scheduling and provides a low-cost, highly efficient way to run tasks on a predefined schedule."},{"comment_id":"1217823","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"2","timestamp":"1716584640.0","poster":"65703c1"},{"comment_id":"1189655","timestamp":"1712291940.0","upvote_count":"3","poster":"trungtd","content":"Selected Answer: D\\nBest practice for cronjob in Lamda"},{"poster":"seetpt","upvote_count":"2","content":"Selected Answer: D\\nD is right","timestamp":"1711831860.0","comment_id":"1186372"},{"poster":"DeaconStJohn","comment_id":"1183242","content":"Selected Answer: D\\nA - This does not meet the criteria. it will trigger with every report upload which is multiple invocations. the requirement is a single invocation that analyses all reports at a predefined time. these invocations will be firing off all over the place as every report comes in.\\nB - Step functions is over the top for this use case.\\nC - lambda to run continuously...\\nD - This is a single invocation that triggers the lambda function at a predefined time using CRON. Eventbridge was developed for this use case.","timestamp":"1711451820.0","upvote_count":"4"},{"poster":"KarBiswa","comment_id":"1180477","comments":[{"timestamp":"1722056400.0","upvote_count":"1","comment_id":"1256032","content":"analyzes the reports from all branch offices in a single pass","poster":"albert_kuo"}],"upvote_count":"2","content":"Selected Answer: A\\nLeast cost involved and simple","timestamp":"1711161600.0"}],"answer_description":"","extracted_at":"2025-12-24T09:04:35.139Z","extraction_method":"api_direct_v1"},{"question_id":"fQdhxS8L288ilXAwzd7D","question_number":265,"page":53,"question_text":"A developer has an application that asynchronously invokes an AWS Lambda function. The developer wants to store messages that resulted in failed invocations of the Lambda function so that the application can retry the call later.\\n\\nWhat should the developer do to accomplish this goal with the LEAST operational overhead?","choices":{"D":"Send Amazon EventBridge events to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda function to pull messages from the SQS queue. Run the Lambda function again.","A":"Set up Amazon CloudWatch Logs log groups to filter and store the messages in an Amazon S3 bucket. Import the messages in Lambda. Run the Lambda function again.","C":"Implement a dead-letter queue for discarded messages. Set the dead-letter queue as an event source for the Lambda function.","B":"Configure Amazon EventBridge to send the messages to Amazon Simple Notification Service (Amazon SNS) to initiate the Lambda function again."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136961-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 03:47:00","unix_timestamp":1711162020,"discussion_count":4,"discussion":[{"timestamp":"1727342460.0","poster":"DeaconStJohn","content":"Selected Answer: C\\nAsync allows DLQ to be created from lambda function\\nSync requires DLQ to be created by SQS.","comment_id":"1183246","upvote_count":"5"},{"timestamp":"1732490400.0","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1217829","upvote_count":"1"},{"timestamp":"1727722320.0","comment_id":"1186374","poster":"seetpt","upvote_count":"2","content":"Selected Answer: C\\nC is correct"},{"upvote_count":"2","timestamp":"1727052420.0","comment_id":"1180484","poster":"KarBiswa","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-dlq"}],"answer_description":"","extracted_at":"2025-12-24T09:04:35.139Z","extraction_method":"api_direct_v1"},{"question_id":"kMpPZiCXVGUEeKvhCZps","question_number":266,"page":54,"question_text":"A company is using AWS CloudFormation templates to deploy AWS resources. The company needs to update one of its AWS CloudFormation stacks.\\n\\nWhat can the company do to find out how the changes will impact the resources that are running?","choices":{"C":"Investigate the Metadata section.","B":"Investigate the stack policies.","D":"Investigate the Resources section.","A":"Investigate the change sets."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136645-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-19 15:24:00","unix_timestamp":1710858240,"discussion_count":3,"discussion":[{"comment_id":"1388114","content":"Selected Answer: A\\nChange sets provide a summary of proposed changes to your stack that allows you to see how those changes might impact existing resources before implementing them.","timestamp":"1741823040.0","poster":"4f3e02e","upvote_count":"1"},{"comment_id":"1217830","poster":"65703c1","upvote_count":"3","timestamp":"1716585720.0","content":"Selected Answer: A\\nA is the correct answer."},{"timestamp":"1710858240.0","comment_id":"1177409","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","upvote_count":"4","poster":"KarBiswa"}],"answer_description":"","extracted_at":"2025-12-24T09:04:46.154Z","extraction_method":"api_direct_v1"},{"question_id":"G0vuug8rlGj16ZBjtPRP","question_number":267,"page":54,"question_text":"A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. Developers are working on an application that is running on Amazon EC2 instances in Account B. The application in Account B requires access to the PII table.\\n\\nAn administrator in Account A creates an IAM role named AccessPII that has permission to access the PII table. The administrator also creates a trust policy that specifies Account B as a principal that can assume the role.\\n\\nWhich combination of steps should the developers take in Account B to allow their application to access the PII table? (Choose two.)","choices":{"A":"Allow the EC2 IAM role the permission to assume the AccessPII role.","C":"Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table.","B":"Allow the EC2 IAM role the permission to access the PII table.","E":"Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table.","D":"Include the AssumeRole API operation in the application code logic to obtain temporary credentials to access the PII table."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (85%)","BD (15%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136962-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 03:57:00","unix_timestamp":1711162620,"discussion_count":5,"discussion":[{"poster":"trungtd","comment_id":"1189660","upvote_count":"5","content":"Selected Answer: AD\\nAssumeRole\\n\\n-- Returns a set of temporary security credentials that you can use to access AWS resources.\\n-- These temporary credentials consist of an access key ID, a secret access key, and a security token.\\n-- Typically, you use AssumeRole within your account or for cross-account access.\\n\\nhttps://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","timestamp":"1728103800.0"},{"comment_id":"1217871","upvote_count":"3","content":"Selected Answer: AD\\nAD is the correct answer.","poster":"65703c1","timestamp":"1732498200.0"},{"comment_id":"1189004","timestamp":"1728002700.0","upvote_count":"2","content":"Selected Answer: AD\\nhttps://www.examtopics.com/discussions/amazon/view/96243-exam-aws-certified-developer-associate-topic-1-question-434/","poster":"jerry118118"},{"upvote_count":"1","poster":"koltysh","content":"Selected Answer: AD\\na d answer","timestamp":"1727968200.0","comment_id":"1188730"},{"timestamp":"1727398500.0","poster":"komorebi","content":"Selected Answer: BD\\nThe correct answer to ChetGPT is B, D","upvote_count":"2","comment_id":"1183817"}],"answer_description":"","extracted_at":"2025-12-24T09:04:46.154Z","extraction_method":"api_direct_v1"},{"question_id":"HNQFcXvGG6KzsMEx61Qt","question_number":268,"page":54,"question_text":"A developer is creating a template that uses AWS CloudFormation to deploy an application. The application is serverless and uses Amazon API Gateway, Amazon DynamoDB, and AWS Lambda.\\nWhich AWS service or tool should the developer use to define serverless resources in YAML?","choices":{"A":"CloudFormation serverless intrinsic functions","B":"AWS Elastic Beanstalk","D":"AWS Cloud Development Kit (AWS CDK)","C":"AWS Serverless Application Model (AWS SAM)"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103517-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:29:00","unix_timestamp":1679434140,"discussion_count":7,"discussion":[{"poster":"Bibay","upvote_count":"21","comment_id":"897361","comments":[{"upvote_count":"2","comment_id":"971861","timestamp":"1707044220.0","content":"your explanation helps me a lot !","poster":"jipark"}],"timestamp":"1699954620.0","content":"The recommended AWS service for defining serverless resources in YAML is the AWS Serverless Application Model (AWS SAM).\\n\\nAWS SAM is an open-source framework that extends AWS CloudFormation to provide a simplified way to define the Amazon API Gateway APIs, AWS Lambda functions, and Amazon DynamoDB tables needed by your serverless application. You can define your serverless resources in a YAML template and then use the AWS SAM CLI to package and deploy your application.\\n\\nAWS CloudFormation serverless intrinsic functions can also be used to define serverless resources in YAML, but they have some limitations compared to AWS SAM. AWS Elastic Beanstalk is a platform as a service (PaaS) that is not serverless specific, while the AWS Cloud Development Kit (AWS CDK) is an alternative to YAML-based templates that uses familiar programming languages like TypeScript, Python, and Java to define AWS infrastructure."},{"content":"Selected Answer: C\\nC\\nhttps://aws.amazon.com/serverless/sam/","upvote_count":"6","poster":"Untamables","timestamp":"1695535920.0","comment_id":"849106"},{"upvote_count":"1","timestamp":"1734886440.0","comment_id":"1330474","poster":"sumanshu","content":"Selected Answer: C\\nAWS SAM is specifically designed for serverless applications."},{"poster":"trieudo","content":"Selected Answer: C\\n==> Discard A. CloudFormation serverless intrinsic functions: Does not exist; CloudFormation has no intrinsic functions specifically for serverless. \\n==> Discard B. AWS Elastic Beanstalk: Not serverless; used for managing EC2-based applications. \\n==> Discard D. AWS Cloud Development Kit (AWS CDK): Does not use YAML; CDK defines infrastructure using programming languages.\\n\\n\\nC. AWS Serverless Application Model (AWS SAM): Extends CloudFormation, specifically designed for defining and deploying serverless resources (API Gateway, DynamoDB, Lambda) in YAML with simplified syntax. It perfectly aligns with the requirements in the question: serverless resources, YAML, and CloudFormation","upvote_count":"1","timestamp":"1734149100.0","comment_id":"1326337"},{"content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1732209480.0","upvote_count":"1","comment_id":"1215055"},{"upvote_count":"1","content":"O AWS Serverless Application Model (AWS SAM) \xe9 uma extens\xe3o do AWS CloudFormation que facilita a defini\xe7\xe3o de aplica\xe7\xf5es sem servidor. AWS SAM fornece modelos mais simples para configurar recursos sem servidor como AWS Lambda, Amazon API Gateway e Amazon DynamoDB. Os modelos podem ser definidos em YAML ou JSON.\\nC","poster":"Jonalb","timestamp":"1714102980.0","comment_id":"1054263"},{"timestamp":"1695324540.0","poster":"svrnvtr","comment_id":"846372","upvote_count":"3","content":"Selected Answer: C\\nC is the answer"}],"answer_description":"","extracted_at":"2025-12-24T09:04:46.154Z","extraction_method":"api_direct_v1"},{"question_id":"xUuWnULZQQTVEKZHjvZx","question_number":269,"page":54,"question_text":"A gaming website gives users the ability to trade game items with each other on the platform. The platform requires both users\' records to be updated and persisted in one transaction. If any update fails, the transaction must roll back.\\n\\nWhich AWS solutions can provide the transactional capability that is required for this feature? (Choose two.)","choices":{"A":"Amazon DynamoDB with operations made with the ConsistentRead parameter set to true","D":"Amazon Aurora MySQL with operations made within a transaction block","C":"Amazon DynamoDB with reads and writes made by using Transact* operations","B":"Amazon ElastiCache for Memcached with operations made within a transaction block","E":"Amazon Athena with operations made within a transaction block"},"correct_answer":"CD","answer_ET":"CD","answers_community":["CD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136964-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:02:00","unix_timestamp":1711162920,"discussion_count":3,"discussion":[{"comment_id":"1217952","content":"Selected Answer: CD\\nCD is the correct answer.","timestamp":"1732511820.0","upvote_count":"2","poster":"65703c1"},{"timestamp":"1727631360.0","upvote_count":"2","poster":"seetpt","content":"Selected Answer: CD\\nCD is right","comment_id":"1185646"},{"poster":"KarBiswa","comment_id":"1180496","upvote_count":"3","content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","timestamp":"1727053320.0"}],"answer_description":"","extracted_at":"2025-12-24T09:04:46.154Z","extraction_method":"api_direct_v1"},{"question_id":"02LeMr3W8BDC3IfmmPEe","question_number":270,"page":54,"question_text":"A developer is deploying an application in the AWS Cloud by using AWS CloudFormation. The application will connect to an existing Amazon RDS database. The hostname of the RDS database is stored in AWS Systems Manager Parameter Store as a plaintext value. The developer needs to incorporate the database hostname into the CloudFormation template to initialize the application when the stack is created.\\n\\nHow should the developer reference the parameter that contains the database hostname?","choices":{"D":"Use the ssm-secure dynamic reference.","C":"Use the Fn::ImportValue intrinsic function.","B":"Use the Ref intrinsic function.","A":"Use the ssm dynamic reference."},"correct_answer":"A","answer_ET":"A","answers_community":["A (91%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136965-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:05:00","unix_timestamp":1711163100,"discussion_count":7,"discussion":[{"upvote_count":"6","poster":"DeaconStJohn","timestamp":"1711452840.0","comment_id":"1183252","content":"Selected Answer: A\\nAs it is the DB hostname and not sensitive credentials I think ssm dynamic is the correct answer. \\nOption D - is for secure string whereas this parameter is currently stored in plain text.\\nFor option C, I opted against this because for an import value, I believe there needs to be an export value from another template. The question didn\'t state that anything else was created via CF template.\\nOption B - I understand to be used to reference another resource block that is in the same YAML template."},{"comment_id":"1400882","poster":"teban0130","content":"Selected Answer: A\\nParameters:\\n Environment:\\n Type: AWS::SSM::Parameter::Value<String>\\n Default: env","upvote_count":"1","timestamp":"1742433720.0"},{"upvote_count":"1","content":"Selected Answer: A\\nTo reference a plaintext value stored in Parameter Store in your template, you use the ssm dynamic reference pattern. This pattern allows you to reference values from parameters of type String or StringList in Parameter Store.","timestamp":"1727787840.0","poster":"preachr","comment_id":"1291970"},{"upvote_count":"1","poster":"Anandesh","comment_id":"1252104","timestamp":"1721524200.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html"},{"timestamp":"1716607140.0","comment_id":"1217953","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer."},{"content":"A since the question stated that the value is just plain text, not a secureString type","comment_id":"1193739","upvote_count":"3","timestamp":"1712836260.0","poster":"be1dca8"},{"timestamp":"1711163100.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html#dynamic-references-ssm-secure-strings","upvote_count":"1","poster":"KarBiswa","comment_id":"1180499"}],"answer_description":"","extracted_at":"2025-12-24T09:04:46.154Z","extraction_method":"api_direct_v1"},{"question_id":"CtcaADP3ornP6crckFuH","question_number":271,"page":55,"question_text":"A company uses an AWS Lambda function to call a third-party service. The third-party service has a limit of requests each minute. If the number of requests exceeds the limit, the third-party service returns rate-limiting errors.\\n\\nA developer needs to configure the Lambda function to avoid receiving rate limiting errors from the third-party service.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Set the provisioned concurrency on the Lambda function to match the number of concurrent requests that the third-party service allows.","B":"Decrease the memory that is allocated to the Lambda function.","D":"Increase the timeout value that is specified on the Lambda function.","A":"Set the reserved concurrency on the Lambda function to match the number of concurrent requests that the third-party service allows."},"correct_answer":"A","answer_ET":"A","answers_community":["A (93%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136966-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:09:00","unix_timestamp":1711163340,"discussion_count":4,"discussion":[{"comment_id":"1183255","content":"Selected Answer: A\\nCorrect answer is A. This will limit the lambda function to a defined concurrency which can be set to match the third party vendor limits.\\nB - will lower the cpu of the function, not limit the invocations.\\nC - Provisioned concurrency is a minimum value to keep lambda function execution environments on warm standby for critical workloads.\\nD - Issue isn\'t with timeouts or lack of processing power","upvote_count":"8","timestamp":"1727343540.0","poster":"DeaconStJohn"},{"poster":"KarBiswa","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html","timestamp":"1727053740.0","comment_id":"1180502","upvote_count":"5"},{"comment_id":"1217954","poster":"65703c1","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732512000.0"},{"poster":"KarBiswa","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html","timestamp":"1727053800.0","comment_id":"1180504","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:04:57.153Z","extraction_method":"api_direct_v1"},{"question_id":"9ifQuUNuz7N3TnTpGKPU","question_number":272,"page":55,"question_text":"A developer is building a new containerized application by using AWS Copilot. The developer uses the AWS Copilot command line interface (CLI) to deploy the application during development. The developer committed the application code to a new AWS CodeCommit repository. The developer must create an automated deployment process before releasing the new application to production.\\n\\nWhat should the developer do to meet these requirements in the MOST operationally efficient way?","choices":{"A":"Create a buildspec file that invokes the AWS Copilot CLI commands to build and deploy the application. Use the AWS Copilot CLI to create an AWS CodePipeline that uses the CodeCommit repository in the source stage and AWS CodeBuild in the build stage.","C":"Use the AWS Copilot CLI to define the AWS Copilot pipeline and to deploy the AWS CodePipeline. Select CodeCommit as the source for the AWS CodePipeline.","D":"Define an AWS CloudFormation template for an AWS CodePipeline with CodeCommit as the source. Configure the template as an AWS Copilot CLI add-on. Use the AWS Copilot CLI to deploy the application.","B":"Use the AWS Serverless Application Model (AWS SAM) CLI to bootstrap and initialize an AWS CodePipeline configuration. Use the CodeCommit repository as the source. Invoke the AWS Copilot CLI to build and deploy the application."},"correct_answer":"C","answer_ET":"C","answers_community":["C (67%)","A (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136967-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:24:00","unix_timestamp":1711164240,"discussion_count":8,"discussion":[{"upvote_count":"1","poster":"examuserss","content":"Selected Answer: C\\nCorrect Answer:\\nC. Use the AWS Copilot CLI to define the AWS Copilot pipeline and to deploy the AWS CodePipeline. Select CodeCommit as the source for the AWS CodePipeline.\\n\\nThis option is the most operationally efficient solution, as it makes full use of AWS Copilot\'s built-in capabilities to define and deploy the automated pipeline with minimal effort.","comment_id":"1331173","timestamp":"1735055640.0"},{"timestamp":"1727809980.0","poster":"preachr","content":"Selected Answer: C\\nhttps://aws.github.io/copilot-cli/docs/concepts/pipelines/","upvote_count":"2","comment_id":"1292084"},{"content":"Selected Answer: C\\nBoth A and C work, the key word is efficiency. C is the most efficient way.","upvote_count":"1","poster":"wh1t4k3r","comment_id":"1275095","timestamp":"1725026880.0"},{"upvote_count":"2","comment_id":"1217958","poster":"65703c1","timestamp":"1716607500.0","content":"Selected Answer: A\\nA is the correct answer."},{"upvote_count":"1","timestamp":"1716600480.0","poster":"Lucky4Life","content":"Selected Answer: C\\nPer Chatgpt","comment_id":"1217926"},{"timestamp":"1713675960.0","content":"Selected Answer: C\\nC ,,,,,,,,,,,,,,,,,,,","poster":"a1971h","upvote_count":"1","comment_id":"1199476"},{"comment_id":"1184783","timestamp":"1711631940.0","upvote_count":"2","poster":"DeaconStJohn","content":"Selected Answer: C\\nhttps://ecsworkshop.com/microservices/frontend/#deploy-frontend-0:~:text=on%20the%20pipeline.-,Creating%20the%20pipeline,-Generally%2C%20when%20we\\n\\nThis workshop is linked from AWS docs @ https://docs.aws.amazon.com/AmazonECS/latest/developerguide/getting-started-aws-copilot-cli.html#:~:text=Step%206.%20Learn%20to%20create%20a%20CI/CD%20Pipeline\\n\\nCo-pilot CLI is a substitute for AWS console. As the question states the dev is using co-pilot I think this is the best answer, although option A is more suited to my experience."},{"upvote_count":"2","timestamp":"1711507860.0","comment_id":"1183815","content":"Selected Answer: A\\nThe correct answer to ChetGPT is A","poster":"komorebi"}],"answer_description":"","extracted_at":"2025-12-24T09:04:57.153Z","extraction_method":"api_direct_v1"},{"question_id":"oRdUhGT6HmauMnnS14ND","question_number":273,"page":55,"question_text":"A developer is creating a new application for a pet store. The application will manage customer rewards points. The developer will use Amazon DynamoDB to store the data for the application. The developer needs to optimize query performance and limit partition overload before actual performance analysis.\\n\\nWhich option should the developer use for a partition key to meet these requirements?","choices":{"C":"The date when the customer signed up for the rewards program","D":"The name of the customer\'s pet","A":"A randomly generated universally unique identifier (UUID)","B":"The customer\'s full name"},"correct_answer":"A","answer_ET":"A","answers_community":["A (88%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136968-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:26:00","unix_timestamp":1711164360,"discussion_count":4,"discussion":[{"poster":"65703c1","upvote_count":"2","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716607260.0","comment_id":"1217955"},{"poster":"trungtd","content":"Selected Answer: A\\nThink of it as CustomerID","comment_id":"1189680","timestamp":"1712298720.0","upvote_count":"3"},{"content":"Selected Answer: A\\nThis is the only feasible option for a partition key..\\n\\nB - Two John Smith\'s sign up for the programme\\nC - Both John Smith\'s signed up on the same day\\nD - Both John Smith\'s signed up on the same day with a poodle called Betsy May.\\n\\nCant rule it out.","timestamp":"1711454640.0","poster":"DeaconStJohn","upvote_count":"2","comment_id":"1183280"},{"comments":[{"comment_id":"1265436","poster":"tirthyakamaldasgupta","content":"Based on my understanding, using the start date as a Partition Key could result in partition overload if a large number of sign-ups occur on the same date. In contrast, choosing a randomly generated UUID as a Partition Key would prevent this issue, as each ID is unique, ensuring even distribution and eliminating the risk of creating a hot partition. Please correct me if my understanding is incorrect, as I am still learning.","timestamp":"1723592100.0","upvote_count":"1"}],"comment_id":"1180507","poster":"KarBiswa","timestamp":"1711164360.0","upvote_count":"1","content":"Selected Answer: C\\nThe start date for the rewards program"}],"answer_description":"","extracted_at":"2025-12-24T09:04:57.153Z","extraction_method":"api_direct_v1"},{"question_id":"wC3I3aeYqO1xNlPjhCiC","question_number":274,"page":55,"question_text":"A developer uses AWS IAM Identity Center (AWS Single Sign-On) to interact with the AWS CLI and AWS SDKs on a local workstation. API calls to AWS services were working when the SSO access was first configured. However, the developer is now receiving Access Denied errors. The developer has not changed any configuration files or scripts that were previously working on the workstation.\\n\\nWhat is the MOST likely cause of the developer\'s access issue?","choices":{"B":"The permission set that is assumed by IAM Identity Center does not have the necessary permissions to complete the API call.","D":"The developer is attempting to make API calls to the incorrect AWS account.","A":"The access permissions to the developer\'s AWS CLI binary file have changed.","C":"The credentials from the IAM Identity Center federated role have expired."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136969-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:29:00","unix_timestamp":1711164540,"discussion_count":3,"discussion":[{"poster":"cachac","timestamp":"1719785820.0","content":"Selected Answer: C\\nAWS SSO credentials are temporary and typically have an expiration time","comment_id":"1239880","upvote_count":"4"},{"content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716607380.0","comment_id":"1217957","upvote_count":"1","poster":"65703c1"},{"content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/security-creds.html","upvote_count":"3","poster":"KarBiswa","timestamp":"1711164540.0","comment_id":"1180510"}],"answer_description":"","extracted_at":"2025-12-24T09:04:57.153Z","extraction_method":"api_direct_v1"},{"question_id":"kr3GlQeO9jBbQeSvWuKQ","question_number":275,"page":55,"question_text":"A company is building a serverless application. The application uses an API key to authenticate with a third-party application. The company wants to store the external API key as a part of an AWS Lambda configuration. The company needs to have full control over the AWS Key Management Service (AWS KMS) keys that will encrypt the API key and should be visible only to authorized entities.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Store the API key in the code repository. Use an AWS managed key to encrypt the code repository.","A":"Store the API key in AWS Systems Manager Parameter Store as a string parameter. Use the default AWS KMS key that AWS provides to encrypt the API key.","D":"Store the API key as an Amazon DynamoDB table record. Use an AWS managed key to encrypt the API key.","B":"Store the API key in AWS Lambda environment variables. Create an AWS KMS customer managed key to encrypt the API key."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136970-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:37:00","unix_timestamp":1711165020,"discussion_count":5,"discussion":[{"upvote_count":"6","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html#configuration-envvars-encryption:~:text=If%20you%20prefer,on%20the%20function.","poster":"KarBiswa","comment_id":"1180514","timestamp":"1711165020.0"},{"poster":"albert_kuo","comment_id":"1292672","content":"Selected Answer: B\\nThe company needs to have full control over the AWS Key Management Service (AWS KMS) => customer managed key in AWS Key Management Service (KMS)","timestamp":"1727935440.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars-encryption.html","timestamp":"1727882940.0","comment_id":"1292475","poster":"preachr"},{"upvote_count":"1","comment_id":"1217960","poster":"65703c1","timestamp":"1716607620.0","content":"Selected Answer: B\\nB is the correct answer."},{"poster":"Lucky4Life","timestamp":"1716601380.0","content":"Selected Answer: B\\nBy creating a customer managed key in AWS Key Management Service (KMS), you gain full control over the encryption process.","upvote_count":"2","comment_id":"1217930"}],"answer_description":"","extracted_at":"2025-12-24T09:04:57.153Z","extraction_method":"api_direct_v1"},{"question_id":"Pv0JSWTfEplfsEo5NxBZ","question_number":276,"page":56,"question_text":"A developer is writing an application to analyze the traffic to a fleet of Amazon EC2 instances. The EC2 instances run behind a public Application Load Balancer (ALB). An HTTP server runs on each of the EC2 instances, logging all requests to a log file.\\n\\nThe developer wants to capture the client public IP addresses. The developer analyzes the log files and notices only the IP address of the ALB.\\n\\nWhat must the developer do to capture the client public IP addresses in the log file?","choices":{"C":"Install the AWS X-Ray daemon on each EC2 instance. Configure the daemon to write to the log file.","D":"Add an X-Forwarded-For header to the HTTP server log configuration file.","A":"Add a Host header to the HTTP server log configuration file.","B":"Install the Amazon CloudWatch Logs agent on each EC2 instance. Configure the agent to write to the log file."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136971-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:39:00","unix_timestamp":1711165140,"discussion_count":3,"discussion":[{"upvote_count":"5","timestamp":"1716119160.0","content":"Selected Answer: D\\nD. Add an X-Forwarded-For header to the HTTP server log configuration file.\\n\\nThe `X-Forwarded-For` header is used to capture the original client IP address when requests are routed through a load balancer like the ALB.","comment_id":"1213761","poster":"608064a"},{"timestamp":"1719786360.0","comment_id":"1239888","poster":"cachac","content":"Selected Answer: D\\nX-Forwarded-For: This header helps you accurately determine the public IP address of the client","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716607620.0","comment_id":"1217961","poster":"65703c1"}],"answer_description":"","extracted_at":"2025-12-24T09:05:08.137Z","extraction_method":"api_direct_v1"},{"question_id":"sYLALDnzqjMi4BtclidB","question_number":277,"page":56,"question_text":"A company is developing a serverless application by using AWS Lambda functions. One of the Lambda functions needs to access an Amazon RDS DB instance. The DB instance is in a private subnet inside a VPC.\\n\\nThe company creates a role that includes the necessary permissions to access the DB instance. The company then assigns the role to the Lambda function. A developer must take additional action to give the Lambda function access to the DB instance.\\n\\nWhat should the developer do to meet these requirements?","choices":{"D":"Configure the Lambda function to connect to the private subnets in the VPC. Add security group rules to allow traffic to the DB instance from the Lambda function.","A":"Assign a public IP address to the DB instance. Modify the security group of the DB instance to allow inbound traffic from the IP address of the Lambda function.","C":"Configure an Amazon CloudFront distribution to create a secure connection between the Lambda function and the DB instance.","B":"Set up an AWS Direct Connect connection between the Lambda function and the DB instance."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/141193-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-05-25 05:30:00","unix_timestamp":1716607800,"discussion_count":2,"discussion":[{"poster":"65703c1","timestamp":"1716607800.0","content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"5","comment_id":"1217964"},{"content":"Selected Answer: D\\nIf your Lambda wants to access resources available only within the VPC, you must attach the Lambda to that VPC (or to some other VPC peered with it).\\n\\nAs soon as you attach your Lambda to a VPC subnet, AWS Lambda will create an ENI inside the subnet, and that ENI will be assigned with a private IP address from the IP address range of that subnet. Thereafter through that ENI, your Lambda can access anything available within that VPC (or in its peered VPCs).","comment_id":"1292869","upvote_count":"1","timestamp":"1727971860.0","poster":"preachr"}],"answer_description":"","extracted_at":"2025-12-24T09:05:08.137Z","extraction_method":"api_direct_v1"},{"question_id":"hBZne3xaxsLQAuDQai7M","question_number":278,"page":56,"question_text":"A developer needs temporary access to resources in a second account.\\n\\nWhat is the MOST secure way to achieve this?","choices":{"B":"Create a dedicated IAM access key for the second account, and send it by mail.","C":"Create a cross-account access role, and use sts:AssumeRole API to get short-lived credentials.","D":"Establish trust, and add an SSH key for the second account to the IAM user.","A":"Use the Amazon Cognito user pools to get short-lived credentials for the second account."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/137947-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-04-05 08:46:00","unix_timestamp":1712299560,"discussion_count":3,"discussion":[{"poster":"65703c1","comment_id":"1217962","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1732512540.0","upvote_count":"1"},{"upvote_count":"4","timestamp":"1732024080.0","comment_id":"1213762","poster":"608064a","content":"Selected Answer: C\\nC. Create a cross-account access role, and use sts:AssumeRole API to get short-lived credentials.\\n\\nThis method provides temporary, limited access to the necessary resources in the second account without sharing long-term credentials, ensuring security and adherence to best practices."},{"poster":"trungtd","upvote_count":"4","content":"Selected Answer: C\\nHere\'s how it works:\\n1. Create an IAM Role in the Second Account: The administrator of the second account creates an IAM role and attaches policies that grant permissions to the resources that the developer needs to access. The trust policy of the role allows the first account (the developer\'s account) to assume this role.\\n\\n2. Assume the IAM Role: The developer in the first account can then call the sts:AssumeRole API operation, passing the ARN of the role to assume in the second account. If the request is successful, the response includes temporary security credentials that the developer can use to access resources in the second account.","comment_id":"1189686","timestamp":"1728110760.0"}],"answer_description":"","extracted_at":"2025-12-24T09:05:08.137Z","extraction_method":"api_direct_v1"},{"question_id":"seXrkg6aMru4ghSSNPGU","question_number":279,"page":56,"question_text":"A developer wants to insert a record into an Amazon DynamoDB table as soon as a new file is added to an Amazon S3 bucket.\\nWhich set of steps would be necessary to achieve this?","choices":{"A":"Create an event with Amazon EventBridge that will monitor the S3 bucket and then insert the records into DynamoDB.","C":"Create an AWS Lambda function that will poll the S3 bucket and then insert the records into DynamoDB.","B":"Configure an S3 event to invoke an AWS Lambda function that inserts records into DynamoDB.","D":"Create a cron job that will run at a scheduled time and insert the records into DynamoDB."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103519-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:30:00","unix_timestamp":1679434200,"discussion_count":8,"discussion":[{"timestamp":"1699954800.0","poster":"Bibay","upvote_count":"13","content":"The correct answer is B.\\n\\nTo insert a record into DynamoDB as soon as a new file is added to an S3 bucket, you can configure an S3 event notification to invoke an AWS Lambda function that inserts the records into DynamoDB. When a new file is added to the S3 bucket, the S3 event notification will trigger the Lambda function, which will insert the record into the DynamoDB table.\\n\\nOption A is incorrect because Amazon EventBridge is not necessary to achieve this. S3 event notifications can directly invoke a Lambda function to insert records into DynamoDB.\\n\\nOption C is incorrect because polling the S3 bucket periodically to check for new files is inefficient and not necessary with S3 event notifications.\\n\\nOption D is incorrect because running a cron job at a scheduled time is not real-time and would not insert the record into DynamoDB as soon as a new file is added to the S3 bucket.","comment_id":"897364"},{"timestamp":"1695685680.0","upvote_count":"8","poster":"Untamables","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html","comment_id":"850586"},{"comment_id":"1399610","upvote_count":"1","content":"Selected Answer: B\\n\ud83d\udd39 For simple automation \u2192 Use S3 Events.\\n\ud83d\udd39 For advanced event-driven applications \u2192 Use EventBridge.","timestamp":"1742208480.0","poster":"pratik7006"},{"upvote_count":"3","content":"Selected Answer: B\\nA) Eliminated - This approach introduces unnecessary complexity when S3 already supports native event notifications to Lambda.\\n\\nB) Correct - S3 has native support for event notifications to trigger Lambda functions\\n\\nC) Eliminated - Polling is inefficient and unnecessary\\n\\nD) Eliminated - This is a time-based solution, not event-driven, meaning there could be a delay between the file being added and the record being inserted.","comment_id":"1330478","timestamp":"1734886740.0","poster":"sumanshu"},{"timestamp":"1734149640.0","upvote_count":"1","comment_id":"1326339","content":"Selected Answer: B\\n==> Discard A: EventBridge is unnecessary because S3 already provides direct event notifications. \\n==> Discard C: Polling violates the \\"as soon as\\" requirement due to delay and inefficiency. \\n==> Discard D: Cron jobs do not respond immediately, violating the \\"as soon as\\" requirement.\\n\\nB is correct because S3 event notifications can trigger a Lambda function immediately when a new file is added, ensuring real-time insertion into DynamoDB.\\nB is better than A because S3 event notifications directly trigger a Lambda function, eliminating the need for additional configuration or services like EventBridge, making it simpler and more efficient.","poster":"trieudo"},{"timestamp":"1732209600.0","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215057","upvote_count":"1","poster":"65703c1"},{"comment_id":"1124683","upvote_count":"2","poster":"JohnPl","timestamp":"1721184720.0","content":"Selected Answer: B\\nA is also a solution for this which is better if we want loose coupling but will introduce a slight latency. The key word here is \\"as soon as\\" so the correct answer will be B."},{"timestamp":"1695324600.0","content":"It is B","comment_id":"846377","upvote_count":"4","poster":"svrnvtr"}],"answer_description":"","extracted_at":"2025-12-24T09:05:08.137Z","extraction_method":"api_direct_v1"},{"question_id":"CQxaEfflxcRtqgko0nIu","question_number":280,"page":56,"question_text":"A company wants to migrate applications from its on-premises servers to AWS. As a first step, the company is modifying and migrating a non-critical application to a single Amazon EC2 instance. The application will store information in an Amazon S3 bucket. The company needs to follow security best practices when deploying the application on AWS.\\n\\nWhich approach should the company take to allow the application to interact with Amazon S3?","choices":{"B":"Create an IAM user. Attach the AdministratorAccess policy. Copy the generated access key and secret key. Within the application code, use the access key and secret key along with the AWS SDK to communicate with Amazon S3.","D":"Create an IAM user. Attach a policy that provides the necessary access to Amazon S3. Copy the generated access key and secret key. Within the application code, use the access key and secret key along with the AWS SDK to communicate with Amazon S3.","A":"Create an IAM role that has administrative access to AWS. Attach the role to the EC2 instance.","C":"Create an IAM role that has the necessary access to Amazon S3. Attach the role to the EC2 instance."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/141194-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-05-25 05:31:00","unix_timestamp":1716607860,"discussion_count":3,"discussion":[{"timestamp":"1735057020.0","comment_id":"1331180","poster":"examuserss","upvote_count":"1","content":"Selected Answer: C\\nConclusion:\\nOption C is the best choice because it follows AWS security best practices, uses IAM roles (which automatically handle credentials securely), and adheres to the principle of least privilege."},{"content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1718699760.0","upvote_count":"2","poster":"chris_spencer","comment_id":"1232330"},{"content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716607860.0","upvote_count":"3","comment_id":"1217965"}],"answer_description":"","extracted_at":"2025-12-24T09:05:08.137Z","extraction_method":"api_direct_v1"},{"question_id":"GMdvuAzWArDbKRPZuPPR","question_number":281,"page":57,"question_text":"A company has an internal website that contains sensitive data. The company wants to make the website public. The company must ensure that only employees who authenticate through the company\'s OpenID Connect (OIDC) identity provider (IdP) can access the website. A developer needs to implement authentication without editing the website.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"D":"Configure a listener for the load balancer that listens on HTTP port 80. Add a default authenticate action providing the OIDC IdP configuration.","B":"Create a public Application Load Balancer.","A":"Create a public Network Load Balancer.","E":"Configure a listener for the load balancer that listens on HTTPS port 443. Add a default AWS Lambda action providing an Amazon Resource Name (ARN) to a Lambda authentication function.","C":"Configure a listener for the load balancer that listens on HTTPS port 443. Add a default authenticate action providing the OIDC IdP configuration."},"correct_answer":"BC","answer_ET":"BC","answers_community":["BC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136972-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:52:00","unix_timestamp":1711165920,"discussion_count":6,"discussion":[{"poster":"aws_god","content":"Selected Answer: BC\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html#configure-user-authentication","comment_id":"1307696","upvote_count":"2","timestamp":"1730877420.0"},{"timestamp":"1716654780.0","poster":"65703c1","content":"Selected Answer: BC\\nBC is the correct answer.","upvote_count":"4","comment_id":"1218450"},{"comment_id":"1212496","upvote_count":"2","timestamp":"1715876160.0","content":"BC. Since website contains sensitive data, I would use HTTPS port 433, instead of HTTP port 80.","poster":"jane_doe_1"},{"timestamp":"1712784240.0","comment_id":"1193315","poster":"be1dca8","upvote_count":"1","content":"BD, The company wants to make the application public so we using HTTP will allow it to be public."},{"poster":"seetpt","timestamp":"1711741620.0","content":"Selected Answer: BC\\nBC is correct","comment_id":"1185649","upvote_count":"3"},{"upvote_count":"3","comment_id":"1183814","timestamp":"1711507800.0","poster":"komorebi","content":"The correct answer to ChetGPT is B, C"}],"answer_description":"","extracted_at":"2025-12-24T09:05:19.158Z","extraction_method":"api_direct_v1"},{"question_id":"7LkGKZdOwaq2Z9Ca4uMR","question_number":282,"page":57,"question_text":"A developer is working on a web application that requires selective activation of specific features. The developer wants to keep the features hidden from end users until the features are ready for public access.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create a feature flag configuration profile in AWS AppSync. Store the feature flag values in the configuration profile. Activate and deactivate feature flags as needed.","B":"Store prerelease data in an Amazon DynamoDB table. Enable Amazon DynamoDB Streams in the table. Toggle between hidden and visible states by using DynamoDB Streams.","D":"Store prerelease data in AWS Amplify DataStore. Toggle between hidden and visible states by using Amplify DataStore cloud synchronization.","C":"Create a feature flag configuration profile in AWS AppConfig. Store the feature flag values in the configuration profile. Activate and deactivate feature flags as needed."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136973-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 04:57:00","unix_timestamp":1711166220,"discussion_count":3,"discussion":[{"poster":"KarBiswa","upvote_count":"6","comment_id":"1180526","timestamp":"1711166220.0","content":"Selected Answer: C\\nhttps://aws.amazon.com/blogs/mt/using-aws-appconfig-feature-flags/"},{"content":"Selected Answer: C\\ncreate a Configuration Profile, then edit feature flags\\n{\\n \\"featureA\\": true,\\n \\"featureB\\": false,\\n \\"featureC\\": true\\n}","upvote_count":"1","poster":"albert_kuo","timestamp":"1722061200.0","comment_id":"1256121"},{"timestamp":"1716661440.0","comment_id":"1218505","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","poster":"65703c1"}],"answer_description":"","extracted_at":"2025-12-24T09:05:19.158Z","extraction_method":"api_direct_v1"},{"question_id":"wY1jBiwMRfwCnVMbSW6R","question_number":283,"page":57,"question_text":"A developer at a company writes an AWS CloudFormation template. The template refers to subnets that were created by a separate AWS CloudFormation template that the company\'s network team wrote. When the developer attempts to launch the stack for the first time, the launch fails.\\n\\nWhich template coding mistakes could have caused this failure? (Choose two.)","choices":{"C":"The Mappings section of the developer\'s template does not refer to the subnets.","A":"The developer\'s template does not use the Ref intrinsic function to refer to the subnets.","B":"The developer\'s template does not use the ImportValue intrinsic function to refer to the subnets.","D":"The network team\'s template does not export the subnets in the Outputs section.","E":"The network team\'s template does not export the subnets in the Mappings section."},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/140014-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-05-05 08:01:00","unix_timestamp":1714888860,"discussion_count":5,"discussion":[{"timestamp":"1727973840.0","upvote_count":"2","comment_id":"1292878","content":"Selected Answer: BD\\nThe intrinsic function Fn::ImportValue returns the value of an output exported by another stack. You typically use this function to create cross-stack references.","poster":"preachr"},{"timestamp":"1724246940.0","content":"Selected Answer: BD\\nB. When referencing resources from another stack, the ImportValue function should be used. If the developer didn\'t use this, it would cause a failure when trying to reference the subnets.\\nD. For a resource to be imported by another stack, it needs to be exported in the Outputs section of the original stack. If the network team didn\'t export the subnets, they can\'t be imported by the developer\'s stack.","poster":"KennethNg923","comment_id":"1270146","upvote_count":"3"},{"timestamp":"1716662160.0","upvote_count":"1","poster":"65703c1","comment_id":"1218517","content":"Selected Answer: BD\\nBD is the correct answer."},{"content":"Selected Answer: BD\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference.html","poster":"Lucky4Life","timestamp":"1716603060.0","upvote_count":"3","comment_id":"1217937"},{"comment_id":"1206784","poster":"mehanizator","upvote_count":"2","content":"Selected Answer: BD\\nChatGPT: BD","timestamp":"1714888860.0"}],"answer_description":"","extracted_at":"2025-12-24T09:05:19.158Z","extraction_method":"api_direct_v1"},{"question_id":"vSZpLKWklkF2WnBb3JTa","question_number":284,"page":57,"question_text":"A developer is running an application on an Amazon EC2 instance. When the application tries to read an Amazon S3 bucket, the application fails. The developer notices that the associated IAM role is missing the S3 read permission. The developer needs to give the application the ability to read the S3 bucket.\\n\\nWhich solution will meet this requirement with the LEAST application disruption?","choices":{"A":"Add the permission to the role. Terminate the existing EC2 instance. Launch a new EC2 instance.","C":"Add the permission to the role. Hibernate and restart the existing EC2 instance.","B":"Add the permission to the role so that the change will take effect automatically.","D":"Add the permission to the S3 bucket. Restart the EC2 instance."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/140015-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-05-05 08:05:00","unix_timestamp":1714889100,"discussion_count":3,"discussion":[{"comment_id":"1270148","upvote_count":"5","timestamp":"1724247060.0","content":"Selected Answer: B\\nWhen you modify an IAM role\'s permissions, the changes take effect almost immediately (typically within a few minutes) without requiring any instance restart or replacement.","poster":"KennethNg923"},{"comment_id":"1218667","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716685680.0","upvote_count":"4","poster":"65703c1"},{"upvote_count":"3","timestamp":"1714889100.0","content":"Selected Answer: B\\nChatGPT: B","poster":"mehanizator","comment_id":"1206785"}],"answer_description":"","extracted_at":"2025-12-24T09:05:19.158Z","extraction_method":"api_direct_v1"},{"question_id":"af5AdqS0aB3h7iZS4Bv0","question_number":285,"page":57,"question_text":"A developer is writing a web application that is deployed on Amazon EC2 instances behind an internet-facing Application Load Balancer (ALB). The developer must add an Amazon CloudFront distribution in front of the ALB. The developer also must ensure that customer data from outside the VPC is encrypted in transit.\\n\\nWhich combination of CloudFront configuration settings should the developer use to meet these requirements? (Choose two.)","choices":{"A":"Restrict viewer access by using signed URLs.","D":"Enable automatic object compression.","B":"Set the Origin Protocol Policy setting to Match Viewer.","E":"Set the Viewer Protocol Policy setting to Redirect HTTP to HTTPS.","C":"Enable field-level encryption."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136974-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 05:02:00","unix_timestamp":1711166520,"discussion_count":5,"discussion":[{"poster":"KarBiswa","content":"Selected Answer: BE\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.html","comment_id":"1180529","upvote_count":"6","timestamp":"1711166520.0"},{"timestamp":"1730877840.0","content":"Selected Answer: BE\\nChoose Match Viewer only if you specify Redirect HTTP to HTTPS or HTTPS Only for Viewer Protocol Policy.\\nCloudFront caches the object only once even if viewers make requests using both HTTP and HTTPS protocols.\\n\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.html","poster":"aws_god","comment_id":"1307697","upvote_count":"1"},{"poster":"KennethNg923","upvote_count":"2","timestamp":"1724247360.0","content":"Selected Answer: BE\\nB. Set the Origin Protocol Policy setting to Match Viewer. then if it is HTTP, Viewer Protocol Policy setting can Redirect HTTP to HTTPS (Option E).","comment_id":"1270155"},{"timestamp":"1716685980.0","upvote_count":"1","content":"Selected Answer: BE\\nBE is the correct answer.","poster":"65703c1","comment_id":"1218669"},{"timestamp":"1712915520.0","comment_id":"1194282","poster":"chigs508","content":"https://www.examtopics.com/discussions/amazon/view/88225-exam-aws-certified-developer-associate-topic-1-question-171/","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:05:19.158Z","extraction_method":"api_direct_v1"},{"question_id":"cdm85v6WfWKMyzFR1RnN","question_number":286,"page":58,"question_text":"A developer is implementing an AWS Lambda function that will be invoked when an object is uploaded to Amazon S3. The developer wants to test the Lambda function in a local development machine before publishing the function to a production AWS account.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Create a JSON string for the put object S3 event. In the AWS Management Console, use the JSON string to create a test event for the local Lambda function. Perform the test.","C":"Use the sam local start-lambda CLI command to start Lambda. Use the sam local generate-event s3 put CLI command to create the Lambda test JSON file. Use the sam local invoke CLI command with the JSON file as the argument to invoke the Lambda function.","B":"Create a sample JSON text file for a put object S3 event. Invoke the Lambda function locally. Use the aws lambda invoke CLI command with the JSON file and Lambda function name as arguments.","A":"Upload an object to Amazon S3 by using the aws s3api put-object CLI command. Wait for the local Lambda invocation from the S3 event."},"correct_answer":"C","answer_ET":"C","answers_community":["C (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/139677-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-04-26 22:18:00","unix_timestamp":1714162680,"discussion_count":5,"discussion":[{"upvote_count":"1","comment_id":"1332001","timestamp":"1735231020.0","poster":"sqlquaker","content":"Selected Answer: D\\nSAM is not involved in this application setting. Solution should use \\"LEAST operational overhead\\". How to test Lambda functions in the console:\\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-functions.html"},{"comment_id":"1293099","upvote_count":"1","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/using-sam-cli-local-start-lambda.html","timestamp":"1728040140.0","poster":"preachr"},{"comment_id":"1256136","poster":"albert_kuo","timestamp":"1722062040.0","upvote_count":"2","content":"Selected Answer: C\\nsam local start-lambda\\nsam local generate-event s3 put > event.json\\nsam local invoke -e event.json <LambdaFunctionName>"},{"upvote_count":"1","poster":"65703c1","timestamp":"1716686580.0","comment_id":"1218673","content":"Selected Answer: C\\nC is the correct answer."},{"content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/96490-exam-aws-certified-developer-associate-topic-1-question-395/","poster":"koltysh","comment_id":"1202810","timestamp":"1714162680.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:05:30.133Z","extraction_method":"api_direct_v1"},{"question_id":"gjzxM0iclrIz3bCR7msz","question_number":287,"page":58,"question_text":"A developer is publishing critical log data to a log group in Amazon CloudWatch Logs. The log group was created 2 months ago. The developer must encrypt the log data by using an AWS Key Management Service (AWS KMS) key so that future data can be encrypted to comply with the company\'s security policy.\\n\\nWhich solution will meet this requirement with the LEAST effort?","choices":{"D":"Use the AWS CLI aws logs associate-kms-key command, and specify the key Amazon Resource Name (ARN).","B":"Use the AWS KMS console to associate the KMS key with the log group.","C":"Use the AWS CLI aws logs create-log-group command, and specify the key Amazon Resource Name (ARN).","A":"Use the AWS Encryption SDK for encryption and decryption of the data before writing to the log group."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/136975-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-03-23 05:06:00","unix_timestamp":1711166760,"discussion_count":4,"discussion":[{"content":"Selected Answer: D\\naws logs associate-kms-key --log-group-name <LogGroupName> --kms-key-id <KMSKeyARN>","comment_id":"1256139","poster":"albert_kuo","timestamp":"1722062160.0","upvote_count":"2"},{"upvote_count":"3","poster":"cachac","comment_id":"1239850","content":"Selected Answer: D\\nassociate-kms-key command.\\n\\nThis command specifically associates a KMS key with an existing log group, which is exactly what the developer needs to do.","timestamp":"1719783600.0"},{"poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716688080.0","upvote_count":"1","comment_id":"1218677"},{"poster":"KarBiswa","timestamp":"1711166760.0","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/cli/latest/reference/logs/associate-kms-key.html","comment_id":"1180530","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:05:30.133Z","extraction_method":"api_direct_v1"},{"question_id":"bO9eECpebUoHkdz6JFCR","question_number":288,"page":58,"question_text":"A developer is working on an app for a company that uses an Amazon DynamoDB table named Orders to store customer orders. The table uses OrderID as the partition key and there is no sort key. The table contains more than 100,000 records. The developer needs to add a functionality that will retrieve all Orders records that contain an OrderSource attribute with the MobileApp value.\\n\\nWhich solution will improve the user experience in the MOST efficient way?","choices":{"D":"Create a global secondary index (GSI) with OrderSource as the partition key. Perform a Query operation by using MobileApp as the key.","A":"Perform a Scan operation on the Orders table. Provide a QueryFilter condition to filter to only the items where the OrderSource attribute is equal to the MobileApp value.","B":"Create a local secondary index (LSI) with OrderSource as the partition key. Perform a Query operation by using MobileApp as the key.","C":"Create a global secondary index (GSI) with OrderSource as the sort key. Perform a Query operation by using MobileApp as the key."},"correct_answer":"D","answer_ET":"D","answers_community":["D (71%)","C (29%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143129-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-01 13:07:00","unix_timestamp":1719832020,"discussion_count":3,"discussion":[{"poster":"Alagong","comment_id":"1240506","upvote_count":"5","content":"Selected Answer: D\\nAnswer : D","timestamp":"1719889800.0"},{"comment_id":"1307700","poster":"aws_god","upvote_count":"2","content":"Selected Answer: C\\nYou should add the OrderSource as the sort key, only the OrderID is unique should be set as the partition key to give the best performance","timestamp":"1730878500.0"},{"comments":[{"content":"LSI can not be added to existing table. You have to create a new GSI and use OrderSource as partition key","comment_id":"1270157","upvote_count":"4","timestamp":"1724247540.0","poster":"KennethNg923"}],"upvote_count":"1","poster":"Skip","comment_id":"1240118","timestamp":"1719832020.0","content":"Going for B, feel free to comment. I think these comments sections help me a lot!"}],"answer_description":"","extracted_at":"2025-12-24T09:05:30.133Z","extraction_method":"api_direct_v1"},{"question_id":"3D7ULinVzXgQT8gsbDQX","question_number":289,"page":58,"question_text":"A company has an application that uses an AWS Lambda function to process data. A developer must implement encryption in transit for all sensitive configuration data, such as API keys, that is stored in the application. The developer creates an AWS Key Management Service (AWS KMS) customer managed key.\\n\\nWhat should the developer do next to meet the encryption requirement?","choices":{"B":"Create secrets in AWS Secrets Manager by using the customer managed KMS key. Create a new Lambda function and set up a Lambda layer. Configure the Lambda layer to retrieve the values from Secrets Manager.","A":"Create parameters of the String type in AWS Systems Manager Parameter Store. For each parameter, specify the KMS key ID to encrypt the parameter in transit. Reference the GetParameter API call in the Lambda environment variables.","C":"Create objects in Amazon S3 for each sensitive data field. Specify the customer managed KMS key to encrypt the object. Configure the Lambda function to retrieve the objects from Amazon S3 during data processing.","D":"Create encrypted Lambda environment variables. Specify the customer managed KMS key to encrypt the variables. Enable encryption helpers for encryption in transit. Grant permission to the Lambda function\'s execution role to access the KMS key."},"correct_answer":"D","answer_ET":"D","answers_community":["D (67%)","B (27%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143121-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-30 23:54:00","unix_timestamp":1719784440,"discussion_count":9,"discussion":[{"timestamp":"1719784440.0","comment_id":"1239860","upvote_count":"8","poster":"cachac","content":"Selected Answer: D\\nConsidering: \\"API keys, that is stored in the application\\". \\n\\nD is the most direct approach. Lambda supports encrypting environment variables with a KMS key, eliminating the need for additional services or layers."},{"content":"Selected Answer: B\\nD is incorrect - encrypting environment variables cannot be done in transit","timestamp":"1750234080.0","comment_id":"1578537","upvote_count":"1","poster":"08dc0cf"},{"poster":"AlmeroSenior","content":"Selected Answer: B\\nQuestion is regarding encryption in TRANSIT, not REST guys. So answer is B.\\n\\nLambda vars : These can be encrypted at rest using KMS, but are decrypted and stored in plaintext in memory during function execution.","upvote_count":"1","comment_id":"1578510","timestamp":"1750221900.0"},{"poster":"alemaricame","content":"Selected Answer: D\\nCreate encrypted Lambda environment variables. Specify the customer managed KMS key to encrypt the variables. Enable encryption helpers for encryption in transit. Grant permission to the Lambda function\'s execution role to access the KMS key.","timestamp":"1747951260.0","comment_id":"1571420","upvote_count":"1"},{"comment_id":"1362816","poster":"lak_83","upvote_count":"1","timestamp":"1740717000.0","content":"Selected Answer: B\\nAnswer is B and it does provide more flexibility than D"},{"comment_id":"1339290","content":"Selected Answer: A\\nI feel it should be A.\\nD can\'t be used as this approach does not use encryption in transit when retrieving sensitive data, as the data is embedded directly in the Lambda configuration.","poster":"bp07","upvote_count":"1","timestamp":"1736631300.0"},{"content":"Selected Answer: B\\nAWS Secret Manager and pulling the secrets from it using layers sounds reasonable to me. I have seen that implementation in real life.","upvote_count":"1","comment_id":"1312065","poster":"CloudChingon","timestamp":"1731595380.0"},{"timestamp":"1728060960.0","upvote_count":"1","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars-encryption.html","comment_id":"1293196","poster":"preachr"},{"poster":"tomchandler077","timestamp":"1721252820.0","content":"OPTION B ---CORRECT . To meet the requirement of encrypting sensitive configuration data in transit while using it within an AWS Lambda function, the developer should leverage AWS Secrets Manager. Secrets Manager is specifically designed for handling and securing sensitive information like API keys, database credentials, and similar data, making it suitable for this scenario.","comment_id":"1250005","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:05:30.133Z","extraction_method":"api_direct_v1"},{"question_id":"HDImy1aoG6mlaZoCZoxn","question_number":290,"page":58,"question_text":"A development team maintains a web application by using a single AWS CloudFormation template. The template defines web servers and an Amazon RDS database. The team uses the Cloud Formation template to deploy the Cloud Formation stack to different environments.\\nDuring a recent application deployment, a developer caused the primary development database to be dropped and recreated. The result of this incident was a loss of data. The team needs to avoid accidental database deletion in the future.\\nWhich solutions will meet these requirements? (Choose two.)","choices":{"C":"Modify the database to use a Multi-AZ deployment.","B":"Update the CloudFormation stack policy to prevent updates to the database.","A":"Add a CloudFormation Deletion Policy attribute with the Retain value to the database resource.","E":"Add a Cloud Formation DeletionPolicy attribute with the Retain value to the stack.","D":"Create a CloudFormation stack set for the web application and database deployments."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103521-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:35:00","unix_timestamp":1679434500,"discussion_count":15,"discussion":[{"upvote_count":"16","content":"A. Add a CloudFormation Deletion Policy attribute with the Retain value to the database resource: By adding a DeletionPolicy attribute with the Retain value to the database resource in the CloudFormation template, the database will not be deleted even if the CloudFormation stack is deleted. This helps prevent accidental database loss during stack deletion.\\n\\nB. Update the CloudFormation stack policy to prevent updates to the database: By updating the CloudFormation stack policy, the development team can restrict updates to the database resource. This prevents accidental modifications or recreations of the database during stack updates. The stack policy can define specific actions that are allowed or denied, providing an additional layer of protection against unintentional database changes.","comment_id":"944853","poster":"Mtho96","timestamp":"1704566700.0"},{"content":"Selected Answer: AB\\nAB\\nhttps://aws.amazon.com/ru/premiumsupport/knowledge-center/cloudformation-accidental-updates/","comment_id":"846384","poster":"svrnvtr","upvote_count":"7","timestamp":"1695324900.0"},{"upvote_count":"4","content":"Selected Answer: AB\\nA) Correct - When a DeletionPolicy: Retain is applied to a resource, CloudFormation retains (does not delete) the resource even if the stack is deleted or updated.\\n\\nB) Correct - Preventing updates ensures that no actions (such as deletion or replacement) can accidentally impact the database. This is an effective safeguard to avoid both deletion and unintended modifications.\\n\\nC) Eliminated - Multi-AZ deployment is for ensuring database availability and durability, not to prevent accidental deletion. Even with Multi-AZ, the database can still be deleted.\\n\\nD) Eliminated - Stack sets are for multi-account/multi-region deployments and do not inherently prevent resource deletion.\\n\\nE) Eliminated - The DeletionPolicy attribute applies only to individual resources, not the entire stack.","poster":"sumanshu","timestamp":"1734887580.0","comment_id":"1330485"},{"timestamp":"1732210860.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: AB\\nAB is the correct answer.","comment_id":"1215065"},{"content":"A and B, A is straightforward. For B, within stack policy you can deny update to logical resource for RDS DB. This will prevent any updates to stack resource which could also erase and create new RDS instance.","upvote_count":"1","timestamp":"1729816560.0","poster":"Vaibs099","comment_id":"1201669"},{"content":"Selected Answer: AB\\nhttps://aws.amazon.com/ru/premiumsupport/knowledge-center/cloudformation-accidental-updates/","comment_id":"1054684","poster":"Jonalb","timestamp":"1714143540.0","upvote_count":"1"},{"comment_id":"1002506","upvote_count":"3","content":"Selected Answer: AB\\nThis came up in the exam today, I chose A&B","poster":"magicjims","timestamp":"1709911200.0"},{"content":"D & A for me","comment_id":"1002473","timestamp":"1709908980.0","poster":"panoptica","upvote_count":"2"},{"content":"Selected Answer: AB\\nA and B","poster":"nguyenta","timestamp":"1705399260.0","comment_id":"953146","upvote_count":"2"},{"timestamp":"1702271160.0","poster":"marvel21","content":"A & B Correct Answer","upvote_count":"2","comment_id":"920380"},{"comment_id":"915831","content":"D because grandma said?","timestamp":"1701833880.0","upvote_count":"2","poster":"s50600822"},{"poster":"Japanjot","timestamp":"1699013820.0","upvote_count":"1","content":"A B CORRECT","comment_id":"888386"},{"comment_id":"884050","upvote_count":"1","content":"Selected Answer: AB\\nD is wrong, because while it still doesn\'t protect from the accidental deletion of the DB.","comments":[{"poster":"ihebchorfi","content":"After more thinking, combining A & D is the correct answer, so i would go with AD","timestamp":"1698563820.0","comment_id":"884051","upvote_count":"2"}],"poster":"ihebchorfi","timestamp":"1698563700.0"},{"timestamp":"1695685740.0","poster":"Untamables","content":"Selected Answer: AB\\nA and B\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html","comment_id":"850588","upvote_count":"5"},{"poster":"March2023","content":"Selected Answer: AB\\nI agree it is AB","upvote_count":"3","comment_id":"848524","timestamp":"1695484500.0"}],"answer_description":"","extracted_at":"2025-12-24T09:05:30.133Z","extraction_method":"api_direct_v1"},{"question_id":"S8vVznpQGSlRPxslmq2K","question_number":291,"page":59,"question_text":"A developer is building an ecommerce application. When there is a sale event, the application needs to concurrently call three third-party systems to record the sale. The developer wrote three AWS Lambda functions. There is one Lambda function for each third-party system, which contains complex integration logic.\\n\\nThese Lambda functions are all independent. The developer needs to design the application so each Lambda function will run regardless of others\' success or failure.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Publish the sale event from the application to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the three Lambda functions to poll the queue.","C":"Publish the sale event from the application to an Application Load Balancer (ALB). Add the three Lambda functions as ALB targets.","B":"Publish the sale event from the application to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the three Lambda functions to be triggered by the SNS topic.","D":"Publish the sale event from the application to an AWS Step Functions state machine. Move the logic from the three Lambda functions into the Step Functions state machine."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143366-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-05 16:46:00","unix_timestamp":1720190760,"discussion_count":3,"discussion":[{"comment_id":"1243785","poster":"tomchandler077","content":"B\\n\\nGiven the requirements to concurrently call three independent third-party systems when there is a sale event, and ensuring that each Lambda function runs regardless of the success or failure of the others, the best solution is to use Amazon Simple Notification Service (SNS).","timestamp":"1720348380.0","upvote_count":"5"},{"content":"Selected Answer: B\\n1. create sns topic\\naws sns create-topic --name SaleEvents\\n\\n2. create three lambda function to subscribe sns topic\\naws sns subscribe --topic-arn arn:aws:sns:region:account-id:SaleEvents --protocol lambda --notification-endpoint arn:aws:lambda:region:account-id:function:Function1\\naws sns subscribe --topic-arn arn:aws:sns:region:account-id:SaleEvents --protocol lambda --notification-endpoint arn:aws:lambda:region:account-id:function:Function2\\naws sns subscribe --topic-arn arn:aws:sns:region:account-id:SaleEvents --protocol lambda --notification-endpoint arn:aws:lambda:region:account-id:function:Function3","poster":"albert_kuo","comment_id":"1256145","upvote_count":"4","timestamp":"1722062880.0"},{"content":"Selected Answer: B\\nDefinitely B","poster":"siheom","comment_id":"1246409","timestamp":"1720747140.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:05:41.168Z","extraction_method":"api_direct_v1"},{"question_id":"fFISAwPlbL68g7mPGI5b","question_number":292,"page":59,"question_text":"A developer is writing an application, which stores data in an Amazon DynamoDB table. The developer wants to query the DynamoDB table by using the partition key and a different sort key value. The developer needs the latest data with all recent write operations.\\n\\nHow should the developer write the DynamoDB query?","choices":{"B":"Add a local secondary index (LSI) during table creation. Query the LSI by using strongly consistent reads.","D":"Add a global secondary index (GSI) during table creation. Query the GSI by using strongly consistent reads.","C":"Add a global secondary index (GSI) during table creation. Query the GSI by using eventually consistent reads.","A":"Add a local secondary index (LSI) during table creation. Query the LSI by using eventually consistent reads."},"correct_answer":"B","answer_ET":"B","answers_community":["B (78%)","D (22%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143107-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-30 18:29:00","unix_timestamp":1719764940,"discussion_count":4,"discussion":[{"content":"Selected Answer: B\\nGSI - diff part key and sort key | LSI - same part key and diff sort key\\nStrongly consistent - most recent data","comment_id":"1245346","upvote_count":"7","poster":"Anandesh","timestamp":"1720598400.0"},{"comment_id":"1243782","content":"The correct answer is: B. \\n\\nLocal Secondary Index (LSI):\\nAn LSI allows you to create an index with a different sort key for the same partition key as the base table. This lets you query the table using the same partition key but with a different sort key.\\nLSIs are created at the same time as the table and cannot be added to an existing table.\\n\\nStrongly consistent reads ensure that you always receive the most up-to-date data after all previous write operations are acknowledged.\\nThis is important when the developer needs to ensure they are getting the latest data, as stated in the question.","poster":"tomchandler077","timestamp":"1720348140.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1719890100.0","comments":[{"poster":"albert_kuo","timestamp":"1728011280.0","content":"you can only create LSI during table creation","comment_id":"1293008","upvote_count":"1"},{"timestamp":"1719890160.0","upvote_count":"2","content":"ANSWER IS B... NOT D","poster":"Alagong","comment_id":"1240509"}],"content":"Selected Answer: D\\nANSWER IS D","poster":"Alagong","comment_id":"1240508"},{"poster":"cachac","content":"Selected Answer: D\\nStrongly Consistent Reads","timestamp":"1719764940.0","upvote_count":"1","comment_id":"1239744"}],"answer_description":"","extracted_at":"2025-12-24T09:05:41.168Z","extraction_method":"api_direct_v1"},{"question_id":"lAnfp6jw7QFCeZmfId5P","question_number":293,"page":59,"question_text":"A developer manages an application that writes customer orders to an Amazon DynamoDB table. The orders use customer_id as the partition key, order_id as the sort key, and order_date as an attribute. A new access pattern requires accessing data by order_date and order_id. The developer needs to implement a new AWS Lambda function to support the new access pattern.\\n\\nHow should the developer support the new access pattern in the MOST operationally efficient way?","choices":{"C":"Add a new global secondary index (GSI) to the DynamoDB table that specifies order_date as the partition key and order_id as the sort key. Write the new Lambda function to query the new GSI index.","B":"Write the new Lambda function to scan the DynamoDB table. In the Lambda function, write a method to retrieve and combine results by order_date and order_id.","D":"Enable DynamoDB Streams on the table. Choose the new and old images information to write to the DynamoDB stream. Write the new Lambda function to query the DynamoDB stream","A":"Add a new local secondary index (LSI) to the DynamoDB table that specifies order_date as the partition key and order_id as the sort key. Write the new Lambda function to query the new LSI index."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143367-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-05 16:51:00","unix_timestamp":1720191060,"discussion_count":3,"discussion":[{"comment_id":"1243263","upvote_count":"5","content":"C\\nGlobal Secondary Index (GSI) allows you to specify a completely different partition key and potentially a different sort key from those on the main table. This flexibility is crucial when you need to support additional access patterns that aren\'t directly supported by the existing table\'s key structure. In this scenario, specifying order_date as the new partition key and order_id as the sort key in a GSI will enable efficient querying based on these attributes.\\n\\nLambda Function Querying GSI: Once the GSI is set up, the Lambda function can perform efficient query operations directly on this index to fetch records based on order_date and order_id, which is much more efficient than scanning the entire table.","timestamp":"1720253460.0","poster":"tomchandler077"},{"content":"Selected Answer: C\\nC is correct","timestamp":"1721281020.0","upvote_count":"3","poster":"dombox","comment_id":"1250149"},{"timestamp":"1720754340.0","poster":"rdiaz","comment_id":"1246445","upvote_count":"2","content":"Selected Answer: C\\nC is the correct answer"}],"answer_description":"","extracted_at":"2025-12-24T09:05:41.168Z","extraction_method":"api_direct_v1"},{"question_id":"tbO0HyIw4TcHWP467tYZ","question_number":294,"page":59,"question_text":"A developer is creating a web application for a school that stores data in Amazon DynamoDB. The ExamScores table has the following attributes: student_id, subject_name, and top_score.\\n\\nEach item in the ExamScores table is identified with student_id as the partition key and subject_name as the sort key. The web application needs to display the student _id for the top scores for each school subject. The developer needs to increase the speed of the queries to retrieve the student_id for the top scorer for each school subject.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create a local secondary index (LSI) with top_score as the partition key and student_id as the sort key.","C":"Create a global secondary index (GSI) with subject_name as the partition key and top_score as the sort key.","D":"Create a global secondary index (GSI) with subject_name as the partition key and student_id as the sort key.","A":"Create a local secondary index (LSI) with subject_name as the partition key and top_score as the sort key."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143747-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:20:00","unix_timestamp":1720754400,"discussion_count":2,"discussion":[{"upvote_count":"2","timestamp":"1735247820.0","poster":"examuserss","content":"Selected Answer: C\\nThe best solution is C. Create a global secondary index (GSI) with subject_name as the partition key and top_score as the sort key.\\n\\nHere\'s why: The goal is to efficiently retrieve the student ID of the top scorer for each subject. A GSI allows querying on a key combination different from the table\'s primary key. By using subject_name as the partition key, you can easily query all scores for a given subject. Then, sorting by top_score in descending order will allow you to quickly identify the top scorer using a single query. An LSI (options A and B) is tied to the table\'s primary key, making efficient retrieval of this data impossible. Option D would allow retrieval of student IDs given a subject, but not directly sorted by top score to find the top scorer for each subject efficiently. A GSI offers the flexibility to achieve the desired retrieval speeds without requiring multiple queries.","comment_id":"1332118"},{"poster":"rdiaz","upvote_count":"3","content":"Selected Answer: C\\nGSI - diff part key and sort key | LSI - same part key and diff sort key","timestamp":"1720754400.0","comment_id":"1246446"}],"answer_description":"","extracted_at":"2025-12-24T09:05:41.168Z","extraction_method":"api_direct_v1"},{"question_id":"oLe3OgppOrnXxW7eJRLQ","question_number":295,"page":59,"question_text":"A developer wrote an application that uses an AWS Lambda function to asynchronously generate short videos based on requests from customers. This video generation can take up to 10 minutes. After the video is generated, a URL to download the video is pushed to the customer\'s web browser. The customer should be able to access these videos for at least 3 hours after generation.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Store the video in Amazon S3. Generate a pre-signed URL for the video object and push the URL to the customer.","B":"Store the video in an Amazon Elastic File System (Amazon EFS) file system attached to the function. Generate a pre-signed URL for the video object and push the URL to the customer.","A":"Store the video in the /tmp folder within the Lambda execution environment. Push a Lambda function URL to the customer.","D":"Store the video in an Amazon CloudFront distribution. Generate a pre-signed URL for the video object and push the URL to the customer."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143369-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-05 16:53:00","unix_timestamp":1720191180,"discussion_count":1,"discussion":[{"timestamp":"1728068460.0","content":"Selected Answer: C\\nBy default, all Amazon S3 objects are private, only the object owner has permission to access them. However, the object owner may share objects with others by creating a presigned URL. A presigned URL uses security credentials to grant time-limited permission to download objects. The URL can be entered in a browser or used by a program to download the object. The credentials used by the presigned URL are those of the AWS user who generated the URL.","comment_id":"1293241","poster":"preachr","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:05:41.168Z","extraction_method":"api_direct_v1"},{"question_id":"KIAEBZrN91jCqlBgIrbw","question_number":296,"page":60,"question_text":"A developer is creating an AWS Lambda function that is invoked by messages to an Amazon Simple Notification Service (Amazon SNS) topic. The messages represent customer data updates from a customer relationship management (CRM) system\\n\\nThe developer wants the Lambda function to process only the messages that pertain to email address changes. Additional subscribers to the SNS topic will process any other messages.\\n\\nWhich solution will meet these requirements in the LEAST development effort?","choices":{"B":"Use an SNS filter policy on the Lambda function subscription to allow only messages that are related to email address changes to invoke the Lambda function.","A":"Use Lambda event filtering to allow only messages that are related to email address changes to invoke the Lambda function.","D":"Configure the Lambda code to check the received message. If the message is not related to an email address change, configure the Lambda function to publish the message back to the SNS topic for the other subscribers to process.","C":"Subscribe an Amazon Simple Queue Service (Amazon SQS) queue to the SNS topic. Configure the SQS queue with a filter policy to allow only messages that are related to email address changes.\\nConnect the SQS queue to the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143748-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:25:00","unix_timestamp":1720754700,"discussion_count":5,"discussion":[{"poster":"Saudis","content":"Selected Answer: B\\nANS IS B","timestamp":"1731003840.0","upvote_count":"1","comment_id":"1308502"},{"upvote_count":"1","poster":"preachr","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html\\n\\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-subscription-filter-policies.html","timestamp":"1728108180.0","comment_id":"1293353"},{"poster":"FYXL","upvote_count":"1","timestamp":"1726537200.0","comment_id":"1285001","content":"Selected Answer: B\\nFor A, Lambda event filtering does not support SNS"},{"poster":"KennethNg923","upvote_count":"2","comment_id":"1270168","timestamp":"1724248260.0","content":"Selected Answer: B\\nSNS filter policies are designed specifically for this purpose and require the least development effort. They allow you to filter messages at the SNS level before they reach the Lambda function."},{"upvote_count":"2","comment_id":"1246449","poster":"rdiaz","timestamp":"1720754700.0","content":"Selected Answer: B\\nSNS filter policies allow you to specify criteria that messages must meet to be delivered to a particular subscriber."}],"answer_description":"","extracted_at":"2025-12-24T09:05:52.160Z","extraction_method":"api_direct_v1"},{"question_id":"hkfZVKj9EtHSdzLgC67M","question_number":297,"page":60,"question_text":"A developer is designing a fault-tolerant environment where client sessions will be saved.\\n\\nHow can the developer ensure that no sessions are lost if an Amazon EC2 instance fails?","choices":{"A":"Use sticky sessions with an Elastic Load Balancer target group.","D":"Use Elastic Load Balancer connection draining to stop sending requests to failing instances.","B":"Use Amazon SQS to save session data.","C":"Use Amazon DynamoDB to perform scalable session handling."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143749-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:27:00","unix_timestamp":1720754820,"discussion_count":3,"discussion":[{"upvote_count":"3","timestamp":"1724248440.0","content":"Selected Answer: C\\nSticky sessions ensure that all requests from a particular client are sent to the same EC2 instance. While this can be useful for maintaining session state, it doesn\'t protect against data loss if an instance fails. If the instance holding a client\'s session fails, that session data would be lost.\\n\\nC is Correct: Use Amazon DynamoDB to perform scalable session handling.\\nIf an EC2 instance fails, the session data stored in DynamoDB remains intact and can be accessed by other instances.","comment_id":"1270169","poster":"KennethNg923"},{"upvote_count":"1","poster":"lpennington","content":"A : Sticky sessions \u2014 also known as session persistence \u2014 is the method that makes it possible for the load balancer to identify requests coming from the same client and to always send those requests to the same server.","timestamp":"1722716940.0","comment_id":"1260438"},{"content":"Selected Answer: C\\nC is the best of the options provided","timestamp":"1720754820.0","upvote_count":"2","poster":"rdiaz","comment_id":"1246450"}],"answer_description":"","extracted_at":"2025-12-24T09:05:52.160Z","extraction_method":"api_direct_v1"},{"question_id":"sPiHQYevorscDtbrfGQF","question_number":298,"page":60,"question_text":"A developer is creating AWS CloudFormation templates to manage an application\'s deployment in Amazon Elastic Container Service (Amazon ECS) through AWS CodeDeploy. The developer wants to automatically deploy new versions of the application to a percentage of users before the new version becomes available for all users.\\n\\nHow should the developer manage the deployment of the new version?","choices":{"A":"Modify the CloudFormation template to include a Transform section and the AWS::CodeDeploy::BlueGreen hook.","C":"Run CloudFormation stack updates on the application stack to deploy new application versions when they are available.","D":"Create a nested stack for the new version. Include a Transform section and the AWS::CodeDeploy::BlueGreen hook.","B":"Deploy the new version in a new CloudFormation stack. After testing is complete, update the application\'s DNS records for the new stack."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143750-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:29:00","unix_timestamp":1720754940,"discussion_count":2,"discussion":[{"timestamp":"1728113280.0","upvote_count":"1","comment_id":"1293380","content":"Selected Answer: A\\nTo perform CodeDeploy blue/green deployments on ECS using CloudFormation, you include the following information in your stack template: \\n- A Hooks section that describes a AWS::CodeDeploy::BlueGreen hook.\\n- A Transform section that specifies the AWS::CodeDeployBlueGreen transform.","poster":"preachr"},{"comment_id":"1246452","upvote_count":"3","content":"Selected Answer: A\\noption A \\nleverages the AWS::CodeDeploy::BlueGreen transform hook in the CloudFormation template. This hook allows the developer to specify blue/green deployment strategies directly in the CloudFormation template. It facilitates deploying new versions to a subset of users (canary or linear deployments) before fully rolling out to all users. This approach is designed for seamless and automated deployments using AWS CodeDeploy and ECS.","timestamp":"1720754940.0","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:05:52.160Z","extraction_method":"api_direct_v1"},{"question_id":"xFvVKOipGopXLOOwrUgb","question_number":299,"page":60,"question_text":"A developer has written a distributed application that uses microservices. The microservices are running on Amazon EC2 instances. Because of message volume, the developer is unable to match log output from each microservice to a specific transaction. The developer needs to analyze the message flow to debug the application.\\n\\nWhich combination of steps should the developer take to meet this requirement? (Choose two.)","choices":{"E":"Set up Amazon CloudWatch metric streams to collect streaming data from the microservices.","C":"Enable AWS X-Ray. Configure Amazon CloudWatch to push logs to X-Ray.","D":"Add the AWS X-Ray software development kit (SDK) to the microservices. Use X-Ray to trace requests that each microservice makes.","B":"Configure an interface VPC endpoint to allow traffic to reach the global AWS X-Ray daemon on TCP port 2000.","A":"Download the AWS X-Ray daemon. Install the daemon on an EC2 instance. Ensure that the EC2 instance allows UDP traffic on port 2000."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143751-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:31:00","unix_timestamp":1720755060,"discussion_count":3,"discussion":[{"timestamp":"1728115740.0","upvote_count":"1","content":"Selected Answer: AD\\nThe AWS X-Ray daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. The daemon works in conjunction with the AWS X-Ray SDKs and must be running so that data sent by the SDKs can reach the X-Ray service.","comment_id":"1293393","poster":"preachr"},{"upvote_count":"2","content":"Selected Answer: AD\\nA. The X-Ray daemon is necessary for collecting trace data from the EC2 instances running the microservices. It needs to be installed on each EC2 instance, and UDP port 2000 should be open for the daemon to communicate with the X-Ray service.\\n\\nD. Adding the X-Ray SDK to the microservices allows you to instrument your application code to send trace data to X-Ray. This is crucial for tracing requests across different microservices.","timestamp":"1724248740.0","comment_id":"1270173","poster":"KennethNg923"},{"content":"Selected Answer: AD\\nAD are the best of the options provided","comment_id":"1246453","timestamp":"1720755060.0","upvote_count":"1","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:05:52.160Z","extraction_method":"api_direct_v1"},{"question_id":"MZnz3EDSaEcMpjl8ydns","question_number":300,"page":60,"question_text":"A company is working on a new serverless application. A developer needs to find an automated way to deploy AWS Lambda functions and the dependent infrastructure with minimum coding effort. The application also needs to be reliable.\\n\\nWhich method will meet these requirements with the LEAST operational overhead?","choices":{"A":"Build the application by using shell scripts to create .zip files for each Lambda function. Manually upload the .zip files to the AWS Management Console.","C":"Build the application by using shell scripts to create .zip files for each Lambda function. Upload the .zip files. Deploy the .zip files as Lambda functions by using the AWS CLI in a continuous integration and continuous delivery (CI/CD) pipeline.","D":"Build a container for each Lambda function. Store the container images in AWS CodeArtifact. Deploy the containers as Lambda functions by using the AWS CLI in a continuous integration and continuous delivery (CI/CD) pipeline.","B":"Build the application by using the AWS Serverless Application Model (AWS SAM). Use a continuous integration and continuous delivery (CI/CD) pipeline and the SAM CLI to deploy the Lambda functions."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143752-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:32:00","unix_timestamp":1720755120,"discussion_count":1,"discussion":[{"timestamp":"1720755120.0","content":"Selected Answer: B\\nB is the best of the options provided","upvote_count":"2","poster":"rdiaz","comment_id":"1246455"}],"answer_description":"","extracted_at":"2025-12-24T09:05:52.160Z","extraction_method":"api_direct_v1"},{"question_id":"nj75qPwM5cQ3TnE2IZ1b","question_number":301,"page":61,"question_text":"A company has an Amazon S3 bucket that contains sensitive data. The data must be encrypted in transit and at rest. The company encrypts the data in the S3 bucket by using an AWS Key Management Service (AWS KMS) key. A developer needs to grant several other AWS accounts the permission to use the S3 GetObject operation to retrieve the data from the S3 bucket.\\nHow can the developer enforce that all requests to retrieve the data provide encryption in transit?","choices":{"D":"Define a resource-based policy on the KMS key to deny access when a request meets the condition of \u201caws:SecureTransport\u201d: \u201cfalse\u201d.","B":"Define a resource-based policy on the S3 bucket to allow access when a request meets the condition \u201caws:SecureTransport\u201d: \u201cfalse\u201d.","C":"Define a role-based policy on the other accounts\' roles to deny access when a request meets the condition of \u201caws:SecureTransport\u201d: \u201cfalse\u201d.","A":"Define a resource-based policy on the S3 bucket to deny access when a request meets the condition \u201caws:SecureTransport\u201d: \u201cfalse\u201d."},"correct_answer":"A","answer_ET":"A","answers_community":["A (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103850-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-25 13:22:00","unix_timestamp":1679746920,"discussion_count":10,"discussion":[{"upvote_count":"10","content":"Selected Answer: A\\nA\\nhttps://repost.aws/knowledge-center/s3-bucket-policy-for-config-rule","poster":"Untamables","timestamp":"1679791800.0","comment_id":"850590"},{"content":"Selected Answer: A\\nA is correct.","timestamp":"1679746920.0","upvote_count":"5","comment_id":"850107","poster":"Watascript"},{"comment_id":"1399617","poster":"pratik7006","content":"Selected Answer: A\\nB. Allow access when \\"aws:SecureTransport\\": \\"false\\" \u274c This would allow HTTP instead of enforcing HTTPS.\\nC. Role-based policy on other accounts\' roles \u274c The bucket owner controls access, not external accounts. A bucket policy is required.\\nD. Resource-based policy on the KMS key \u274c KMS policies control encryption keys, not transport security. HTTP/HTTPS enforcement must happen at the S3 bucket level.","timestamp":"1742209020.0","upvote_count":"2"},{"timestamp":"1734887880.0","content":"Selected Answer: A\\nA) Correct - The condition \u201caws:SecureTransport\u201d: \u201cfalse\u201d ensures that only secure requests (encrypted in transit) are allowed.\\n\\nB) Eliminated - This allows access only when the request does not use secure transport. This is opposite of the requirement\\n\\nC) Eliminated - Resource-based policies at the bucket level are better suited for cross-account access.\\n\\nD) Eliminated - The GetObject operation is specific to the S3 bucket, not the KMS key.","upvote_count":"3","poster":"sumanshu","comment_id":"1330490"},{"content":"aws:SecureTransport condition does not apply to KMS key policies","poster":"rue_","comment_id":"1303932","upvote_count":"1","timestamp":"1730114520.0"},{"timestamp":"1716306720.0","content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1215073","poster":"65703c1","upvote_count":"1"},{"poster":"ibratoev","timestamp":"1711454280.0","comment_id":"1183275","upvote_count":"1","content":"A is correct."},{"comments":[{"poster":"KarBiswa","comment_id":"1098673","upvote_count":"1","timestamp":"1702790700.0","content":"Agree, but id we compare between A & D, A seems to be more accurate."}],"timestamp":"1697601360.0","comment_id":"1046526","upvote_count":"2","content":"Selected Answer: D\\nHesitate between A and D.\\nQuestion is not clear on weather we want to block all the information or only the sensitive part.","poster":"CrescentShared"},{"comment_id":"996676","upvote_count":"3","content":"I know A is correct but D seems correct as well, since users will need access to the KMS key to decrypt the data in the bucket.","timestamp":"1693638300.0","poster":"winzzhhzzhh"},{"poster":"Malkia","content":"Selected Answer: A\\nA is correct.","timestamp":"1683269700.0","upvote_count":"1","comment_id":"889844"}],"answer_description":"","extracted_at":"2025-12-24T09:06:03.133Z","extraction_method":"api_direct_v1"},{"question_id":"nAdAbJVYVsFvN6Qw4AWr","question_number":302,"page":61,"question_text":"A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait until the next day to view the processed data and have asked to have it available in near-real time.\\n\\nWhich application architecture pattern would enable the data to be processed as it is received?","choices":{"B":"Client-server driven","A":"Event driven","C":"Fan-out driven","D":"Schedule driven"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143753-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:33:00","unix_timestamp":1720755180,"discussion_count":2,"discussion":[{"upvote_count":"5","poster":"rdiaz","content":"Selected Answer: A\\nA, event driven","timestamp":"1720755180.0","comment_id":"1246456"},{"content":"Selected Answer: A\\nEvent-driven systems are inherently real-time, where actions occur in response to events, as opposed to the request/response model seen in client-server systems.","poster":"preachr","upvote_count":"1","timestamp":"1728119220.0","comment_id":"1293407"}],"answer_description":"","extracted_at":"2025-12-24T09:06:03.133Z","extraction_method":"api_direct_v1"},{"question_id":"GDgkcLFeVSRtnJKGs38C","question_number":303,"page":61,"question_text":"A company hosts its application in the us-west-1 Region. The company wants to add redundancy in the us-east-1 Region.\\n\\nThe application secrets are stored in AWS Secrets Manager in us-west-1. A developer needs to replicate the secrets to us-east-1.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Configure secret replication for each secret. Add us-east-1 as a replication Region. Choose an AWS Key Management Service (AWS KMS) key in us-east-1 to encrypt the replicated secrets.","C":"Create a replication rule for each secret. Set us-east-1 as the destination Region. Configure the rule to run during secret rotation. Choose an AWS Key Management Service (AWS KMS) key in us-east-1 to encrypt the replicated secrets.","D":"Create a Secrets Manager lifecycle rule to replicate each secret to a new Amazon S3 bucket in us-west-1. Configure an S3 replication rule to replicate the secrets to us-east-1.","B":"Create a new secret in us-east-1 for each secret. Configure secret replication in us-east-1. Set the source to be the corresponding secret in us-west-1. Choose an AWS Key Management Service (AWS KMS) key in us-west-1 to encrypt the replicated secrets."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143754-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:36:00","unix_timestamp":1720755360,"discussion_count":2,"discussion":[{"upvote_count":"6","timestamp":"1720755360.0","poster":"rdiaz","content":"Selected Answer: A\\nA - AWS Secrets Manager provides a built-in feature for cross-region replication of secrets. By configuring secret replication, you can add the us-east-1 Region as a replication destination. This ensures that the secrets are automatically and securely replicated from us-west-1 to us-east-1. You also have the option to specify an AWS KMS key in the destination region (us-east-1) to encrypt the replicated secrets, ensuring they are protected by encryption keys in the appropriate region.","comment_id":"1246457"},{"timestamp":"1724248920.0","comment_id":"1270176","content":"Selected Answer: A\\nD has operational overhead so is A","upvote_count":"2","poster":"KennethNg923"}],"answer_description":"","extracted_at":"2025-12-24T09:06:03.133Z","extraction_method":"api_direct_v1"},{"question_id":"p3FLSlOrKjYnxy42sdRx","question_number":304,"page":61,"question_text":"A company runs an ecommerce application on AWS. The application stores data in an Amazon Aurora database.\\n\\nA developer is adding a caching layer to the application. The caching strategy must ensure that the application always uses the most recent value for each data item.\\n\\nWhich caching strategy will meet these requirements?","choices":{"D":"Implement a read-through strategy for every item that is loaded.","B":"Implement a write-through strategy for every item that is created and updated.","C":"Implement a lazy loading strategy for every item that is loaded.","A":"Implement a TTL strategy for every item that is saved in the cache."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143755-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:38:00","unix_timestamp":1720755480,"discussion_count":1,"discussion":[{"comment_id":"1246458","upvote_count":"7","timestamp":"1720755480.0","content":"Selected Answer: B\\nWrite-Through Caching (Option B): With a write-through caching strategy, every time an item is written to the database, it is also written to the cache. This ensures that the cache is always updated with the most recent value immediately after any write operation. Consequently, any read operation can fetch the most recent value directly from the cache, ensuring data consistency between the cache and the database.","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:06:03.133Z","extraction_method":"api_direct_v1"},{"question_id":"wWssknwM88A3OUgOlZMf","question_number":305,"page":61,"question_text":"A company has a serverless application that uses Amazon API Gateway backed by AWS Lambda proxy integration. The company is developing several backend APIs. The company needs a landing page to provide an overview of navigation to the APIs.\\n\\nA developer creates a new/LandingPage resource and a new GET method that uses mock integration.\\n\\nWhat should the developer do next to meet these requirements?","choices":{"D":"Configure the integration request mapping template with Content-Type of text/html. In the integration request mapping template, include the LandingPage HTML code that references the APIs. Configure the integration response mapping template with Content-Type of application/json and statusCode of 200.","C":"Configure the integration request mapping template with Content-Type of application/json and statusCode of 200. Configure the integration response mapping template with Content-Type of text/html. In the integration response mapping template, include the LandingPage HTML code that references the APIs.","A":"Configure the integration request mapping template with Content-Type of text/html and statusCode of 200. Configure the integration response mapping template with Content-Type of application/json. In the integration response mapping template, include the LandingPage HTML code that references the APIs.","B":"Configure the integration request mapping template with Content-Type of application/json. In the integration request mapping template, include the LandingPage HMTL code that references the APIs. Configure the integration response mapping template with Content-Type of text/html and statusCode of 200."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143069-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 14:48:00","unix_timestamp":1719665280,"discussion_count":2,"discussion":[{"poster":"albert_kuo","content":"Selected Answer: C\\nIntegration Request Mapping Template:\\n{\\n \\"statusCode\\": 200\\n}\\n\\nIntegration Response Mapping Template:\\n<html>\\n<head>\\n <title>Landing Page</title>\\n</head>\\n<body>\\n <h1>Welcome to our API Gateway!</h1>\\n <p>Here are our APIs:</p>\\n <ul>\\n <li><a href=\\"/api1\\">API 1</a></li>\\n <li><a href=\\"/api2\\">API 2</a></li>\\n <li><a href=\\"/api3\\">API 3</a></li>\\n </ul>\\n</body>\\n</html>","comment_id":"1256535","upvote_count":"3","timestamp":"1722128340.0"},{"comment_id":"1239270","upvote_count":"2","poster":"Alabi","content":"Selected Answer: C\\nBy configuring the integration request and response mapping templates as described, you ensure that the mock integration correctly serves the HTML landing page, meeting the requirement of providing an overview and navigation to the backend APIs.","timestamp":"1719665280.0"}],"answer_description":"","extracted_at":"2025-12-24T09:06:03.133Z","extraction_method":"api_direct_v1"},{"question_id":"Nr48dEYKyEOzCzVrCoHd","question_number":306,"page":62,"question_text":"A developer creates an AWS Lambda function that is written in Java. During testing, the Lambda function does not work how the developer expected. The developer wants to use tracing capabilities to troubleshoot the problem.\\n\\nWhich AWS service should the developer use to accomplish this goal?","choices":{"B":"Amazon CloudWatch","A":"AWS Trusted Advisor","D":"AWS CloudTrail","C":"AWS X-Ray"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143756-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:41:00","unix_timestamp":1720755660,"discussion_count":1,"discussion":[{"content":"Selected Answer: C\\nTracing = XRAY","upvote_count":"2","timestamp":"1720755660.0","comment_id":"1246459","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:06:14.169Z","extraction_method":"api_direct_v1"},{"question_id":"Os5TH3MqrG857cvmzEAg","question_number":307,"page":62,"question_text":"A company is developing an application that will be accessed through the Amazon API Gateway REST API. Registered users should be the only ones who can access certain resources of this API. The token being used should expire automatically and needs to be refreshed periodically.\\n\\nHow can a developer meet these requirements?","choices":{"A":"Create an Amazon Cognito identity pool, configure the Amazon Cognito Authorizer in API Gateway, and use the temporary credentials generated by the identity pool.","B":"Create and maintain a database record for each user with a corresponding token and use an AWS Lambda authorizer in API Gateway.","C":"Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token.","D":"Create an IAM user for each API user, attach an invoke permissions policy to the API, and use an IAM authorizer in API Gateway."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143757-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:44:00","unix_timestamp":1720755840,"discussion_count":2,"discussion":[{"comment_id":"1246460","timestamp":"1720755840.0","upvote_count":"5","poster":"rdiaz","content":"Selected Answer: C\\nOption A (Amazon Cognito Identity Pool): An Amazon Cognito Identity Pool provides temporary AWS credentials for users but is typically used in conjunction with user pools for unauthenticated access and to interact with AWS services. It does not handle user authentication and token expiration directly as needed for API access."},{"comment_id":"1334742","upvote_count":"1","timestamp":"1735642200.0","poster":"examuserss","content":"Selected Answer: C\\nThe best solution is C. Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token.\\n\\nHere\'s why:\\n\\nCognito User Pools are designed for managing user identities and authentication. They handle user registration, login, and token generation securely. The tokens (ID and access tokens) generated by Cognito have built-in expiration mechanisms, automatically handling the refresh requirement.\\n\\nCognito Authorizer in API Gateway seamlessly integrates with Cognito User Pools. It verifies the tokens presented by the client, ensuring only authorized users can access protected resources."}],"answer_description":"","extracted_at":"2025-12-24T09:06:14.169Z","extraction_method":"api_direct_v1"},{"question_id":"VfPZndhgCpZoIMrRS46d","question_number":308,"page":62,"question_text":"A company used AWS to develop an application for customers. The application includes an Amazon API Gateway API that invokes AWS Lambda functions. The Lambda functions process data and store the data in Amazon DynamoDB tables.\\n\\nThe company must monitor the entire application to identify potential bottlenecks in the architecture that can negatively affect customers.\\n\\nWhich solution will meet this requirement with the LEAST development effort?","choices":{"C":"Configure API Gateway to log responses to Amazon CloudWatch. Create a metric filter for the TooManyRequestsException error message.","B":"Configure Lambda exceptions and additional logging to Amazon CloudWatch. Use CloudWatch Logs Insights to query the logs.","A":"Instrument the application with AWS X-Ray. Inspect the service map to identify errors and issues.","D":"Use Amazon CloudWatch metrics for the DynamoDB tables to identify all the ProvisionedThroughputExceededException error messages."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143758-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:46:00","unix_timestamp":1720755960,"discussion_count":2,"discussion":[{"upvote_count":"2","timestamp":"1728132660.0","poster":"preachr","content":"Selected Answer: A\\nTo monitor the entire application with the least development effort, the company should use AWS X-Ray integrated with Amazon API Gateway, AWS Lambda, and Amazon DynamoDB. AWS X-Ray provides end-to-end tracing of requests through the application components, allowing the company to identify performance bottlenecks in a serverless architecture with minimal additional development work.","comment_id":"1293483"},{"comment_id":"1246462","timestamp":"1720755960.0","content":"Selected Answer: A\\nA Xray","upvote_count":"2","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:06:14.169Z","extraction_method":"api_direct_v1"},{"question_id":"XKjhxc1BJeEss8OwInhc","question_number":309,"page":62,"question_text":"A company launched an online portal to announce a new product that the company will release in 6 months. The portal requests that users enter an email address to receive communications about the product. The company needs to create a REST API that will store the email addresses in Amazon DynamoDB.\\n\\nA developer has created an AWS Lambda function that can store the email addresses. The developer will deploy the Lambda function by using the AWS Serverless Application Model (AWS SAM). The developer must provide access to the Lambda function over HTTP.\\n\\nWhich solutions will meet these requirements with the LEAST additional configuration? (Choose two.)","choices":{"E":"Expose the Lambda function by using Amazon API Gateway.","B":"Expose the Lambda function by using a Gateway Load Balancer.","A":"Expose the Lambda function by using function URLs.","C":"Expose the Lambda function by using a Network Load Balancer.","D":"Expose the Lambda function by using AWS Global Accelerator."},"correct_answer":"AE","answer_ET":"AE","answers_community":["AE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143759-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:47:00","unix_timestamp":1720756020,"discussion_count":2,"discussion":[{"content":"Selected Answer: AE\\nLambda Function URLs and Amazon API Gateway provide direct HTTP/HTTPS access to serverless functions (AWS Lambda) and automatically handle routing, scaling, and performance optimization without the need for a load balancer.\\n\\nAPI Gateway already acts as a front door for your API, handling incoming HTTP requests and forwarding them to the appropriate Lambda function (or other backend services), so there\u2019s no need for a Gateway Load Balancer.\\n\\nLambda Function URLs similarly provide a direct way to invoke a Lambda function over HTTP without requiring a load balancer.","timestamp":"1728134460.0","upvote_count":"2","poster":"preachr","comment_id":"1293486"},{"upvote_count":"4","comment_id":"1246463","poster":"rdiaz","timestamp":"1720756020.0","content":"Selected Answer: AE\\nfunction urls and apigw"}],"answer_description":"","extracted_at":"2025-12-24T09:06:14.169Z","extraction_method":"api_direct_v1"},{"question_id":"iL9hqlKwCnyouqbw1cvn","question_number":310,"page":62,"question_text":"A company has a website that displays a daily newsletter. When a user visits the website, an AWS Lambda function processes the browser\'s request and queries the company\'s on-premises database to obtain the current newsletter. The newsletters are stored in English. The Lambda function uses the Amazon Translate TranslateText API operation to translate the newsletters, and the translation is displayed to the user.\\n\\nDue to an increase in popularity, the website\'s response time has slowed. The database is overloaded. The company cannot change the database and needs a solution that improves the response time of the Lambda function.\\n\\nWhich solution meets these requirements?","choices":{"B":"Cache the translated newsletters in the Lambda/tmp directory.","D":"Change the Lambda function to use parallel processing.","C":"Enable TranslateText API caching.","A":"Change to asynchronous Lambda function invocation."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143767-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 06:52:00","unix_timestamp":1720759920,"discussion_count":4,"discussion":[{"upvote_count":"1","comment_id":"1312107","timestamp":"1731598440.0","content":"Selected Answer: B\\nA company has a website that displays a daily newsletter. When a user visits the website, an AWS Lambda function processes the browser\'s request and queries the company\'s on-premises database to obtain the current newsletter. The newsletters are stored in English. The Lambda function uses the Amazon Translate TranslateText API operation to translate the newsletters, and the translation is displayed to the user.\\n\\nDue to an increase in popularity, the website\'s response time has slowed. The database is overloaded. The company cannot change the database and needs a solution that improves the response time of the Lambda function.\\n\\nWhich solution meets these requirements?\\n\\nA. Change to asynchronous Lambda function invocation.\\nB. Cache the translated newsletters in the Lambda/tmp directory.\\nC. Enable TranslateText API caching.\\nD. Change the Lambda function to use parallel processing.","poster":"CloudChingon"},{"upvote_count":"2","comment_id":"1276936","timestamp":"1725296340.0","content":"Selected Answer: B\\nB is correct. Why? All others make no sense.\\nBut using /tmp to cache this content is far from being optimal. \\nAWS itself proposes using S3 or dynamo for caching of this kind:\\nhttps://aws.amazon.com/pt/blogs/machine-learning/maximize-your-amazon-translate-architecture-using-strategic-caching-layers/\\nhttps://aws.amazon.com/pt/blogs/machine-learning/translating-your-website-or-application-automatically-with-amazon-translate-in-your-ci-cd-pipeline/\\n\\nUsing lambda\'s /tmp will solve the DB overload but create problems of performance by its own, AND probably increase costs.","poster":"wh1t4k3r"},{"upvote_count":"3","timestamp":"1724249340.0","poster":"KennethNg923","comment_id":"1270180","content":"Selected Answer: B\\nB is correct. Caching the translated newsletters in the Lambda /tmp directory would significantly improve response times and reduce the load on the database.\\nC is Wrong as Amazon Translate doesn\'t offer an API-level caching feature."},{"comments":[{"content":"No. Tmp directory is TEMPORAL and ephemeral","comment_id":"1252450","poster":"catoteja","upvote_count":"3","timestamp":"1721566920.0"}],"poster":"komorebi","comment_id":"1247082","timestamp":"1720834500.0","content":"B. Cache the translated newsletters in the Lambda/tmp directory.","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:06:14.169Z","extraction_method":"api_direct_v1"},{"question_id":"njX8uzQ9FLPq65LtRKwb","question_number":311,"page":63,"question_text":"A developer is monitoring an application that runs on an Amazon EC2 instance. The developer has configured a custom Amazon CloudWatch metric with data granularity of 1 second. If any issues occur, the developer wants to be notified within 30 seconds by Amazon Simple Notification Service (Amazon SNS).\\n\\nWhat should the developer do to meet this requirement?","choices":{"B":"Set up a custom CloudWatch dashboard.","C":"Use Amazon CloudWatch Logs Insights.","A":"Configure a high-resolution CloudWatch alarm.","D":"Change to a default CloudWatch metric."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143760-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:53:00","unix_timestamp":1720756380,"discussion_count":2,"discussion":[{"timestamp":"1721556240.0","comment_id":"1252372","content":"Selected Answer: A\\nA is correct","poster":"Mo_1981","upvote_count":"2"},{"poster":"komorebi","comment_id":"1247078","timestamp":"1720833900.0","content":"A. Configure a high-resolution CloudWatch alarm.","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:06:25.143Z","extraction_method":"api_direct_v1"},{"question_id":"2nlfUoqNrEqwiuT4ZHB4","question_number":312,"page":63,"question_text":"An application that is hosted on an Amazon EC2 instance needs access to files that are stored in an Amazon S3 bucket. The application lists the objects that are stored in the S3 bucket and displays a table to the user. During testing, a developer discovers that the application does not show any objects in the list.\\nWhat is the MOST secure way to resolve this issue?","choices":{"D":"Update the S3 bucket policy by including the S3:ListBucket permission and by setting the Principal element to specify the account number of the EC2 instance.","B":"Update the IAM instance profile that is attached to the EC2 instance to include the S3:ListBucket permission for the S3 bucket.","A":"Update the IAM instance profile that is attached to the EC2 instance to include the S3:* permission for the S3 bucket.","C":"Update the developer\'s user permissions to include the S3:ListBucket permission for the S3 bucket."},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","A (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103522-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:41:00","unix_timestamp":1679434860,"discussion_count":12,"discussion":[{"content":"Selected Answer: B\\nThe correct answer is B.\\nhttps://repost.aws/knowledge-center/ec2-instance-access-s3-bucket\\nOption A also works, but it is not compliant to the AWS security practice of the least privilege permissions.","timestamp":"1679791920.0","poster":"Untamables","upvote_count":"11","comment_id":"850592","comments":[{"upvote_count":"3","timestamp":"1684445460.0","content":"Option B only allows you to list the bucket - you will still not see the objects if only s3:ListBucket permission is configured.","comment_id":"901507","poster":"yeacuz"}]},{"upvote_count":"5","comments":[{"comment_id":"1303778","upvote_count":"3","timestamp":"1730076840.0","poster":"nbxyzd","content":"Hey, don\'t mislead the others, please. Read the official document carefully before posting here."},{"upvote_count":"3","poster":"Jeremy11","timestamp":"1690768380.0","content":"Not true:\\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html\\nTo use this action in an AWS Identity and Access Management (IAM) policy, you must have permission to perform the s3:ListBucket action.","comments":[{"comment_id":"1179958","poster":"ec8or","content":"Answer is A: The questions is not stating the the list of buckets cannot seen but the objects within the lists cannot be seen. Seems the dev already has the s3:ListBucket option its the objects part that is missing.","timestamp":"1711096200.0","upvote_count":"1"}],"comment_id":"967660"}],"comment_id":"893468","poster":"yeacuz","timestamp":"1683671580.0","content":"Selected Answer: A\\nOption A allows you to list buckets AND objects. Option B only allows you to list the bucket - you will still not see the objects if only s3:ListBucket permission is configured."},{"timestamp":"1735158480.0","poster":"aaaaatoz","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/access-policy-language-overview.html\\n\\nFor example, the s3:ListBucket permission allows the user to use the Amazon S3 ListObjectsV2 operation. (The s3:ListBucket permission is a case where the action name doesn\'t map directly to the operation name.)","upvote_count":"2","comment_id":"1331702"},{"content":"Selected Answer: B\\nA) Eliminated - Too permissive: Grants more permissions than needed (S3:*), violating the principle of least privilege.\\n\\nB) Correct - Minimal permissions: Only grants the permission needed for the application to perform the ListBucket operation. Permissions are tied to the EC2 instance\'s IAM instance profile, limiting access to that instance.\\n\\nC) Eliminated - The developer\u2019s permissions are unrelated to the application running on the EC2 instance.\\n\\nD) Eliminated - Grants permissions at the S3 bucket policy level, which applies to all resources in the account, not just the EC2 instance.","upvote_count":"2","poster":"sumanshu","comment_id":"1330491","timestamp":"1734888180.0"},{"timestamp":"1716308220.0","comment_id":"1215086","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1"},{"timestamp":"1714006140.0","comment_id":"1201672","upvote_count":"1","poster":"Vaibs099","content":"B is correct, Question is asking for lists the objects that are stored in the S3 bucket. s3:ListBucket gives bucket level objects list."},{"content":"The correct answer is B.\\nOption A works as well but only listing the files is mentioned as requirement.","timestamp":"1711454340.0","upvote_count":"1","poster":"ibratoev","comment_id":"1183276"},{"content":"Selected Answer: B\\nIt is B, but I had to dig into docs to learn that to use ListObjectsV2, in an AWS Identity and Access Management (IAM) policy, you must have permission to perform the s3:ListBucket action.\\n\\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html","comment_id":"985009","timestamp":"1692426180.0","poster":"ninomfr64","upvote_count":"2"},{"comments":[{"comment_id":"1022050","timestamp":"1696142100.0","upvote_count":"1","content":"Option D is not the most secure choice, as utilizing bucket policies and specifying account numbers can potentially lead to overly complex and less secure configurations, especially if not managed carefully.\\n\\nTo implement option B, follow these and it most secure!!!\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": \\"s3:ListBucket\\",\\n \\"Resource\\": \\"arn:aws:s3:::your-bucket-name\\"\\n }\\n ]\\n}","poster":"nmc12"}],"poster":"jipark","comment_id":"971877","content":"are there anyone who can explain D ? - S3 bucket policy","upvote_count":"3","timestamp":"1691140380.0"},{"upvote_count":"3","poster":"s50600822","content":"A violated least privilege principle so B","timestamp":"1686019740.0","comment_id":"915859"},{"poster":"yashika2005","timestamp":"1685770500.0","content":"Selected Answer: B\\nthe s3:ListBucket permission allows the user to use the Amazon S3 GET Bucket (List Objects) operation.\\nReference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-policy-language-overview.html","upvote_count":"3","comment_id":"913308"},{"upvote_count":"4","content":"Selected Answer: B\\nIt is B","timestamp":"1679434860.0","poster":"svrnvtr","comment_id":"846390"}],"answer_description":"","extracted_at":"2025-12-24T09:06:25.143Z","extraction_method":"api_direct_v1"},{"question_id":"PK6CuSOo2SIaWpW1uBlA","question_number":313,"page":63,"question_text":"A company has a web application that contains an Amazon API Gateway REST API. A developer has created an AWS CloudFormation template for the initial deployment of the application. The developer has deployed the application successfully as part of an AWS CodePipeline continuous integration and continuous delivery (CI/CD) process. All resources and methods are available through the deployed stage endpoint.\\n\\nThe CloudFormation template contains the following resource types:\\n\\n\u2022 AWS::ApiGateway::RestApi\\n\u2022 AWS::ApiGateway::Resource\\n\u2022 AWS::ApiGateway::Method\\n\u2022 AWS::ApiGateway::Stage\\n\u2022 AWS::ApiGateway::Deployment\\n\\nThe developer adds a new resource to the REST API with additional methods and redeploys the template. CloudFormation reports that the deployment is successful and that the stack is in the UPDATE_COMPLETE state. However, calls to all new methods are returning 404 (Not Found) errors.\\n\\nWhat should the developer do to make the new methods available?","choices":{"A":"Specify the disable-rollback option during the update-stack operation.","B":"Unset the CloudFormation stack failure options.","D":"Add an action to CodePipeline to run the aws cloudfront create-invalidation AWS CLI command.","C":"Add an AWS CodeBuild stage to CodePipeline to run the aws apigateway create-deployment AWS CLI command."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143761-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 05:55:00","unix_timestamp":1720756500,"discussion_count":2,"discussion":[{"poster":"albert_kuo","content":"Selected Answer: C\\ncreate a buildspec.yml\\n\\nversion: 0.2\\n\\nphases:\\n build:\\n commands:\\n - aws apigateway create-deployment --rest-api-id <your-rest-api-id> --stage-name <your-stage-name>","upvote_count":"2","comment_id":"1256542","timestamp":"1722129360.0"},{"poster":"rdiaz","timestamp":"1720756500.0","content":"Selected Answer: C\\nto ensure that new resources and methods are properly deployed and available in API Gateway, you need to create a new deployment of the API configuration. Adding an AWS CodeBuild stage to your CodePipeline to run the aws apigateway create-deployment command (Option C) is the correct approach to accomplish this.","upvote_count":"2","comment_id":"1246468"}],"answer_description":"","extracted_at":"2025-12-24T09:06:25.143Z","extraction_method":"api_direct_v1"},{"question_id":"6kfAIbtIX6tqJTQZJBu6","question_number":314,"page":63,"question_text":"A developer updates an AWS Lambda function that an Amazon API Gateway API uses. The API is the backend for a web application.\\n\\nThe developer needs to test the updated Lambda function before deploying the Lambda function to production. The testing must not affect any production users of the web application.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"A":"Create a canary release deployment for the existing API stage. Deploy the API to the existing stage. Test the updated Lambda function by using the existing URL.","D":"Create a new AWS CloudFormation stack to deploy a copy of the entire production API and Lambda function. Use the stack\'s API URL to test the updated Lambda function.","B":"Update the API Gateway API endpoint type to private. Deploy the changes to the existing API stage. Test the API by using the existing URL.","C":"Create a new test API stage in API Gateway. Add stage variables to deploy the updated Lambda function to only the test stage. Test the updated Lambda function by using the new stage URL."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143721-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-11 14:48:00","unix_timestamp":1720702080,"discussion_count":2,"discussion":[{"upvote_count":"3","timestamp":"1720756560.0","content":"Selected Answer: C\\ncreating a new test API stage in API Gateway and deploying the updated Lambda function to this stage (Option C) is the most efficient and least disruptive way to test the function while ensuring that no changes affect the production environment.","comment_id":"1246469","poster":"rdiaz"},{"poster":"blow96","timestamp":"1720702080.0","upvote_count":"1","comment_id":"1246127","content":"C\\nis correct"}],"answer_description":"","extracted_at":"2025-12-24T09:06:25.143Z","extraction_method":"api_direct_v1"},{"question_id":"4o6MOJubGHkmoAmdkTf8","question_number":315,"page":63,"question_text":"A developer wants the ability to roll back to a previous version of an AWS Lambda function in the event of errors caused by a new deployment.\\n\\nHow can the developer achieve this with MINIMAL impact on users?","choices":{"C":"Do not make any changes to the application. Deploy the new version of the code. If too many errors are encountered, point the application back to the previous version using the version number in the Amazon Resource Name (ARN).","B":"Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to direct 10% of users to the newly deployed version. If too many errors are encountered, send 100% of traffic to the previous version.","A":"Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to use the newly deployed version. If too many errors are encountered, point the alias back to the previous version.","D":"Create three aliases: new, existing, and router. Point the existing alias to the current version. Have the router alias direct 100% of users to the existing alias. Update the application to use the router alias. Deploy the new version of the code. Point the new alias to this version. Update the router alias to direct 10% of users to the new alias. If too many errors are encountered, send 100% of traffic to the existing alias."},"correct_answer":"B","answer_ET":"B","answers_community":["B (73%)","A (27%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143722-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-11 14:49:00","unix_timestamp":1720702140,"discussion_count":11,"discussion":[{"poster":"tomchandler077","upvote_count":"5","content":"Option B is the best choice for achieving the objective with minimal impact on users. It uses a canary deployment strategy, which allows for testing the new version on a smaller scale before a full rollout. This method provides a balance between risk management and operational simplicity, ensuring that any potential negative impacts of the new deployment are contained and easily reversible.","comment_id":"1250021","timestamp":"1721256300.0"},{"content":"Selected Answer: A\\nThe question state that the developer wants the ability to rollback to a previous version, not to deploy a new version with a minimal impact as stated by the the answer B.\\nSo A is the best answer in this case.","comment_id":"1573781","timestamp":"1748712060.0","upvote_count":"1","poster":"egosselin"},{"upvote_count":"1","poster":"preachr","comment_id":"1293550","timestamp":"1728147240.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuring-alias-routing.html"},{"comment_id":"1276939","content":"Selected Answer: B\\nFor people voting A: you have no idea what is the traffic load to the application. Using the method described on A will affect 100% of all users all at once until you are able to rollback. B divertes 10% of traffic only than can be easly switched back and would impact only 10% of users","poster":"wh1t4k3r","timestamp":"1725296880.0","upvote_count":"2"},{"upvote_count":"1","poster":"KennethNg923","timestamp":"1724249640.0","comment_id":"1270182","content":"Selected Answer: B\\nB Update the alias to direct 10% of users to the newly deployed version -> minimal impact"},{"poster":"piipo","comment_id":"1256678","timestamp":"1722159660.0","content":"Selected Answer: B\\nB is best","upvote_count":"1"},{"poster":"catoteja","timestamp":"1721773080.0","upvote_count":"2","comment_id":"1253988","content":"B looks better"},{"content":"Selected Answer: A\\nVOTE A","comment_id":"1249275","timestamp":"1721166960.0","poster":"Alagong","upvote_count":"2"},{"content":"SHOULD BE A","poster":"siheom","upvote_count":"3","timestamp":"1721166900.0","comment_id":"1249273"},{"poster":"rdiaz","content":"Selected Answer: B\\nMinimal impact","comment_id":"1246471","upvote_count":"3","timestamp":"1720756740.0"},{"content":"A\\nis correct","upvote_count":"2","comment_id":"1246129","timestamp":"1720702140.0","poster":"blow96"}],"answer_description":"","extracted_at":"2025-12-24T09:06:25.143Z","extraction_method":"api_direct_v1"},{"question_id":"P1DlrhoTg9Lu3LmmMhgi","question_number":316,"page":64,"question_text":"A company maintains a REST service using Amazon API Gateway and the API Gateway native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using CreateApiKey and sends the new key to the user. When the user attempts to call the API using this key, the user receives a 403 Forbidden error. Existing users are unaffected and can still call the API.\\n\\nWhat code updates will grant these new users access to the API?","choices":{"C":"The importApiKeys method must be called to import all newly created API keys into the current stage of the API.","D":"The createUsagePlanKey method must be called to associate the newly created API key with the correct usage plan.","B":"The updateAuthorizer method must be called to update the API\'s authorizer to include the newly created API key.","A":"The createDeployment method must be called so the API can be redeployed to include the newly created API key."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143762-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 06:01:00","unix_timestamp":1720756860,"discussion_count":3,"discussion":[{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-create-usage-plans-with-rest-api.html","comment_id":"1307987","poster":"aws_god","timestamp":"1730909520.0","upvote_count":"1"},{"poster":"albert_kuo","upvote_count":"1","comment_id":"1256543","timestamp":"1722130320.0","content":"Selected Answer: D\\nimport boto3\\n\\nclient = boto3.client(\'apigateway\')\\n\\n# Create API Key\\nresponse = client.create_api_key(\\n name=\'NewUserKey\',\\n enabled=True\\n)\\n\\napi_key_id = response[\'id\']\\n\\n# Associate API Key and usage plan\\nclient.create_usage_plan_key(\\n usagePlanId=\'YOUR_USAGE_PLAN_ID\',\\n keyId=api_key_id,\\n keyType=\'API_KEY\'\\n)"},{"comment_id":"1246474","content":"Selected Answer: D\\nD chatgpt","timestamp":"1720756860.0","poster":"rdiaz","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:06:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"LKpZYrr4Ku2iticUvnKB","question_number":317,"page":64,"question_text":"A company uses an AWS CloudFormation template to deploy and manage its AWS infrastructure. The CloudFormation template creates Amazon VPC security groups and Amazon EC2 security groups.\\n\\nA manager finds out that some engineers modified the security groups of a few EC2 instances for testing purposes. A developer needs to determine what modifications occurred.\\n\\nWhich solution will meet this requirement?","choices":{"B":"Perform a drift detection operation on the CloudFormation stack.","A":"Add a Conditions section statement in the source YAML file of the template. Run the CloudFormation stack.","D":"Use Amazon Detective to detect the modifications.","C":"Execute a change set for the CloudFormation stack."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144606-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-28 03:33:00","unix_timestamp":1722130380,"discussion_count":3,"discussion":[{"content":"Selected Answer: B\\nYou can use drift detection to identify stack resources to which configuration changes have been made outside of CloudFormation management.","poster":"preachr","comment_id":"1293761","timestamp":"1728196200.0","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift.html","comment_id":"1256842","poster":"Mo_1981","timestamp":"1722176940.0"},{"poster":"albert_kuo","timestamp":"1722130380.0","comment_id":"1256544","upvote_count":"2","content":"Selected Answer: B\\nDetect drift"}],"answer_description":"","extracted_at":"2025-12-24T09:06:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"h4LRf3VTPPIsLsFqoqYL","question_number":318,"page":64,"question_text":"An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access.\\n\\nGiven that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?","choices":{"B":"The EC2 instance will only be able to list the contents of one S3 bucket at a time.","D":"The EC2 instance will not be able to perform any S3 action on any S3 bucket.","A":"The EC2 instance will only be able to list the S3 buckets.","C":"The EC2 instance will be able to perform all actions on any S3 bucket."},"correct_answer":"D","answer_ET":"D","answers_community":["D (60%)","C (40%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143353-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-05 13:14:00","unix_timestamp":1720178040,"discussion_count":5,"discussion":[{"upvote_count":"10","comment_id":"1243910","poster":"tomchandler077","content":"D \\nExplicit deny policies in IAM take precedence over any allow policies. If the IAM role attached to the EC2 instance explicitly denies access to S3, this deny will apply regardless of any other credentials or policies that might grant access.\\n\\nEven though the EC2 instance\'s credentials file specifies keys with full administrative access, the explicit deny in the IAM role will override these permissions for S3 actions.","timestamp":"1720367040.0"},{"comment_id":"1321415","timestamp":"1733237820.0","content":"Selected Answer: D\\nExplicit deny policies in IAM take precedence over any allow policies","upvote_count":"2","poster":"ShakthiGCP"},{"comment_id":"1320274","content":"Selected Answer: C\\nBy default the AWS CLI uses environment variables then credentials file. Then if neither are present and an EC2 instance profile is attached, then this would be used. So with full access allowed by the key and secret in the local credentials file, full access to S3 would be allowed. Give it a try if you don\'t believe.","poster":"Kb80","timestamp":"1732980360.0","upvote_count":"2"},{"poster":"CloudChingon","comment_id":"1312211","content":"Selected Answer: C\\nThe credentials file containing IAM user credentials with full administrative permissions overrides the IAM role\'s permissions for S3 actions, allowing full access to S3.","upvote_count":"2","timestamp":"1731608760.0"},{"upvote_count":"4","timestamp":"1720178040.0","poster":"Anandesh","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html","comment_id":"1242727"}],"answer_description":"","extracted_at":"2025-12-24T09:06:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"vJO9Ihi0Ws7AMDxxUEQG","question_number":319,"page":64,"question_text":"A company uses an AWS Lambda function to transfer files from an Amazon S3 bucket to the company\'s SFTP server. The Lambda function connects to the SFTP server by using credentials such as username and password. The company uses Lambda environment variables to store these credentials.\\n\\nA developer needs to implement encrypted username and password credentials.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Move the user credentials from Lambda environment variables to AWS Systems Manager Parameter Store.","A":"Remove the user credentials from the Lambda environment. Implement IAM database authentication.","C":"Move the user credentials from Lambda environment variables to AWS Key Management Service (AWS KMS).","D":"Move the user credentials from the Lambda environment to an encrypted .txt file. Store the file in an S3 bucket."},"correct_answer":"B","answer_ET":"B","answers_community":["B (86%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143763-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 06:08:00","unix_timestamp":1720757280,"discussion_count":7,"discussion":[{"timestamp":"1735643100.0","upvote_count":"1","poster":"examuserss","content":"Selected Answer: B\\nThe best solution is B. Move the user credentials from Lambda environment variables to AWS Systems Manager Parameter Store.\\n\\nHere\'s why:\\n\\nParameter Store is designed for securely storing sensitive information. It allows you to encrypt parameters (like usernames and passwords) using AWS KMS, offering strong encryption at rest and in transit. Parameter Store also provides fine-grained access control, ensuring only authorized entities can retrieve the credentials.","comment_id":"1334746"},{"poster":"xdeveloper","timestamp":"1735401900.0","upvote_count":"1","comment_id":"1333038","content":"Selected Answer: B\\nAWS Key Management Service (KMS) is used for managing encryption keys but is not intended to directly store sensitive data like credentials. You would use KMS for encrypting data, and you would still need a service like Parameter Store to store and retrieve the encrypted credential"},{"poster":"preachr","comment_id":"1293809","timestamp":"1728208200.0","upvote_count":"1","content":"Selected Answer: B\\nWe can use two SecureString parameters\u2014one for the SFTP username and one for the SFTP password."},{"poster":"albert_kuo","timestamp":"1728106740.0","upvote_count":"1","comment_id":"1293340","content":"Selected Answer: B\\nimport boto3\\nimport os\\n\\nssm = boto3.client(\'ssm\')\\ndef lambda_handler(event, context):\\n username = ssm.get_parameter(Name=\'SFTPUsername\', WithDecryption=True)[\'Parameter\'][\'Value\']\\n password = ssm.get_parameter(Name=\'SFTPPassword\', WithDecryption=True)[\'Parameter\'][\'Value\']"},{"upvote_count":"1","comment_id":"1283099","poster":"28304e5","timestamp":"1726222080.0","content":"Selected Answer: D\\nD is only answer that clearly encrypts the credentials."},{"upvote_count":"1","comment_id":"1283098","poster":"28304e5","timestamp":"1726221900.0","content":"Answer: D\\nThe question explicitly states that the credentials must be encrypted. AWS Systems Manager Parameter does not encrypt the parameters by default, so B does not work as it doesn\'t state that encryption has been enabled."},{"content":"Selected Answer: B\\nparameter store is the most suitable option","upvote_count":"2","comment_id":"1246482","timestamp":"1720757280.0","poster":"rdiaz"}],"answer_description":"","extracted_at":"2025-12-24T09:06:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"If8T88MYCW3sBgviK8xI","question_number":320,"page":64,"question_text":"A developer is creating a new batch application that will run on an Amazon EC2 instance. The application requires read access to an Amazon S3 bucket. The developer needs to follow security best practices to grant S3 read access to the application.\\n\\nWhich solution meets these requirements?","choices":{"D":"Add the permissions to an IAM policy. Use IAM web identity federation to access the S3 bucket with the policy.","B":"Add the permissions inline to an IAM group. Attach the group to the EC2 instance profile.","A":"Add the permissions to an IAM policy. Attach the policy to a role. Attach the role to the EC2 instance profile.","C":"Add the permissions to an IAM policy. Attach the policy to a user. Attach the user to the EC2 instance profile."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143764-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 06:09:00","unix_timestamp":1720757340,"discussion_count":1,"discussion":[{"comment_id":"1246483","timestamp":"1720757340.0","poster":"rdiaz","content":"Selected Answer: A\\nusing an IAM role attached to an EC2 instance profile with the appropriate IAM policy for S3 read access is the best practice. This approach ensures that the EC2 instance has the necessary permissions without embedding credentials or using less appropriate methods.","upvote_count":"5"}],"answer_description":"","extracted_at":"2025-12-24T09:06:36.148Z","extraction_method":"api_direct_v1"},{"question_id":"wQTOahSP8ViCkCpgraXp","question_number":321,"page":65,"question_text":"A company has an application that receives batches of orders from partners every day. The application uses an AWS Lambda function to process the batches.\\n\\nIf a batch contains no orders, the Lambda function must publish to an Amazon Simple Notification Service (Amazon SNS) topic as soon as possible.\\n\\nWhich combination of steps will meet this requirement with the LEAST implementation effort? (Choose two.)","choices":{"B":"Create a new Lambda function as an Amazon Kinesis data stream consumer. Configure the new Lambda function to track orders and to publish to the SNS topic when a batch contains no orders.","E":"Modify the existing Lambda function to log orders to an Amazon Kinesis data stream.","C":"Set up an Amazon CloudWatch alarm that will send a notification to the SNS topic when the value of the custom metric is 0.","D":"Schedule a new Lambda function to analyze Amazon CloudWatch metrics every 24 hours to identify batches that contain no orders. Configure the Lambda function to publish to the SNS topic.","A":"Update the existing Lambda function\'s code to send an Amazon CloudWatch custom metric for the number of orders in a batch for each partner."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143799-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 15:25:00","unix_timestamp":1720790700,"discussion_count":1,"discussion":[{"comment_id":"1246777","upvote_count":"5","content":"Selected Answer: AC\\nAC metric + alarm","poster":"rdiaz","timestamp":"1720790700.0"}],"answer_description":"","extracted_at":"2025-12-24T09:06:47.131Z","extraction_method":"api_direct_v1"},{"question_id":"VhzVsXMeXu8szG0CdSXa","question_number":322,"page":65,"question_text":"A developer has an application that uses an Amazon DynamoDB table with a configured local secondary index (LSI). During application testing, the DynamoDB table metrics report a ProvisionedThroughputExceededException error message. The number of requests made by the test suite did not exceed the table\'s provisioned capacity limits.\\n\\nWhat is the cause of this issue?","choices":{"A":"The data in the table\'s partition key column is not evenly distributed.","D":"The application has the IAM permission to query the DynamoDB table but not to query the LSI.","B":"The LSI\'s capacity is different from the table\'s capacity.","C":"The application is not implementing exponential backoff retry logic while interacting with the DynamoDB API."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143067-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 14:34:00","unix_timestamp":1719664440,"discussion_count":2,"discussion":[{"upvote_count":"6","content":"Selected Answer: A\\nThe most likely cause of the ProvisionedThroughputExceededException error message is:\\n\\nA. The data in the table\'s partition key column is not evenly distributed.\\nExplanation\\n\\nIn DynamoDB, the provisioned throughput capacity is distributed across all the partitions in the table. If the data in the partition key column is not evenly distributed, some partitions may receive more traffic than others. This can lead to hot partitions, which consume more read/write capacity units than others, resulting in ProvisionedThroughputExceededException errors even if the overall request rate is within the table\'s provisioned throughput limits.","comment_id":"1239258","timestamp":"1719664440.0","poster":"Alabi"},{"upvote_count":"2","content":"Selected Answer: A\\nhot partition problem","timestamp":"1722130800.0","comment_id":"1256545","poster":"albert_kuo"}],"answer_description":"","extracted_at":"2025-12-24T09:06:47.131Z","extraction_method":"api_direct_v1"},{"question_id":"dw05bwUTB3crycZb19nN","question_number":323,"page":65,"question_text":"A company is planning to securely manage one-time fixed license keys in AWS. The company\'s development team needs to access the license keys in automaton scripts that run in Amazon EC2 instances and in AWS CloudFormation stacks.\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"C":"AWS Systems Manager Parameter Store SecureString parameters","D":"CloudFormation NoEcho parameters","B":"AWS Secrets Manager secrets with a tag that is named SecretString","A":"Amazon S3 with encrypted files prefixed with \u201cconfig\u201d"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103913-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 01:53:00","unix_timestamp":1679791980,"discussion_count":9,"discussion":[{"timestamp":"1710151560.0","content":"Both B and C are feasible solutions. Just consider the \\"MOST cost effectively\\" here.\\nAWS Systems Manager Parameter Store comes with no additional cost (Standard type). However, AWS Secrets Manager costs $0.40 per secret per month, and data retrieval costs $0.05 per 10,000 API calls.\\nC is much cheaper, guy.","comment_id":"1004551","upvote_count":"27","poster":"alohayo"},{"content":"I chose C because AWS Secrets Manager does auto key rotation(The question says that the key is one-time fixed).","poster":"hanJR","comment_id":"882201","upvote_count":"19","timestamp":"1698379020.0"},{"content":"Selected Answer: C\\nA) Eliminated - this solution involves additional complexity \\n\\nB) Eliminated - Secrets Manager charges a fee for secret storage and API calls. For one-time fixed license keys, this might be unnecessary overhead. Secrets Manager is more suited for dynamically rotated secrets (e.g., database credentials), not fixed keys.\\n\\nC) Correct: SecureString parameters are free to store unless using advanced features, making it highly cost-efficient.\\n\\nD) Eliminated - Parameters marked with NoEcho are limited to the stack and cannot be accessed programmatically by EC2 instances","upvote_count":"3","comment_id":"1330496","poster":"sumanshu","timestamp":"1734888780.0"},{"upvote_count":"1","comment_id":"1330453","timestamp":"1734884220.0","poster":"Freddie26","content":"Selected Answer: C\\n\\"One-time fixed license keys\\" are unique codes provided when purchasing a software license. It\'s more cost effective to provide this via AWS Systems Manager with secure parameters."},{"upvote_count":"1","timestamp":"1732213380.0","comment_id":"1215089","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer."},{"comment_id":"1184684","content":"It said \'one-time fixed license keys\' and \'MOST cost-effectively\', so C is better","timestamp":"1727510100.0","poster":"william_cit","upvote_count":"2"},{"content":"C seems the best fit.","upvote_count":"2","poster":"ibratoev","timestamp":"1727344860.0","comment_id":"1183279"},{"content":"PS prob is free for this use case https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-advanced-parameters.html, even though SM cost may also count to nothing(due to the scale of the use case and caching client). \\nAgain the only notable difference is the aforementioned irrelevant tag.","upvote_count":"3","timestamp":"1701839160.0","comment_id":"915861","poster":"s50600822"},{"upvote_count":"9","timestamp":"1695685980.0","comment_id":"850593","content":"Selected Answer: C\\nC\\n\'https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html","poster":"Untamables"}],"answer_description":"","extracted_at":"2025-12-24T09:06:47.131Z","extraction_method":"api_direct_v1"},{"question_id":"0j1hv6oaPayTsVD1jnHp","question_number":324,"page":65,"question_text":"A developer manages a website that distributes its content by using Amazon CloudFront. The website\'s static artifacts are stored in an Amazon S3 bucket.\\n\\nThe developer deploys some changes and can see the new artifacts in the S3 bucket. However, the changes do not appear on the webpage that the CloudFront distribution delivers.\\n\\nHow should the developer resolve this issue?","choices":{"D":"Set CloudFront to modify the distribution origin after the artifacts have been deployed to Amazon S3.","B":"Configure the S3 bucket to clear all old objects from the bucket before new artifacts are uploaded.","A":"Configure S3 Object Lock to update to the latest version of the files every time an S3 object is updated.","C":"Set CloudFront to invalidate the cache after the artifacts have been deployed to Amazon S3."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143800-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 15:29:00","unix_timestamp":1720790940,"discussion_count":4,"discussion":[{"poster":"preachr","upvote_count":"1","timestamp":"1728227640.0","comment_id":"1293889","content":"Selected Answer: C\\nWhen a user requests content from a website, CloudFront checks if the content is available in its cache. If the content is available in the cache, CloudFront delivers the content to the user from its cache. This speeds up the delivery of the content and reduces the load on the website\u2019s servers.\\n\\nHowever, if the content has changed on the website, the cached content in CloudFront will be outdated. To ensure that users receive the latest content, the cached content in CloudFront needs to be invalidated. This means that the cached content is removed from the CDN, and the next time a user requests the content, it is fetched from the website\u2019s servers."},{"content":"Selected Answer: C\\naws cloudfront create-invalidation --distribution-id EXAMPLE_DIST_ID --paths \\"/*\\"","upvote_count":"2","timestamp":"1722130860.0","poster":"albert_kuo","comment_id":"1256547"},{"timestamp":"1720825680.0","content":"C. Set CloudFront to invalidate the cache after the artifacts have been deployed to Amazon S3.","poster":"komorebi","upvote_count":"2","comment_id":"1247038"},{"comment_id":"1246778","poster":"rdiaz","timestamp":"1720790940.0","upvote_count":"2","content":"Selected Answer: C\\nBy invalidating the CloudFront cache, you ensure that the latest artifacts in your S3 bucket are delivered to users, resolving the issue of outdated content being displayed."}],"answer_description":"","extracted_at":"2025-12-24T09:06:47.131Z","extraction_method":"api_direct_v1"},{"question_id":"Qb14Vi7v8OX8fG4kWoWA","question_number":325,"page":65,"question_text":"A company has a development team that uses AWS CodeCommit for version control. The development team has CodeCommit repositories in multiple AWS accounts. The team is expanding to include developers who work in various locations.\\n\\nThe company must ensure that the developers have secure access to the repositories.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"D":"Use public SSH keys for authentication to the CodeCommit repositories.","B":"Configure permission sets in AWS IAM Identity Center to grant access to the accounts.","C":"Share AWS access keys with the development team for direct repository access.","A":"Configure IAM roles for each developer and grant access individually."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143081-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 22:09:00","unix_timestamp":1719691740,"discussion_count":2,"discussion":[{"content":"Selected Answer: B\\nB. Configure permission sets in AWS IAM Identity Center to grant access to the accounts.","upvote_count":"6","poster":"cachac","timestamp":"1719691740.0","comment_id":"1239396"},{"upvote_count":"3","comment_id":"1270191","content":"Selected Answer: B\\nB is best. AWS IAM Identity Center (formerly AWS Single Sign-On) provides a centralized way to manage access across multiple AWS accounts.\\n\\nA could work but it\'s not the most operationally efficient, especially for a growing team across multiple AWS accounts.","poster":"KennethNg923","timestamp":"1724251020.0"}],"answer_description":"","extracted_at":"2025-12-24T09:06:47.131Z","extraction_method":"api_direct_v1"},{"question_id":"aIR0dnvIxKd0GYIiiJjs","question_number":326,"page":66,"question_text":"A developer received the following error message during an AWS CloudFormation deployment:\\n\\nDELETE_FAILED (The following resource(s) failed to delete: [ASGInstanceRole12345678].)\\n\\nWhich action should the developer take to resolve this error?","choices":{"B":"Add a DependsOn attribute to the ASGInstanceRole12345678 resource in the CloudFormation template. Then delete the stack.","C":"Modify the CloudFormation template to retain the ASGInstanceRole12345678 resource. Then manually delete the resource after deployment.","A":"Contact AWS Support to report an issue with the Auto Scaling Groups (ASG) service.","D":"Add a force parameter when calling CloudFormation with the role-arn of ASGInstanceRole12345678."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143082-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 22:11:00","unix_timestamp":1719691860,"discussion_count":3,"discussion":[{"timestamp":"1728230220.0","upvote_count":"1","comment_id":"1293899","poster":"preachr","content":"Selected Answer: C\\nIf you are unable to automatically resolve the issue through CloudFormation, you may need to manually delete the IAM role.\\nGo to the IAM console, locate the role (ASGInstanceRole12345678), and manually delete any attached policies or instance profiles. Then, delete the role manually.\\nAfter manually deleting the role, you can retry the stack deletion process in CloudFormation."},{"content":"Selected Answer: C\\nResources:\\n ASGInstanceRole12345678:\\n Type: AWS::IAM::Role\\n DeletionPolicy: Retain","comment_id":"1293346","poster":"albert_kuo","timestamp":"1728107520.0","upvote_count":"1"},{"comment_id":"1239397","content":"Selected Answer: C\\nManually delete the ASGInstanceRole12345678 resource if it is no longer needed.","upvote_count":"2","timestamp":"1719691860.0","poster":"cachac"}],"answer_description":"","extracted_at":"2025-12-24T09:06:58.161Z","extraction_method":"api_direct_v1"},{"question_id":"eVlvl0xy5JWUxO1Q1xzN","question_number":327,"page":66,"question_text":"A company runs a critical application on Amazon Elastic Container Service (Amazon ECS) by using Amazon EC2 instances. The company needs to migrate the application to Amazon ECS on AWS Fargate. A developer is configuring Fargate and the ECS capacity providers to make the change.\\n\\nWhich solution will meet these requirements with the LEAST downtime during migration?","choices":{"B":"Use the CreateCapacityProvider API operation to associate the ECS cluster with the FARGATE and FARGATE_SPOT capacity provider strategies. Use FARGATE as Provider 1 with a base value. Use FARGATE_SPOT as Provider 2 for failover.","C":"Use the PutClusterCapacityProviders API operation to associate the ECS cluster with the FARGATE and FARGATE_SPOT capacity provider strategies. Use FARGATE_SPOT as Provider 1 with a base value. Use FARGATE as Provider 2 for failover.","A":"Use the PutClusterCapacityProviders API operation to associate the ECS cluster with the FARGATE and FARGATE_SPOT capacity provider strategies. Use FARGATE as Provider 1 with a base value. Use FARGATE_SPOT as Provider 2 for failover.","D":"Use the CreateCapacityProvider API operation to associate the ECS cluster with the FARGATE and FARGATE_SPOT capacity provider strategies. Use FARGATE_SPOT as Provider 1 with a base value. Use FARGATE as Provider 2 for failover."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143072-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 19:31:00","unix_timestamp":1719682260,"discussion_count":2,"discussion":[{"content":"Selected Answer: A\\n1. Provision with PutClusterCapacityProviders API \\naws ecs put-cluster-capacity-providers --cluster your-cluster-name --capacity-providers FARGATE FARGATE_SPOT --default-capacity-provider-strategy capacityProvider=FARGATE,base=1,weight=1 capacityProvider=FARGATE_SPOT,weight=1\\n\\n\\n2. Update ECS\\naws ecs update-service --cluster your-cluster-name --service your-service-name --force-new-deployment","comment_id":"1256589","upvote_count":"2","poster":"albert_kuo","timestamp":"1722144000.0"},{"comment_id":"1239366","content":"Selected Answer: A\\nBy following Option A, you ensure that your ECS tasks are reliably running on Fargate, with minimal downtime during the migration process. This strategy leverages the reliability of Fargate and the cost-effectiveness of Fargate Spot for non-critical workloads.","poster":"Alabi","timestamp":"1719682260.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:06:58.161Z","extraction_method":"api_direct_v1"},{"question_id":"ijjaCCclJrkhYQxQcLOK","question_number":328,"page":66,"question_text":"A company has a web application that is hosted on AWS. The application is behind an Amazon CloudFront distribution. A developer needs a dashboard to monitor error rates and anomalies of the CloudFront distribution as frequently as possible.\\n\\nWhich combination of steps should the developer take to meet these requirements? (Choose two.)","choices":{"D":"Stream the CloudFront distribution logs to Amazon Kinesis Data Firehose.","C":"Set up Amazon Kinesis Data Streams to send the logs to Amazon OpenSearch Service by using an AWS Lambda function. Make a dashboard in OpenSearch Dashboards.","E":"Set up Amazon Kinesis Data Firehose to send the logs to AWS CloudTrail. Create CloudTrail metrics, alarms, and dashboards.","B":"Enable real-time logs on the CloudFront distribution. Create a data stream in Amazon Kinesis Data Streams.","A":"Stream the CloudFront distribution logs to an Amazon S3 bucket. Detect anomalies and error rates by using Amazon Athena."},"correct_answer":"BC","answer_ET":"BC","answers_community":["BC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143083-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 22:18:00","unix_timestamp":1719692280,"discussion_count":2,"discussion":[{"upvote_count":"3","poster":"ahadh7621","content":"Selected Answer: BC\\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html#integrations-kinesis\\n\\nYou can use OpenSearch Ingestion to directly load streaming data into your Amazon OpenSearch Service domain, without needing to use third-party solutions.\\n\\nYou can load streaming data from Kinesis Data Streams to OpenSearch Service. New data that arrives in the data stream triggers an event notification to Lambda, which then runs your custom code to perform the indexing. \\n\\n\\nOnce the Lambda function is configured with Kinesis DataStreams, you can use OpenSearch Dashboards to create visualizations.","timestamp":"1721522760.0","comment_id":"1252082"},{"content":"Selected Answer: BC\\nreal-time logs + Kinesis Data Streams","poster":"cachac","timestamp":"1719692280.0","upvote_count":"2","comment_id":"1239399"}],"answer_description":"","extracted_at":"2025-12-24T09:06:58.161Z","extraction_method":"api_direct_v1"},{"question_id":"Sa2hb0q9UixBwBl1MkWA","question_number":329,"page":66,"question_text":"A developer creates an Amazon DynamoDB table. The table has OrderID as the partition key and NumberOfItemsPurchased as the sort key. The data type of the partition key and the sort key is Number.\\n\\nWhen the developer queries the table, the results are sorted by NumberOfItemsPurchased in ascending order. The developer needs the query results to be sorted by NumberOfItemsPurchased in descending order.\\n\\nWhich solution will meet this requirement?","choices":{"B":"Change the sort key from NumberOfItemsPurchased to NumberOfItemsPurchasedDescending.","C":"In the Query operation, set the ScanIndexForward parameter to false.","D":"In the Query operation, set the KeyConditionExpression parameter to false.","A":"Create a local secondary index (LSI) on the NumberOfItemsPurchased sort key."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143801-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 15:40:00","unix_timestamp":1720791600,"discussion_count":4,"discussion":[{"comment_id":"1256590","upvote_count":"1","poster":"albert_kuo","timestamp":"1722144360.0","content":"Selected Answer: C\\nimport boto3\\n\\ndynamodb = boto3.resource(\'dynamodb\')\\n\\ntable = dynamodb.Table(\'YourTableName\')\\n\\nresponse = table.query(\\n KeyConditionExpression=boto3.dynamodb.conditions.Key(\'OrderID\').eq(123),\\n ScanIndexForward=False # decending\\n)\\n\\nitems = response[\'Items\']\\nfor item in items:\\n print(item)"},{"poster":"ahadh7621","timestamp":"1721757960.0","upvote_count":"2","content":"Selected Answer: C\\nThis question was on my exam, July 23rd, 2024. Answer is C.","comment_id":"1253890"},{"content":"C. In the Query operation, set the ScanIndexForward parameter to false.","poster":"komorebi","timestamp":"1720825740.0","comment_id":"1247039","upvote_count":"1"},{"poster":"rdiaz","content":"Selected Answer: C\\nThis approach directly addresses the requirement without the need for creating additional indexes or modifying the table schema. It leverages the existing sorting capabilities of DynamoDB and provides a straightforward solution.","upvote_count":"1","comment_id":"1246787","timestamp":"1720791600.0"}],"answer_description":"","extracted_at":"2025-12-24T09:06:58.161Z","extraction_method":"api_direct_v1"},{"question_id":"onrxczHjyQcKB0F0jxd4","question_number":330,"page":66,"question_text":"A developer needs to use a code template to create an automated deployment of an application onto Amazon EC2 instances. The template must be configured to repeat deployment, installation, and updates of resources for the application. The template must be able to create identical environments and roll back to previous versions.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Use AWS AppSync to deploy the application. Upload the template as a GraphQL schema. Specify the EC2 instances for deployment of the application. Use resolvers as a version control mechanism and to make any updates to the deployments.","A":"Use AWS Amplify for automatic deployment templates. Use a traffic-splitting deployment to copy any deployments. Modify any resources created by Amplify, if necessary.","C":"Use AWS CloudFormation to create an infrastructure template in JSON format to deploy the EC2 instances. Use CloudFormation helper scripts to install the necessary software and to start the application. Call the scripts directly from the template.","B":"Use AWS CodeBuild for automatic deployment. Upload the required AppSpec file template. Save the appspec.yml file in the root directory folder of the revision. Specify the deployment group that includes the EC2 instances for the deployment."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144607-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-28 07:28:00","unix_timestamp":1722144480,"discussion_count":2,"discussion":[{"content":"Selected Answer: C\\nC is best","comment_id":"1257264","poster":"piipo","timestamp":"1722229200.0","upvote_count":"1"},{"timestamp":"1722213240.0","poster":"komorebi","content":"Selected Answer: C\\nAnsswer is C","upvote_count":"1","comment_id":"1257148"}],"answer_description":"","extracted_at":"2025-12-24T09:06:58.161Z","extraction_method":"api_direct_v1"},{"question_id":"OTdjCvMWm3HoHUHtjtxu","question_number":331,"page":67,"question_text":"A developer has a continuous integration and continuous delivery (CI/CD) pipeline that uses AWS CodeArtifact and AWS CodeBuild. The build artifacts are between 0.5 GB and 1.5 GB in size. The builds happen frequently and retrieve many dependencies from CodeArtifact each time.\\n\\nThe builds have been slow because of the time it takes to transfer dependencies. The developer needs to improve build performance by reducing the number of dependencies that are retrieved for each build.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Specify an Amazon S3 cache in CodeBuild. Add the S3 cache folder path to the buildspec.yaml file for the build project.","B":"Specify a local cache in CodeBuild. Add the CodeArtifact repository name to the buildspec.yaml file for the build project.","D":"Retrieve the buildspec.yaml file directly from CodeArtifact. Add the CodeArtifact repository name to the buildspec.yaml file for the build project.","C":"Specify a local cache in CodeBuild. Add the cache folder path to the buildspec.yaml file for the build project."},"correct_answer":"C","answer_ET":"C","answers_community":["C (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143073-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-29 19:41:00","unix_timestamp":1719682860,"discussion_count":4,"discussion":[{"poster":"Alabi","timestamp":"1719682860.0","upvote_count":"7","content":"Selected Answer: C\\nExplanation\\n\\nUsing a local cache in CodeBuild allows you to cache dependencies locally on the build host, which can significantly reduce the time it takes to retrieve dependencies during subsequent builds.","comment_id":"1239368"},{"poster":"Duke315","comment_id":"1262320","upvote_count":"1","timestamp":"1723095000.0","content":"Selected Answer: C\\nversion: 0.2\\n\\nphases:\\ninstall:\\nAnyone want cheaper contributor PDF then check certificationtest[.]net\\nUsing a local cache in CodeBuild allows you to cache dependencies locally on the build host, which can significantly reduce the time it takes to retrieve dependencies during subsequent builds."},{"content":"Selected Answer: C\\nupdate buildspec.yaml\\n\\nversion: 0.2\\n\\nphases:\\n install:\\n commands:\\n - echo Installing dependencies...\\n - pip install -r requirements.txt\\n build:\\n commands:\\n - echo Build started on `date`\\n - echo Compiling the Python code...\\n - python setup.py build\\n\\ncache:\\n paths:\\n - \'/root/.cache/pip/**/*\' # dependencies cache","poster":"albert_kuo","comment_id":"1256595","upvote_count":"1","timestamp":"1722144660.0"},{"content":"Selected Answer: B\\nC does not specify how to integrate it with CodeArtifact","upvote_count":"1","poster":"cachac","timestamp":"1719692820.0","comment_id":"1239407"}],"answer_description":"","extracted_at":"2025-12-24T09:07:09.375Z","extraction_method":"api_direct_v1"},{"question_id":"yw4OK6cIy825c1noW8j2","question_number":332,"page":67,"question_text":"A company that has large online business uses an Amazon DynamoDB table to store sales data. The company enabled Amazon DynamoDB Streams on the table. The transaction status of each sale is stored in a TransactionStatus attribute in the table. The value of the TransactionStatus attribute must be either failed, pending, or completed.\\n\\nThe company wants to be notified of failed sales where the Price attribute is above a specific threshold. A developer needs to set up notification for the failed sales.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"B":"Create an event source mapping between DynamoDB Streams and an AWS Lambda function. Configure the Lambda function handler code to publish to an Amazon Simple Notification Service (Amazon SNS) topic if sales fail when price is above the specified threshold.","D":"Create an Amazon CloudWatch alarm to monitor the DynamoDB Streams sales data. Configure the alarm to publish to an Amazon Simple Notification Service (Amazon SNS) topic if sales fail due when price is above the specified threshold.","C":"Create an event source mapping between DynamoDB Streams and an Amazon Simple Notification Service (Amazon SNS) topic. Use event filtering to publish to the SNS topic if sales fail when the price is above the specified threshold.","A":"Create an event source mapping between DynamoDB Streams and an AWS Lambda function. Use Lambda event filtering to trigger the Lambda function only if sales fail when the price is above the specified threshold. Configure the Lambda function to publish the data to an Amazon Simple Notification Service (Amazon SNS) topic."},"correct_answer":"A","answer_ET":"A","answers_community":["A (81%)","C (19%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143357-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-05 14:10:00","unix_timestamp":1720181400,"discussion_count":7,"discussion":[{"comment_id":"1249282","upvote_count":"5","timestamp":"1721167620.0","content":"Selected Answer: A\\nDynamoDB Streams cannot be directly mapped to SNS. This option is not feasible as described. So C is wrong.","poster":"Alagong"},{"comment_id":"1307034","timestamp":"1730742000.0","content":"why not D ??","poster":"Saudis","upvote_count":"2"},{"poster":"albert_kuo","content":"Selected Answer: A\\nLambda event filtering\\n\\n{\\n \\"eventName\\": [\\"MODIFY\\"],\\n \\"dynamodb.NewImage.TransactionStatus.S\\": [\\"failed\\"],\\n \\"dynamodb.NewImage.Price.N\\": [{\\"numeric\\": [\\">\\", 100]}]\\n}","comment_id":"1293662","timestamp":"1728175140.0","upvote_count":"2"},{"timestamp":"1721474280.0","upvote_count":"4","comment_id":"1251712","content":"Selected Answer: A\\nCorrection, answer should be A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-ddb","poster":"Anandesh"},{"poster":"siheom","upvote_count":"2","timestamp":"1720746720.0","comment_id":"1246405","content":"Selected Answer: A\\ndefinitely A"},{"comment_id":"1243906","timestamp":"1720366740.0","poster":"tomchandler077","upvote_count":"1","content":"A\\n\\nBy using event filtering, the Lambda function will only be triggered if the conditions (TransactionStatus is \'failed\' and Price is above the specified threshold) are met. This reduces unnecessary executions and simplifies the logic within the function."},{"poster":"Anandesh","upvote_count":"3","comment_id":"1242763","timestamp":"1720181400.0","content":"Selected Answer: C\\ndynamodb can be mapped as an event source to SNS. While creating the table, we can turn the stream on. We can push events to SNS topic and apply filter policy"}],"answer_description":"","extracted_at":"2025-12-24T09:07:09.375Z","extraction_method":"api_direct_v1"},{"question_id":"bXuxBSUpzwvHeVIjP2DL","question_number":333,"page":67,"question_text":"An AWS Lambda function is invoked asynchronously to process events. Occasionally, the Lambda function falls to process events. A developer needs to collect and analyze these failed events to fix the issue.\\n\\nWhat should the developer do to meet these requirements with the LEAST development effort?","choices":{"D":"Add a dead-letter queue to send messages to an Amazon Simple Notification Service (Amazon SNS) FIFO topic.","A":"Add logging statements for all events in the Lambda function. Filter AWS CloudTrail logs for errors.","B":"Configure the Lambda function to start an AWS Step Functions workflow with retries for failed events.","C":"Add a dead-letter queue to send messages to an Amazon Simple Queue Service (Amazon SQS) standard queue."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143802-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 15:49:00","unix_timestamp":1720792140,"discussion_count":4,"discussion":[{"poster":"0bdf3af","comment_id":"1388220","content":"Selected Answer: C\\nC. SQS\\nThe dead letter queue specified for the Lambda function is not compatible with the FIFO (First-In-First-Out) SNS topic. FIFO SNS topics are not supported for dead letter configuration in AWS Lambda.","timestamp":"1741852440.0","upvote_count":"1"},{"content":"Selected Answer: C\\nTo collect and analyze the failed events of an AWS Lambda function invoked asynchronously, the developer can leverage Lambda\'s built-in Dead Letter Queue (DLQ) feature with minimal development effort.","comment_id":"1294417","poster":"preachr","upvote_count":"1","timestamp":"1728322860.0"},{"comment_id":"1247040","timestamp":"1720825740.0","upvote_count":"3","poster":"komorebi","content":"C. Add a dead-letter queue to send messages to an Amazon Simple Queue Service (Amazon SQS) standard queue."},{"poster":"rdiaz","upvote_count":"3","timestamp":"1720792140.0","content":"Selected Answer: C\\nA dlq in SQS","comment_id":"1246796"}],"answer_description":"","extracted_at":"2025-12-24T09:07:09.375Z","extraction_method":"api_direct_v1"},{"question_id":"hquh8hPmnwGmeQpmXtK4","question_number":334,"page":67,"question_text":"A company is building a scalable data management solution by using AWS services to improve the speed and agility of development. The solution will ingest large volumes of data from various sources and will process this data through multiple business rules and transformations.\\nThe solution requires business rules to run in sequence and to handle reprocessing of data if errors occur when the business rules run. The company needs the solution to be scalable and to require the least possible maintenance.\\nWhich AWS service should the company use to manage and automate the orchestration of the data flows to meet these requirements?","choices":{"B":"AWS Step Functions","D":"AWS Lambda","C":"AWS Glue","A":"AWS Batch"},"correct_answer":"B","answer_ET":"B","answers_community":["B (89%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102789-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 10:17:00","unix_timestamp":1678958220,"discussion_count":33,"discussion":[{"poster":"geekdamsel","timestamp":"1683390060.0","upvote_count":"15","comment_id":"890862","content":"Got this question in exam.Correct answer is B."},{"comment_id":"1329452","timestamp":"1734700680.0","upvote_count":"2","poster":"sumanshu","content":"Selected Answer: B\\nAWS Step Functions is an orchestration service that is designed to manage and automate workflows","comments":[{"comments":[{"poster":"sumanshu","timestamp":"1734700740.0","upvote_count":"1","content":"B) Eliminated - AWS Glue is a managed ETL (Extract, Transform, Load) service that helps you prepare and transform data. While it can handle data processing, it does not provide the orchestration and workflow management features","comments":[{"comment_id":"1329457","poster":"sumanshu","content":"Sorry I mean C for above explanation\\n\\nD) Eliminated - it does not provide built-in orchestration or workflow management capabilities like AWS Step Functions","upvote_count":"1","timestamp":"1734700740.0"}],"comment_id":"1329454"}],"upvote_count":"1","content":"A) Eliminated - AWS Batch is great for running batch processing jobs, especially for large-scale computational workloads. However, it is not designed for orchestrating complex workflows","timestamp":"1734700680.0","comment_id":"1329453","poster":"sumanshu"}]},{"comment_id":"1324961","timestamp":"1733911860.0","poster":"trieudo","upvote_count":"2","content":"Selected Answer: B\\nI think those keyword when pick B: scalable, sequence, reprocessing of data if errors, least possible maintenance"},{"comment_id":"1222765","timestamp":"1717257420.0","content":"Selected Answer: B\\nB is correct answer.","upvote_count":"1","poster":"NagaoShingo"},{"content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716295680.0","comment_id":"1214950"},{"upvote_count":"2","timestamp":"1712670900.0","comment_id":"1192315","poster":"Dikshika","content":"Selected Answer: B\\nits clearly mention orchestration , sequence and multiple processing and transformations"},{"content":"Selected Answer: B\\nStepFunctions, es el servicio recomedado para orquestar. B correcto","timestamp":"1712440320.0","upvote_count":"1","poster":"vinfo","comment_id":"1190631"},{"content":"Selected Answer: B\\nB is correct","upvote_count":"1","poster":"ibratoev","comment_id":"1182550","timestamp":"1711376040.0"},{"comment_id":"1084986","upvote_count":"3","poster":"alven_alinan","content":"Selected Answer: B\\nAnswer is B. Step Function is about orchestrating workflows","timestamp":"1701411900.0"},{"timestamp":"1699079580.0","poster":"dongocanh272","comment_id":"1061932","content":"Selected Answer: B\\nMy answer is B","upvote_count":"1"},{"poster":"Digo30sp","timestamp":"1696703760.0","content":"Selected Answer: B\\nB is correct","comment_id":"1027588","upvote_count":"1"},{"upvote_count":"1","comment_id":"1021375","content":"Best option: B","timestamp":"1696066860.0","poster":"NinjaCloud"},{"upvote_count":"1","content":"Selected Answer: B\\nb init","comment_id":"1002365","poster":"panoptica","timestamp":"1694169480.0"},{"content":"The answer is B(Step Functions). For people confused with AWS Lambda, it is a compute service and can be used within Step Functions, but it alone does not provide the orchestration and error handling features required in this case.","comment_id":"998633","upvote_count":"3","poster":"sharma_ps93","timestamp":"1693840200.0"},{"upvote_count":"1","comment_id":"995106","timestamp":"1693484880.0","content":"Selected Answer: D\\ncheck the link below:\\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/orchestration.html","poster":"casharan"},{"poster":"hmdev","comment_id":"992307","timestamp":"1693233960.0","content":"Selected Answer: B\\nYou can use Step functions to create a workflow of functions that should be invoked in a sequence. You can also push output from one one-step function and use it as an input for next-step function. Also, Step functions have very useful Retry and Catch -> error-handling features.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1691547600.0","poster":"jayvarma","comment_id":"976173","content":"Keyword: run in sequence and to handle reprocessing of data. So, answer is option B. And also each task in a step function can be handled by a different AWS Service such as AWS Lambda or AWS Glue which is used for ETL jobs."},{"content":"Selected Answer: B\\nI\'m thinking B","poster":"elfinka9","comment_id":"968778","upvote_count":"1","timestamp":"1690871280.0"},{"comment_id":"945549","timestamp":"1688724360.0","upvote_count":"1","content":"Selected Answer: D\\nD is the right answer","poster":"Suvomita"},{"upvote_count":"1","timestamp":"1687428300.0","poster":"MatthewHuiii","comment_id":"930363","content":"B is correct"},{"timestamp":"1685706300.0","poster":"Baba_Eni","content":"Selected Answer: B\\nAll the key words of the question points at Step Function, check the link below:\\n\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/welcome.html","comment_id":"912781","upvote_count":"2"},{"upvote_count":"1","comment_id":"910338","timestamp":"1685457780.0","content":"B is correct","poster":"ricky536"},{"content":"Selected Answer: B\\nEasily B","comment_id":"883805","poster":"ihebchorfi","timestamp":"1682704800.0","upvote_count":"1"},{"timestamp":"1682378460.0","poster":"MrTee","content":"Selected Answer: B\\nOption B is the correct choice. AWS Step Functions allows you to coordinate multiple AWS services into serverless workflows so you can build and update apps quickly. It also provides a way to handle errors and retry failed steps, making it a good fit for the company\u2019s requirements.","comment_id":"879768","upvote_count":"2"},{"comment_id":"870847","timestamp":"1681555980.0","poster":"MrTee","content":"Selected Answer: C\\nQuestion talks of ingesting huge volumes of data and orchestrating data flows, keywords for aws glue. I go with C","comments":[{"timestamp":"1682954400.0","content":"Glue is an ETL tool it is not for orchestration of data flows, Step Function is for orchestration I think Glue is not the best option here.","poster":"rlnd2000","comment_id":"886434","upvote_count":"2"}],"upvote_count":"1"},{"comment_id":"857915","upvote_count":"2","timestamp":"1680353820.0","content":"Selected Answer: B\\nB is correct","poster":"ihta_2031"},{"poster":"March2023","timestamp":"1679787660.0","upvote_count":"2","content":"Selected Answer: B\\nim going with B","comment_id":"850556"},{"upvote_count":"2","comment_id":"845432","content":"Selected Answer: B\\nB\\nThe requirement is the orchestration of the data flows, not data.","timestamp":"1679362560.0","poster":"Untamables"},{"upvote_count":"2","timestamp":"1679355360.0","content":"Selected Answer: B\\nIt is B","comment_id":"845350","poster":"svrnvtr"},{"upvote_count":"1","content":"The answer is C, Glue is an ETL service where data processing code is pushed then multiple crawler jobs are setup to import the data from different sources. So I go with \u2018C\u2019.","timestamp":"1679290920.0","poster":"Warlord_92","comment_id":"844564"},{"poster":"clarksu","content":"Selected Answer: B\\nNo brainer B.\\n\\n`manage and automate the orchestration` is the key , it is not about the processing data jobs itself, but the management","upvote_count":"2","comment_id":"842402","timestamp":"1679102340.0"},{"poster":"m4r0ck","comment_id":"841481","upvote_count":"1","content":"Selected Answer: C\\nThe answer is clearly C. Glue is an ETL that can process large volume of data and is scalable https://docs.aws.amazon.com/glue/latest/dg/auto-scaling.html","timestamp":"1679015880.0"},{"upvote_count":"2","poster":"haaris786","comment_id":"840743","content":"It can\'t be anything other than B.","comments":[{"timestamp":"1679015940.0","content":"how come B is the answer ??? Step functions do not do data transformation!","comment_id":"841483","upvote_count":"1","poster":"m4r0ck"},{"poster":"m4r0ck","timestamp":"1679016060.0","upvote_count":"1","content":"https://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html","comment_id":"841487","comments":[{"upvote_count":"1","poster":"CapJackSparrow","content":"I too thought it was glue, but that is because of the pre-amble. What it does.. but the question is HOW to orchestrate the job.","comment_id":"846545","timestamp":"1679446980.0"}]}],"timestamp":"1678958220.0"}],"answer_description":"","extracted_at":"2025-12-24T09:07:09.375Z","extraction_method":"api_direct_v1"},{"question_id":"r2TPNok34ttSzNKGAnvn","question_number":335,"page":67,"question_text":"A company has deployed infrastructure on AWS. A development team wants to create an AWS Lambda function that will retrieve data from an Amazon Aurora database. The Amazon Aurora database is in a private subnet in company\'s VPC. The VPC is named VPC1. The data is relational in nature. The Lambda function needs to access the data securely.\\nWhich solution will meet these requirements?","choices":{"A":"Create the Lambda function. Configure VPC1 access for the function. Attach a security group named SG1 to both the Lambda function and the database. Configure the security group inbound and outbound rules to allow TCP traffic on Port 3306.","D":"Export the data from the Aurora database to Amazon S3. Create and launch a Lambda function in VPC1. Configure the Lambda function query the data from Amazon S3.","B":"Create and launch a Lambda function in a new public subnet that is in a new VPC named VPC2. Create a peering connection between VPC1 and VPC2.","C":"Create the Lambda function. Configure VPC1 access for the function. Assign a security group named SG1 to the Lambda function. Assign a second security group named SG2 to the database. Add an inbound rule to SG1 to allow TCP traffic from Port 3306."},"correct_answer":"A","answer_ET":"A","answers_community":["A (65%)","C (28%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103523-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-21 22:47:00","unix_timestamp":1679435220,"discussion_count":33,"discussion":[{"timestamp":"1701927240.0","comment_id":"1089964","comments":[{"comments":[{"upvote_count":"3","comment_id":"1327958","content":"SG1 is for the lambda, SG2 is for the database. In option C it says setting inbound traffic for the SG1 on TCP port 3306. But it should be setting inbound traffic for SG2 on TCP port 3306.","poster":"Yuri_024","timestamp":"1734446340.0"}],"upvote_count":"1","poster":"9d8dd9c","comment_id":"1299222","timestamp":"1729170120.0","content":"But aren\'t the routing on SGs state-full so allowing inbound allows outbound too? or am I confusing that with something else?"}],"upvote_count":"10","content":"ooooh this one was rough. I am going with A --\x3e https://repost.aws/knowledge-center/connect-lambda-to-an-rds-instance\\n\\nI was between A and C... wording for both tricky. But the only way C would work is if the last portion of the sentence the read \\"Add an inbound rule to SG2 to allow TCP traffic from port 3306\\" or \\"Add an outbound rule to SG1 to allow TCP traffic... \\"","poster":"[Removed]"},{"comment_id":"854015","upvote_count":"7","poster":"shahs10","timestamp":"1680065580.0","content":"Selected Answer: A\\nCorrect Answer is Answer A\\nFor B creating new VPC for lambda does not seems a suitable solution\\nFor C Assigning differrent security groups to both will not work\\nOption D will not be suitable for relational data and involve S3 in solution"},{"timestamp":"1734889080.0","upvote_count":"1","poster":"sumanshu","comment_id":"1330497","content":"Selected Answer: A\\nB) Eliminated - Placing the Lambda function in a public subnet compromises security\\n\\nC) Eliminated - The rule should allow traffic to SG2 (the database\u2019s security group) from SG1 (the Lambda function\u2019s security group), not the other way around.\\n\\nD) Eliminated - Adds significant operational complexity"},{"poster":"wh1t4k3r","comment_id":"1267243","upvote_count":"2","timestamp":"1723823340.0","content":"this one is badly written hehe\\nI would say A, but they missed to mention that this only works securely if the secgroup is listed as destination of the rules.\\nB would also work, but you need to properly configure it...."},{"comment_id":"1260610","content":"Correction answer should be option C. Lambda function, configure VPC1 access, and assign separate security groups:\\nLambda Function: Associate the Lambda function with VPC1.\\nSecurity Group (SG1): Assign SG1 to the Lambda function.\\nSecurity Group (SG2): Assign a second security group (SG2) to the Aurora database.\\nInbound Rule: Add an inbound rule to SG1 to allow TCP traffic from Port 3306 (Aurora database port).\\nThis approach ensures proper separation of concerns and simplifies security group management.","upvote_count":"1","poster":"Saurabh04","timestamp":"1722766140.0"},{"comment_id":"1231690","poster":"tsangckl","content":"This appear at 17 Jun exam","upvote_count":"4","timestamp":"1718595240.0"},{"content":"Selected Answer: A\\nA is the correct answer.","comment_id":"1215091","upvote_count":"2","poster":"65703c1","timestamp":"1716309060.0"},{"poster":"ibratoev","content":"A seems the answer, although a single SG for both the DB and Lambda is not a great practice. I would go with 2 SGs.","comment_id":"1183281","timestamp":"1711454760.0","upvote_count":"3"},{"upvote_count":"3","comment_id":"1165779","timestamp":"1709568240.0","poster":"TheFivePips","content":"Selected Answer: A\\nSecurity groups are statefull so you dont need to specify both inbound and outbound rules. However, you should have security groups on both resources as a best practice, and I dont think it is enough to have an inbound rule just on the lambda security group in this case. \\nThis would essentially give the DB access to send traffic to the lambda function, rather than the lambda function accessing data from the DB like we want. If the lambda function doesnt have a permission on its security group letting it access the DB, then it will never communicate with it unless the DB contacts it first.\\nIf C had placed the inbound permission on the DB, or if it had placed the outbound permission on the lambda then I think it would be right.\\nSo while the wording is a little confusing, I think A is correct"},{"upvote_count":"2","comment_id":"1056067","poster":"quanghao","timestamp":"1698483120.0","content":"Selected Answer: B\\nA Lambda function and RDS instance in different VPCs\\nFirst, use VPC peering to connect the two VPCs. Then, use the networking configurations to connect the Lambda function in one VPC to the RDS instance in the other:"},{"comment_id":"1048330","timestamp":"1697770980.0","content":"Selected Answer: B\\nThis is the only one where lambda can reach the Database anyway, seems to me a prerequisite if the VPC was mentioned. Lambda by default, launched outside your VPC (in an AWS-owned VPC) so it cannot access resources.","upvote_count":"1","comments":[{"comment_id":"1089949","timestamp":"1701924060.0","upvote_count":"1","content":"if it were private maybe... but public so this answer definitely wrong","poster":"[Removed]"}],"poster":"hcsaba1982"},{"poster":"dexdinh91","timestamp":"1697518500.0","comment_id":"1045525","upvote_count":"1","content":"Selected Answer: B\\nB is correct?"},{"comments":[{"comment_id":"1089955","content":"C the wording throws me off... Because the inbound rule in the end of the statement should be to the database not SG1. so we want to allow lambda access to the DB... The way this option is worded is not really giving lambda access to the db... it\'s giving DB access to lambda but not the other way around which we need. So leaning with A","poster":"[Removed]","upvote_count":"1","timestamp":"1701925020.0"}],"content":"Selected Answer: C\\nC, need 2 SG","timestamp":"1697088720.0","comment_id":"1041389","upvote_count":"2","poster":"quanbui"},{"timestamp":"1695248520.0","comments":[{"comment_id":"1136794","poster":"konieczny69","content":"nonsense\\nwhy would anyone want sql application port access to lambda??\\n\\nA is the only naswer","upvote_count":"2","timestamp":"1706708400.0"}],"comment_id":"1012640","content":"Selected Answer: C\\nNeed two security groups. One is for Lambda function. The other one is for DB","poster":"sofiatian","upvote_count":"1"},{"content":"A. right\\nB. public, unsecure\\nC. excessive connections\\nD. additional cost and complexity","comment_id":"1003533","timestamp":"1694299680.0","poster":"hsinchang","upvote_count":"3"},{"poster":"love777","content":"Selected Answer: A\\nVPC Configuration:\\n\\nEnsure that your Lambda function is configured to run within the same VPC where your Amazon Aurora database resides (VPC1 in this case).\\nConfigure the Lambda function to use the appropriate subnets within VPC1, which are associated with the private subnet where your Amazon Aurora database is located.\\nSecurity Groups:\\n\\nAttach a security group (SG1) to both the Lambda function and the Amazon Aurora database.\\nConfigure the security group inbound rules for SG1 to allow incoming TCP traffic on Port 3306, which is the default port for MySQL (used by Aurora). This will allow communication between the Lambda function and the database.\\nOutbound rules should be allowed by default, so you don\'t need to make any changes there.","upvote_count":"2","comment_id":"990274","timestamp":"1692984780.0"},{"timestamp":"1692429660.0","content":"Selected Answer: A\\nThere isn\'t the ideal solution to the use case among the options.\\n\\nB) no need to create a new VPC and also you need to add route tables and configure SGs to make it works\\nC) this could work if the rule on SG1 was outbound instead of inbound (the connection is initiated from Lambda to Aurora)\\nD) export data to S3 is overkill and if you do that you no longer need to deploy the lambda in the VPC\\n\\nA) works, as SG1 is attached to both Lambda and Aurora we need outbound rule to 3306 (Lambda initiate communication to Aurora) and also inbound rule from 3306 (to allow Aurora accept connection from Lambda). I don\'t like to have the same SG1 for both the Lambda and the Aurora","comment_id":"985035","upvote_count":"5","poster":"ninomfr64"},{"upvote_count":"2","comment_id":"958267","poster":"AWSdeveloper08","timestamp":"1689931500.0","content":"Selected Answer: C\\nhttps://www.youtube.com/watch?v=UgWjbSixRg4&ab_channel=DevProblems"},{"comment_id":"955143","poster":"ancomedian","content":"Selected Answer: C\\nThe correct answer is C\\nhttps://www.youtube.com/watch?v=UgWjbSixRg4","timestamp":"1689668580.0","upvote_count":"3"},{"timestamp":"1688039280.0","content":"It seems it is A but as I know we don\u2019t need to create outbound rules when we return something. So why it is A ?","comments":[{"upvote_count":"2","content":"Nevermind. We need it to let Lambda to make outbound request","poster":"awsazedevsh","timestamp":"1688750340.0","comment_id":"945889"}],"upvote_count":"1","poster":"awsazedevsh","comment_id":"938007"},{"content":"The correct answer is C\\nhttps://www.youtube.com/watch?v=UgWjbSixRg4","comments":[{"comment_id":"933705","content":"For B (There is no need to create another VPC, since we can simply add a lambda to a VPC with private subnets)\\nFor A (Security Group (SG) is stateless. By using NACL we can do outbound and inbound rules modification + SG is used to give access, if you keep both Lambda and DB in same same SG, if you try to give access of lambda to another resource, that another resource will automatically gets the RDS access - which is out of question)","upvote_count":"2","timestamp":"1687705080.0","poster":"umer1998"}],"timestamp":"1687704840.0","poster":"umer1998","upvote_count":"1","comment_id":"933703"},{"timestamp":"1686998160.0","upvote_count":"1","content":"Selected Answer: C\\nC is correct, \\nA is a wrong choice, how to config outbound rules in SG? :)","poster":"rlnd2000","comment_id":"925911"},{"content":"I think B ,\\n\\nplease verify this guys,\\n\\nhttps://repost.aws/en/knowledge-center/connect-lambda-to-an-rds-instance#:~:text=Lambda%27s%20subnets%27%20CIDRs.-,A%20Lambda%20function%20and%20RDS%20instance%20in%20different%20VPCs,function%20in%20one%20VPC%20to%20the%20RDS%20instance%20in%20the%20other,-%3A","upvote_count":"2","poster":"kavi00203","comment_id":"922844","timestamp":"1686727260.0"},{"poster":"Nagendhar","timestamp":"1684121640.0","upvote_count":"2","comment_id":"898019","content":"Ans: C\\n\\nTo access the Amazon Aurora database in a private subnet of VPC1, the Lambda function should be launched inside the same VPC1 and should have access to that VPC."},{"comments":[{"comment_id":"900425","content":"Answer C allows inbound traffic to SG1 which is attached to the Lambda function. The Lambda function does not need inbound traffic allowed inbound on port 3306 - the database does. Also, while you do not need to configure outbound rules for *return* traffic, you DO need to configure outbound rules if the Lambda function is *initiating* the traffic - which in this case it is. Therefore, the answer is A.","timestamp":"1684345740.0","poster":"yeacuz","upvote_count":"4"},{"poster":"AgboolaKun","content":"After further research on this question, I agree that Answer A is the right answer. The scenario described in this question is similar to the example explanation in this repost: https://repost.aws/knowledge-center/connect-lambda-to-an-rds-instance\\n\\nAn outbound rule is indeed required in this situation, therefore, answer C is wrong.","comment_id":"907006","timestamp":"1685069400.0","upvote_count":"2"}],"poster":"AgboolaKun","comment_id":"896159","content":"Selected Answer: C\\nAnswers B and D are obviously incorrect. \\n\\nAnswer A is wrong because you do not need to configure outbound rule for security groups. Security groups are stateful, meaning you do not need to add rules for return.\\n\\nTherefore, the correct answer is C.","timestamp":"1683916020.0","upvote_count":"3"},{"content":"Selected Answer: A\\nC is incorrect, because it\'s missing the step where both security groups need to allow access to each other","upvote_count":"3","timestamp":"1682112300.0","comment_id":"876833","poster":"awsdummie"},{"upvote_count":"4","timestamp":"1682078520.0","poster":"Rpod","comment_id":"876491","content":"Selected Answer: A\\nCorrect Answer is Answer A"},{"comment_id":"867632","comments":[{"upvote_count":"2","comment_id":"894830","content":"I think C is incorrect. because it doesn\'t set the outbound rule","timestamp":"1683792540.0","poster":"stlim83"}],"upvote_count":"2","timestamp":"1681242420.0","content":"Selected Answer: C\\nYou must create two security groups, one for the lambda ENI and another for the RDS, the same SG for both won\'t work.\\n\\nhttps://repost.aws/knowledge-center/connect-lambda-to-an-rds-instance\\n\\nhttps://medium.com/@Oldmanyellingatcloud/how-to-connect-your-lambda-function-securely-to-your-private-rds-instances-in-your-vpc-29789220a33","poster":"rlnd2000"},{"content":"Selected Answer: A\\nThe correct answer is A.\\nI agree with Watascript.","comment_id":"850596","timestamp":"1679792160.0","poster":"Untamables","upvote_count":"4"},{"poster":"DenMaslov","content":"Based on the requirement to access the Amazon Aurora database securely from the Lambda function, the correct solution is A. The Lambda function needs to be configured to access resources in VPC1, where the database is located. A security group (SG1) should be attached to both the Lambda function and the database, and the inbound and outbound rules of SG1 should allow TCP traffic on port 3306 to enable communication between the Lambda function and the database. This approach ensures that the connection between the Lambda function and the database is secure and the data is accessed only through the allowed port.","timestamp":"1679779920.0","comment_id":"850476","upvote_count":"3"},{"comment_id":"850132","content":"Selected Answer: A\\nA?\\nhttps://repost.aws/en/knowledge-center/connect-lambda-to-an-rds-instance","poster":"Watascript","upvote_count":"6","timestamp":"1679748660.0"},{"timestamp":"1679595120.0","upvote_count":"1","content":"Selected Answer: C\\nI think its C as well","comment_id":"848539","poster":"March2023"},{"upvote_count":"1","poster":"svrnvtr","comment_id":"846396","content":"Selected Answer: C\\nMay be C","comments":[{"poster":"Dun6","upvote_count":"1","comment_id":"847591","timestamp":"1679526180.0","content":"I was thinking C too but the second security group throws me off"}],"timestamp":"1679435220.0"}],"answer_description":"","extracted_at":"2025-12-24T09:07:09.375Z","extraction_method":"api_direct_v1"},{"question_id":"FO7TMbzJjMIYeMYVPd3d","question_number":336,"page":68,"question_text":"A company has an application that uses an Amazon S3 bucket for object storage. A developer needs to configure in-transit encryption for the S3 bucket. All the S3 objects containing personal data needs to be encrypted at rest with AWS Key Management Service (AWS KMS) keys, which can be rotated on demand.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"E":"Configure S3 Block Public Access settings for the S3 bucket to allow only encrypted connections over HTTPS.","D":"Write an S3 bucket policy to allow only encrypted connections over HTTPS by using the aws:SecureTransport condition.","A":"Write an S3 bucket policy to allow only encrypted connections over HTTPS by using permissions boundary.","B":"Configure an S3 bucket policy to enable client-side encryption for the objects containing personal data by using an AWS KMS customer managed key.","C":"Configure the application to encrypt the objects by using an AWS KMS customer managed key before uploading the objects containing personal data to Amazon S3."},"correct_answer":"CD","answer_ET":"CD","answers_community":["CD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143803-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-12 15:50:00","unix_timestamp":1720792200,"discussion_count":2,"discussion":[{"comment_id":"1247041","content":"C. Configure the application to encrypt the objects by using an AWS KMS customer managed key before uploading the objects containing personal data to Amazon S3.\\nD. Write an S3 bucket policy to allow only encrypted connections over HTTPS by using the aws:SecureTransport condition.","poster":"komorebi","upvote_count":"2","timestamp":"1720825800.0"},{"timestamp":"1720792200.0","poster":"rdiaz","upvote_count":"4","comment_id":"1246797","content":"Selected Answer: CD\\nTo achieve the requirements of ensuring encryption in transit and at rest for the S3 bucket with AWS KMS keys, the most suitable steps are:\\n\\nD: Enforce HTTPS connections to ensure encryption in transit.\\nC: Configure encryption with AWS KMS for encryption at rest."}],"answer_description":"","extracted_at":"2025-12-24T09:07:20.146Z","extraction_method":"api_direct_v1"},{"question_id":"hVs4MlLt1bwf3ejr5fy7","question_number":337,"page":68,"question_text":"A company has a monolithic desktop-based application that processes images. A developer is converting the application into an AWS Lambda function by using Python. Currently, the desktop application runs every 5 minutes to process the latest image from an Amazon S3 bucket. The desktop application completes the image processing task within 1 minute.\\n\\nDuring testing on AWS, the developer notices that the Lambda function runs at the specified 5-minute interval. However, the Lambda function takes more than 2 minutes to complete the image processing task. The developer needs a solution that will improve the Lambda function\'s performance.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Increase the memory that is allocated to the Lambda function.","D":"Configure a reserved concurrency on the Lambda function.","B":"Update the configuration of the Lambda function to use the latest Python runtime.","A":"Update the instance type of the Lambda function to a compute optimized instance with at least eight virtual CPU (vCPU)."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143029-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-28 21:19:00","unix_timestamp":1719602340,"discussion_count":2,"discussion":[{"comment_id":"1238864","timestamp":"1719602340.0","upvote_count":"7","content":"Selected Answer: C\\nBy increasing the memory allocation, you leverage more CPU power for your Lambda function, which is likely to reduce the processing time and meet your performance requirements.","poster":"Alabi"},{"timestamp":"1723729020.0","poster":"7368e4a","comment_id":"1266473","upvote_count":"1","content":"Selected Answer: C\\nmemory"}],"answer_description":"","extracted_at":"2025-12-24T09:07:20.146Z","extraction_method":"api_direct_v1"},{"question_id":"XNDYXvKKFlMrUE8vVdZU","question_number":338,"page":68,"question_text":"A company uses AWS CloudFormation templates to manage infrastructure for a public-facing application in its development, pre-production, and production environments. The company needs to scale for increasing customer demand. A developer must upgrade the Amazon RDS DB instance type to a larger instance.\\n\\nThe developer deploys an update to the CloudFormation stack with the instance size change in the pre-production environment. The developer notices that the stack is in an UPDATE_ROLLBACK_FAILED slate in CloudFormation.\\n\\nWhich option is the cause of this issue?","choices":{"C":"There is a syntax error in the CloudFormation template","D":"The developer has insufficient IAM permissions to provision an instance of the specified type","B":"The database was deleted or modified manually outside of the CloudFormation stack","A":"The new instance type specified in the CloudFormation template is invalid"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143030-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-06-28 21:20:00","unix_timestamp":1719602400,"discussion_count":2,"discussion":[{"poster":"Alabi","content":"Selected Answer: B\\nWhen CloudFormation encounters an issue during the stack update process, it attempts to roll back to the previous state. If resources have been modified or deleted outside of CloudFormation, the rollback process can fail, resulting in the UPDATE_ROLLBACK_FAILED state.","comment_id":"1238867","upvote_count":"5","timestamp":"1719602400.0"},{"poster":"Anandesh","content":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-continueupdaterollback.html","comment_id":"1240611","timestamp":"1719904800.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:07:20.146Z","extraction_method":"api_direct_v1"},{"question_id":"yJROl1sWasRmJjnihmJp","question_number":339,"page":68,"question_text":"A developer needs to store files in an Amazon S3 bucket for a company\'s application. Each S3 object can have multiple versions. The objects must be permanently removed 1 year after object creation.\\n\\nThe developer creates an S3 bucket that has versioning enabled.\\n\\nWhat should the developer do next to meet the data retention requirements?","choices":{"A":"Create an S3 Lifecycle rule on the S3 bucket. Configure the rule to expire current versions of objects and permanently delete noncurrent versions 1 year after object creation.","C":"Create an event notification for all object removal events in the S3 bucket. Configure the event notification to invoke an AWS Lambda function. Program the Lambda function to check the object creation date and to delete the object if the object is older than 1 year.","B":"Create an event notification for all object creation events in the S3 bucket. Configure the event notification to invoke an AWS Lambda function. Program the Lambda function to check the object creation date and to delete the object if the object is older than 1 year.","D":"Create an S3 Lifecycle rule on the S3 bucket. Configure the rule to delete expired object delete markers and permanently delete noncurrent versions 1 year after object creation."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144455-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-23 20:07:00","unix_timestamp":1721758020,"discussion_count":1,"discussion":[{"poster":"ahadh7621","upvote_count":"5","comment_id":"1253891","timestamp":"1721758020.0","content":"Selected Answer: A\\nThis question was on my exam, July 23rd, 2024. Answer is A."}],"answer_description":"","extracted_at":"2025-12-24T09:07:20.146Z","extraction_method":"api_direct_v1"},{"question_id":"IQUXQAMJaJQSYEYycmd7","question_number":340,"page":68,"question_text":"A company uses AWS X-Ray to monitor a serverless application. The components of the application have different request rates. The user interactions and transactions are important to trace, but they are low in volume. The background processes such as application health checks, polling, and connection maintenance generate high volumes of read-only requests.\\n\\nCurrently, the default X-Ray sampling rules are universal for all requests. Only the first request per second and some additional requests are recorded. This setup is not helping the company review the requests based on service or request type.\\n\\nA developer must configure rules to trace requests based on service or request properties. The developer must trace the user interactions and transactions without wasting effort recording minor background tasks.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Disable sampling and trace all requests for requests that handle user interactions or transactions. Sample high-volume read-only requests at a lower rate.","A":"Disable sampling for high-volume read-only requests. Sample at a lower rate for all requests that handle user interactions or transactions.","B":"Disable sampling and trace all requests for requests that handle user interactions or transactions. Sample high-volume read-only requests at a higher rate.","D":"Disable sampling for high-volume read-only requests. Sample at a higher rate for all requests that handle user interactions or transactions."},"correct_answer":"C","answer_ET":"C","answers_community":["C (58%)","D (42%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144274-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-20 18:52:00","unix_timestamp":1721494320,"discussion_count":5,"discussion":[{"poster":"KennethNg923","upvote_count":"5","content":"Selected Answer: C\\n1. Ensures all important user interactions and transactions are traced (by disabling sampling for these).\\n2. Reduces the sampling rate for high-volume background tasks, which helps avoid wasting resources on less important requests.","timestamp":"1724245380.0","comment_id":"1270132"},{"timestamp":"1741531380.0","comment_id":"1371560","content":"Selected Answer: D\\nD. Sampling for user requests - transactions and and interactions and disable tracing healthckes and so on. X-Ray answears for the question asked by user \\"why it took it so long?\\" \\nC is not correct answear, because recording ALL requests (even low-volume requests) is overwhelming for the system","upvote_count":"1","poster":"0bdf3af"},{"upvote_count":"2","content":"Selected Answer: C\\nC: trace everything, not sample it.","timestamp":"1722233760.0","comment_id":"1257293","poster":"piipo"},{"comment_id":"1252725","upvote_count":"2","content":"It\u2019s C","timestamp":"1721597880.0","poster":"catoteja"},{"content":"Selected Answer: D\\nD is correct\\nChatgpt explanation\\nFocus on Important Traces: By disabling sampling for high-volume read-only requests such as health checks, polling, and connection maintenance, you can prevent these low-priority requests from overwhelming the tracing system. This ensures that the system resources are conserved for more critical user interactions and transactions.\\n\\nHigher Sampling Rate for User Interactions: By sampling at a higher rate for requests that handle user interactions or transactions, you can ensure that these important requests are traced more comprehensively. This allows for better monitoring and troubleshooting of the application where it matters most.\\n\\nSelective Tracing: This approach allows you to selectively trace and monitor requests based on their importance and volume. High-volume background tasks are sampled minimally or not at all, while low-volume but critical user interactions and transactions are sampled more frequently.","upvote_count":"4","comment_id":"1251852","timestamp":"1721494320.0","poster":"Mo_1981"}],"answer_description":"","extracted_at":"2025-12-24T09:07:20.146Z","extraction_method":"api_direct_v1"},{"question_id":"Zk1Nht23mV6jGfdlyFAG","question_number":341,"page":69,"question_text":"A developer uses an AWS Lambda function in an application to edit users\' uploaded photos. The developer needs to update the Lambda function code and needs to test the updates.\\n\\nFor testing, the developer must divide the user traffic between the original version of the Lambda function and the new version of the Lambda function.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"D":"Create an alias that points to the original version of the Lambda function. Configure the alias to be a weighted alias that also includes the new version of the Lambda function. Divide traffic between the two versions.","E":"Create an alias that points to the original function URL. Configure the alias to be a weighted alias that also includes the additional function URL. Divide traffic between the two function URLs.","A":"Publish a version of the original Lambda function. Make the necessary changes to the Lambda code. Publish a new version of the Lambda function.","C":"Update the original version of the Lambda function to add a function URL. Make the necessary changes to the Lambda code. Publish another function URL for the updated Lambda code.","B":"Use AWS CodeBuild to detect updates to the Lambda function. Configure CodeBuild to incrementally shift traffic from the original version of the Lambda function to the new version of the Lambda function."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144673-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-29 08:20:00","unix_timestamp":1722234000,"discussion_count":3,"discussion":[{"content":"Selected Answer: AD\\naws lambda update-alias --function-name myFunction --name myAlias --routing-config \'{\\"AdditionalVersionWeights\\": {\\"2\\": 0.1}}\'","upvote_count":"1","timestamp":"1728176580.0","comment_id":"1293672","poster":"albert_kuo"},{"comment_id":"1270134","timestamp":"1724245620.0","upvote_count":"2","poster":"KennethNg923","content":"Selected Answer: AD\\nA. Publish a version of the original Lambda function. Make the necessary changes to the Lambda code. Publish a new version of the Lambda function.\\nD. Create an alias that points to the original version of the Lambda function. Configure the alias to be a weighted alias that also includes the new version of the Lambda function. Divide traffic between the two versions."},{"poster":"piipo","content":"Selected Answer: AD\\nAD is best","timestamp":"1722234000.0","comment_id":"1257295","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:07:31.144Z","extraction_method":"api_direct_v1"},{"question_id":"sBF7tI5iB3sc5gl5Q9jp","question_number":342,"page":69,"question_text":"A company had an Amazon RDS for MySQL DB instance that was named mysql-db. The DB instance was deleted within the past 90 days.\\n\\nA developer needs to find which IAM user or role deleted the DB instance in the AWS environment.\\n\\nWhich solution will provide this information?","choices":{"B":"Retrieve the Amazon CloudWatch log events from the most recent log stream within the rds/mysql-db log group. Inspect the log events.","D":"Retrieve the AWS Systems Manager deletions inventory. Filter the inventory by deletions that have a TypeName value of RDS. Inspect the deletion details.","A":"Retrieve the AWS CloudTrail events for the resource mysql-db where the event name is DeleteDBInstance. Inspect each event.","C":"Retrieve the AWS X-Ray trace summaries. Filter by services with the name mysql-db. Inspect the ErrorRootCauses values within each summary."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144456-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-23 20:07:00","unix_timestamp":1721758020,"discussion_count":2,"discussion":[{"upvote_count":"4","content":"Selected Answer: A\\nThe DeleteDBInstance is the API call that would be made when deleting an RDS instance. By retrieving and inspecting these events, you can find out who initiated the deletion.","comment_id":"1270137","poster":"KennethNg923","timestamp":"1724245740.0"},{"comment_id":"1253892","poster":"ahadh7621","upvote_count":"3","timestamp":"1721758020.0","content":"Selected Answer: A\\nThis question was on my exam, July 23rd, 2024. Answer is A."}],"answer_description":"","extracted_at":"2025-12-24T09:07:31.144Z","extraction_method":"api_direct_v1"},{"question_id":"Umj39zhZtSW3USSj7tmd","question_number":343,"page":69,"question_text":"A company has an ecommerce web application that uses an on-premises MySQL database as a data store. The company migrates the on-premises MySQL database to Amazon RDS for MySQL.\\n\\nA developer needs to configure the application\'s access to the RDS for MySQL database. The developer\'s solution must not use long term credentials.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Configure the MySQL credentials as environment variables that are available at runtime for the application.","D":"Store the MySQL credentials as SecureString parameters in AWS Systems Manager Parameter Store. Create an IAM role that has the minimum required permissions to retrieve the parameters. Assign the role to the application.","A":"Enable IAM database authentication on the RDS for MySQL DB instance. Create an IAM role that has the minimum required permissions. Assign the role to the application.","B":"Store the MySQL credentials as secrets in AWS Secrets Manager. Create an IAM role that has the minimum required permissions to retrieve the secrets. Assign the role to the application."},"correct_answer":"A","answer_ET":"A","answers_community":["A (64%)","B (36%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144295-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-21 03:11:00","unix_timestamp":1721524260,"discussion_count":8,"discussion":[{"upvote_count":"5","comment_id":"1252105","comments":[{"timestamp":"1725375900.0","comment_id":"1277682","content":"No, it does not imply that. \\"needs the credentials to be rotated every X period of time\\" would imply that. The question Implies that you need to use something like a auth token, which is exactly what IAM db authentication does.","upvote_count":"4","poster":"wh1t4k3r"}],"content":"Selected Answer: B\\nB. \\"The developer\'s solution must not use long term credentials\\" implies that the credentials will be rotated, which SecretsManager supports.","timestamp":"1721524260.0","poster":"ahadh7621"},{"upvote_count":"1","poster":"ShakthiGCP","comment_id":"1313530","content":"Selected Answer: A\\nAnswer is A","timestamp":"1731849540.0"},{"timestamp":"1730404320.0","poster":"MasoudK","upvote_count":"2","comment_id":"1305572","content":"A. AWS Secrets Manager can store and manage database credentials, and it can automatically rotate these credentials. However, the credentials stored in Secrets Manager are still considered long-term credentials because they exist for a period of time until they are rotated. \u2022 IAM Database Authentication: This method allows you to use IAM roles and policies to manage access to the RDS instance. It uses temporary security credentials provided by IAM roles, which are short-lived and automatically rotated."},{"upvote_count":"1","content":"Selected Answer: A\\naws rds modify-db-instance \\\\\\n --db-instance-identifier mydbinstance \\\\\\n --enable-iam-database-authentication \\\\\\n --apply-immediately\\n\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": \\"rds-db:connect\\",\\n \\"Resource\\": \\"arn:aws:rds-db:us-west-2:123456789012:dbuser:db-ABCDEFGHIJKLMNOPQRSTUVWX/db_user\\"\\n }\\n ]\\n}","poster":"albert_kuo","comments":[{"upvote_count":"1","comment_id":"1293675","content":"import boto3\\nimport pymysql\\n\\n# \u5275\u5efa\u4e00\u500b RDS \u8a8d\u8b49\u5ba2\u6236\u7aef\\nrds_client = boto3.client(\'rds\')\\n\\n# \u7372\u53d6\u81e8\u6642\u6191\u8b49\\ntoken = rds_client.generate_db_auth_token(DBHostname=\'your-db-hostname\',\\n Port=3306,\\n DBUsername=\'your-db-username\',\\n Region=\'us-west-2\')\\n\\n# \u4f7f\u7528 PyMySQL \u9023\u63a5\u8cc7\u6599\u5eab\\nconnection = pymysql.connect(host=\'your-db-hostname\',\\n user=\'your-db-username\',\\n passwd=token,\\n port=3306,\\n ssl={\'ca\': \'/path/rds-combined-ca-bundle.pem\'})","timestamp":"1728177180.0","poster":"albert_kuo"}],"timestamp":"1728177180.0","comment_id":"1293674"},{"comment_id":"1277685","content":"Selected Answer: A\\nUser/pass is a long term credential. IAM db auth allows connection to the database without user/pass, which solves the problem.","timestamp":"1725376020.0","upvote_count":"2","poster":"wh1t4k3r"},{"timestamp":"1725282780.0","content":"Selected Answer: A\\nVOTE A","comment_id":"1276717","poster":"siheom","upvote_count":"1"},{"poster":"minime","upvote_count":"2","comment_id":"1271927","content":"A. \\"Amazon RDS for MySQL can use AWS Identity and Access Management (IAM) database authentication to allow users to connect to a DB instance without a password. Instead, users can use an authentication token, which is a unique string of characters generated by Amazon RDS on request. Each token is valid for 15 minutes and is generated using AWS Signature Version 4.\\"","timestamp":"1724541960.0"},{"timestamp":"1722147420.0","comment_id":"1256605","content":"Selected Answer: A\\nA. Enable IAM database authentication on the RDS for MySQL DB instance. Create an IAM role that has the minimum required permissions. Assign the role to the application.","poster":"albert_kuo","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:07:31.144Z","extraction_method":"api_direct_v1"},{"question_id":"MUWr472zhSs1WUvoXw7z","question_number":344,"page":69,"question_text":"A developer is creating an application that must transfer expired items from Amazon DynamoDB to Amazon S3. The developer sets up the DynamoDB table to automatically delete items after a specific TTL. The application must process the items in DynamoDB and then must store the expired items in Amazon S3. The entire process, including item processing and storage in Amazon S3, will take 5 minutes.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Configure DynamoDB Accelerator (DAX) to query for expired items based on the TTL. Save the results to Amazon S3.","B":"Configure DynamoDB Streams to invoke an AWS Lambda function. Program the Lambda function to process the items and to store the expired items in Amazon S3.","D":"Create an Amazon EventBridge rule to invoke an AWS Lambda function. Program the Lambda function to process the items and to store the expired items in Amazon S3.","C":"Deploy a custom application on an Amazon Elastic Container Service (Amazon ECS) cluster on Amazon EC2 instances. Program the custom application to process the items and to store the expired items in Amazon S3."},"correct_answer":"B","answer_ET":"B","answers_community":["B (75%)","A (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143936-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-16 03:22:00","unix_timestamp":1721092920,"discussion_count":7,"discussion":[{"upvote_count":"1","timestamp":"1741532820.0","poster":"0bdf3af","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/time-to-live-ttl-streams.html","comment_id":"1371800"},{"poster":"7368e4a","upvote_count":"4","timestamp":"1723730100.0","content":"Selected Answer: B\\nB looks good to me","comment_id":"1266481"},{"upvote_count":"2","comment_id":"1266393","poster":"Saurabh04","timestamp":"1723720920.0","content":"Correct answer is B"},{"upvote_count":"1","poster":"lpennington","comment_id":"1260764","timestamp":"1722795360.0","content":"B is correct"},{"content":"Selected Answer: B\\nB is best","upvote_count":"1","comment_id":"1257307","poster":"piipo","timestamp":"1722237360.0"},{"comment_id":"1253995","upvote_count":"3","poster":"catoteja","timestamp":"1721775120.0","content":"Selected Answer: B\\nIt\'s B"},{"content":"Selected Answer: A\\nAnswer is B","comment_id":"1251900","upvote_count":"3","timestamp":"1721499120.0","poster":"Mo_1981"}],"answer_description":"","extracted_at":"2025-12-24T09:07:31.144Z","extraction_method":"api_direct_v1"},{"question_id":"z1pJSIKMKTNs6CLx6i4T","question_number":345,"page":69,"question_text":"A developer has an application that uses WebSocket APIs in Amazon API Gateway. The developer wants to use an API Gateway Lambda authorizer to control access to the application.\\n\\nThe developer needs to add credential caching and reduce repeated usage of secret keys and authorization tokens on every request.\\n\\nWhich combination of steps should the developer take to meet these requirements? (Choose two.)","choices":{"A":"Use a token-based Lambda authorizer.","B":"Use a request parameter-based Lambda authorizer.","C":"Configure an integration request mapping template to reference the context map from the APIGateway Lambda authorizer.","E":"Use VPC endpoint policies for the WebSocket APIs.","D":"Configure an integration request mapping template to reference the identity API key value from the API Gateway Lambda authorizer."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (67%)","BC (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144297-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-21 03:25:00","unix_timestamp":1721525100,"discussion_count":4,"discussion":[{"poster":"0bdf3af","timestamp":"1741595220.0","upvote_count":"1","content":"Selected Answer: BC\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-lambda-auth.html","comment_id":"1379911"},{"content":"Selected Answer: BC\\nRequest parameter-based Lambda authorizers are indeed more suitable and the recommended approach.\\n\\nAfter authorization, you can use the context map to pass relevant information to your backend without re-evaluating credentials for each message.","upvote_count":"1","comment_id":"1293768","poster":"albert_kuo","timestamp":"1728197940.0"},{"poster":"Mo_1981","timestamp":"1722395100.0","upvote_count":"3","content":"Selected Answer: AC\\nAnswers A,C","comment_id":"1258532","comments":[{"comment_id":"1258534","poster":"Mo_1981","upvote_count":"1","content":"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html\\n\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html","timestamp":"1722395220.0"}]},{"comment_id":"1253996","upvote_count":"1","content":"Selected Answer: AC\\nIt\'s A C.","poster":"catoteja","timestamp":"1721775240.0"}],"answer_description":"","extracted_at":"2025-12-24T09:07:31.144Z","extraction_method":"api_direct_v1"},{"question_id":"4rkZBzNfRUtz9v3BX8qR","question_number":346,"page":70,"question_text":"A developer is building a web application that uses Amazon API Gateway to expose an AWS Lambda function to process requests from clients. During testing, the developer notices that the API Gateway times out even though the Lambda function finishes under the set time limit.\\nWhich of the following API Gateway metrics in Amazon CloudWatch can help the developer troubleshoot the issue? (Choose two.)","choices":{"D":"Latency","E":"Count","B":"IntegrationLatency","C":"CacheMissCount","A":"CacheHitCount"},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103858-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-25 14:01:00","unix_timestamp":1679749260,"discussion_count":5,"discussion":[{"comment_id":"850597","timestamp":"1695686340.0","upvote_count":"14","content":"Selected Answer: BD\\nB and D\\nThe issue is caused by timeout. So the developer needs to know the latency information.\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html\\nhttps://repost.aws/knowledge-center/api-gateway-rest-api-504-errors","poster":"Untamables"},{"upvote_count":"5","comment_id":"850137","timestamp":"1695639660.0","poster":"Watascript","content":"Selected Answer: BD\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring-cloudwatch.html"},{"timestamp":"1734947820.0","content":"Selected Answer: BD\\nA) Eliminated - there is no mention of caching being involved in the problem, this metric is irrelevant for troubleshooting a timeout issue.\\n\\nB) Correct - A high value for IntegrationLatency can indicate that the API Gateway is experiencing delays in receiving responses from Lambda\\n\\nC) Eliminated - this metric is related to caching, which is not mentioned as part of the problem\\n\\nD) Correct - high value for Latency can indicate where delays are occurring overall, including the Lambda function\'s processing time and any overhead in API Gateway.\\n\\nE) Eliminated - While this metric provides information about the volume of requests, it does not help identify the cause of a timeout or latency issues.","upvote_count":"2","poster":"sumanshu","comment_id":"1330763"},{"comment_id":"1215093","timestamp":"1732213980.0","content":"Selected Answer: BD\\nBD is the correct answer.","poster":"65703c1","upvote_count":"1"},{"poster":"Jonalb","upvote_count":"1","content":"Selected Answer: BD\\nAs melhores op\xe7\xf5es s\xe3o, portanto, B. Integra\xe7\xe3oLat\xeancia e D. Lat\xeancia. Ambas as m\xe9tricas fornecer\xe3o insights sobre onde pode estar ocorrendo a lat\xeancia ou o atraso, ajudando o desenvolvedor a solucionar o problema.","timestamp":"1714147860.0","comment_id":"1054746"}],"answer_description":"","extracted_at":"2025-12-24T09:07:42.139Z","extraction_method":"api_direct_v1"},{"question_id":"9X08BU2XZyJ0nY6SpdlQ","question_number":347,"page":70,"question_text":"A developer builds a serverless application on AWS by using Amazon API Gateway, AWS Lambda functions, and Amazon Route 53. During testing, the developer notices errors but cannot immediately locate the root cause.\\n\\nTo identify the errors, the developer needs to search all the application\'s logs.\\n\\nWhat should the developer do to meet these requirements with the LEAST operational overhead?","choices":{"A":"Set up API Gateway health checks to monitor the application\'s availability. Use the Amazon CloudWatch PutMetricData API operation to publish the logs to CloudWatch. Search and query the logs by using Amazon Athena.","D":"Set up Route 53 health checks to monitor the application\'s availability. Turn on Amazon CloudWatch Logs for the API Gateway stages to log API requests with a JSON log format. Use CloudWatch Logs Insights to search and analyze the logs from the AWS services that the application uses.","B":"Set up Route 53 health checks to monitor the application\'s availability. Turn on AWS CloudTrail logs for all the AWS services that the application uses. Send the logs to a specified Amazon S3 bucket. Use Amazon Athena to query the log files directly from Amazon S3.","C":"Configure all the application\'s AWS services to publish a real-time feed of log events to an Amazon Kinesis Data Firehose delivery stream. Configure the delivery stream to publish all the logs to an Amazon S3 bucket. Use Amazon OpenSearch Service to search and analyze the logs."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/143937-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-16 03:29:00","unix_timestamp":1721093340,"discussion_count":3,"discussion":[{"timestamp":"1722181380.0","comment_id":"1256879","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html","poster":"Mo_1981","upvote_count":"2"},{"poster":"albert_kuo","content":"Selected Answer: D\\nMinimal Operational Overhead: Uses built-in AWS services with minimal configuration.\\nCentralized Log Analysis: CloudWatch Logs Insights provides a powerful, interactive query interface to analyze logs.\\nCost-Efficient: Utilizing existing AWS services like CloudWatch and Route 53 reduces the need for additional third-party tools or infrastructure.","comment_id":"1256610","upvote_count":"3","timestamp":"1722147900.0"},{"timestamp":"1721775540.0","upvote_count":"4","content":"Selected Answer: D\\nIt\'s D-","comment_id":"1253999","poster":"catoteja"}],"answer_description":"","extracted_at":"2025-12-24T09:07:42.139Z","extraction_method":"api_direct_v1"},{"question_id":"2RWBsg6Nf9v8arhnYch9","question_number":348,"page":70,"question_text":"A developer needs to freeze changes to an AWS CodeCommit repository before a production release. The developer will work on new features while a quality assurance (QA) team tests the release.\\n\\nThe QA testing and all bug fixes must take place in isolation from the main branch. After the release, the developer must integrate all bug fixes into the main branch.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create a Git tag on the latest Git commit that will be in the release. Continue developing new features, and merge the features into the main branch. Apply fixes to the main branch. Update the Git tag for the release to be on the latest commit on the main branch.","D":"Create a Git tag on the latest Git commit that will be in the release. Continue developing new features, and merge the features into the main branch. Apply the Git commits for fixes to the Git tag for the release.","C":"Create a release branch from the latest Git commit that will be in the release. Apply fixes to the release branch. Continue developing new features, and merge the features into the main branch. Rebase the main branch onto the release branch after the release.","A":"Create a release branch from the latest Git commit that will be in the release. Apply fixes to the release branch. Continue developing new features, and merge the features into the main branch. Merge the release branch into the main branch after the release."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144464-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-24 01:02:00","unix_timestamp":1721775720,"discussion_count":2,"discussion":[{"comment_id":"1254080","content":"Selected Answer: A\\nCreate a release branch from the latest Git commit that will be in the release. Apply fixes to the release branch. Continue developing new features, and merge the features into the main branch. Merge the release branch into the main branch after the release.","poster":"komorebi","upvote_count":"6","timestamp":"1721791740.0"},{"upvote_count":"2","timestamp":"1721775720.0","comment_id":"1254000","content":"It\'s C","poster":"catoteja"}],"answer_description":"","extracted_at":"2025-12-24T09:07:42.139Z","extraction_method":"api_direct_v1"},{"question_id":"G8E0aliqMxZuK0Y94KaY","question_number":349,"page":70,"question_text":"A developer is setting up AWS CodePipeline for a new application. During each build, the developer must generate a test report.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Create an AWS CodeBuild build project that runs tests. Configure the buildspec file with the test report information.","C":"Run the builds on an Amazon EC2 instance that has AWS Systems Manager Agent (SSM Agent) installed and activated.","D":"Create a repository in AWS CodeArtifact. Select the test report template.","B":"Create an AWS CodeDeploy deployment that runs tests. Configure the AppSpec file with the test report information."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144608-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-28 08:29:00","unix_timestamp":1722148140,"discussion_count":2,"discussion":[{"comment_id":"1256881","content":"Selected Answer: A\\nAnswer is A","poster":"Mo_1981","upvote_count":"3","timestamp":"1722181500.0"},{"content":"Selected Answer: A\\nversion: 0.2\\n\\nphases:\\n install:\\n runtime-versions:\\n nodejs: 12\\n build:\\n commands:\\n - echo Running tests...\\n - npm install\\n - npm test\\nartifacts:\\n files:\\n - \'**/*\'\\n base-directory: build\\nreports:\\n my-test-report:\\n files:\\n - \'**/*\'\\n base-directory: test-results\\n discard-paths: no","upvote_count":"1","timestamp":"1722148140.0","comment_id":"1256611","poster":"albert_kuo"}],"answer_description":"","extracted_at":"2025-12-24T09:07:42.139Z","extraction_method":"api_direct_v1"},{"question_id":"46QLlITzkwTpm3RGGEKb","question_number":350,"page":70,"question_text":"A developer built an application by using multiple AWS Lambda functions. The Lambda functions must access dynamic configuration data at runtime. The data is maintained as a 6 KB JSON document in AWS AppConfig. The configuration data needs to be updated without requiring the redeployment of the application.\\n\\nThe developer needs a solution that will give the Lambda functions access to the dynamic configuration data.\\n\\nWhat should the developer do to meet these requirements with the LEAST development effort?","choices":{"A":"Migrate the document from AWS AppConfig to a Lambda environment variable. Read the document at the runtime.","B":"Configure the AWS AppConfig Agent Lambda extension. Access the dynamic configuration data by calling the extension on a local host.","D":"Migrate the configuration file to a Lambda deployment package. Read the file from the file system at runtime.","C":"Use the AWS X-Ray SDK to call the AWS AppConfig APIs. Retrieve the configuration file at runtime."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144609-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-28 08:31:00","unix_timestamp":1722148260,"discussion_count":4,"discussion":[{"content":"Selected Answer: B\\nThe AWS AppConfig Agent Lambda extension is specifically designed to provide easy access to AppConfig configurations from Lambda functions. It allows for dynamic updates without redeployment and requires minimal development effort.","timestamp":"1724246640.0","upvote_count":"5","poster":"KennethNg923","comment_id":"1270143"},{"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-integration-lambda-extensions.html","upvote_count":"2","timestamp":"1722688140.0","poster":"Anandesh","comment_id":"1260285"},{"poster":"komorebi","timestamp":"1722213240.0","content":"Selected Answer: B\\nAnsswer is B","comment_id":"1257150","upvote_count":"1"},{"upvote_count":"2","poster":"albert_kuo","timestamp":"1722148260.0","comment_id":"1256613","content":"Selected Answer: B\\nEnvironment variables have a size limit of 4 KB, which is insufficient for a 6 KB document."}],"answer_description":"","extracted_at":"2025-12-24T09:07:42.139Z","extraction_method":"api_direct_v1"},{"question_id":"PghBZgcNHRDRJCgRcwi3","question_number":351,"page":71,"question_text":"A developer has AWS Lambda functions that need to access a company\'s internal data science libraries and reference data. Separate teams manage the libraries and the data. The teams must be able to update and upload new data independently. The Lambda functions are connected to the company\'s central VPC.\\n\\nWhich solution will provide the Lambda functions with access to the libraries and data?","choices":{"B":"Compress the libraries and reference data in a Lambda /tmp folder. Update the Lambda function code to reference the files in the /tmp folder.","D":"Set up an Amazon FSx for Windows File Server file system with mount targets in the central VPC. Configure the Lambda functions to mount the Amazon FSx file system. Update the Lambda function execution roles to give the functions to access the Amazon FSx file system.","C":"Set up an Amazon Elastic File System (Amazon EFS) file system with mount targets in the central VPConfigure the Lambda functions to mount the EFS file system. Update the Lambda function execution roles to give the functions to access the EFS file system.","A":"Attach an Amazon Elastic Block Store (Amazon EBS) volume to the Lambda functions by using EBS Multi-Attach in the central VPC. Update the Lambda function execution roles to give the functions to access the EBS volume. Update the Lambda function code to reference the files in the EBS volume."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/144610-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-07-28 08:34:00","unix_timestamp":1722148440,"discussion_count":4,"discussion":[{"timestamp":"1724780340.0","comment_id":"1273617","content":"Selected Answer: C\\nCan\'t use EBS volumes with Lambda, used with EC2 only.","poster":"Arnaud92","upvote_count":"3"},{"comment_id":"1259349","upvote_count":"3","poster":"chris_spencer","timestamp":"1722513000.0","content":"Selected Answer: C\\nConfigure a function to mount an Amazon Elastic File System (Amazon EFS) file system to a local directory\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-filesystem.html"},{"content":"Selected Answer: C\\nAnsswer is c","upvote_count":"2","timestamp":"1722213180.0","poster":"komorebi","comment_id":"1257147"},{"poster":"albert_kuo","content":"Selected Answer: C\\nC. Set up an Amazon Elastic File System (Amazon EFS) file system with mount targets in the central VPConfigure the Lambda functions to mount the EFS file system. Update the Lambda function execution roles to give the functions to access the EFS file system.","comment_id":"1256614","upvote_count":"1","timestamp":"1722148440.0"}],"answer_description":"","extracted_at":"2025-12-24T09:07:53.136Z","extraction_method":"api_direct_v1"},{"question_id":"x4kQqDJ5hQsR7Lr6ZOJ7","question_number":352,"page":71,"question_text":"A company has an application that uses an AWS Lambda function to consume messages from an Amazon Simple Queue Service (Amazon SQS) queue. The SQS queue is configured with a dead-letter queue. Due to a defect in the application, AWS Lambda failed to process some messages. A developer fixed the bug and wants to process the failed messages again.\\n\\nHow should the developer resolve this issue?","choices":{"D":"Use the PurgeQueue API to remove messages from the dead-letter queue and return the messages to the original SQS queue.","A":"Use the SendMessageBatch API to send messages from the dead-letter queue to the original SQS queue.","B":"Use the ChangeMessageVisibility API to configure messages in the dead-letter queue to be visible in the original SQS queue.","C":"Use the StartMessageMoveTask API to move messages from the dead-letter queue to the original SQS queue."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148595-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-03 10:46:00","unix_timestamp":1727945160,"discussion_count":4,"discussion":[{"timestamp":"1730967120.0","comment_id":"1308275","poster":"devmo","upvote_count":"1","content":"Selected Answer: C\\nIf answer is C, why does it show as A?"},{"comment_id":"1306228","upvote_count":"1","content":"vote C","timestamp":"1730562780.0","poster":"raeIT"},{"poster":"siheom","upvote_count":"2","content":"Selected Answer: C\\nVOTE C","timestamp":"1728045540.0","comment_id":"1293119"},{"content":"C\\nStartMessageMoveTask: This API is specifically designed for moving messages between SQS queues, including moving messages from a dead-letter queue (DLQ) back to the original queue. This method is efficient and preserves message attributes and other metadata.","upvote_count":"1","comment_id":"1292716","poster":"gdm83","timestamp":"1727945160.0"}],"answer_description":"","extracted_at":"2025-12-24T09:07:53.136Z","extraction_method":"api_direct_v1"},{"question_id":"tIx9gc3eoCJB1RxKk7UG","question_number":353,"page":71,"question_text":"A developer is working on an application that will be deployed on AWS. The developer needs to test and debug the code locally. The code is packaged and stored in an Amazon S3 bucket.\\n\\nHow can the developer test and debug the code locally with the LEAST amount of configuration?","choices":{"B":"Create a repository in AWS CodeArtifact. Publish the application code package to the repository. Before deployment, create an upstream repository to test and validate the code.","D":"Install the AWS CodeDeploy agent locally to validate the deployment package. Run the codedeploy-local command. Specify the S3 bucket where the code package is located by using the --bundle-location option.","C":"Create a build project in AWS CodeBuild. In AWS CodePipeline, add a CodeBuild test action by adding a stage and an action. For the action provider, specify a CodeBuild test and the build project. View the build log to see the test results.","A":"Create an application and a deployment group in AWS CodeDeploy. For the compute platform, specify the local machine as the individual instance for the deployment. For the repository type, specify that the application is stored in Amazon S3. Start the deployment to test on the local machine."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150175-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-24 20:36:00","unix_timestamp":1729794960,"discussion_count":2,"discussion":[{"comment_id":"1308264","timestamp":"1730963580.0","upvote_count":"2","poster":"aws_god","content":"Selected Answer: D\\nhttps://aws.amazon.com/blogs/devops/how-to-test-and-debug-aws-codedeploy-locally-before-you-ship-your-code/"},{"content":"D es la respuesta correcta.","comment_id":"1302615","timestamp":"1729794960.0","upvote_count":"2","poster":"AngelSaldivar"}],"answer_description":"","extracted_at":"2025-12-24T09:07:53.136Z","extraction_method":"api_direct_v1"},{"question_id":"8U1dehwYsIxPiVPMJ08H","question_number":354,"page":71,"question_text":"A developer is creating an application on Amazon Elastic Container Service (Amazon ECS). The developer needs to configure the application parameters. The developer must configure limits for the application\'s maximum number of simultaneous connections and maximum number of transactions per second.\\n\\nThe maximum number of connections and transactions can change in the future. The developer needs a solution that can automatically deploy these changes to the application, as needed, without causing downtime.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Install the AWS AppConfig agent on Amazon ECS. Configure an IAM role with access to AWS AppConfig. Make the deployment changes by using AWS AppConfig. Specify Canary10Percent20Minutes as the deployment strategy.","B":"Bootstrap the application to use the AWS Cloud Development Kit (AWS CDK) and make the configuration changes. Specify the ECSCanary10Percent15Minutes launch type in the properties section of the ECS resource. Deploy the application by using the AWS CDK to implement the changes.","A":"Make the configuration changes for the application. Use AWS CodeDeploy to create a deployment configuration. Specify an in-place deployment to deploy the changes.","D":"Create an AWS Lambda function to make the configuration changes. Create an Amazon CloudWatch alarm that monitors the Lambda function every 5 minutes to check if the Lambda function has been updated. When the Lambda function is updated, deploy the changes by using AWS CodeDeploy."},"correct_answer":"C","answer_ET":"C","answers_community":["C (75%)","D (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146743-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-01 09:07:00","unix_timestamp":1725174420,"discussion_count":5,"discussion":[{"upvote_count":"3","content":"Selected Answer: C\\nThe agent calls AWS AppConfig on your behalf by using an AWS Identity and Access Management (IAM) role and managing a local cache of configuration data. By pulling configuration data from the local cache, your application requires fewer code updates to manage configuration data, retrieves configuration data in milliseconds, and isn\'t affected by network issues that can disrupt calls for such data.\\n\\nhttps://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-integration-ec2.html","poster":"jasonczx","comment_id":"1278434","timestamp":"1725476340.0"},{"timestamp":"1725476280.0","content":"Selected Answer: C\\nThe AWS AppConfig Agent is the recommended method for retrieving AWS AppConfig feature flags or free form configuration data. The agent automatically implements best practices and may lower your cost of using AWS AppConfig as a result of fewer API calls to retrieve configurations.\\n\\nhttps://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-agent-how-to-use.html","upvote_count":"2","poster":"jasonczx","comment_id":"1278433"},{"upvote_count":"1","poster":"jasonczx","comment_id":"1278431","content":"Selected Answer: C\\nThis environment variable configures the maximum number of connections that the agent uses to retrieve configurations from AWS AppConfig.\\n\\nhttps://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-integration-containers-agent.html","timestamp":"1725475920.0"},{"poster":"siheom","comments":[{"timestamp":"1725417060.0","upvote_count":"2","content":"D is wrong.. vote C","poster":"siheom","comment_id":"1277916"}],"comment_id":"1277915","timestamp":"1725417060.0","upvote_count":"1","content":"Selected Answer: D\\nvote D"},{"timestamp":"1725174420.0","poster":"jasonczx","comment_id":"1275912","comments":[{"upvote_count":"1","timestamp":"1725475560.0","poster":"jasonczx","content":"Correct, C is correct","comment_id":"1278425"}],"upvote_count":"1","content":"Selected Answer: D\\nLambda automatically handles scaling the number of execution environments until you reach your account\'s concurrency limit. By default, Lambda provides your account with a total concurrency limit of 1,000 concurrent executions across all functions in an AWS Region.\\n\\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html"}],"answer_description":"","extracted_at":"2025-12-24T09:07:53.136Z","extraction_method":"api_direct_v1"},{"question_id":"WIb1uYbLJlhehxvHztxc","question_number":355,"page":71,"question_text":"A developer has built an application running on AWS Lambda using AWS Serverless Application Model (AWS SAM).\\n\\nWhat is the correct sequence of steps to successfully deploy the application?","choices":{"D":"1. Build the SAM template locally.\\n2. Package the SAM template from AWS CodeCommit.\\n3. Deploy the SAM template to CodeCommit.","A":"1. Build the SAM template in Amazon EC2.\\n2. Package the SAM template to Amazon EBS storage.\\n3. Deploy the SAM template from Amazon EBS.","C":"1. Build the SAM template locally.\\n2. Deploy the SAM template from Amazon S3.\\n3. Package the SAM template for use.","B":"1. Build the SAM template locally.\\n2. Package the SAM template onto Amazon S3.\\n3. Deploy the SAM template from Amazon S3."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148935-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-09 15:29:00","unix_timestamp":1728480540,"discussion_count":2,"discussion":[{"comment_id":"1295838","timestamp":"1728621660.0","poster":"preachr","upvote_count":"3","content":"Selected Answer: B\\nThe AWS Serverless Application Model Command Line Interface (AWS SAM CLI) packages an AWS SAM application. This command creates a . zip file of your code and dependencies, and uploads the file to Amazon Simple Storage Service (Amazon S3)."},{"timestamp":"1728480540.0","comment_id":"1295175","poster":"YUICH","upvote_count":"1","content":"Selected Answer: B\\nthe answer is B"}],"answer_description":"","extracted_at":"2025-12-24T09:07:53.136Z","extraction_method":"api_direct_v1"},{"question_id":"KyvD8bhEkOMFjurdXgk2","question_number":356,"page":72,"question_text":"A developer needs to deploy the code for a new application on an AWS Lambda function. The application needs a dependency file that is 500 MB to run the business logic.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Package the application code and dependencies into a container image. Upload the image to an Amazon S3 bucket. Configure the Lambda function to run the code in the image.","B":"Compress the application code and dependencies into a .zip file. Upload the .zip file to an Amazon S3 bucket. Configure the Lambda function to run the code from the .zip file in the S3 bucket.","A":"Compress the application code and dependencies into a .zip file. Directly upload the .zip file as a deployment package for the Lambda function instead of copying the code.","D":"Package the application code and dependencies into a container image. Push the image to an Amazon Elastic Container Registry (Amazon ECR) repository. Deploy the image to the Lambda function."},"correct_answer":"D","answer_ET":"D","answers_community":["D (60%)","B (40%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148936-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-09 15:30:00","unix_timestamp":1728480600,"discussion_count":3,"discussion":[{"comment_id":"1339934","poster":"tullio85","content":"Selected Answer: B\\nI think the question should have been more specific about the size of the code. The solution D is always correct. The solutiuon B is correct if the uncompressed size is less than 512MB. In the question was not specified the size of the code. In my experience is rarely to have a micoreservice code size more 12MB.","upvote_count":"1","timestamp":"1736780160.0"},{"content":"Selected Answer: B\\nIf the dependency file is too large for a Lambda layer (i.e., greater than 250 MB when compressed), store the file in an Amazon S3 bucket.\\nIn your Lambda function code, you can download the dependency file from S3 at runtime using the AWS SDK. This would ensure that the function has access to the file without exceeding Lambda\'s storage limits.","timestamp":"1728623100.0","upvote_count":"1","poster":"preachr","comment_id":"1295840","comments":[{"content":"option D also is possible, and Lambda can run from /tmp the .zip, not inside S3 bucket. So, maybe D is correct","poster":"preachr","comment_id":"1295842","timestamp":"1728623520.0","upvote_count":"1"}]},{"content":"Selected Answer: D\\nthe answer is D","poster":"YUICH","comment_id":"1295176","timestamp":"1728480600.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:08:04.138Z","extraction_method":"api_direct_v1"},{"question_id":"iHsTjhiKdH4JbUDI6VPM","question_number":357,"page":72,"question_text":"A development team wants to build a continuous integration/continuous delivery (CI/CD) pipeline. The team is using AWS CodePipeline to automate the code build and deployment. The team wants to store the program code to prepare for the CI/CD pipeline.\\nWhich AWS service should the team use to store the program code?","choices":{"B":"AWS CodeArtifact","C":"AWS CodeCommit","D":"Amazon CodeGuru","A":"AWS CodeDeploy"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103914-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 02:02:00","unix_timestamp":1679792520,"discussion_count":6,"discussion":[{"upvote_count":"9","timestamp":"1695686520.0","comment_id":"850598","poster":"Untamables","content":"Selected Answer: C\\nC\\nhttps://aws.amazon.com/codecommit/"},{"content":"Selected Answer: C\\nThis is likely outdated, as CodeCommit is being deprecated. They already do not allow new users to access CodeCommit.","comment_id":"1335282","poster":"bahubba","timestamp":"1735763580.0","upvote_count":"3"},{"timestamp":"1734947880.0","upvote_count":"2","comment_id":"1330764","content":"Selected Answer: C\\nCodeCommit is explicitly designed for storing and version-controlling program code,","poster":"sumanshu"},{"upvote_count":"1","poster":"65703c1","comment_id":"1215094","timestamp":"1732214040.0","content":"Selected Answer: C\\nC is the correct answer."},{"timestamp":"1708778100.0","poster":"Lucian2407","upvote_count":"2","comment_id":"989086","content":"Selected Answer: C\\nSimple answer: CodeCommit"},{"comment_id":"855899","content":"Selected Answer: C\\nC is the right answer","poster":"jgopireddy","timestamp":"1696086240.0","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:08:04.138Z","extraction_method":"api_direct_v1"},{"question_id":"o8bGcwhgpEmPofdytL9m","question_number":358,"page":72,"question_text":"A company is developing a publicly accessible single-page application. The application makes calls from a client web browser to backend services to provide a user interface to customers. The application depends on a third-party web service exposed as an HTTP API. The web client must provide an API key to the third-party web service by using the HTTP header as part of the HTTP request. The company\'s API key must not be exposed to the users of the web application.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"A":"Use Amazon API Gateway to create a private REST API. Create an HTTP integration to integrate with the third-party HTTP API. Add the company\u2019s API key to the HTTP headers list of the integration request configuration.","B":"Use Amazon API Gateway to create a private REST API. Create an AWS Lambda proxy integration. Make calls to the third-party HTTP API from the Lambda function. Pass the company\'s API key as an HTTP request header.","D":"Use Amazon API Gateway to create a REST API. Create an AWS Lambda proxy integration. Make calls to the third-party HTTP API from the Lambda function. Pass the company\'s API key as an HTTP request header.","C":"Use Amazon API Gateway to create a REST API. Create an HTTP integration to integrate with the third-party HTTP API. Add the company\'s API key to the HTTP headers list of the integration request configuration."},"correct_answer":"C","answer_ET":"C","answers_community":["C (57%)","D (29%)","14%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146857-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-03 17:49:00","unix_timestamp":1725378540,"discussion_count":7,"discussion":[{"content":"Selected Answer: A\\nBy using a private REST API with an HTTP integration and adding the API key to the HTTP headers list, you can securely forward requests to the third-party API without exposing the API key to the client, while also minimizing costs by avoiding the need for a Lambda function for each request.","upvote_count":"1","poster":"tullio85","comment_id":"1339936","timestamp":"1736780460.0"},{"timestamp":"1731615360.0","poster":"CloudChingon","content":"Selected Answer: C\\nCorrect Answer: C\\nWhy Option C Works:\\nSecure: The API key is added server-side in the API Gateway integration, ensuring it is not exposed to users.\\nCost-Effective: Avoids the cost of running a Lambda function while still using API Gateway for request routing.\\nPublic Access: The REST API is publicly accessible to the web client.","upvote_count":"1","comment_id":"1312319"},{"timestamp":"1727673360.0","upvote_count":"3","comment_id":"1291407","poster":"YUICH","content":"C. Amazon API Gateway with REST API and HTTP integration is the best solution because it allows the company to securely add the API key to requests sent to the third-party HTTP API without exposing the API key to the client."},{"timestamp":"1727319480.0","comment_id":"1289267","content":"C:\\n While D would work, but it introduces extra Lambda overhead, increasing both complexity and cost compared to directly using API Gateway\u2019s HTTP integration.","poster":"stevesuperdx","upvote_count":"3"},{"timestamp":"1726943340.0","poster":"jasonczx","comment_id":"1287438","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html","upvote_count":"1"},{"upvote_count":"1","timestamp":"1726099800.0","poster":"aragon_saa","comment_id":"1282378","content":"Selected Answer: D\\nAnswer is D"},{"poster":"wh1t4k3r","timestamp":"1725378540.0","content":"Selected Answer: C\\nIm going with C as per this post:\\nhttps://stackoverflow.com/questions/62443262/aws-api-gateway-to-external-rest-api\\nI am discarding the use of a private rest api because that would imply a VPC endpoint required and that is not cost effective.","upvote_count":"3","comment_id":"1277703"}],"answer_description":"","extracted_at":"2025-12-24T09:08:04.138Z","extraction_method":"api_direct_v1"},{"question_id":"LT3r1oNR2pt2ViTtntYn","question_number":359,"page":72,"question_text":"A developer is setting up the deployment of application stacks to new test environments by using the AWS Cloud Development Kit (AWS CDK). The application contains the code for several AWS Lambda functions that will be deployed as assets. Each Lambda function is defined by using the AWS CDK Lambda construct library.\\n\\nThe developer has already successfully deployed the application stacks to the alpha environment in the first account by using the AWS CDK CLI\'s cdk deploy command. The developer is preparing to deploy to the beta environment in a second account for the first time. The developer makes no significant changes to the CDK code between deployments, but the initial deployment in the second account is unsuccessful and returns a NoSuchBucket error.\\n\\nWhich command should the developer run before redeployment to resolve this error?","choices":{"C":"cdk init","A":"cdk synth","D":"cdk destroy","B":"cdk bootstrap"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146859-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-03 17:57:00","unix_timestamp":1725379020,"discussion_count":2,"discussion":[{"timestamp":"1725944400.0","poster":"maha12345678765432","upvote_count":"1","content":"Selected Answer: B\\nB. cdk bootstrap","comment_id":"1281352"},{"content":"Selected Answer: B\\nB is correct, this error implies the bucket was not bootstrapped\\nIdeally the command needs a few more parameters, but B is the correct one:\\n\\nhttps://docs.aws.amazon.com/cdk/v2/guide/troubleshooting.html","poster":"wh1t4k3r","timestamp":"1725379020.0","upvote_count":"2","comment_id":"1277710"}],"answer_description":"","extracted_at":"2025-12-24T09:08:04.138Z","extraction_method":"api_direct_v1"},{"question_id":"LiHqst7ivoFw2g6roqUw","question_number":360,"page":72,"question_text":"A developer is automating a new application deployment with AWS Serverless Application Model (AWS SAM). The new application has one AWS Lambda function and one Amazon S3 bucket. The Lambda function must access the S3 bucket to only read objects.\\n\\nHow should the developer configure AWS SAM to grant the necessary read privilege to the S3 bucket?","choices":{"B":"Add a custom S3 bucket policy to the Lambda function.","A":"Reference a second Lambda authorizer function.","D":"Add the S3ReadPolicy template to the Lambda function\'s execution role.","C":"Create an Amazon Simple Queue Service (SQS) topic for only S3 object reads. Reference the topic in the template."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150944-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-07 15:44:00","unix_timestamp":1730990640,"discussion_count":3,"discussion":[{"comment_id":"1339947","upvote_count":"1","poster":"tullio85","content":"Selected Answer: D\\nD is correct. S3 and role is coupled.","timestamp":"1736781660.0"},{"comment_id":"1335630","timestamp":"1735830960.0","content":"Selected Answer: D\\nThe correct answer is D. \\nAWS SAM simplifies infrastructure-as-code deployments. To grant the Lambda function read access to the S3 bucket, you should define an IAM role for the Lambda function that includes the necessary S3 read permissions. AWS SAM provides pre-defined policy templates, including S3ReadPolicy, which grants read-only access to S3. This is the most efficient way to handle permissions within the SAM template.","poster":"examuserss","upvote_count":"1"},{"comment_id":"1308409","content":"Selected Answer: D\\nans is D","poster":"Saudis","upvote_count":"1","timestamp":"1730990640.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:04.138Z","extraction_method":"api_direct_v1"},{"question_id":"c1hxyVZymH9prmtr55i7","question_number":361,"page":73,"question_text":"A development team wants to immediately build and deploy an application whenever there is a change to the source code.\\n\\nWhich approaches could be used to trigger the deployment? (Choose two.)","choices":{"C":"Store the source code in an AWS CodeCommit repository. Configure AWS CodePipeline to start whenever a change is committed to the repository.","B":"Store the source code in an encrypted Amazon EBS volume. Configure AWS CodePipeline to start whenever a file in the volume changes.","D":"Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start every 15 minutes.","E":"Store the source code in an Amazon EC2 instance\u2019s ephemeral storage. Configure the instance to start AWS CodePipeline whenever there are changes to the source code.","A":"Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start whenever a file in the bucket changes."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146861-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-03 18:04:00","unix_timestamp":1725379440,"discussion_count":4,"discussion":[{"upvote_count":"1","timestamp":"1736781780.0","content":"Selected Answer: AC\\nboth A and C are correct","poster":"tullio85","comment_id":"1339949"},{"upvote_count":"1","comment_id":"1308406","timestamp":"1730990520.0","poster":"Saudis","content":"Selected Answer: AC\\nAnswer is AC"},{"comment_id":"1282377","poster":"aragon_saa","content":"Selected Answer: AC\\nAnswer is AC","upvote_count":"1","timestamp":"1726099800.0"},{"poster":"wh1t4k3r","comment_id":"1277716","upvote_count":"1","content":"Selected Answer: AC\\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/reference-pipeline-structure.html#:~:text=When%20you%20create%20a%20pipeline,commit%20a%20source%20code%20change.\\n\\nOnly A and C present valid repository types for codepipeline. D also does, but it is not automatic.","timestamp":"1725379440.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:15.145Z","extraction_method":"api_direct_v1"},{"question_id":"AEQitaMJgrHmC9joDpFT","question_number":362,"page":73,"question_text":"A developer is building an application integrating an Amazon API Gateway with an AWS Lambda function. When calling the API, the developer receives the following error:\\n\\nWed Nov 08 01:13:00 UTC 2017 : Method completed with status: 502\\n\\nWhat should the developer do to resolve the error?","choices":{"A":"Change the HTTP endpoint of the API to an HTTPS endpoint.","D":"Change the authorization header in the API call to access the Lambda function.","B":"Change the format of the payload sent to the API Gateway.","C":"Change the format of the Lambda function response to the API call."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148937-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-09 15:32:00","unix_timestamp":1728480720,"discussion_count":4,"discussion":[{"comment_id":"1308403","poster":"Saudis","upvote_count":"1","timestamp":"1730990280.0","content":"Selected Answer: C\\nWhen you see a 502 Bad Gateway error in Amazon API Gateway, it means that the API Gateway was unable to get a valid response from Lambda."},{"timestamp":"1730968320.0","poster":"aws_god","comment_id":"1308292","content":"Selected Answer: C\\nIn the logs, review the format of your Lambda function\'s response to your API. If the response isn\'t in the required JSON format, then reformat it.\\n\\nhttps://repost.aws/knowledge-center/malformed-502-api-gateway","upvote_count":"1"},{"comment_id":"1295401","content":"Selected Answer: C\\nCorrect response format should be\\n\\n{\\n \\"statusCode\\": 200,\\n \\"headers\\": {\\n \\"Content-Type\\": \\"application/json\\"\\n },\\n \\"body\\": \\"{\\\\\\"message\\\\\\": \\\\\\"Success\\\\\\"}\\"\\n}","upvote_count":"1","poster":"albert_kuo","timestamp":"1728537600.0"},{"upvote_count":"1","comment_id":"1295178","timestamp":"1728480720.0","poster":"YUICH","content":"the answer is C"}],"answer_description":"","extracted_at":"2025-12-24T09:08:15.145Z","extraction_method":"api_direct_v1"},{"question_id":"Dw3KBFmmXoSqynsgfxup","question_number":363,"page":73,"question_text":"A developer is building various microservices for an application that will run on Amazon EC2 instances. The developer needs to monitor the end-to-end view of the requests between the microservices and debug any issues in the various microservices.\\n\\nWhat should the developer do to accomplish these tasks?","choices":{"A":"Use Amazon CloudWatch to aggregate the microservices\' logs and metrics, and build the monitoring dashboard.","C":"Use the AWS X-Ray SDK to add instrumentation in all the microservices, and monitor using the X-Ray service map.","D":"Use AWS Health to monitor the health of all the microservices.","B":"Use AWS CloudTrail to aggregate the microservices\' logs and metrics, and build the monitoring dashboard."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148938-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-09 15:33:00","unix_timestamp":1728480780,"discussion_count":4,"discussion":[{"timestamp":"1736782020.0","content":"Selected Answer: C\\nX-Ray is correct","comment_id":"1339952","upvote_count":"1","poster":"tullio85"},{"upvote_count":"1","content":"Selected Answer: C\\nThe best solution is C.\\n\\nAWS X-Ray is specifically designed for tracing and debugging distributed applications like microservices architectures running on EC2. By instrumenting your microservices with the X-Ray SDK, you gain visibility into requests as they flow between services. X-Ray\'s service map provides a visual representation of your application\'s architecture and helps pinpoint bottlenecks or errors within individual microservices or across the system.","poster":"examuserss","comment_id":"1335633","timestamp":"1735831260.0"},{"comment_id":"1308399","poster":"Saudis","upvote_count":"1","timestamp":"1730990160.0","content":"Selected Answer: C\\nalways AWS X-RAY for debugging"},{"comment_id":"1295180","content":"the answer is C","poster":"YUICH","upvote_count":"1","timestamp":"1728480780.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:15.145Z","extraction_method":"api_direct_v1"},{"question_id":"CNuUznfeErdhytLdqHHk","question_number":364,"page":73,"question_text":"A developer is building a microservice that uses AWS Lambda to process messages from an Amazon Simple Queue Service (Amazon SQS) standard queue. The Lambda function calls external APIs to enrich the SQS message data before loading the data into an Amazon Redshift data warehouse. The SQS queue must handle a maximum of 1,000 messages per second.\\n\\nDuring initial testing, the Lambda function repeatedly inserted duplicate data into the Amazon Redshift table. The duplicate data led to a problem with data analysis. All duplicate messages were submitted to the queue within 1 minute of each other.\\n\\nHow should the developer resolve this issue?","choices":{"C":"Use Lambda\'s temporary storage to keep track of processed message identifiers","B":"Reduce the maximum Lambda concurrency that the SQS queue can invoke.","D":"Configure a message group ID for every sent message. Enable message deduplication on the SQS standard queue.","A":"Create an SQS FIFO queue. Enable message deduplication on the SQS FIFO queue."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148955-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 07:23:00","unix_timestamp":1728537780,"discussion_count":2,"discussion":[{"timestamp":"1730989980.0","upvote_count":"2","content":"Selected Answer: A\\nSQS FIFO prevent duplication","poster":"Saudis","comment_id":"1308395"},{"timestamp":"1728537780.0","poster":"albert_kuo","upvote_count":"3","comment_id":"1295402","content":"Selected Answer: A\\nSQS FIFO queue can use MessageDeduplicationId to avoid duplicate message"}],"answer_description":"","extracted_at":"2025-12-24T09:08:15.145Z","extraction_method":"api_direct_v1"},{"question_id":"xwoUQFHwieJGlXPg6QFB","question_number":365,"page":73,"question_text":"A company has an application that uses an Amazon API Gateway API to invoke an AWS Lambda function. The application is latency sensitive.\\n\\nA developer needs to configure the Lambda function to reduce the cold start time that is associated with default scaling.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Increase the Lambda function\'s memory to the maximum amount. Increase the Lambda function\'s reserved concurrency limit.","C":"Increase the reserved concurrency of the Lambda function to a number that matches the current production load.","A":"Publish a new version of the Lambda function. Configure provisioned concurrency. Set the provisioned concurrency limit to meet the company requirements.","D":"Use Service Quotas to request an increase in the Lambda function\'s concurrency limit for the AWS account where the function is deployed."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150694-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-04 01:09:00","unix_timestamp":1730678940,"discussion_count":2,"discussion":[{"timestamp":"1735831560.0","comment_id":"1335635","content":"Selected Answer: A\\nThe best solution is A. .\\n\\nProvisioned concurrency allows you to keep a specified number of Lambda function instances \\"warm\\" and ready to execute. This significantly reduces cold start latency because the instances are already running when requests arrive. Publishing a new version is generally recommended when making significant configuration changes like enabling provisioned concurrency.","upvote_count":"2","poster":"examuserss"},{"upvote_count":"1","comment_id":"1308393","content":"Selected Answer: A\\nA provision concurrency reduce the cold start","poster":"Saudis","timestamp":"1730989800.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:15.145Z","extraction_method":"api_direct_v1"},{"question_id":"cPmuCXjXUUx8kt1v58J0","question_number":366,"page":74,"question_text":"A developer is deploying an application on Amazon EC2 instances that run in Account A. The application needs to read data from an existing Amazon Kinesis data stream in Account B.\\n\\nWhich actions should the developer take to provide the application with access to the stream? (Choose two.)","choices":{"C":"Add a trust policy to the instance profile role and IAM role in Account B to allow the instance profile role to assume the IAM role.","D":"Add a trust policy to the instance profile role and IAM role in Account B to allow reads from the stream.","B":"Create an IAM role with stream read permissions in Account B.","A":"Update the instance profile role in Account A with stream read permissions.","E":"Add a resource-based policy in Account B to allow read access from the instance profile role."},"correct_answer":"BC","answer_ET":"BC","answers_community":["BC (65%)","BE (24%)","12%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146862-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-03 18:18:00","unix_timestamp":1725380280,"discussion_count":8,"discussion":[{"timestamp":"1736783280.0","poster":"tullio85","upvote_count":"1","content":"In the soltion C the EC2 istance is missing. I have to assume that it is reference to the EC2 istance.","comment_id":"1339959"},{"poster":"bp07","comment_id":"1339699","content":"Selected Answer: AE\\nB and C together could be part of the solution, but they still don\'t fully address the requirement because the Kinesis stream needs a resource-based policy to grant permission for cross-account access. Hence I feel AE will be answer.","upvote_count":"1","timestamp":"1736722020.0"},{"content":"Selected Answer: BC\\nSelectec Answer: BC \\nTo allow an EC2 instance in one account (Account A) to access a Kinesis stream in another account (Account B), you need cross-account access. This is achieved by:\\n\\nCreating an IAM role in Account B: This role will have the necessary Kinesis read permissions.\\n\\nAdding a trust policy: This policy, added to the role in Account B, allows the EC2 instance\'s IAM role (in Account A) to assume the role in Account B. The EC2 instance\'s role then acts as a temporary security credential for accessing the Kinesis stream in Account B.","upvote_count":"1","timestamp":"1735831740.0","comment_id":"1335638","poster":"examuserss"},{"upvote_count":"2","timestamp":"1728538020.0","content":"Selected Answer: BC\\ncreate iam role\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": [\\n \\"kinesis:DescribeStream\\",\\n \\"kinesis:GetRecords\\",\\n \\"kinesis:GetShardIterator\\",\\n \\"kinesis:ListStreams\\"\\n ],\\n \\"Resource\\": \\"arn:aws:kinesis:<region>:<AccountB-ID>:stream/<stream-name>\\"\\n }\\n ]\\n}","poster":"albert_kuo","comment_id":"1295404","comments":[{"comment_id":"1295405","poster":"albert_kuo","timestamp":"1728538080.0","upvote_count":"1","content":"create trust policy\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Principal\\": {\\n \\"AWS\\": \\"arn:aws:iam::<AccountA-ID>:role/<InstanceProfileRoleName>\\"\\n },\\n \\"Action\\": \\"sts:AssumeRole\\"\\n }\\n ]\\n}"}]},{"comment_id":"1291409","upvote_count":"1","timestamp":"1727673720.0","poster":"YUICH","content":"Selected Answer: AE\\nA. Update the instance profile role in Account A with the necessary permissions to read from the Kinesis stream. This allows the EC2 instance to assume the required permissions.\\nE. Add a resource-based policy to the Kinesis stream in Account B to grant read access to the instance profile role in Account A. This enables cross-account access."},{"poster":"jasonczx","comment_id":"1284027","content":"Selected Answer: BC\\nhttps://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles","timestamp":"1726393260.0","upvote_count":"4"},{"poster":"28304e5","comment_id":"1283613","upvote_count":"4","content":"Selected Answer: BE\\nC: This action involves cross-account role assumption, but for Kinesis access, you would typically use resource-based policies rather than cross-account role assumption unless the use case specifically involves assuming roles across accounts.","timestamp":"1726315800.0"},{"content":"Selected Answer: BC\\nAnswer is BC","comment_id":"1282376","upvote_count":"4","poster":"aragon_saa","timestamp":"1726099740.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:26.142Z","extraction_method":"api_direct_v1"},{"question_id":"3J76Ddz20f0wjJ4JfyCr","question_number":367,"page":74,"question_text":"An ecommerce startup is preparing for an annual sales event. As the traffic to the company\'s application increases, the development team wants to be notified when the Amazon EC2 instance\'s CPU utilization exceeds 80%.\\n\\nWhich solution will meet this requirement?","choices":{"B":"Create a custom AWS CloudTrail alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%.","C":"Create a cron job on the EC2 instance that invokes the --describe-instance-information command on the host instance every 15 minutes and sends the results to an Amazon SNS topic.","A":"Create a custom Amazon CloudWatch alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%.","D":"Create an AWS Lambda function that queries the AWS CloudTrail logs for the CPUUtilization metric every 15 minutes and sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150695-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-04 01:13:00","unix_timestamp":1730679180,"discussion_count":3,"discussion":[{"content":"Selected Answer: A\\nThe correct answer is A. \\n\\nCloudWatch is the AWS service specifically designed for monitoring metrics like CPU utilization. Creating a CloudWatch alarm with a threshold of 80% and configuring it to send notifications to an SNS topic is the most straightforward and efficient method for achieving this requirement.","comment_id":"1335639","poster":"examuserss","timestamp":"1735831920.0","upvote_count":"1"},{"comment_id":"1308390","upvote_count":"1","timestamp":"1730989320.0","poster":"Saudis","content":"A is the correct answer"},{"content":"A is the correct answer","poster":"ogogundare","timestamp":"1730679180.0","upvote_count":"1","comment_id":"1306709"}],"answer_description":"","extracted_at":"2025-12-24T09:08:26.142Z","extraction_method":"api_direct_v1"},{"question_id":"Xvz8g2i25UvmGL02eOXu","question_number":368,"page":74,"question_text":"A developer is designing an AWS Lambda function that creates temporary files that are less than 10 MB during invocation. The temporary files will be accessed and modified multiple times during invocation. The developer has no need to save or retrieve these files in the future.\\nWhere should the temporary files be stored?","choices":{"B":"Amazon Elastic File System (Amazon EFS)","D":"Amazon S3","C":"Amazon Elastic Block Store (Amazon EBS)","A":"the /tmp directory"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103915-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 02:03:00","unix_timestamp":1679792580,"discussion_count":4,"discussion":[{"content":"Selected Answer: A\\nA\\nA Lambda function has access to local storage in the /tmp directory. Each execution environment provides between 512 MB and 10,240 MB, in 1-MB increments, of disk space in the /tmp directory.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/foundation-progmodel.html","timestamp":"1695686580.0","upvote_count":"19","comment_id":"850600","poster":"Untamables"},{"comment_id":"1330767","content":"Selected Answer: A\\nA) Correct - AWS Lambda provides a /tmp directory with storage between 51B to 10,240 MB. https://docs.aws.amazon.com/lambda/latest/dg/configuration-ephemeral-storage.html. The files in this directory are ephemeral and will be deleted after the function execution ends.\\nB) Eliminated - Temporary files are not required to persist beyond the invocation, and using EFS would increase complexity and cost.\\n\\nC) Eliminated - Lambda does not directly support EBS volumes\\n\\nD) Eliminated- While S3 can store temporary data, it is not optimized for high-speed read/write operations during a Lambda invocation. Additionally, the use case specifies that the files do not need to be saved or retrieved later, making S3 an unnecessary overhead.","timestamp":"1734948180.0","upvote_count":"2","poster":"sumanshu"},{"timestamp":"1732214160.0","upvote_count":"1","comment_id":"1215095","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1"},{"timestamp":"1704829800.0","content":"The correct answer is A\\nThe /tmp directory is the recommended location for storing temporary files within an AWS Lambda function. The /tmp directory provides a writable space with a local storage capacity of 512 MB. It is specifically designed for temporary storage within the Lambda execution environment.","poster":"Mtho96","upvote_count":"4","comment_id":"947468"}],"answer_description":"","extracted_at":"2025-12-24T09:08:26.142Z","extraction_method":"api_direct_v1"},{"question_id":"ZLc3tL2cYK6PmHprl4NJ","question_number":369,"page":74,"question_text":"A company has an application that is deployed on AWS Elastic Beanstalk. The application generates user-specific PDFs and stores the PDFs in an Amazon S3 bucket. The application then uses Amazon Simple Email Service (Amazon SES) to send the PDFs by email to subscribers.\\n\\nUsers no longer access the PDFs 90 days after the PDFs are generated. The S3 bucket is not versioned and contains many obsolete PDFs.\\n\\nA developer must reduce the number of files in the S3 bucket by removing PDFs that are older than 90 days.\\n\\nWhich solution will meet this requirement with the LEAST development effort?","choices":{"A":"Update the application code. In the code, add a rule to scan all the objects in the S3 bucket every day and to delete objects after 90 days.","B":"Create an AWS Lambda function. Program the Lambda function to scan all the objects in the S3 bucket every day and to delete objects after 90 days.","D":"Partition the S3 objects with a // key prefix. Create an AWS Lambda function to remove objects that have prefixes that have reached the expiration date.","C":"Create an S3 Lifecycle rule for the S3 bucket to expire objects after 90 days."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/146863-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-03 18:20:00","unix_timestamp":1725380400,"discussion_count":2,"discussion":[{"poster":"Saudis","upvote_count":"1","content":"Selected Answer: C\\nAnswer is C","timestamp":"1730989260.0","comment_id":"1308389"},{"timestamp":"1726099740.0","content":"Selected Answer: C\\nAnswer is C","comment_id":"1282375","upvote_count":"2","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T09:08:26.142Z","extraction_method":"api_direct_v1"},{"question_id":"ZIO2CpNr3gODUzBz4UZY","question_number":370,"page":74,"question_text":"A developer is troubleshooting an application. The application includes several AWS Lambda functions that invoke an Amazon API Gateway API. The API Gateway\'s method request is set up to use an Amazon Cognito authorizer for authentication.\\n\\nAll the Lambda functions pass the user ID as part of the Authorization header to the API Gateway API. The API Gateway API returns a 403 status code for all GET requests.\\n\\nHow should the developer resolve this issue?","choices":{"B":"Modify the client GET request to include a valid token in the Authorization header.","C":"Update the resource policy for the API Gateway API to allow the execute-api:Invoke action.","A":"Modify the client GET request to include a valid API key in the Authorization header.","D":"Modify the client to send an OPTIONS preflight request before the GET request."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148103-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-26 05:18:00","unix_timestamp":1727320680,"discussion_count":4,"discussion":[{"poster":"Saudis","content":"Selected Answer: B\\nthe answer is B","comment_id":"1308387","upvote_count":"1","timestamp":"1730989080.0"},{"poster":"albert_kuo","upvote_count":"1","timestamp":"1728538740.0","content":"Selected Answer: B\\nconst apiUrl = \'https://api.example.com/my-resource\';\\n\\nconst headers = {\\n \'Authorization\': `Bearer ${idToken}`, // JWT token\\n \'Content-Type\': \'application/json\'\\n};\\n\\nfetch(apiUrl, { method: \'GET\', headers: headers })\\n .then(response => {\\n if (!response.ok) {\\n throw new Error(\'API request failed\');\\n }\\n return response.json();\\n })\\n .then(data => console.log(data))\\n .catch(error => console.log(\'Error:\', error));","comment_id":"1295410"},{"content":"Selected Answer: B\\nthe answer is B","comment_id":"1295183","upvote_count":"1","poster":"YUICH","timestamp":"1728480960.0"},{"content":"Option B is the correct solution, as the client must provide a valid token in the Authorization header for Cognito authorizer to work properly.","comment_id":"1289268","poster":"stevesuperdx","timestamp":"1727320680.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:08:26.142Z","extraction_method":"api_direct_v1"},{"question_id":"P25kMexBki1lhu0lyH2W","question_number":371,"page":75,"question_text":"A company processes incoming documents from an Amazon S3 bucket. Users upload documents to an S3 bucket using a web user interface. Upon receiving files in S3, an AWS Lambda function is invoked to process the files, but the Lambda function times out intermittently.\\n\\nIf the Lambda function is configured with the default settings, what will happen to the S3 event when there is a timeout exception?","choices":{"C":"The S3 event is processed until it is successful.","A":"Notification of a failed S3 event is sent as an email through Amazon SNS.","D":"The S3 event is discarded after the event is retried twice.","B":"The S3 event is sent to the default Dead Letter Queue."},"correct_answer":"D","answer_ET":"D","answers_community":[],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/147042-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-09-06 00:23:00","unix_timestamp":1725574980,"discussion_count":3,"discussion":[{"content":"D\\n This means that Lambda will make two additional attempts to process the event (a total of three attempts). If the function still fails after the retries, and if no Dead Letter Queue (DLQ) or on-failure destination is configured, the event is discarded.","timestamp":"1727320740.0","upvote_count":"5","poster":"stevesuperdx","comment_id":"1289269"},{"comment_id":"1339968","poster":"tullio85","content":"answer D","timestamp":"1736783820.0","upvote_count":"1"},{"comment_id":"1279198","upvote_count":"2","poster":"8621a7c","timestamp":"1725574980.0","content":"D\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async-error-handling.html#:~:text=Lambda%20manages%20your%20function\'s%20asynchronous,the%20second%20and%20third%20attempts."}],"answer_description":"","extracted_at":"2025-12-24T09:08:37.124Z","extraction_method":"api_direct_v1"},{"question_id":"XQfOIeyX3ynyvP4PbN2q","question_number":372,"page":75,"question_text":"A developer uses Amazon S3 Event Notifications to invoke AWS Lambda functions. The Lambda functions process images after the images are uploaded to S3 buckets. The developer has set up a development S3 bucket, a production S3 bucket, a development Lambda function, and a production Lambda function in the same AWS account.\\n\\nThe developer notices that uploads to the development S3 bucket wrongly invoke the production Lambda function. The developer must prevent development data from affecting the production Lambda function.\\n\\nWhat should the developer do to meet these requirements?","choices":{"C":"Separate the development environment and the production environment into their own AWS accounts. Update the execution role for each Lambda function. Add a policy that allows the execution role to read from only the S3 bucket that is in the same account.","A":"Update the execution role for the production Lambda function. Add a policy that allows the execution role to read from only the production S3 bucket.","B":"Update the S3 bucket policy for the production S3 bucket to invoke the production Lambda function. Update the S3 bucket policy for the development S3 bucket to invoke the development Lambda function.","D":"Separate the development environment and the production environment into their own AWS accounts. Add a resource policy to the Lambda functions to allow only S3 bucket events in the same account to invoke the functions."},"correct_answer":"D","answer_ET":"D","answers_community":["D (90%)","10%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148956-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 07:43:00","unix_timestamp":1728538980,"discussion_count":6,"discussion":[{"content":"Selected Answer: B\\nThe best solution is B. \\nThe issue stems from incorrectly configured S3 bucket policies. Each bucket\'s policy should explicitly specify which Lambda function to invoke when an event occurs in that bucket. By updating the policies to correctly map each bucket to its corresponding Lambda function, you ensure that events from the development bucket only trigger the development function, preventing accidental invocation of the production function.","poster":"examuserss","comment_id":"1335660","upvote_count":"1","timestamp":"1735835640.0"},{"content":"Selected Answer: D\\nD is the answer. @Moderator, please correct the answer from B to D.","upvote_count":"3","comment_id":"1311163","timestamp":"1731484620.0","poster":"devmo"},{"timestamp":"1731000480.0","content":"Selected Answer: D\\nDDDDDDDDDDDDDDDDD","upvote_count":"2","poster":"Saudis","comment_id":"1308489"},{"upvote_count":"1","timestamp":"1730988540.0","poster":"Saudis","comment_id":"1308386","content":"Selected Answer: D\\nD is the correct answer"},{"poster":"ogogundare","comment_id":"1306713","timestamp":"1730679540.0","upvote_count":"1","content":"D is the correct answer"},{"timestamp":"1728538980.0","upvote_count":"3","content":"Selected Answer: D\\nAccount Separation: By separating development and production environments into different AWS accounts, you create a strong boundary between the two. This is a best practice for security and resource management.\\nResource Policy: Adding a resource policy to the Lambda functions that allows only S3 bucket events from the same account to invoke them ensures that cross-account invocations cannot occur accidentally.","poster":"albert_kuo","comment_id":"1295413"}],"answer_description":"","extracted_at":"2025-12-24T09:08:37.124Z","extraction_method":"api_direct_v1"},{"question_id":"XoymnKdJk1EhwbOoC3ZH","question_number":373,"page":75,"question_text":"A developer is writing an application that will run on Amazon EC2 instances in an Auto Scaling group. The developer wants to externalize the session state to support the application.\\n\\nWhich AWS services or resources can the developer use to meet these requirements? (Choose two.)","choices":{"E":"Amazon Simple Queue Service (Amazon SQS)","A":"Amazon DynamoDB","B":"Amazon Cognito","C":"Amazon ElastiCache","D":"Application Load Balancer"},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156702-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 12:13:00","unix_timestamp":1739790780,"discussion_count":1,"discussion":[{"timestamp":"1739790780.0","poster":"italiancloud2025","content":"Selected Answer: AC\\nAmazon DynamoDB: Permite almacenar y acceder r\xe1pidamente a datos de sesi\xf3n de manera escalable y gestionada.\\nAmazon ElastiCache: Ofrece almacenamiento en memoria (por ejemplo, Redis o Memcached) para datos de sesi\xf3n, con baja latencia y alto rendimiento.","upvote_count":"2","comment_id":"1357768"}],"answer_description":"","extracted_at":"2025-12-24T09:08:37.124Z","extraction_method":"api_direct_v1"},{"question_id":"Axhijbob6y5gAMup8NyH","question_number":374,"page":75,"question_text":"A company has a serverless application that uses an Amazon API Gateway API to invoke an AWS Lambda function. A developer creates a fix for a defect in the Lambda function code. The developer wants to deploy this fix to the production environment.\\n\\nTo test the changes, the developer needs to send 10% of the live production traffic to the updated Lambda function version.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"D":"Set up a routing policy on a Network Load Balancer. Configure 10% of the traffic to go to the new Lambda function version.","C":"Create an alias for the Lambda function. Configure weighted routing on the alias. Specify a 10% weight for the new Lambda function version.","A":"Publish a new version of the Lambda function that contains the updated code.","B":"Set up a new stage in API Gateway with a new Lambda function version. Enable weighted routing in API Gateway stages.","E":"Set up a weighted routing policy by using Amazon Route 53. Configure 10% of the traffic to go to the new Lambda function version."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150942-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-07 14:36:00","unix_timestamp":1730986560,"discussion_count":2,"discussion":[{"timestamp":"1735835940.0","poster":"examuserss","content":"Selected Answer: AC\\nThe correct answers are AC\\n\\nHere\'s why:\\n\\nA. Publish a new version: Lambda\'s versioning mechanism allows you to deploy updated code without affecting the currently running version. This is a crucial first step.\\n\\nC. Create an alias and configure weighted routing: API Gateway doesn\'t directly support weighted routing to different Lambda function versions. However, creating an alias allows you to point to multiple versions of a function. You can then configure the API Gateway to use this alias, allowing for weighted routing between the versions through the alias. This provides a controlled rollout of the updated function.","upvote_count":"1","comment_id":"1335661"},{"poster":"Saudis","content":"Selected Answer: AC\\nAC -----","comment_id":"1308371","upvote_count":"1","timestamp":"1730986560.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:37.124Z","extraction_method":"api_direct_v1"},{"question_id":"7BMyd6UuIU6YQlsR8EDP","question_number":375,"page":75,"question_text":"A developer is creating a video search application for a global company. The video files have an average size of 2.5 TB. The video storage system must provide instant access to the video files for the first 90 days. After the first 90 days, the video files can take more than 10 minutes to load.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"A":"Upload the video files to the Amazon Elastic File System (Amazon EFS) Standard storage class for the first 90 days. After 90 days, transition the video files to the EFS Standard-Infrequent Access (Standard-IA) storage class.","C":"Use Amazon Elastic Block Store (Amazon EBS) to store the video files for the first 90 days. After 90 days, transition the video files to the Amazon S3 Glacier Deep Archive storage class.","D":"Upload the video files to Amazon S3. Use the S3 Glacier Instant Retrieval storage class for the first 90 days. After 90 days, transition the video files to the S3 Glacier Flexible Retrieval storage class.","B":"Upload the video files to Amazon S3. Use the S3 Glacier Deep Archive storage class for the first 90 days. After 90 days, transition the video file to the S3 Glacier Flexible Retrieval storage class."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/151546-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-18 12:46:00","unix_timestamp":1731930360,"discussion_count":3,"discussion":[{"upvote_count":"1","timestamp":"1736859960.0","content":"Selected Answer: D\\nD solution is better","comment_id":"1340356","poster":"tullio85"},{"upvote_count":"1","content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/glacier-storage-classes.html","poster":"xdeveloper","timestamp":"1735390260.0","comment_id":"1332953"},{"upvote_count":"1","timestamp":"1731930360.0","poster":"albert_kuo","content":"Selected Answer: D\\n{\\n \\"Rules\\": [\\n {\\n \\"ID\\": \\"TransitionToGlacier\\",\\n \\"Status\\": \\"Enabled\\",\\n \\"Filter\\": {},\\n \\"Transitions\\": [\\n {\\n \\"Days\\": 90,\\n \\"StorageClass\\": \\"GLACIER_IR\\"\\n },\\n {\\n \\"Days\\": 91,\\n \\"StorageClass\\": \\"GLACIER\\"\\n }\\n ]\\n }\\n ]\\n}","comment_id":"1313967"}],"answer_description":"","extracted_at":"2025-12-24T09:08:37.124Z","extraction_method":"api_direct_v1"},{"question_id":"jlJV2ODhOEcQayBHN09H","question_number":376,"page":76,"question_text":"A company has an ecommerce platform. A developer is designing an Amazon DynamoDB table to store customer order data for the platform. The table uses the order ID as the partition key.\\n\\nThe developer needs to modify the table to get all order IDs that are associated with a given customer email address in a single query. The solution must give the developer the ability to query order IDs by other item attributes in the future.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create a local secondary index (LSI) with the customer email address as the sort key.","B":"Update the table to use the customer email address as the partition key.","A":"Configure the partition key to use the customer email address as the sort key.","D":"Create a global secondary index (GSI) with the customer email address as the partition key."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/303051-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-04-27 20:17:00","unix_timestamp":1745777820,"discussion_count":1,"discussion":[{"comment_id":"1564206","timestamp":"1745777820.0","poster":"vbloise","content":"Selected Answer: D\\nThe main table uses order ID as the partition key (good for fast lookups by order ID).\\n\\nYou now need a new access pattern: query by customer email address.\\n\\nA Global Secondary Index (GSI) lets you define different partition keys and sort keys from the base table, supporting completely different queries.\\n\\nUsing customer email address as the GSI partition key allows you to quickly fetch all orders for a given email.\\n\\nGSIs also allow you to add more indexes later if you want to query by other attributes (because you can define multiple GSIs).","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:08:48.153Z","extraction_method":"api_direct_v1"},{"question_id":"DX61sTEUxj6qfvxoFEba","question_number":377,"page":76,"question_text":"A company has a virtual reality (VR) game. The game has a serverless backend that consists of Amazon API Gateway, AWS Lambda, and Amazon DynamoDB. Recently, the company noticed a sudden increase of new users globally. The company also noticed delays in the retrieval of user data.\\n\\nWhich AWS service or feature can the company use to reduce the database response time to microseconds?","choices":{"D":"Amazon CloudFront","C":"DynamoDB auto scaling","B":"DynamoDB Accelerator (DAX)","A":"Amazon ElastiCache"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150938-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-07 12:33:00","unix_timestamp":1730979180,"discussion_count":2,"discussion":[{"upvote_count":"1","timestamp":"1730985420.0","comment_id":"1308364","content":"Selected Answer: B\\nDynamoDB Accelerator (DAX) => response microseconds","poster":"Saudis"},{"timestamp":"1730979180.0","poster":"aws_god","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html\\n\\nAs an in-memory cache, DAX reduces the response times of eventually consistent read workloads by an order of magnitude from single-digit milliseconds to microseconds.","upvote_count":"1","comment_id":"1308339"}],"answer_description":"","extracted_at":"2025-12-24T09:08:48.153Z","extraction_method":"api_direct_v1"},{"question_id":"N1Pigw3ggKpDxkkWOEzz","question_number":378,"page":76,"question_text":"A developer is creating a solution to track an account\'s Amazon S3 buckets over time. The developer has created an AWS Lambda function that will run on a schedule. The function will list the account\'s S3 buckets and will store the list in an Amazon DynamoDB table. The developer receives a permissions error when the developer runs the function with the AWSLambdaBasicExecutionRole AWS managed policy.\\n\\nWhich combination of permissions should the developer use to resolve this error? (Choose two.)","choices":{"B":"Permission for the Lambda function to list buckets in Amazon S3","E":"Permission for DynamoDB to invoke the Lambda function","D":"Permission for Amazon S3 to invoke the Lambda function","C":"Permission for the Lambda function to write in DynamoDB","A":"Cross-account IAM role"},"correct_answer":"BC","answer_ET":"BC","answers_community":["BC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148957-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 07:58:00","unix_timestamp":1728539880,"discussion_count":3,"discussion":[{"comment_id":"1570470","upvote_count":"1","content":"Selected Answer: BC\\nList and write","poster":"thalasi","timestamp":"1747708500.0"},{"poster":"preachr","upvote_count":"2","content":"Selected Answer: BC\\nB and C","timestamp":"1728669660.0","comment_id":"1296201"},{"timestamp":"1728539880.0","comment_id":"1295416","upvote_count":"3","poster":"albert_kuo","content":"Selected Answer: BC\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": [\\n \\"dynamodb:PutItem\\",\\n \\"dynamodb:BatchWriteItem\\"\\n ],\\n \\"Resource\\": \\"arn:aws:dynamodb:REGION:ACCOUNT_ID:table/TABLE_NAME\\"\\n }\\n ]\\n}\\n\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": [\\n \\"dynamodb:PutItem\\",\\n \\"dynamodb:BatchWriteItem\\"\\n ],\\n \\"Resource\\": \\"arn:aws:dynamodb:REGION:ACCOUNT_ID:table/TABLE_NAME\\"\\n }\\n ]\\n}"}],"answer_description":"","extracted_at":"2025-12-24T09:08:48.153Z","extraction_method":"api_direct_v1"},{"question_id":"vzzhz7ppQ6S68Tzu3fov","question_number":379,"page":76,"question_text":"A developer is designing a serverless application with two AWS Lambda functions to process photos. One Lambda function stores objects in an Amazon S3 bucket and stores the associated metadata in an Amazon DynamoDB table. The other Lambda function fetches the objects from the S3 bucket by using the metadata from the DynamoDB table. Both Lambda functions use the same Python library to perform complex computations and are approaching the quota for the maximum size of zipped deployment packages.\\nWhat should the developer do to reduce the size of the Lambda deployment packages with the LEAST operational overhead?","choices":{"B":"Create a Lambda layer with the required Python library. Use the Lambda layer in both Lambda functions.","D":"Download the Python library to an S3 bucket. Program the Lambda functions to reference the object URLs.","A":"Package each Python library in its own .zip file archive. Deploy each Lambda function with its own copy of the library.","C":"Combine the two Lambda functions into one Lambda function. Deploy the Lambda function as a single .zip file archive."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103916-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 02:04:00","unix_timestamp":1679792640,"discussion_count":6,"discussion":[{"comment_id":"1062035","poster":"Ponyi","upvote_count":"13","timestamp":"1714813800.0","content":"Whenever you see \\"to make deployment package smaller\\" -----\x3e Layers"},{"upvote_count":"13","comment_id":"850602","timestamp":"1695686640.0","poster":"Untamables","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-layers.html"},{"content":"Selected Answer: B\\nA) Eliminated - This approach would increase operational overhead because it requires packaging and maintaining duplicate libraries for each function.\\n\\nB) Correct - A Lambda layer is a shared resource containing code or data that can be used by multiple Lambda functions. It reduces the size of individual deployment packages by offloading the library into a shared layer.\\n\\nC) Eliminated - Combining the two functions increases code complexity \\n\\nD) Eliminated - Each Lambda invocation would need to download the library, increasing cold-start time.","upvote_count":"1","comment_id":"1330870","poster":"sumanshu","timestamp":"1734970020.0"},{"upvote_count":"1","timestamp":"1732214220.0","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215097"},{"upvote_count":"6","content":"B\\ncreating a Lambda layer with the required Python library and using it in both Lambda functions, is the most suitable solution for reducing the size of the deployment packages with minimal operational overhead.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-layers.html","comment_id":"947469","poster":"Mtho96","timestamp":"1704829980.0"},{"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-layers.html","upvote_count":"4","timestamp":"1701858300.0","poster":"Baba_Eni","comment_id":"916046"}],"answer_description":"","extracted_at":"2025-12-24T09:08:48.153Z","extraction_method":"api_direct_v1"},{"question_id":"KK1FFQBQyoyLDMYDk9oP","question_number":380,"page":76,"question_text":"A company uses AWS to run its learning management system (LMS) application. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The application\'s domain name is managed in Amazon Route 53. The application is deployed in a single AWS Region, but the company wants to improve application performance for users all over the world.\\n\\nWhich solution will improve global performance with the LEAST operational overhead?","choices":{"B":"Launch more EC2 instances behind the ALConfigure the ALB to use session affinity (sticky sessions). Create a Route 53 alias record for the ALB by using a geolocation routing policy.","C":"Create an AWS Client VPN endpoint in the VPInstruct users to connect to the VPN to access the application. Create a Route 53 alias record for the VPN endpoint. Configure Route 53 to use a geolocation routing policy.","D":"Deploy the application to multiple Regions across the world. Create a Route 53 alias record for the ALB by using a latency-based routing policy.","A":"Set up an Amazon CloudFront distribution that uses the ALB as the origin server. Configure Route 53 to create a DNS alias record that points the application\'s domain name to the CloudFront distribution URL."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148958-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 08:04:00","unix_timestamp":1728540240,"discussion_count":1,"discussion":[{"poster":"albert_kuo","content":"Selected Answer: A\\nOption A provides the best balance of improved global performance and minimal operational overhead. It leverages AWS\'s global infrastructure without requiring complex multi-region deployments or significant changes to the existing application architecture.","timestamp":"1728540240.0","comment_id":"1295422","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:08:48.153Z","extraction_method":"api_direct_v1"},{"question_id":"rOwbzCUB1HfWGNVXdfZK","question_number":381,"page":77,"question_text":"A developer hosts a static website on Amazon S3 and connects the website to an Amazon CloudFront distribution. The website uses a custom domain name that points to the CloudFront URL.\\n\\nThe developer has set up a continuous integration and continuous delivery (CI/CD) pipeline. The pipeline automatically runs when changes occur in an AWS CodeCommit repository. The pipeline has a source stage and then a build stage. The build stage invokes an AWS CodeBuild project that references a buildspec.yml file. The buildspec.yml file builds the code and deploys the static files to the S3 bucket.\\n\\nThe pipeline runs successfully, and the latest website files are visible in the S3 bucket and at the S3 website URL. However, when the developer accesses the website through the CloudFront domain, the updates are not reflected on the website.\\n\\nWhat should the developer configure the buildspec.yml file to do to resolve this issue?","choices":{"D":"Modify the cross-origin resource sharing (CORS) policy of the S3 bucket and redeploy the website files.","C":"Invalidate the file caches for the primary CloudFront distribution.","A":"Properly synchronize the objects in the S3 bucket with new files from the source stage.","B":"Delete the previous website files in the S3 bucket and redeploy the website files."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148959-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 08:08:00","unix_timestamp":1728540480,"discussion_count":3,"discussion":[{"poster":"examuserss","comment_id":"1335669","upvote_count":"1","timestamp":"1735836900.0","content":"Selected Answer: C\\nSelected Answer: C \\nInvalidate the CloudFront cache: To ensure that CloudFront serves the most up-to-date content, you can trigger a cache invalidation in your buildspec.yml file. This will force CloudFront to fetch the latest files from the S3 bucket rather than serving cached content. You can do this by using the AWS CLI to invalidate the CloudFront distribution cache."},{"poster":"4d716d6","comment_id":"1319223","content":"Selected Answer: C\\nInvalidate the caches to enable the new code deployed to reflect","timestamp":"1732796700.0","upvote_count":"1"},{"content":"Selected Answer: C\\naws cloudfront create-invalidation --distribution-id EXAMPLE123 --paths \\"/*\\"","poster":"albert_kuo","comment_id":"1295425","timestamp":"1728540480.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:08:59.139Z","extraction_method":"api_direct_v1"},{"question_id":"F6I18x4gytguR2KyaYYU","question_number":382,"page":77,"question_text":"A developer is working on an ecommerce application that stores data in an Amazon RDS for MySQL cluster. The developer needs to implement a caching layer for the application to retrieve information about the most viewed products.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Configure the RDS for MySQL cluster to add a standby instance in a different Availability Zone. Configure the application to read the data from the standby instance.","C":"Create an Amazon DynamoDB Accelerator (DAX) cluster in front of the RDS for MySQL cluster. Configure the application to connect to the DAX endpoint instead of the RDS endpoint.","B":"Create an Amazon ElastiCache for Redis cluster. Update the application code to use the ElastiCache for Redis cluster endpoint.","A":"Edit the RDS for MySQL cluster by adding a cache node. Configure the cache endpoint instead of the cluster endpoint in the application."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153821-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-02 17:58:00","unix_timestamp":1735837080,"discussion_count":1,"discussion":[{"upvote_count":"1","poster":"examuserss","content":"Selected Answer: B\\nThe best solution to implement a caching layer for the application to retrieve information about the most viewed products is:\\n\\nExplanation:\\nAmazon ElastiCache for Redis is a fully managed, in-memory data store that supports caching. It is commonly used to implement caching layers in applications because it can provide fast, low-latency access to frequently accessed data. In this case, caching the most viewed products would allow the application to quickly retrieve this data without querying the RDS for MySQL database every time, which would reduce the load on the database and improve performance.\\n\\nHow it works: The application would update to use the ElastiCache for Redis cluster endpoint to store and retrieve the most viewed products. Redis supports various data structures, such as hashes, lists, and sets, which can be efficiently used to store the product data.","timestamp":"1735837080.0","comment_id":"1335670"}],"answer_description":"","extracted_at":"2025-12-24T09:08:59.139Z","extraction_method":"api_direct_v1"},{"question_id":"38rTFvSVG7MturGun3Yv","question_number":383,"page":77,"question_text":"A gaming application stores scores for players in an Amazon DynamoDB table that has four attributes: user_id, user_name, user_score, and user_rank. The users are allowed to update their names only. A user is authenticated by web identity federation.\\n\\nWhich set of conditions should be added in the policy attached to the role for the dynamodb:PutItem API call?","choices":{"B":"","D":"","C":"","A":""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148960-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-10 08:11:00","unix_timestamp":1728540660,"discussion_count":2,"discussion":[{"comment_id":"1300289","poster":"gdm83","timestamp":"1729401600.0","content":"Selected Answer: A\\nAnswer is A","upvote_count":"1"},{"comment_id":"1295427","poster":"albert_kuo","content":"Selected Answer: A\\nIt uses \\"dynamodb:LeadingKeys\\" with \\"${www.amazon.com:user_id}\\", ensuring that users can only modify their own records.\\nIt specifies \\"dynamodb:Attributes\\" as [\\"user_name\\"], restricting the operation to only modify the user\'s name.","upvote_count":"2","timestamp":"1728540660.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:59.139Z","extraction_method":"api_direct_v1"},{"question_id":"fJt2miZSpYE4Hzw1nIqJ","question_number":384,"page":77,"question_text":"A developer is creating a database of products. Queries for frequently accessed products must have retrieval times of microseconds. To ensure data consistency, the application cache must be updated whenever products are added, changed, or deleted.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Set up an Amazon RDS database and an Amazon DynamoDB Accelerator (DAX) cluster. Specify a TTL setting for the DAX cluster.","C":"Setup an Amazon DynamoDB database that has an in-memory cache. Implement a lazy loading caching strategy in the application.","A":"Set up an Amazon DynamoDB database and a DynamoDB Accelerator (DAX) cluster.","B":"Set up an Amazon RDS database and an Amazon ElastiCache for Redis cluster. Implement a lazy loading caching strategy with ElastiCache."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/149825-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-20 07:23:00","unix_timestamp":1729401780,"discussion_count":2,"discussion":[{"timestamp":"1730680980.0","poster":"ogogundare","content":"A is the correct answer. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html","comment_id":"1306726","upvote_count":"1"},{"comment_id":"1300292","poster":"gdm83","upvote_count":"1","content":"Selected Answer: A\\nDAX is a fully managed, in-memory caching service for DynamoDB that provides fast read performance (typically in microseconds). DAX is designed specifically to be used with DynamoDB, which makes it ideal for your use case where quick retrieval of frequently accessed products is essential.","timestamp":"1729401780.0"}],"answer_description":"","extracted_at":"2025-12-24T09:08:59.139Z","extraction_method":"api_direct_v1"},{"question_id":"OFW38ep1EVgnIi2DfLCB","question_number":385,"page":77,"question_text":"A developer is creating a script to automate the deployment process for a serverless application. The developer wants to use an existing AWS Serverless Application Model (AWS SAM) template for the application.\\n\\nWhat should the developer use for the project? (Choose two.)","choices":{"A":"Call aws cloudformation package to create the deployment package. Call aws cloudformation deploy to deploy the package afterward.","B":"Call sam package to create the deployment package. Call sam deploy to deploy the package afterward.","E":"Create a ZIP package and upload it to Amazon S3. Call aws cloudformation create-stack to create the application.","C":"Call aws s3 cp to upload the AWS SAM template to Amazon S3. Call aws lambda update-function-code to create the application.","D":"Create a ZIP package locally and call aws serverlessrepo create-applicatiion to create the application."},"correct_answer":"AB","answer_ET":"AB","answers_community":["AB (56%)","BE (44%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/148536-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-10-02 05:48:00","unix_timestamp":1727840880,"discussion_count":4,"discussion":[{"timestamp":"1728481140.0","poster":"YUICH","content":"Selected Answer: AB\\nthe answer is A B","comment_id":"1295184","upvote_count":"5"},{"upvote_count":"1","poster":"DSExam","content":"Selected Answer: BE\\nCopilot said so","timestamp":"1754320980.0","comment_id":"1594836"},{"upvote_count":"3","poster":"LingZ","comment_id":"1359099","content":"Selected Answer: BE\\n\u2705 B. Call sam package to create the deployment package. Call sam deploy to deploy the package afterward.\\n\u2705 E. Create a ZIP package and upload it to Amazon S3. Call aws cloudformation create-stack to create the application.","timestamp":"1740029700.0"},{"poster":"donakolab94","upvote_count":"1","content":"CE","timestamp":"1727840880.0","comment_id":"1292196"}],"answer_description":"","extracted_at":"2025-12-24T09:08:59.139Z","extraction_method":"api_direct_v1"},{"question_id":"8E6J7XCHy8pc1vQJO1v4","question_number":386,"page":78,"question_text":"A developer adds new dependencies to an existing AWS Lambda function. The developer cannot deploy the Lambda function because the unzipped deployment package exceeds the maximum size quota for the Lambda function. The instruction set architecture of the Lambda function is x86_64.\\n\\nThe developer must implement a solution to deploy the Lambda function with the new dependencies.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create and deploy a Lambda container image with all the dependencies.","C":"Associate an Amazon Elastic Block Store (Amazon EBS) volume with the Lambda function. Store all the dependencies on the EBS volume.","B":"Change the instruction set architecture of the Lambda function to use an arm64 architecture.","A":"Create a snapshot of all the dependencies. Configure the Lambda function to use the snapshot."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/303078-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-04-28 14:45:00","unix_timestamp":1745844300,"discussion_count":1,"discussion":[{"poster":"vbloise","timestamp":"1745844300.0","content":"Selected Answer: D\\nExplanation:\\n\\n AWS Lambda has a maximum unzipped package size limit of 250 MB when you deploy using ZIP files.\\n\\n However, Lambda container images can be up to 10 GB in size, allowing you to include much larger sets of code and dependencies.\\n\\n Since the unzipped package is too large, moving to a container image is the correct and AWS-recommended solution.\\n\\nOther options are incorrect because:\\n\\n A. Snapshots don\'t apply to Lambda deployment \u2014 that\'s not a supported feature.\\n\\n B. Changing to arm64 doesn\'t solve the package size problem. It just changes the architecture (and possibly reduces costs).\\n\\n C. Lambda cannot mount EBS volumes directly \u2014 that\'s not how Lambda storage works.","comment_id":"1564429","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:09:10.150Z","extraction_method":"api_direct_v1"},{"question_id":"1VbNwqyFSasTS0qAokGj","question_number":387,"page":78,"question_text":"A developer is working on a project that requires regular updates to a web application\u2019s backend code. The code is stored in AWS CodeCommit. Company policy states that all code must have complete unit testing and that the test results must be available for access.\\n\\nThe developer needs to implement a solution that will take each change to the code repository, build the code, and run unit tests. The solution also must provide a detailed report of the test results.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Configure Amazon CodeWhisperer to create the code and to run unit tests. Save the test results in an Amazon S3 bucket to generate reports.","C":"Configure AWS CodeBuild to build the code and to run unit tests. Use test reporting in CodeBuild to generate and view reports.","A":"Configure AWS CodeDeploy to deploy code from CodeCommit and to run unit tests. Send the test results to Amazon CloudWatch metrics to view reports.","D":"Create AWS Lambda functions that run when changes are made in CodeCommit. Program the Lambda functions to build the code, run unit tests, and save the test results to a Lambda layer."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156844-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-20 06:43:00","unix_timestamp":1740030180,"discussion_count":1,"discussion":[{"timestamp":"1740030180.0","upvote_count":"4","poster":"LingZ","content":"Selected Answer: C\\nCodeBuild compiles the code, runs tests, and produces artifacts.\\nIt supports test reporting features, which provide detailed insights into test results.\\nDevelopers can view reports directly in the AWS Management Console.\\nCodeBuild integrates seamlessly with CodeCommit and other AWS CI/CD tools.","comment_id":"1359102"}],"answer_description":"","extracted_at":"2025-12-24T09:09:10.150Z","extraction_method":"api_direct_v1"},{"question_id":"oIze9z3RD8Lh22FvMxzO","question_number":388,"page":78,"question_text":"A developer is building an application on AWS. The application has an Amazon API Gateway API that sends requests to an AWS Lambda function. The API is experiencing increased latency because the Lambda function has limited available CPU to fulfill the requests.\\n\\nBefore the developer deploys the API into production, the developer must configure the Lambda function to have more CPU.\\n\\nWhich solution will meet this requirement?","choices":{"D":"Increase the timeout value of the Lambda function.","A":"Increase the virtual CPU (vCPU) cores quota of the Lambda function.","B":"Increase the amount of memory that is allocated to the Lambda function.","C":"Increase the ephemeral storage size of the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150940-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-07 13:32:00","unix_timestamp":1730982720,"discussion_count":1,"discussion":[{"upvote_count":"1","timestamp":"1730982720.0","poster":"Saudis","comment_id":"1308355","content":"Selected Answer: B\\nIn lambda The more memory, the more CPU available."}],"answer_description":"","extracted_at":"2025-12-24T09:09:10.150Z","extraction_method":"api_direct_v1"},{"question_id":"09toKLascB2VBwPTqS6D","question_number":389,"page":78,"question_text":"A developer is creating a web application to upload and store private data. The application will encrypt private data and then will upload the data to an Amazon S3 bucket.\\n\\nThe developer needs to implement a solution to automatically find any unencrypted private data in the S3 bucket. The solution must monitor the security and access control of the S3 bucket and must provide a notification if there are any security issues.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create an Amazon Kinesis data stream. Configure Amazon S3 to send new object notifications to the stream. Create an AWS Lambda function that runs every 10 minutes to check the stream for unencrypted private data and to monitor for security issues. Program the Lambda function to provide a notification when security issues are detected.","A":"Use AWS Step Functions to run Amazon Athena queries. Configure Athena to find unencrypted private data and to monitor for security issues in the S3 bucket. Start the queries when new objects are added to the S3 bucket. Configure Athena to provide a notification if security issues are detected.","C":"Enable Amazon Inspector for the AWS account. Use Amazon Inspector to scan the S3 bucket to find unencrypted private data and to monitor for security issues. Set up Amazon EventBridge to provide a notification when Amazon Inspector detects security issues.","B":"Enable Amazon Macie for the S3 bucket. Set up custom criteria to find unencrypted private data in the S3 bucket. Set up AWS User Notifications to provide a notification when Macie detects security issues."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/303080-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-04-28 14:54:00","unix_timestamp":1745844840,"discussion_count":1,"discussion":[{"upvote_count":"1","timestamp":"1745844840.0","poster":"vbloise","comment_id":"1564436","content":"Selected Answer: B\\nThe correct answer is B. Enable Amazon Macie for the S3 bucket. Set up custom criteria to find unencrypted private data in the S3 bucket. Set up AWS User Notifications to provide a notification when Macie detects security issues.\\n\\nReasoning:\\n\\n Amazon Macie is specifically designed to automatically discover, classify, and protect sensitive data stored in Amazon S3 buckets.\\n\\n Macie can detect unencrypted data, public access issues, and sensitive data exposure.\\n\\n It integrates with Amazon EventBridge and User Notifications to send alerts when security issues are detected.\\n\\n Other options like Inspector (C) do not scan S3 for data classification or encryption status (Inspector is more for EC2 and ECR).\\n\\n Step Functions + Athena (A) would require custom development and maintenance, which is unnecessary since Macie natively does this.\\n\\n Kinesis + Lambda (D) would be overly complex, error-prone, and again unnecessary because Macie exists specifically for this use case."}],"answer_description":"","extracted_at":"2025-12-24T09:09:10.150Z","extraction_method":"api_direct_v1"},{"question_id":"kGlyviMBKrkH1o8NDDr8","question_number":390,"page":78,"question_text":"A developer is writing an AWS Lambda function. The developer wants to log key events that occur while the Lambda function runs. The developer wants to include a unique identifier to associate the events with a specific function invocation. The developer adds the following code to the Lambda function:\\n//IMG//\\n\\nWhich solution will meet this requirement?","choices":{"A":"Obtain the request identifier from the AWS request ID field in the context object. Configure the application to write logs to standard output.","D":"Obtain the request identifier from the AWS request ID field in the context object. Configure the application to write logs to a file.","C":"Obtain the request identifier from the AWS request ID field in the event object. Configure the application to write logs to standard output.","B":"Obtain the request identifier from the AWS request ID field in the event object. Configure the application to write logs to a file."},"correct_answer":"A","answer_ET":"A","answers_community":["A (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103708-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image2.png"],"answer_images":[],"timestamp":"2023-03-23 23:34:00","unix_timestamp":1679610840,"discussion_count":19,"discussion":[{"content":"Selected Answer: A\\nBoth A and D could work here, as both rely on the context object to get access to execution ID https://docs.aws.amazon.com/us_en/lambda/latest/dg/python-context.html \\nWhile A uses stoud to send log to CloudWatch Log, D writes to a file. D is less specific (where is the file stored? A single file for each execution?) and looks more comples (manage file(s), manage concurrency access to the file ...), thus I\'ll go for A","comment_id":"985063","poster":"ninomfr64","timestamp":"1708338000.0","upvote_count":"15"},{"timestamp":"1695686820.0","comment_id":"850603","poster":"Untamables","upvote_count":"8","comments":[{"comment_id":"948367","poster":"Pupina","content":"\u2022 https://docs.aws.amazon.com/prescriptive-guidance/latest/implementing-logging-monitoring-cloudwatch/lambda-logging-metrics.html\\n\u2022 Lambda automatically streams standard output and standard error messages from a Lambda function to CloudWatch Logs, without requiring logging drivers.","timestamp":"1704924420.0","upvote_count":"2"}],"content":"Selected Answer: A\\nA\\nhttps://docs.aws.amazon.com/lambda/latest/dg/nodejs-context.html\\nhttps://docs.aws.amazon.com/lambda/latest/dg/nodejs-logging.html\\nThere is no explicit information for the runtime, the code is written in Node.js."},{"comment_id":"1399147","poster":"ProcureSense","upvote_count":"1","timestamp":"1742105100.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/lambda/latest/dg/getting-started.html"},{"poster":"sumanshu","timestamp":"1734970200.0","upvote_count":"2","content":"Selected Answer: A\\nA) Correct - The context object contains the AWS request ID, which uniquely identifies each function invocation. Writing logs to standard output ensures they are automatically captured by CloudWatch Logs.\\n\\n\\nB) Eliminated - The event object contains input data passed to the Lambda function but does not include the AWS request ID. Writing logs to a file is not practical in Lambda because the filesystem is ephemeral, and logs stored in files would not persist beyond the function invocation.","comment_id":"1330871"},{"timestamp":"1732214340.0","comment_id":"1215098","poster":"65703c1","upvote_count":"1","content":"Selected Answer: A\\nA is the correct answer."},{"comment_id":"1192956","poster":"badsati","content":"Selected Answer: A\\nA should work","upvote_count":"1","timestamp":"1728562320.0"},{"timestamp":"1724193120.0","comment_id":"1155099","content":"Selected Answer: A\\nSee getAwsRequestId() at https://docs.aws.amazon.com/lambda/latest/dg/java-context.html","upvote_count":"1","poster":"james2033"},{"poster":"rimaSamir","content":"Tricky question. Sure A and D both can do, but... The question is: why we need to get the request identifier if we will write logs to CloudWatch?\\nSo, I will go with answer A.","comment_id":"1151768","upvote_count":"1","timestamp":"1723781160.0"},{"content":"I think it should be A. Also can anyone advise why the two answers are different ? \\nhttps://www.examtopics.com/discussions/amazon/view/29007-exam-aws-certified-developer-associate-topic-1-question-26/","comment_id":"1138289","timestamp":"1722579060.0","upvote_count":"2","poster":"SD_CS"},{"content":"The Option A is correct because:\\nThe second argument is the context object. A context object is passed to your function by Lambda at runtime. This object provides methods and properties that provide information about the invocation, function, and runtime environment.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/python-handler.html","comment_id":"1098688","upvote_count":"1","poster":"KarBiswa","timestamp":"1718596980.0"},{"timestamp":"1710034020.0","content":"invocation is in the Context object, and loggging into Standard output, which goes into CloudWatch(more durable, more scalable, etc.), is generally better than using temporary Files","comment_id":"1003548","poster":"hsinchang","upvote_count":"1"},{"comment_id":"948366","upvote_count":"1","poster":"Pupina","timestamp":"1704924240.0","content":"Selected Answer A: \\nHandler function https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html\\nContext object awsRequestId \u2013 The identifier of the invocation request. https://docs.aws.amazon.com/lambda/latest/dg/nodejs-context.html"},{"content":"Selected Answer: A\\nIn my opinion both options A and D can fulfill the requirement, since there is no requirement about any specific logging and monitoring tool I will go with defaults (A) because, simple is better than complex :)","upvote_count":"1","comment_id":"927873","timestamp":"1703022780.0","poster":"rlnd2000"},{"content":"Selected Answer: A\\nThe application can write logs to standard output or to a file. Standard output is the default destination for logs. Logs that are written to standard output are sent to Amazon CloudWatch Logs. Logs that are written to a file are stored on the Lambda function\'s execution environment.","timestamp":"1700446380.0","comment_id":"902280","poster":"Prem28","upvote_count":"5"},{"comment_id":"895857","poster":"Nagendhar","timestamp":"1699794120.0","content":"Ans: D\\n\\nThe code snippet provided in the question is obtaining the request identifier from the context.awsRequestId property, which is available in the context object provided to the Lambda function handler. Therefore, the correct option is:\\n\\nD. Obtain the request identifier from the AWS request ID field in the context object. Configure the application to write logs to a file.\\n\\nThis option meets the requirement of logging key events and including a unique identifier to associate the events with a specific function invocation.","upvote_count":"1"},{"timestamp":"1697891040.0","upvote_count":"3","comment_id":"876508","content":"Selected Answer: D\\nWhy not D ? Writing logs to a file seems more appropriate than stdout","poster":"Rpod"},{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/us_en/lambda/latest/dg/python-context.html\\nhttps://docs.aws.amazon.com/us_en/lambda/latest/dg/python-logging.html","timestamp":"1695641400.0","upvote_count":"4","poster":"Watascript","comment_id":"850158"},{"timestamp":"1695547440.0","upvote_count":"3","poster":"Dun6","comment_id":"849250","content":"Selected Answer: A\\nA it is"},{"poster":"March2023","timestamp":"1695501240.0","content":"Selected Answer: A\\nI think the answer is A","comment_id":"848722","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:09:10.151Z","extraction_method":"api_direct_v1"},{"question_id":"mKhw7JfwcMUAA3ZFZnTM","question_number":391,"page":79,"question_text":"A developer has an application that uses AWS Lambda functions and AWS CloudFormation templates. Usage of the application has increased. As a result, the Lambda functions are encountering rate limit errors when they retrieve data.\\n\\nThe Lambda functions retrieve an advanced parameter from AWS Systems Manager Parameter Store on every call. The parameter changes only during new deployments. Because the application\u2019s usage is unpredictable, the developer needs a way to avoid the rate limiting.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"B":"Add a retry mechanism with exponential backoff to the call to Parameter Store.","D":"Add an SSM dynamic reference as an environment variable to the Lambda functions resource in the CloudFormation templates.","A":"Configure the Lambda functions to use reserved concurrency that is equal to the last month\u2019s average number of concurrent invocations.","C":"Request a service quota increase for Parameter Store GetParameter API operations to match the expected usage of the Lambda functions."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150773-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-05 12:08:00","unix_timestamp":1730804880,"discussion_count":2,"discussion":[{"content":"Selected Answer: D\\nD is correct The application experiences rate limiting because Lambda calls the Parameter Store every time the function is run. This means that as the number of Lambda calls increases, each call also triggers a request from the Parameter Store, which increases the number of requests and leads to exceeding the limit.\\n\\nUsing an SSM dynamic reference as an environmental variable in CloudFormation will allow Lambda to load the value only once on startup, and there will be no need to request the value of the variable from the Parameter Store on each call. This way, the value is obtained directly from the pre-loaded environmental variable instead of sending additional requests.","poster":"Saudis","timestamp":"1730804880.0","comment_id":"1307323","upvote_count":"7"},{"content":"Selected Answer: D\\nD is answer","upvote_count":"1","comment_id":"1339720","timestamp":"1736724360.0","poster":"bp07"}],"answer_description":"","extracted_at":"2025-12-24T09:09:21.142Z","extraction_method":"api_direct_v1"},{"question_id":"pbCmmvU5pFIl7zIsi9n0","question_number":392,"page":79,"question_text":"A developer is using an AWS Lambda function to process data. The developer needs to extract custom metrics about processing times from the Lambda logs. The developer needs to analyze the metrics, set alarms, and detect issues in real time.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create an Amazon Kinesis data stream to stream log events in real time from Lambda. Specify an Amazon S3 bucket as the destination for the Kinesis data stream. Use Amazon CloudWatch to visualize the log data and to set alarms.","A":"Publish custom metric data to AWS CloudTrail by using the PutMetricData API operation. Classify and collect the metrics. Create graphs and alarms in CloudTrail for the custom metrics.","C":"Use Amazon CloudWatch Logs Insights to create custom metrics by querying the logs that come from the Lambda function. Use CloudWatch to create the required graphs and alarms for the custom metrics.","B":"Use the open source client libraries provided by Amazon to generate the logs in the Amazon CloudWatch embedded metric format. Use CloudWatch to create the required graphs and alarms for the custom metrics."},"correct_answer":"B","answer_ET":"B","answers_community":["B (67%)","A (17%)","C (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150775-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-05 12:25:00","unix_timestamp":1730805900,"discussion_count":3,"discussion":[{"content":"Selected Answer: A\\nokkkkkkkkkkkkkk","timestamp":"1754150400.0","poster":"fe600c8","upvote_count":"1","comment_id":"1593734"},{"timestamp":"1736862360.0","comment_id":"1340374","poster":"tullio85","content":"Selected Answer: C\\nCloudWatch Logs Insights: CloudWatch Logs Insights allows you to interactively search and analyze log data from various AWS services, including AWS Lambda. You can use Logs Insights to query the Lambda logs and extract custom metrics, such as processing times, based on specific patterns or conditions in the log data.","upvote_count":"1","comments":[{"poster":"acea5d5","comment_id":"1578898","upvote_count":"1","timestamp":"1750342200.0","content":"Cloudwatch logs insight is not used for creating custom metrics -> B is the right choice"}]},{"content":"Selected Answer: B\\nB is more direct to real-time data due to automatic integration of indicators into CloudWatch, and is best if the data in the logs is static and needs constant monitoring. C gives you more flexibility but not necessarily as fast as B because it relies on queries that are run separately","upvote_count":"4","timestamp":"1730805900.0","comment_id":"1307336","poster":"Saudis"}],"answer_description":"","extracted_at":"2025-12-24T09:09:21.142Z","extraction_method":"api_direct_v1"},{"question_id":"7E0HWRXofirfZ7EMZQSZ","question_number":393,"page":79,"question_text":"A developer needs to fix an AWS CodeDeploy deployment that failed. During the failed deployment, the developer received the following error message:\\n\\n\u201cThe overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems. (Error code: HEALTH-CONSTRAINTS)\u201d\\n\\nWhat are the possible causes of the failed deployment? (Choose two.)","choices":{"B":"The unified Amazon CloudWatch agent was not running on the instances that CodeDeploy was trying to deploy to.","D":"CodeDeploy was trying to deploy to instances that were attached to an IAM instance profile that did not have the required permissions.","E":"CodeDeploy was trying to deploy to instances that were not set up with correct CodeDeploy health checks.","A":"The CodeDeploy agent was not running on the instances that CodeDeploy was trying to deploy to.","C":"The developer\u2019s IAM role did not have the necessary permissions to perform code deployment to the instances."},"correct_answer":"AE","answer_ET":"AE","answers_community":["AE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150946-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-07 16:03:00","unix_timestamp":1730991780,"discussion_count":1,"discussion":[{"upvote_count":"3","timestamp":"1730991780.0","comment_id":"1308416","content":"Selected Answer: AE\\nhttps://repost.aws/questions/QUz-BsaEMhT-qhDfrQyNz7fA/codedeploy-deployment-failed-after-ec2-changed-instance-type","poster":"aws_god"}],"answer_description":"","extracted_at":"2025-12-24T09:09:21.142Z","extraction_method":"api_direct_v1"},{"question_id":"2bxPu0DDKqiYFoVZkeVG","question_number":394,"page":79,"question_text":"A company is developing a serverless application that requires storage of sensitive API keys as environment variables for various services. The application requires the automatic rotation of the encryption keys every year.\\n\\nWhich solution will meet these requirements with no development effort?","choices":{"C":"Encrypt the environment variables by using AWS Key Management Service (AWS KMS) AWS managed keys. Configure a custom AWS Lambda function to automate key rotation.","A":"Encrypt the environment variables by using AWS Secrets Manager. Set up automatic rotation in Secrets Manager.","B":"Encrypt the environment variables by using AWS Key Management Service (AWS KMS) customer managed keys. Enable automatic key rotation.","D":"Encrypt the environment variables by using AWS Systems Manager Parameter Store. Set up automatic rotation in Parameter Store."},"correct_answer":"B","answer_ET":"B","answers_community":["B (50%)","A (38%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/151333-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-14 21:41:00","unix_timestamp":1731616860,"discussion_count":7,"discussion":[{"poster":"thalasi","upvote_count":"1","content":"Selected Answer: D\\nFrom Gemini\\n\\nTo securely store API keys as environment variables in a serverless application and automatically rotate encryption keys annually, the best solution is to use AWS Systems Manager Parameter Store, especially the Parameter Store feature. This service allows you to store secrets and other sensitive data in a secure, managed environment.","timestamp":"1747710120.0","comment_id":"1570475"},{"comment_id":"1364923","timestamp":"1741095540.0","poster":"0bdf3af","upvote_count":"1","content":"Selected Answer: B\\nB is correct\\nWIth custom key in KMS, we can set automatic rotation after 365.\\nTo configure rotation in Secrets Manager we need to provide lambda function. It is costs some develpment effort, right?"},{"content":"Selected Answer: B\\nB is the correct answer.\\nA is wrong as Secret Manager is a place to store things, it does not encrypt things.","poster":"Arad","upvote_count":"2","timestamp":"1736463120.0","comment_id":"1338562"},{"poster":"fbx01","comment_id":"1327632","content":"Selected Answer: A\\nautomatic rotation in Secrets Manager.","timestamp":"1734382860.0","upvote_count":"1"},{"comment_id":"1314037","content":"A. Encrypt the environment variables by using AWS Secrets Manager. Set up automatic rotation in Secrets Manager.\\n\\nExplanation:\\nAWS Secrets Manager is designed specifically for securely managing sensitive information like API keys, database credentials, and other secrets. It provides:\\n\\nBuilt-in encryption using AWS Key Management Service (KMS).\\nAutomatic rotation of secrets with minimal effort. Secrets Manager has a native feature for automatic rotation that can be enabled for supported use cases.\\nIntegration with AWS services (e.g., Lambda, RDS, etc.).\\nKey Features Satisfying the Requirements:\\n\\nThe sensitive API keys can be stored securely as secrets.\\nAutomatic rotation can be set up without requiring custom development. Secrets Manager handles rotation using Lambda functions configured for this purpose.","poster":"YUICH","upvote_count":"4","timestamp":"1731941160.0"},{"poster":"albert_kuo","content":"Selected Answer: B\\nAWS KMS supports key rotation","timestamp":"1731934200.0","upvote_count":"1","comments":[{"comment_id":"1322359","timestamp":"1733402280.0","content":"While KMS enables automatic key rotation, it does not manage secrets. The task of securely storing and rotating API keys requires additional development effort, such as creating a Lambda function or a custom solution to integrate with KMS. This contradicts the requirement of \\"no development effort.\\"","poster":"YUICH","upvote_count":"1"}],"comment_id":"1313984"},{"comment_id":"1312321","poster":"CloudChingon","content":"Selected Answer: A\\nMeets the encryption and key rotation requirement but requires additional development to manage secrets rotation.\\nA is correct","timestamp":"1731616860.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:09:21.142Z","extraction_method":"api_direct_v1"},{"question_id":"zVLaXokvoJQGFogVrLIR","question_number":395,"page":79,"question_text":"A developer built an application that uses AWS Lambda functions to process images. The developer wants to improve image processing times throughout the day.\\n\\nThe developer needs to create an Amazon CloudWatch Logs Insights query that shows the average, slowest, and fastest processing time in 1-minute intervals.\\n\\nWhich query will meet these requirements?","choices":{"D":"","C":"","A":"","B":""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157514-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 14:46:00","unix_timestamp":1741095960,"discussion_count":1,"discussion":[{"timestamp":"1741095960.0","content":"Selected Answer: A\\nA. type REPORT","poster":"0bdf3af","upvote_count":"2","comment_id":"1364926"}],"answer_description":"","extracted_at":"2025-12-24T09:09:21.142Z","extraction_method":"api_direct_v1"},{"question_id":"c89IcWHazkJwt8IHQWXg","question_number":396,"page":80,"question_text":"An application stores user data in Amazon S3 buckets in multiple AWS Regions. A developer needs to implement a solution that analyzes the user data in the S3 buckets to find sensitive information. The analysis findings from all the S3 buckets must be available in the eu-west-2 Region.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"C":"Configure Amazon Inspector to generate findings. Use Amazon EventBridge to create rules that copy the findings to eu-west-2.","D":"Configure Amazon Macie to generate findings and to publish the findings to AWS CloudTrail. Use a CloudTrail trail to copy the results to eu-west-2.","A":"Create an AWS Lambda function to generate findings. Program the Lambda function to send the findings to another S3 bucket in eu-west-2.","B":"Configure Amazon Macie to generate findings. Use Amazon EventBridge to create rules that copy the findings to eu-west-2."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/151627-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-19 11:32:00","unix_timestamp":1732012320,"discussion_count":2,"discussion":[{"timestamp":"1737715620.0","content":"Selected Answer: B\\nfvregrgvergber","poster":"nkuma214","comment_id":"1346065","upvote_count":"1"},{"comment_id":"1314563","poster":"ShakthiGCP","content":"Selected Answer: B\\nANSWER B","upvote_count":"1","timestamp":"1732012320.0"}],"answer_description":"","extracted_at":"2025-12-24T09:09:32.145Z","extraction_method":"api_direct_v1"},{"question_id":"qiBJeXfJ2bSaRVBGkfLC","question_number":397,"page":80,"question_text":"An application ingests data from an Amazon Kinesis data stream. The shards in the data stream are set for normal traffic.\\n\\nDuring tests for peak traffic, the application ingests data slowly. A developer needs to adjust the data stream to handle the peak traffic.\\n\\nWhat should the developer do to meet this requirement MOST cost-effectively?","choices":{"D":"Increase the shard count in the data stream by using the UpdateShardCount API operation.","B":"Switch to on-demand capacity mode for the data stream. Specify a partition key when writing data to the data stream.","C":"Decrease the amount of time that data is kept in the data stream by using the DecreaseStreamRetentionPeriod API operation.","A":"Install the Kinesis Producer Library (KPL) to ingest data into the data stream."},"correct_answer":"D","answer_ET":"D","answers_community":["D (83%)","B (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/151547-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-18 13:56:00","unix_timestamp":1731934560,"discussion_count":3,"discussion":[{"timestamp":"1734922920.0","content":"Selected Answer: D\\nComparison of B and D:\\nB (On-Demand Mode) is better when:\\n\\nTraffic patterns are highly variable or unpredictable.\\nAutomatic scaling is preferred to minimize manual intervention.\\nThe workload is intermittent, making On-Demand pricing more cost-efficient.\\nD (Manually Adjusting Shard Count) is better when:\\n\\nThe application has predictable traffic peaks and troughs.\\nThe goal is to manually control scaling and costs in provisioned mode.\\nImmediate scaling is required to meet throughput needs, as On-Demand Mode may introduce a slight delay for shard scaling.\\nConclusion:\\nThe correct solution depends on the specific requirements mentioned in the question. If the question highlights unpredictable traffic, On-Demand Mode (B) is likely the better choice. However, if the traffic peaks are predictable and manual control is desired, increasing shards (D) is the optimal solution.","upvote_count":"3","comment_id":"1330662","poster":"YUICH"},{"upvote_count":"1","timestamp":"1734001680.0","comment_id":"1325569","content":"Selected Answer: B\\nOn-demand - data streams with an on-demand mode require no capacity planning and automatically scale to handle gigabytes of write and read throughput per minute. With the on-demand mode, Kinesis Data Streams automatically manages the shards in order to provide the necessary throughput.","poster":"ShakthiGCP","comments":[{"upvote_count":"1","timestamp":"1734710700.0","poster":"ShakthiGCP","comment_id":"1329550","content":"The key word is \'Codt effective\' - you dont want to pay more by updating the shards for higher rate."}]},{"upvote_count":"2","poster":"albert_kuo","timestamp":"1731934560.0","comment_id":"1313988","comments":[{"upvote_count":"1","poster":"YUICH","comment_id":"1322360","timestamp":"1733402340.0","content":"Switching to on-demand capacity mode provides automatic scaling, which eliminates the need for manual adjustments while remaining cost-efficient.\\nKinesis adjusts the shard count dynamically based on actual usage, ensuring sufficient capacity during peak traffic without overprovisioning."}],"content":"Selected Answer: D\\naws kinesis update-shard-count \\\\\\n --stream-name my-data-stream \\\\\\n --target-shard-count 4 \\\\\\n --scaling-type UNIFORM_SCALING"}],"answer_description":"","extracted_at":"2025-12-24T09:09:32.146Z","extraction_method":"api_direct_v1"},{"question_id":"pENOSeYsvVEfdwZtJNLl","question_number":398,"page":80,"question_text":"A developer is building an application that uses an AWS Lambda function to process data. The application requires minimum latency. The Lambda function must have predictable function start times. All setup activities for the execution environment must happen before invocation of the Lambda function.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Optimize the static initialization code that runs when a new execution environment is prepared for the first time. Decrease and compress the size of the Lambda function package and the imported libraries and dependencies.","D":"Publish a new version of the Lambda function. Configure provisioned concurrency for the Lambda function with the required minimum number of execution environments.","C":"Increase the reserved concurrency of the Lambda function to the maximum value for unreserved account concurrency. Run any setup activities manually before the initial invocation of the Lambda function.","A":"Increase the memory of the Lambda function to the maximum amount. Configure an Amazon EventBridge rule to schedule invocations of the Lambda function every minute to keep the execution environment active."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152886-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-12 12:10:00","unix_timestamp":1734001800,"discussion_count":2,"discussion":[{"upvote_count":"2","content":"Selected Answer: D\\nmust have predictable function start times\\n\\nso, provisioened consucrrency","timestamp":"1747710660.0","comment_id":"1570477","poster":"thalasi"},{"timestamp":"1734001800.0","content":"Selected Answer: D\\nThe developer\'s requirements\u2014minimum latency, predictable function start times, and all setup activities completed before invocation\u2014point towards using AWS Lambda provisioned concurrency.","upvote_count":"3","comment_id":"1325570","poster":"ShakthiGCP"}],"answer_description":"","extracted_at":"2025-12-24T09:09:32.146Z","extraction_method":"api_direct_v1"},{"question_id":"lGpY2TrR9leQB1mQtee7","question_number":399,"page":80,"question_text":"A company has implemented a pipeline in AWS CodePipeline. The company is using a single AWS account and does not use AWS Organizations. The company needs to test its AWS CloudFormation templates in its primary AWS Region and a disaster recovery Region.\\n\\nWhich solution will meet these requirements with the MOST operational efficiency?","choices":{"C":"Configure CodePipeline to invoke AWS CodeBuild to deploy and test the CloudFormation templates in each Region. Update CodeBuild and CloudFormation with appropriate permissions.","A":"In the CodePipeline pipeline, implement an AWS CodeDeploy action for each Region to deploy and test the CloudFormation templates. Update CodePipeline and AWS CodeBuild with appropriate permissions.","B":"Configure CodePipeline to deploy and test the CloudFormation templates. Use CloudFormation StackSets to start deployment across both Regions.","D":"Use the Snyk action in CodePipeline to deploy and test the CloudFormation templates in each Region."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/150781-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-11-05 13:46:00","unix_timestamp":1730810760,"discussion_count":3,"discussion":[{"poster":"xdeveloper","upvote_count":"2","timestamp":"1735316520.0","comment_id":"1332519","content":"Selected Answer: B\\nAWS CloudFormation StackSets extends the capability of stacks by allowing you to create, update, or delete stacks across multiple accounts and AWS Regions with a single operation. Using an administrator account, you define and manage a CloudFormation template, and use the template as the basis for provisioning stacks into selected target accounts across specified AWS Regions."},{"upvote_count":"1","poster":"aragon_saa","timestamp":"1730845680.0","comment_id":"1307596","content":"Selected Answer: B\\nAnswer is B"},{"timestamp":"1730810760.0","comment_id":"1307368","upvote_count":"2","content":"Selected Answer: B\\nprimary AWS Region and a disaster recovery Region that mean multi regions so should use Staksets","poster":"Saudis"}],"answer_description":"","extracted_at":"2025-12-24T09:09:32.146Z","extraction_method":"api_direct_v1"},{"question_id":"HRUwyNesTTutURRK1Nln","question_number":400,"page":80,"question_text":"A company has an Amazon API Gateway REST API that integrates with an AWS Lambda function. The API\u2019s development stage references a development alias of the Lambda function named dev.\\n\\nA developer needs make a production alias of the Lambda function named prod available through the API.\\n\\nWhich solution meets these requirements?","choices":{"B":"Create a new method on the API. Name the method production. Configure an integration request on the API\u2019s development stage that points to the prod Lambda function alias.","C":"Deploy the API to a new stage named production. Configure the stage to include a stage variable that points to the prod Lambda function alias.","A":"Create a new method on the API. Name the method production. Configure the method to include a stage variable that points to the prod Lambda function alias.","D":"Deploy the API to a new stage named production. Configure an integration request on the API\u2019s production stage that points to the prod Lambda function alias."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153505-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-27 17:30:00","unix_timestamp":1735317000,"discussion_count":3,"discussion":[{"upvote_count":"2","poster":"LingZ","comment_id":"1359464","timestamp":"1740086580.0","content":"Selected Answer: C\\nThis solution separates environments and provides flexibility for future alias updates"},{"upvote_count":"2","poster":"Arad","timestamp":"1736464620.0","content":"Selected Answer: C\\nC is the correct answer.\\nD is wrong as directly configuring the integration request on the production stage is not ideal. You should use stage variables to configure the integration dynamically, allowing you to manage different environments without manually changing the integration in each stage.","comment_id":"1338577"},{"timestamp":"1735317000.0","content":"Selected Answer: C\\nChoose C,\\nD: While it\'s necessary to create a new stage called \\"production\\", the configuration should be done using a stage variable, not by configuring the integration request directly in the production stage.","upvote_count":"2","poster":"xdeveloper","comment_id":"1332521"}],"answer_description":"","extracted_at":"2025-12-24T09:09:32.146Z","extraction_method":"api_direct_v1"},{"question_id":"oLFz9jILAespHDHKAZkM","question_number":401,"page":81,"question_text":"A developer is working on a serverless application that needs to process any changes to an Amazon DynamoDB table with an AWS Lambda function.\\nHow should the developer configure the Lambda function to detect changes to the DynamoDB table?","choices":{"C":"Enable DynamoDB Streams on the table. Create a trigger to connect the DynamoDB stream to the Lambda function.","A":"Create an Amazon Kinesis data stream, and attach it to the DynamoDB table. Create a trigger to connect the data stream to the Lambda function.","B":"Create an Amazon EventBridge rule to invoke the Lambda function on a regular schedule. Conned to the DynamoDB table from the Lambda function to detect changes.","D":"Create an Amazon Kinesis Data Firehose delivery stream, and attach it to the DynamoDB table. Configure the delivery stream destination as the Lambda function."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103917-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 02:07:00","unix_timestamp":1679792820,"discussion_count":6,"discussion":[{"upvote_count":"11","comment_id":"850604","poster":"Untamables","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html","timestamp":"1679792820.0"},{"timestamp":"1734970440.0","content":"Selected Answer: C\\nB) Eliminated - Polling the table for changes introduces unnecessary complexity and delay\\n\\nC) Correct - DynamoDB Streams is specifically designed for this use case, capturing item-level changes in the table.\\n\\nD) Eliminated - Firehose is used for data delivery and transformation to destinations like S3 or Redshift, not for processing DynamoDB table changes.","poster":"sumanshu","comment_id":"1330873","upvote_count":"1"},{"timestamp":"1716310860.0","comment_id":"1215113","poster":"65703c1","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer."},{"content":"A should work as well. Why is it not A?","upvote_count":"1","timestamp":"1711455480.0","poster":"ibratoev","comment_id":"1183296","comments":[{"comment_id":"1303966","upvote_count":"3","poster":"nbxyzd","content":"While option A is technically possible, it introduces unnecessary complexity for detecting changes in a DynamoDB table. Using DynamoDB Streams directly is a more streamlined and optimized solution for this use case.","timestamp":"1730120940.0"}]},{"content":"Selected Answer: C\\nC\\n\\nEnabling DynamoDB Streams on the table allows you to capture and process changes (inserts, updates, deletes) to the table in real-time. You can then create a Lambda trigger that listens to the DynamoDB stream and invokes the Lambda function whenever there is a change in the table. This is a common and effective way to react to changes in DynamoDB tables with AWS Lambda functions.","poster":"nmc12","upvote_count":"4","comment_id":"1022223","timestamp":"1696161660.0"},{"comment_id":"916146","poster":"Baba_Eni","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html","upvote_count":"2","timestamp":"1686047700.0"}],"answer_description":"","extracted_at":"2025-12-24T09:09:43.145Z","extraction_method":"api_direct_v1"},{"question_id":"DvVljx7byShhglxOpebv","question_number":402,"page":81,"question_text":"A developer is implementing a serverless application by using AWS CloudFormation to provision Amazon S3 web hosting. Amazon API Gateway, and AWS Lambda functions. The Lambda function source code is zipped and uploaded to an S3 bucket. The S3 object key of the zipped source code is specified in the Lambda resource in the CloudFormation template.\\n\\nThe developer notices that there are no changes in the Lambda function every time the CloudFormation stack is updated.\\n\\nHow can the developer resolve this issue?","choices":{"D":"Associate a cade signing configuration with the Lambda function before updating the CloudFormation stack.","B":"Change the S3 object key or the S3 version in the CloudFormation template before updating the CloudFormation stack.","C":"Upload the zipped source code to another S3 bucket before updating the CioudFormation stack.","A":"Create a new Lambda function alias before updating the CloudFormation stack."},"correct_answer":"B","answer_ET":"B","answers_community":["B (67%)","A (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152916-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-12 18:59:00","unix_timestamp":1734026340,"discussion_count":3,"discussion":[{"poster":"Shamalka","content":"Selected Answer: B\\nYou have to change the S3 Object Key and the Version every time you update the code,","upvote_count":"1","comment_id":"1399141","timestamp":"1742102820.0"},{"comment_id":"1365325","timestamp":"1741165140.0","content":"Selected Answer: A\\nA. Lambda alias pointing to $LATEST will resolve this issue. \\n\\nB could also fit in this situation, but if deployment can happen even couple times a day it is very annoiyng to change manually the version of the lambda funtion everytime in cloudformation template","upvote_count":"1","poster":"0bdf3af"},{"timestamp":"1734026340.0","poster":"ShakthiGCP","upvote_count":"1","comment_id":"1325790","content":"Selected Answer: B\\nGiving a new object key when load the new zip file"}],"answer_description":"","extracted_at":"2025-12-24T09:09:43.145Z","extraction_method":"api_direct_v1"},{"question_id":"WWtKEWEBDGNIVrl0gs3t","question_number":403,"page":81,"question_text":"A developer published a change to a new version of an AWS Lambda function. To test the change, the developer must route 50% of the traffic to the new version and 60% of the traffic to the current version.\\n\\nWhat is the MOST operationally efficient way to meet this requirement?","choices":{"B":"Create an Amazon API Gateway API with a POST method that is integrated with the Lambda function. Add a stage variable that includes the version of the Lambda function. Add a canary release that will override the version variable 50% of the time. Deploy and test the Lambda function through the API Gateway stage.","C":"Create a Lambda function alias. Set the weight to 50% for the current version and 50% for the new version. Set the event source mappings for the Lambda function to point to the alias.","A":"Create two Amazon Route 53 records that use a simple routing policy to route traffic to the different versions of the Lambda function. Create another Route 53 record that uses a weighted routing policy to route 50% of the traffic to each simple routing record. Test the Lambda function by using the weighted routing record.","D":"Update the event source mappings for the Lambda function. In the mappings, set the weight to 50% for the current version and 50% for the new version."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156669-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:22:00","unix_timestamp":1739784120,"discussion_count":1,"discussion":[{"upvote_count":"1","comment_id":"1357706","poster":"italiancloud2025","timestamp":"1739784120.0","content":"Selected Answer: C\\nLa manera m\xe1s sencilla es usar un alias de Lambda con una configuraci\xf3n de enrutamiento ponderado (routing weights) para distribuir el tr\xe1fico entre versiones."}],"answer_description":"","extracted_at":"2025-12-24T09:09:43.145Z","extraction_method":"api_direct_v1"},{"question_id":"deG5XJxtRPzzwuNQK1N0","question_number":404,"page":81,"question_text":"A developer is building an application that processes a stream of user-supplied data. The data stream must be consumed by multiple Amazon EC2 based processing applications in parallel and in real time. Each processor must be able to resume without losing data if there is a service interruption. The application architect plans to add other processors in the near future, and wants to minimize the amount of data duplication involved.\\n\\nWhich solution will satisfy these requirements?","choices":{"D":"Publish the data to Amazon Kinesis Data Streams.","C":"Publish the data to Amazon EventBridge.","B":"Publish the data to Amazon Data Firehose.","A":"Publish the data to Amazon Simple Queue Service (Amazon SQS)."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152918-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-12 19:21:00","unix_timestamp":1734027660,"discussion_count":1,"discussion":[{"poster":"ShakthiGCP","upvote_count":"1","timestamp":"1734027660.0","content":"Selected Answer: D\\nReal-time Data Streaming: Kinesis Data Streams is designed for real-time processing of streaming data. It offers high throughput and low latency, making it suitable for applications requiring immediate processing of incoming data.\\n\\nParallel Processing: Kinesis Data Streams allows you to partition the data stream into shards. Each shard can be consumed by a single consumer (in this case, an EC2 instance). By creating multiple shards, you can distribute the processing load across multiple EC2 instances for parallel processing. This scales horizontally to accommodate increasing data volume and processing needs.","comment_id":"1325796"}],"answer_description":"","extracted_at":"2025-12-24T09:09:43.145Z","extraction_method":"api_direct_v1"},{"question_id":"pDUobUeTCverceRmLfNk","question_number":405,"page":81,"question_text":"An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A developer must improve performance without changing the database structure.\\n\\nWhich approach will improve performance and MINIMIZE management overhead?","choices":{"C":"Deploy Memcached on Amazon EC2 and cache the data for the application.","B":"Deploy Amazon ElastiCache (Redis OSS) and cache the data for the application.","D":"Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.","A":"Deploy Amazon DynamoDB, move all the data, and point to DynamoDB."},"correct_answer":"C","answer_ET":"B","answers_community":["C (50%)","B (50%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156670-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:23:00","unix_timestamp":1739784180,"discussion_count":2,"discussion":[{"timestamp":"1750320420.0","poster":"AlmeroSenior","comment_id":"1578836","content":"Selected Answer: B\\nB : Redis . Fully manged, and does not require DB structure to be changed, like moving to Dynamo would. \\n\\nC : Memcache could also do the job , but honestly , hosting on EC2 adds managment overhead , and is by nature a single point of failure","upvote_count":"1"},{"content":"Selected Answer: C\\nmemcache fits","comment_id":"1365328","timestamp":"1741165740.0","poster":"0bdf3af","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:09:43.145Z","extraction_method":"api_direct_v1"},{"question_id":"fFOG5PqYXa8UyDEIMCzO","question_number":406,"page":82,"question_text":"A developer is using AWS CloudFormation to deploy an AWS Lambda function. The developer needs to set the Lambda function\'s timeout value based on the environment parameter of the template. The template contains mappings of EnvironmentData for each environment\'s timeout value. The environment parameter and EnvironmentData mappings are as follows:\\n\\nEnvironment parameter:\\n\\n//IMG//\\n\\n\\nEnvironmentData mappings:\\n\\n//IMG//\\n\\n\\nWhich statement will meet these requirements?","choices":{"A":"Timeout: !GetAtt [EnvironmentData, !Ref Environment, Timeout]","B":"Timeout: !FindInMap [EnvironmentData, !Ref Environment, Timeout]","D":"Timeout: !ForEach[EnvironmentData, !Ref Environment, Timeout]","C":"Timeout: !Select [EnvironmentData, !Ref Environment, Timeout]"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152922-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image27.png","https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image28.png"],"answer_images":[],"timestamp":"2024-12-12 19:46:00","unix_timestamp":1734029160,"discussion_count":1,"discussion":[{"comment_id":"1325807","content":"Selected Answer: B\\n!FindInMap is an intrinsic function used to retrieve a value from a mapping","poster":"ShakthiGCP","upvote_count":"2","timestamp":"1734029160.0"}],"answer_description":"","extracted_at":"2025-12-24T09:09:54.191Z","extraction_method":"api_direct_v1"},{"question_id":"3d962Gg1olOaozUlqIDO","question_number":407,"page":82,"question_text":"A company\u2019s AWS accounts are in an organization in AWS Organizations. An application in Account A uses environment variables that are stored as parameters in AWS Systems Manager Parameter Store. A developer is creating a new application in Account B that needs to use the same environment variables.\\n\\nThe application in Account B needs access to the parameters in Account A without duplicating the parameters into Account B.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Configure the application in Account B to use credentials for an IAM user in AccountA that has access to the parameters.","D":"Write a script that stores the parameter values in a private Amazon S3 bucket that both accounts can access.","C":"Configure cross-account resource sharing for the parameters by using AWS Resource Access Manager (AWS RAM).","B":"Create an assumable IAM role in Account A. Grant the role the permission to access the parameters."},"correct_answer":"C","answer_ET":"C","answers_community":["C (80%)","B (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152923-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-12 19:54:00","unix_timestamp":1734029640,"discussion_count":2,"discussion":[{"upvote_count":"1","comments":[{"content":"Its C , This changed in 2024 as per link below from Shakthi . Question also hints that AWS ORG is used , and ORG is requirement for RAM .","comment_id":"1578839","timestamp":"1750320840.0","poster":"AlmeroSenior","upvote_count":"2"}],"content":"Selected Answer: B\\nIts B , Ram not supported for SSMParams \\n\\nAWS RAM: As of now, AWS Systems Manager Parameter Store is not a supported resource type for AWS Resource Access Manager (RAM), so this option is not feasible.","poster":"AlmeroSenior","timestamp":"1749459900.0","comment_id":"1575939"},{"timestamp":"1734029640.0","poster":"ShakthiGCP","content":"Selected Answer: C\\nhttps://aws.amazon.com/blogs/mt/introducing-parameter-store-cross-account-sharing/\\nRAM Share is the easy and best way to share resources across Accounts.","comment_id":"1325813","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:09:54.191Z","extraction_method":"api_direct_v1"},{"question_id":"TYtquWe3wCqdWEugWyE9","question_number":408,"page":82,"question_text":"In a move toward using microservices, a company\u2019s management team has asked all development teams to build their services so that API requests depend only on that service\u2019s data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB.\\n\\nWhat approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?","choices":{"C":"Use Amazon Data Firehose to deliver all changes from the Accounts database to the Payments database.","D":"Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.","B":"Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.","A":"Use AWS Glue to perform frequent ETL updates from the Accounts database to the Payments database."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156644-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:40:00","unix_timestamp":1739781600,"discussion_count":1,"discussion":[{"timestamp":"1739781600.0","comment_id":"1357667","upvote_count":"1","content":"Selected Answer: D\\nDynamoDB Streams te permite capturar cambios en la tabla de Accounts en tiempo real. C una funci\xf3n Lambda puedes actualizar la base de datos de Payments de manera simple, desacoplada y confiable.","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:09:54.191Z","extraction_method":"api_direct_v1"},{"question_id":"lnp432BC1dPtuYfKADnS","question_number":409,"page":82,"question_text":"A developer compiles an AWS Lambda function and packages the result as a .zip file. The developer uses the Functions page on the Lambda console to attempt to upload the local packaged .zip file. When pushing the package ta Lambda, the console returns the following error:\\n\\n//IMG//\\n\\n\\nWhich solutions can the developer use to publish the code? (Choose two.)","choices":{"B":"Create an AWS Support ticket to increase the maximum package size.","D":"Repackage the Lambda function as a Docker container image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Create a new Lambda function by using the Lambda console. Reference the image that is deployed to Amazon ECR.","E":"Sign the .zip file digitally. Create a new Lambda function by using the Lambda console. Update the configuration of the new Lambda function to include the Amazon Resource Name (ARN) of the code signing configuration.","C":"Use the update-function-code AWS CLI command. Pass the --publish parameter.","A":"Upload the package to Amazon 3. Use the Functions page on the Lambda console to upload the package from the S3 location."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156645-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image29.png"],"answer_images":[],"timestamp":"2025-02-17 09:42:00","unix_timestamp":1739781720,"discussion_count":1,"discussion":[{"content":"Selected Answer: AD\\nA: Sube el .zip a un bucket de S3 y luego usa la consola de Lambda para cargarlo desde all\xed, evitando el l\xedmite directo.\\nD: Empaqueta la funci\xf3n como imagen de contenedor, s\xfabela a ECR y crea la funci\xf3n referenciando esa imagen, lo cual permite manejar paquetes m\xe1s grandes.","upvote_count":"1","comment_id":"1357671","timestamp":"1739781720.0","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:09:54.191Z","extraction_method":"api_direct_v1"},{"question_id":"4HSefRG1l2T4C13RYK13","question_number":410,"page":82,"question_text":"A company runs an application on Amazon EC2 instances in an Auto Scaling group. The application experiences variable loads throughout each day.\\n\\nThe company needs to collect detailed metrics from the EC2 instances to right-size the instances. The company also wants to monitor custom application metrics to ensure the application is performing efficiently.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Install the AWS SDK in the application\u2019s cade. Update the application to use the AWS SDK to collect and publish the EC2 instance metrics and the custom application metrics.","B":"Install the Amazon CloudWatch agent on the instances. Configure the agent to collect the EC2 instance metrics and the custom application metrics.","D":"Configure AWS CloudTrail to capture and analyze the EC2 instance metrics and the custom application metrics.","A":"Install the AWS X-Ray agent on the instances. Configure the agent to collect the EC2 instance metrics and the custom application metrics."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156646-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:43:00","unix_timestamp":1739781780,"discussion_count":1,"discussion":[{"content":"Selected Answer: B\\nCloudWatch Agent te permite recopilar tanto m\xe9tricas detalladas de las instancias EC2 (para ajustar su tama\xf1o) como m\xe9tricas personalizadas de la aplicaci\xf3n, todo sin modificar el c\xf3digo de la aplicaci\xf3n.","upvote_count":"1","poster":"italiancloud2025","timestamp":"1739781780.0","comment_id":"1357672"}],"answer_description":"","extracted_at":"2025-12-24T09:09:54.191Z","extraction_method":"api_direct_v1"},{"question_id":"mTCiZJJPvObBCcSOzRU5","question_number":411,"page":83,"question_text":"A developer is creating an application that uses an Amazon DynamoDB table. The developer needs to develop code that reads all records that were added to the table during the previous day, creates HTML reports, and pushes the reports into third-party storage. The item size varies from 1 KB to 4 KB, and the index structure is defined with the date. The developer needs to minimize the read capacity that the application requires from the DynamoDB table.\\n\\nWhich DynamoDB API operation should the developer use in the code to meet these requirements?","choices":{"C":"BatchGetItem","D":"GetItem","A":"Query","B":"Scan"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153145-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-18 03:16:00","unix_timestamp":1734488160,"discussion_count":1,"discussion":[{"comment_id":"1328234","upvote_count":"3","poster":"ShakthiGCP","timestamp":"1734488160.0","content":"Selected Answer: A\\nWhy Use Query?\\nTargeted Retrieval:\\nSince the index is defined with the date, you can use the date as the partition key or sort key (depending on how the index is designed).\\nThe Query operation allows you to specify the exact partition key (e.g., date = \'2024-12-16\' for the previous day)."}],"answer_description":"","extracted_at":"2025-12-24T09:10:05.375Z","extraction_method":"api_direct_v1"},{"question_id":"qmRNM3hxYRGgSV35rrCE","question_number":412,"page":83,"question_text":"An application uses an Amazon EC2 Auto Scaling group. A developer notices that EC2 instances are taking a long time to become available during scale-out events. The UserData script is taking a long time to run.\\nThe developer must implement a solution to decrease the time that elapses before an EC2 instance becomes available. The solution must make the most recent version of the application available at all times and must apply all available security updates. The solution also must minimize the number of images that are created. The images must be validated.\\nWhich combination of steps should the developer take to meet these requirements? (Choose two.)","choices":{"C":"Set up AWS CodeDeploy to deploy the most recent version of the application at runtime.","D":"Set up AWS CodePipeline to deploy the most recent version of the application at runtime.","B":"Use EC2 Image Builder to create an Amazon Machine Image (AMI). Install the latest version of the application and all the patches and agents that are needed to manage and run the application. Update the Auto Scaling group launch configuration to use the AMI.","E":"Remove any commands that perform operating system patching from the UserData script.","A":"Use EC2 Image Builder to create an Amazon Machine Image (AMI). Install all the patches and agents that are needed to manage and run the application. Update the Auto Scaling group launch configuration to use the AMI."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (41%)","AE (40%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103721-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-24 02:40:00","unix_timestamp":1679622000,"discussion_count":55,"discussion":[{"upvote_count":"38","poster":"imvb88","comments":[{"comment_id":"913381","poster":"yashika2005","content":"thanksss a lott!","timestamp":"1685777640.0","upvote_count":"1"},{"comment_id":"1054252","content":"The solution must make the most recent version of the application available at all times","upvote_count":"4","poster":"minh12312312","timestamp":"1698288600.0","comments":[{"content":"I agree I think between A and B.- answer is B","comment_id":"1090722","timestamp":"1702003080.0","upvote_count":"5","poster":"[Removed]"}]},{"timestamp":"1690255860.0","poster":"r3mo","upvote_count":"4","content":"And what about this requisit? \\"The solution must make the most recent version of the application available at all times\\". Only the Answer B fulfill this part.","comment_id":"962298"}],"comment_id":"905958","content":"Selected Answer: AE\\nWhy choose A over B? Problem is that B will tie an AMI with a specific version, so if there is a new version, we need to create a new AMI, and that contradicts with \\"minimize the number of images that are created\\". \\n\\nThen E over C, D? E is obviously complementary to A, where removing commands from User Data will make the instance booting process much faster (and of course with A you don\'t need that anymore). \\n\\nC and D also works but 1/not complementary with any other options; 2/CodeDeploy takes time to execute. \\n\\nHope this helps somebody struggling with this question.","timestamp":"1684937520.0"},{"poster":"KillThemWithKindness","upvote_count":"15","comments":[{"comment_id":"1186501","poster":"maurice2005","upvote_count":"2","content":"well if u choose B and E then this will resolve as well","timestamp":"1711850040.0"}],"comment_id":"966617","content":"Selected Answer: AC\\nOption E, which suggests removing operating system patching from the UserData script, might reduce the startup time. But this could leave your instances unpatched and vulnerable, which doesn\'t meet the requirement to apply all available security updates.","timestamp":"1690660380.0"},{"poster":"Shamalka","upvote_count":"1","timestamp":"1741278300.0","comment_id":"1365955","content":"Selected Answer: AC\\nA and C is the answer"},{"content":"Selected Answer: AE\\nAE is correct answer.","poster":"Arad","upvote_count":"1","comment_id":"1332629","timestamp":"1735334880.0"},{"content":"Selected Answer: AC\\nB) Eliminated - Similar to option A, but also includes the latest version of the application in the AMI. While this reduces initialization time, it violates the requirement to \\"minimize the number of images\\" because it necessitates frequent AMI updates to keep the application version current.\\n\\nC) CodeDeploy ensures that the most recent version of the application is deployed during runtime.\\n\\nE) Eliminated - This violates the requirement to \\"apply all available security updates\\"","poster":"sumanshu","timestamp":"1734971340.0","upvote_count":"2","comment_id":"1330877"},{"comment_id":"1327970","upvote_count":"1","poster":"Yuri_024","timestamp":"1734447360.0","content":"Selected Answer: AE\\n* The problem at hand is scaling-out events taking a long time (Instances need to spawn up fast, userData scripts must not run for long periods).\\n* CodePipeline or CodeDeploy does not play any role there.\\n* It does not mention an issue regarding the latest version of the application not being available.\\n* So I choose A & E"},{"upvote_count":"1","content":"Selected Answer: AC\\nOption B is incorrect because:\\nIncluding the application in the AMI would require new image creation for every application update\\nResults in more frequent image builds than necessary\\nIncreases maintenance overhead","comment_id":"1326148","timestamp":"1734098160.0","poster":"youonebe"},{"content":"Selected Answer: AC\\nB. While similar to A, this option includes installing the latest version of the application in the AMI. This is not ideal because it would require creating a new AMI every time the application is updated, which doesn\'t align with the requirement to minimize the number of images created.","poster":"albert_kuo","comment_id":"1285013","timestamp":"1726540080.0","upvote_count":"1"},{"poster":"wh1t4k3r","timestamp":"1723824180.0","upvote_count":"2","comment_id":"1267247","content":"Selected Answer: AC\\nB would require new images for each new app version. Idea is to minimize image creation, so A is a better fit.\\nE does speed up the process, BUT does not cover the app version requirement, nor the necessity to validate images, which codedeploy covers."},{"comment_id":"1250329","poster":"MrDurian","timestamp":"1721301780.0","upvote_count":"1","content":"IMO the correct answer is A and C.\\n\\nHaving a well set up AMI will reduce the need to run a long userData script.\\n\\nWhy not using B? Because that would couple the image with the app version. It is better to trigger a Code deploy that will deploy the latest version of the app on the \'optimized\' AMI.\\n\\nRegarding answer E, it would also be correct IMO but A and C seems to be the perfect matching scenario"},{"timestamp":"1721006580.0","upvote_count":"2","poster":"IYNH","content":"Selected Answer: AC\\nThe solution must make the most recent version of the application available at all times. B doesn\'t make sense because \\"latest version at the time AMI is created\\" becomes outdated when a newer one comes.\\nC is obviously needed to make the actual \\"latest\\" version deploy.","comment_id":"1248013"},{"poster":"65703c1","timestamp":"1716311820.0","comment_id":"1215118","upvote_count":"1","content":"Selected Answer: BE\\nBE is the correct answer."},{"poster":"MarcosSantos","comment_id":"1211040","content":"I choose BE. Is better response","upvote_count":"1","timestamp":"1715627220.0"},{"timestamp":"1713011820.0","content":"Selected Answer: AC\\nThe requirements are: \\n1. Decreasing the time it takes for EC2 instances to become available during scale-out events.\\n2. Ensuring the most recent version of the application is available.\\n3. Applying all available security updates.\\n4. Minimising the number of images created.\\n\\n[A] will satisfy requirements 1, 3, 4\\n[B] is similar to A, but will involve more AMI images\\n[C] Since the applications are on EC2 instances, CodeDeploy will do just fine to update the applications to the most recent version\\n[E] Removing any command for updates will leave our instances susceptible to vulnerabilities. Some commands can be removed, leaving the essential ones","upvote_count":"2","comment_id":"1194956","poster":"ufuomaapoki"},{"poster":"maurice2005","comment_id":"1186503","timestamp":"1711850100.0","upvote_count":"2","content":"B is faster than A. \\nE delegates all run time to AMI build time on B option."},{"content":"A and E.\\nA because number of images needs to be minimized.\\nE to speed up the boot time.","timestamp":"1711455720.0","comment_id":"1183301","upvote_count":"1","poster":"ibratoev"},{"comment_id":"1179258","content":"Selected Answer: BE\\nThe most practical answers","timestamp":"1711026600.0","upvote_count":"4","poster":"KarBiswa"},{"content":"Selected Answer: AC\\ngoing with ac","upvote_count":"1","timestamp":"1710258060.0","comment_id":"1171801","poster":"Abdullah22"},{"upvote_count":"1","comment_id":"1165821","poster":"TheFivePips","content":"Selected Answer: AE\\nB would need a new image every time the application is updated, so it doesnt meet requirements. Obviously you should remove the thing that is causing the problem in the first place with E","timestamp":"1709571480.0"},{"comment_id":"1158991","poster":"SerialiDr","timestamp":"1708882680.0","upvote_count":"4","content":"Selected Answer: BE\\nB.Use EC2 Image Builder to create an Amazon Machine Image (AMI) that includes the latest version of the application and all necessary patches and agents required to manage and run the application. This approach allows instances to launch faster because it minimizes the amount of setup required after instance startup, reducing the reliance on lengthy UserData scripts for initial setup. \\n\\nE.Remove any commands that perform operating system patching from the UserData script. Operating system patching can significantly increase the time it takes for an instance to become available, especially if there are many updates to apply. By removing these commands and ensuring that the AMI used already includes the latest patches, the startup time can be reduced."},{"poster":"konieczny69","comment_id":"1136902","upvote_count":"1","timestamp":"1706714280.0","content":"Selected Answer: DE\\nAnswers: DE\\n\\nA and B sound good, but since you only have 2 options they are not enough.\\nC is not enough.\\nD is wider and can build an AMI.\\nE is a must to speed it up."},{"poster":"Ashwinvdm22","timestamp":"1706531580.0","comment_id":"1134937","content":"Selected Answer: AE\\nAE is correct.","upvote_count":"1"},{"timestamp":"1703858820.0","comment_id":"1108748","content":"Option A suggests using EC2 Image Builder to create an AMI and install all the patches and agents needed for the application. This ensures that the AMI is pre-configured with the necessary updates and configurations, reducing the time it takes for instances to become available during scale-out events.\\n\\nOption E recommends removing operating system patching from the UserData script. This is because, with EC2 Image Builder, the patches are applied during the AMI creation process, so there\'s no need to perform patching in the UserData script. This helps in minimizing the time it takes for instances to launch during scale-out events.\\n\\nIt\'s A&E","poster":"BaYaga","upvote_count":"1"},{"comment_id":"1104543","poster":"xdkonorek2","upvote_count":"1","timestamp":"1703413680.0","content":"Selected Answer: AD\\nI think D > C\\n\\"The solution must make the most recent version of the application available at all times\\"\\nMost recent version of an application lives in source control and we need whole CI/CD for releasing this version which is use case for code pipeline, code deploy itself won\'t conduct the whole process"},{"comment_id":"1099085","timestamp":"1702831200.0","content":"Selected Answer: AC\\nA-- Decrease the time for EC2 instance availability while minimizing the number of images created\\nC-- Ensure the most recent version of the application( not d because it will also use code deploy)","upvote_count":"1","poster":"Auronb"},{"content":"Selected Answer: CE\\nThe script had time out issues so E covers that, again it must use minimum images so option C is suitable. A & B are created for confusions.","timestamp":"1702793940.0","upvote_count":"1","comment_id":"1098694","comments":[{"poster":"KarBiswa","timestamp":"1708773600.0","upvote_count":"1","comment_id":"1157839","content":"Modifying my answer to A,C"}],"poster":"KarBiswa"},{"timestamp":"1702793820.0","comment_id":"1098693","poster":"KarBiswa","content":"I would go for C&E","upvote_count":"2"},{"upvote_count":"1","content":"it is BC \\nEC2 Image Builder (Option B):\\n\\nUsing EC2 Image Builder to create an AMI allows you to pre-bake the required configurations, application updates, and security patches into the image. This significantly reduces the launch time of instances as the AMI is already prepared with the necessary software and configurations.\\nInstalling the latest version of the application along with patches and agents ensures that the AMI is up-to-date and secure.\\n\\nAWS CodeDeploy (Option C):\\n\\nAWS CodeDeploy allows you to deploy the most recent version of the application at runtime without the need to create a new AMI for every update. This helps in minimizing the number of images created and allows you to quickly roll out changes without launching new instances.\\nThis approach also ensures that the most recent version of the application is always available.","comment_id":"1091157","timestamp":"1702049040.0","poster":"Abdlhince"},{"poster":"tqiu654","upvote_count":"1","timestamp":"1701476400.0","comment_id":"1085570","content":"Selected Answer: BE\\nBased on ChatGPT: BE","comments":[{"upvote_count":"1","poster":"Cable01011000","content":"i just asked chatgpt for answer. It replied A and C. After reevaluation it was still A and C","timestamp":"1703174220.0","comment_id":"1102701"}]},{"poster":"ronn555","content":"Selected Answer: AC\\nA is correct. C vs E. C satisfies latest software req. E contradicts latest patch req., it is red herring to A bc you think that patches are unnecessary on a patched image, but they will eventually be.","upvote_count":"1","timestamp":"1699280940.0","comment_id":"1063924"},{"comment_id":"1054969","timestamp":"1698362520.0","content":"Selected Answer: AC\\nA. Use o EC2 Image Builder para criar uma Amazon Machine Image (AMI). Instale todos os patches e agentes necess\xe1rios para gerenciar e executar o aplicativo. Atualize a configura\xe7\xe3o de inicializa\xe7\xe3o do grupo do Auto Scaling para usar a AMI.\\n\\nC. Configure o AWS CodeDeploy para implantar a vers\xe3o mais recente do aplicativo em tempo de execu\xe7\xe3o.","poster":"Jonalb","upvote_count":"1"},{"poster":"Rameez1","timestamp":"1697216460.0","upvote_count":"2","comment_id":"1042831","content":"Selected Answer: AC\\nIf I look for eliminating options which contradicts with the requirements BDE gets eliminated as below:\\nB: Would need to recreate AMI for every version update (As per the requirement we need to minimize image creations) -> On contrary A will boost faster with all necessary packages and minimum number of AMI creations.\\nD: Code pipeline can\'t deploy code of its own and would need code deploy for doing it -> Making C a better choice.\\nE: User script is necessary for security updates."},{"poster":"Cerakoted","content":"Selected Answer: AC\\nI think AC\\nWhy not AE? -> \\"must apply all available security updates\\" on the question. need to update OS with userdata script","timestamp":"1697091840.0","upvote_count":"1","comment_id":"1041424"},{"poster":"Die_fa_ed","upvote_count":"1","timestamp":"1695745380.0","comment_id":"1017982","content":"Selected Answer: AC\\n- Option B: Use EC2 Image Builder to create an Amazon Machine Image (AMI) that includes the latest version of the application and all necessary patches and agents. This ensures that the AMI is up-to-date and ready to use. Then, update the Auto Scaling group launch configuration to use this AMI.\\n\\n - Option C: Set up AWS CodeDeploy to deploy the most recent version of the application at runtime. CodeDeploy allows you to easily manage and deploy application updates without creating new AMIs. This helps ensure that the most recent version of the application is available without the need to recreate AMIs.\\n\\nThese steps minimize the number of images created (as you update the AMI when necessary) and allow for efficient updates of the application while ensuring security patches and updates are applied."},{"poster":"appuNBablu","upvote_count":"3","comment_id":"1015241","timestamp":"1695495360.0","content":"I would say AC, but I see many answers AE. How AE is answer? the question says we need solution that also deploys latest code?"},{"timestamp":"1693895520.0","poster":"Kashan6109","content":"Selected Answer: BE\\nOption A is not correct because we need most recent version of application as well which is only fulfilled by Option B","comment_id":"999169","upvote_count":"3"},{"comment_id":"993441","upvote_count":"3","poster":"love777","timestamp":"1693335840.0","content":"Selected Answer: AC\\nOption E, which suggests removing any commands that perform operating system patching from the UserData script, might not be the best idea for ensuring the security and stability of your EC2 instances and application. Here\'s why it could be considered a bad idea:\\n\\nSecurity Vulnerabilities: Operating system patches often include security updates that address known vulnerabilities and protect your instances from potential threats. By removing patching from the UserData script, you might leave your instances exposed to security risks."},{"poster":"ninomfr64","upvote_count":"5","content":"Selected Answer: AC\\nA) makes sure the instaces boot faster by having all patches and dependencies baked into the AMI (B would make it too, but would create a new AMI for any new app version thus conflicting with requirement \\"minimize the number of images that are created\\")\\n\\nC) When new EC2 instances are launched as part of an Auto Scaling group, CodeDeploy can deploy your revisions to the new instances automatically. This will meet the requirement to \\"make the most recent application version available all the time\\"","comment_id":"985074","timestamp":"1692435420.0"},{"content":"Selected Answer: BE\\nB. Using EC2 Image Builder to create an AMI ensures that the most recent version of the application, along with all necessary patches and agents, is pre-installed in the image. This reduces the time required during the scaling events because instances launched from this AMI will already have the application and updates in place.\\n\\nE. Removing operating system patching commands from the UserData script is essential because, during scale-out events, the UserData script is executed when a new EC2 instance is launched. If the script is performing time-consuming patching, it will increase the time it takes for the instance to become available. By removing the patching from the script and using a pre-built AMI with the latest patches, the instances will be ready much faster.","comment_id":"972147","upvote_count":"1","poster":"jipark","timestamp":"1691152560.0"},{"timestamp":"1689624420.0","content":"Selected Answer: AE\\nAE \\nNot AC because app deployment from UserData is nonsense. Therefore, you don\'t need to change anything about deployment","upvote_count":"1","poster":"[Removed]","comment_id":"954582"},{"content":"Selected Answer: AC\\nA is obvious to reduce the time of EC2 available.\\nC because codedeploy can deploy the lasted version on scale-out event of ASG\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/integrations-aws-auto-scaling.html","comment_id":"953796","timestamp":"1689563160.0","upvote_count":"4","poster":"acordovam"},{"poster":"tttamtttam","comment_id":"952202","timestamp":"1689411540.0","content":"Selected Answer: BC\\nI am not 100% confident but vote for B and C","upvote_count":"1"},{"upvote_count":"1","timestamp":"1689022320.0","poster":"Pupina","comment_id":"948382","content":"Selected Asnwer BC. \\nI agree with eboehm2 \\nB because it is the standard way to update patches. C Because it is necessary to update the app to the last version and B does not do that. You can do that automatically with CodeDeploy. https://docs.aws.amazon.com/codedeploy/latest/userguide/tutorials-auto-scaling-group.html\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/integrations-aws-auto-scaling.html"},{"comment_id":"944565","upvote_count":"5","timestamp":"1688641680.0","poster":"stlim83","content":"Selected Answer: AC\\nThe requirements: The solution must make the most recent version of the application available at all times and must apply all available security updates.\\nB is incorrect because we need the most recent version of the application. this means we have to recreate AMI for every update.\\nD is incorrect because CodePipeline can\'t deploy anything itself. It is using CodeDeploy for the deployment.\\nE is also incorrect. because it must apply all available security updates. if we delete all commands for the os updates. it can\'t meet the requirements."},{"poster":"eboehm2","comment_id":"922668","timestamp":"1686707820.0","upvote_count":"1","content":"Selected Answer: BC\\nMy guess is that the question is supposed to have you select 3 and not just 2. B&C fully solve the problem where E is just tidying up. That is if the updates are already installed, running the user script will just move on and still speed up the boot process."},{"upvote_count":"2","comment_id":"901733","poster":"mywogunleye","content":"Ans: B & E \\n\\"The solution must make the most recent version of the application available at all times and must apply all available security updates\\"","timestamp":"1684481520.0"},{"upvote_count":"1","content":"Ans: A&C\\n\\nOption B suggests installing the latest version of the application, but does not specify how the patches and agents will be installed. Option D suggests using AWS CodePipeline, which is a continuous delivery service, not a deployment service, and does not apply patches and agents. Option E suggests removing operating system patching from the UserData script, but this does not address the requirement of making the most recent version of the application available at all times and applying security updates.","comment_id":"895986","timestamp":"1683901140.0","poster":"Nagendhar"},{"timestamp":"1682750760.0","poster":"ihebchorfi","upvote_count":"3","comment_id":"884100","content":"Selected Answer: AE\\nA & E are complementary, other answers arent"},{"timestamp":"1682426100.0","comment_id":"880369","upvote_count":"4","poster":"[Removed]","content":"Selected Answer: AE\\nI would favor A instead of B. Question states \\"The solution also must minimize the number of images that are created\\" while each app code change would require a new image."},{"content":"Selected Answer: BE\\nShould it not be B and E ?","timestamp":"1682080500.0","upvote_count":"1","poster":"Rpod","comment_id":"876523"},{"comment_id":"869489","poster":"robotgeek","upvote_count":"1","timestamp":"1681396080.0","content":"Poorly redacted question"},{"timestamp":"1679792940.0","upvote_count":"6","poster":"Untamables","comment_id":"850605","content":"Selected Answer: BE\\nB and E.\\nIt seems that the UserData script runs operating system patching in this scenario.\\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/what-is-image-builder.html"},{"content":"Selected Answer: AC\\nA and C?\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/integrations-aws-auto-scaling.html","upvote_count":"5","timestamp":"1679752200.0","comment_id":"850168","poster":"Watascript"},{"content":"Selected Answer: AE\\nhow could A,B both be right?\\neliminate UserData problem to deal the first deadly blow","comment_id":"849107","poster":"clarksu","timestamp":"1679645640.0","upvote_count":"4"},{"poster":"March2023","timestamp":"1679622000.0","upvote_count":"3","content":"Does anyone think this would be A and E?","comment_id":"848848"}],"answer_description":"","extracted_at":"2025-12-24T09:10:05.375Z","extraction_method":"api_direct_v1"},{"question_id":"Wzlmn0SSDuM7jl9nBegB","question_number":413,"page":83,"question_text":"A company is launching a feature that uses an HTTP API built with Amazon API Gateway and AWS Lambda. An API Gateway endpoint performs several independent tasks that run in a Lambda function. The independent tasks can take up to 10 minutes in total to finish running.\\n\\nUsers report that the endpoint sometimes returns an HTTP 604 status code. The Lambda function invocations are successful.\\n\\nWhich solution will stop the endpoint from returning the HTTP 504 status cade?","choices":{"B":"Increase the reserved concurrency of the Lambda function.","D":"Refactor the Lambda function to start an AWS Step Functions state machine.","A":"Increase the Lambda function\u2019s timeout value.","C":"Increase the memory that is available to the Lambda function."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156647-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:44:00","unix_timestamp":1739781840,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","upvote_count":"2","comment_id":"1357673","content":"Selected Answer: D\\nEl error HTTP 504 ocurre porque API Gateway tiene un tiempo de espera de integraci\xf3n que es menor que el tiempo total de ejecuci\xf3n (hasta 10 minutos). Refactorizando la funci\xf3n para iniciar un Step Functions state machine, se separa el procesamiento largo de la respuesta s\xedncrona, evitando que API Gateway agote el tiempo de espera.","timestamp":"1739781840.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:05.375Z","extraction_method":"api_direct_v1"},{"question_id":"PmzXcpAjGScQGJvfc9Cc","question_number":414,"page":83,"question_text":"A company has an application that uses an Amazon Cognito user pool for authentication. A developer needs to add a new REST API that will use the user pool to authenticate requests.\\n\\nWhich solution will meet this requirement with the LEAST development effort?","choices":{"A":"Create a new API key and a new usage plan. Associate the API key and the REST API with the usage plan.","C":"Create an AWS Lambda token authorizer. Reference the authorization token in the event payload. Authenticate requests based on the token value.","D":"Create an AWS Lambda request authorizer. Reference the authorization header in the event payload. Authenticate requests by using the header value in a request to the Cognito API.","B":"Create a Cognito authorizer for the correct user pool. Reference the header that contains the Cognito token."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152946-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-13 02:51:00","unix_timestamp":1734054660,"discussion_count":1,"discussion":[{"timestamp":"1734054660.0","upvote_count":"1","comment_id":"1325954","poster":"ShakthiGCP","content":"Selected Answer: B\\nhttps://medium.com/@shivkaundal/secure-your-apis-with-cognito-authorizers-for-aws-api-gateway-ba15914b64b2"}],"answer_description":"","extracted_at":"2025-12-24T09:10:05.375Z","extraction_method":"api_direct_v1"},{"question_id":"utArki4fEenYuT00ChgI","question_number":415,"page":83,"question_text":"A developer is testing an AWS Lambda function that has an event source of an Amazon Simple Queue Service (Amazon SQS) queue. The developer notices that some of the messages the Lambda function processes re-appear in the queue while the messages are being processed.\\n\\nThe developer must correct this behavior.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Increase the memory allocation of the Lambda function.","A":"Increase the timeout of the Lambda function.","D":"Increase the batch size in the event source mapping.","B":"Increase the visibility timeout of the SQS queue."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156648-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:45:00","unix_timestamp":1739781900,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","timestamp":"1739781900.0","content":"Selected Answer: B\\nPorque al aumentar el tiempo de visibilidad del SQS, se evita que los mensajes se vuelvan a entregar mientras la funci\xf3n Lambda a\xfan los est\xe1 procesando.","upvote_count":"1","comment_id":"1357674"}],"answer_description":"","extracted_at":"2025-12-24T09:10:05.375Z","extraction_method":"api_direct_v1"},{"question_id":"evN55zyaSFO5YfaAPbuU","question_number":416,"page":84,"question_text":"A developer created reusable code that several AWS Lambda functions need to use. The developer bundled the code into a zip archive. The developer needs to deploy the code to AWS and update the Lambda functions to use the code.\\n\\nWhich solution will meet this requirement in the MOST operationally efficient way?","choices":{"A":"Upload the zip archive to Amazon S3. Configure an import path on the Lambda functions to point to the zip archive.","B":"Create a new Lambda function that contains and runs the shared code. Update the existing Lambda functions to invoke the new Lambda function synchronously.","D":"Create a Lambda container image that includes the shared code. Use the container image as a Lambda base image for all the functions.","C":"Create a Lambda layer that contains the zip archive. Attach the Lambda layer to the Lambda functions."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152947-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-13 02:53:00","unix_timestamp":1734054780,"discussion_count":1,"discussion":[{"content":"Selected Answer: C\\nal crear una Lambda layer con el c\xf3digo compartido y adjuntarla a tus funciones Lambda, puedes reutilizar el c\xf3digo de manera operativamente eficiente sin tener que duplicarlo o reempaquetarlo en cada funci\xf3n.","upvote_count":"1","timestamp":"1739781900.0","poster":"italiancloud2025","comment_id":"1357675"}],"answer_description":"","extracted_at":"2025-12-24T09:10:16.207Z","extraction_method":"api_direct_v1"},{"question_id":"BcKZPYJGQna73u2wQjza","question_number":417,"page":84,"question_text":"A team has an Amazon API Gateway REST API that consists of a single resource and a GET method that is backed by an AWS Lambda integration.\\n\\nA developer makes a change to the Lambda function and deploys the function as a new version. The developer needs to set up a process to test the new version of the function before using the new version in production. The tests must not affect the production REST API.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Update the Lambda integration of the existing GET method to point to the updated version of the Lambda function. Deploy the new version.","A":"Create a new resource in the REST API. Add a GET method to the new resource, and add a Lambda integration to the updated version of the Lambda function. Deploy the new version.","B":"Create a new stage for the REST API. Create a stage variable. Assign the stage variable to the Lambda function. Set the API Gateway integrated Lambda function name to the stage variable. Deploy the new version.","C":"Create a new REST API. Add a resource that has a single GET method that is integrated with the updated version of the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156649-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:46:00","unix_timestamp":1739781960,"discussion_count":1,"discussion":[{"upvote_count":"2","poster":"italiancloud2025","comment_id":"1357676","content":"Selected Answer: B\\nAl crear una etapa (stage) separada y usar variables de etapa para apuntar a la versi\xf3n actualizada de la funci\xf3n, puedes probar sin afectar la etapa de producci\xf3n. Es la opci\xf3n de menor sobrecarga operativa.","timestamp":"1739781960.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:16.207Z","extraction_method":"api_direct_v1"},{"question_id":"Uku1IHe0Kvc9WxCVy41X","question_number":418,"page":84,"question_text":"A developer manages encryption keys in AWS Key Management Service (AWS KMS). The developer must ensure that all encryption keys can be deleted immediately when the keys are no longer required. The developer wants a solution that is highly available and does not require manual management for compute infrastructure.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Use customer managed keys with imported key material. When the keys are no longer required, delete the imported key material.","C":"Use customer managed keys. When the keys are no longer required, delete the key material.","A":"Use AWS KMS managed keys. When the keys are no longer required, schedule the keys for immediate deletion.","D":"Use customer managed keys and an AWS CloudHSM key store. When the keys are no longer required, schedule the keys for immediate deletion."},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","A (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152950-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-13 03:05:00","unix_timestamp":1734055500,"discussion_count":4,"discussion":[{"comment_id":"1357677","timestamp":"1739782080.0","poster":"italiancloud2025","upvote_count":"1","content":"Selected Answer: B\\nB: Con claves administradas por el cliente que utilizan material de clave importado, puedes eliminar el material de clave de forma inmediata cuando ya no se requiera.\\nA y D: Aunque son altamente disponibles, requieren programar la eliminaci\xf3n (no es inmediata)."},{"content":"Selected Answer: B\\nB is the correct answer.\\nA and C are wrong as AWS KMS managed keys (including AWS-managed keys and customer managed keys) cannot be deleted immediately. They must go through a minimum waiting period of 7 days.","poster":"Arad","comment_id":"1338617","upvote_count":"2","timestamp":"1736478780.0"},{"upvote_count":"1","comment_id":"1332594","poster":"xdeveloper","timestamp":"1735329000.0","content":"Selected Answer: A\\nAWS KMS allows you to schedule the keys for immediate or future deletion. This makes it easy to delete keys without manual intervention."},{"timestamp":"1734055500.0","poster":"ShakthiGCP","upvote_count":"2","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/kms/latest/developerguide/importing-keys-delete-key-material.html","comment_id":"1325962"}],"answer_description":"","extracted_at":"2025-12-24T09:10:16.207Z","extraction_method":"api_direct_v1"},{"question_id":"ymwD6Rg10CI22YL9Svnq","question_number":419,"page":84,"question_text":"A company has an ecommerce application. The application\'s API sends order data to an Amazon Simple Queue Service (Amazon SOS) queue. A developer needs to modify the application to enrich the order data before the application sends the order data to a fulfillment system.\\n\\nWhich solution will meet this requirement with the LEAST development effort?","choices":{"C":"Create an Amazon EMR cluster to read messages from the SQS queue. Configure an EMR job to enrich the order data. Create and configure an Amazon S3 bucket as the output location. Adjust the order fulfilment system to retrieve the enriched files from the S3 bucket.","B":"Create an AWS Step Functions state machine. Configure an Amazon EventBridge rule to run the state machine when an order is published to the SQS queue. Map the orders to an AWS Lambda function. Program the Lambda function to perform the data enrichment and to invoke the state machine. Configure the last step of the state machine to send the enriched data to the fulfilment system,","A":"Create an AWS Lambda function to poll the SOS queue. enrich the message data, and send the enriched data to the fulfilment system, Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda function to the SNS topic.","D":"Create an Amazon EventBridge pipe that uses event enrichment. Configure the SQS queue as a source for the pipe. Set the fulfillment system as the target of the pipe."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153146-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-18 03:26:00","unix_timestamp":1734488760,"discussion_count":2,"discussion":[{"poster":"xdeveloper","content":"Selected Answer: D\\nEventBridge Pipes enables you to create point-to-point integrations between sources and targets, including advanced event transformations and enrichment.","comment_id":"1332596","timestamp":"1735329360.0","upvote_count":"2"},{"timestamp":"1734488760.0","content":"Selected Answer: D\\nAWS EventBridge Pipes is a feature of Amazon EventBridge that simplifies building event-driven architectures by connecting event producers and consumers directly with minimal code or custom logic. It allows you to create point-to-point integrations between sources (e.g., AWS services, SaaS applications) and targets with optional filtering and enrichment of events along the way.","upvote_count":"1","comment_id":"1328238","poster":"ShakthiGCP"}],"answer_description":"","extracted_at":"2025-12-24T09:10:16.207Z","extraction_method":"api_direct_v1"},{"question_id":"XggO8vqGer1FbUlvTKsS","question_number":420,"page":84,"question_text":"An application interacts with Amazon Aurora to store and track customer information. The primary database is set up with multiple read replicas for improving the performance of the read queries. However, one of the Aurora replicas is receiving most or all of the traffic, while the other Aurora replica remains idle.\\n\\nHow can this issue be resolved?","choices":{"B":"Enable application-level DNS caching.","C":"Enable application pooling","D":"Disable application pooling","A":"Disable application-level DNS caching."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152952-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-13 03:26:00","unix_timestamp":1734056760,"discussion_count":2,"discussion":[{"content":"Selected Answer: A\\nEl endpoint de lectura de Aurora usa un mecanismo de balanceo de carga basado en DNS para distribuir las solicitudes entre las r\xe9plicas. Si la aplicaci\xf3n almacena en cach\xe9 la resoluci\xf3n DNS, siempre apuntar\xe1 a la misma IP (r\xe9plica), dejando inactiva la otra. Desactivar el caching DNS en la aplicaci\xf3n permitir\xe1 que las solicitudes se distribuyan equitativamente entre las r\xe9plicas.","upvote_count":"1","poster":"italiancloud2025","comment_id":"1357678","timestamp":"1739782080.0"},{"poster":"ShakthiGCP","upvote_count":"1","timestamp":"1734056760.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/whitepapers/latest/amazon-aurora-mysql-db-admin-handbook/dns-caching.html","comment_id":"1325969"}],"answer_description":"","extracted_at":"2025-12-24T09:10:16.207Z","extraction_method":"api_direct_v1"},{"question_id":"jHa2zpQMzdsY7M0Id00c","question_number":421,"page":85,"question_text":"A company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing.\\n\\nHow should the developer incorporate unit tests as part of CI/CD pipelines?","choices":{"B":"Update the AWS CodeBuild build specification to include a phase for running unit tests.","A":"Create a separate CodePipeline pipeline to run unit tests.","D":"Create a testing branch in a git repository for the pipelines to run unit tests.","C":"Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156650-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:49:00","unix_timestamp":1739782140,"discussion_count":1,"discussion":[{"upvote_count":"2","timestamp":"1739782140.0","comment_id":"1357679","poster":"italiancloud2025","content":"Selected Answer: B\\nSimplemente se actualiza el archivo de especificaci\xf3n (buildspec) de CodeBuild para incluir una fase que ejecute los tests unitarios"}],"answer_description":"","extracted_at":"2025-12-24T09:10:27.268Z","extraction_method":"api_direct_v1"},{"question_id":"ibllR7Mf4BozSorIna7p","question_number":422,"page":85,"question_text":"A developer is troubleshooting a three-tier application, which is deployed on Amazon EC2 instances. There is a connectivity problem between the application servers and the database servers.\\n\\nWhich AWS services or tools should be used to identity the faulty component? (Choose two.)","choices":{"D":"Network access control lists","C":"Amazon VPC Flow Logs","E":"AWS Config rules","B":"AWS Trusted Advisor","A":"AWS CloudTrail"},"correct_answer":"CD","answer_ET":"CD","answers_community":["CD (50%)","CE (50%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156651-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:51:00","unix_timestamp":1739782260,"discussion_count":2,"discussion":[{"comment_id":"1357995","upvote_count":"1","timestamp":"1739829240.0","content":"Selected Answer: CD\\nAmazon VPC Flow Logs:\\nAmazon VPC Flow Logs can be used to capture information about the IP traffic going to and from network interfaces in your VPC. This tool helps identify whether the traffic is reaching the intended destination and whether there are any connectivity issues at the network level \\n.\\nNetwork Access Control Lists (NACLs):\\nNetwork ACLs are used to control inbound and outbound traffic at the subnet level. By reviewing the rules in the NACLs, you can determine if they are blocking traffic between the application servers and the database servers. Misconfigured NACLs are a common cause of connectivity issues.","poster":"siheom"},{"upvote_count":"1","comment_id":"1357680","poster":"italiancloud2025","content":"Selected Answer: CE\\nLa D las NACLs no creo que te ayuden a depurar errores en el tr\xe1fico","timestamp":"1739782260.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:27.268Z","extraction_method":"api_direct_v1"},{"question_id":"1r5PrM676TopslajcKX1","question_number":423,"page":85,"question_text":"A developer is creating an AWS Lambda function that needs credentials to connect to an Amazon RDS for MySQL database. An Amazon S3 bucket currently stores the credentials. The developer needs to improve the existing solution by implementing credential rotation and secure storage. The developer also needs to provide integration with the Lambda function.\\nWhich solution should the developer use to store and retrieve the credentials with the LEAST management overhead?","choices":{"D":"Encrypt the credentials by using AWS Key Management Service (AWS KMS). Store the credentials in an Amazon DynamoDB table. Create a second Lambda function to rotate the credentials. Invoke the second Lambda function by using an Amazon EventBridge rule that runs on a schedule. Update the DynamoDB table. Update the database to use the generated credentials. Retrieve the credentials from DynamoDB with the first Lambda function. Connect to the database.","C":"Store the credentials in AWS Secrets Manager. Set the secret type to Credentials for Amazon RDS database. Select the database that the secret will access. Use the default AWS Key Management Service (AWS KMS) key to encrypt the secret. Enable automatic rotation for the secret. Use the secret from Secrets Manager on the Lambda function to connect to the database.","A":"Store the credentials in AWS Systems Manager Parameter Store. Select the database that the parameter will access. Use the default AWS Key Management Service (AWS KMS) key to encrypt the parameter. Enable automatic rotation for the parameter. Use the parameter from Parameter Store on the Lambda function to connect to the database.","B":"Encrypt the credentials with the default AWS Key Management Service (AWS KMS) key. Store the credentials as environment variables for the Lambda function. Create a second Lambda function to generate new credentials and to rotate the credentials by updating the environment variables of the first Lambda function. Invoke the second Lambda function by using an Amazon EventBridge rule that runs on a schedule. Update the database to use the new credentials. On the first Lambda function, retrieve the credentials from the environment variables. Decrypt the credentials by using AWS KMS, Connect to the database."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103918-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 02:24:00","unix_timestamp":1679793840,"discussion_count":8,"discussion":[{"comments":[{"content":"\\"automatic rotation\\" \\"cross region\\" - Security Manager","upvote_count":"1","poster":"jipark","timestamp":"1691152800.0","comment_id":"972156"}],"poster":"Untamables","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/retrieving-secrets_lambda.html","comment_id":"850609","timestamp":"1679793840.0","upvote_count":"11"},{"content":"Selected Answer: C\\nA - KMS provides automatic rotation for AWS Managed Keys, but Custom Managed Keys are not provided (needs to implement rotation logic by dev). A did not specify which key the dev should use. \\n\\nANW : C - SM provides automatic rotation lambda for RDS Param rotation.","upvote_count":"2","comment_id":"1345938","timestamp":"1737704220.0","poster":"mooncake1"},{"content":"Selected Answer: C\\nA) Eliminated - automatic credential rotation is limited\\n\\nC) Correct - Secrets Manager is specifically designed for securely storing and retrieving secrets. Automatic rotation of credentials is fully supported","upvote_count":"1","poster":"sumanshu","comment_id":"1330881","timestamp":"1734973380.0"},{"comment_id":"1304906","upvote_count":"1","poster":"Saudis","content":"Selected Answer: C\\nC The keyword automatic rotation for the parameter.","timestamp":"1730277300.0"},{"upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716311940.0","poster":"65703c1","comment_id":"1215120"},{"poster":"ibratoev","comment_id":"1183304","content":"C. \\"credential rotation\\" = Security Manager","timestamp":"1711455840.0","upvote_count":"2"},{"comment_id":"978115","content":"Option C. \\nKeyword: Implementing credential rotation and secure storage.","timestamp":"1691706720.0","upvote_count":"1","poster":"jayvarma"},{"upvote_count":"2","content":"C\\nThis solution minimizes management overhead by leveraging the built-in capabilities of AWS Secrets Manager, such as encryption, automatic rotation, and integration with AWS Lambda. It provides a secure and efficient way to store and retrieve \\n\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/retrieving-secrets_lambda.html","timestamp":"1688926320.0","comment_id":"947479","poster":"Mtho96"}],"answer_description":"","extracted_at":"2025-12-24T09:10:27.268Z","extraction_method":"api_direct_v1"},{"question_id":"5O5x3bAxKR0LwYZ3aaQb","question_number":424,"page":85,"question_text":"A company runs a new application on AWS Elastic Beanstalk. The company needs to deploy updates to the application. The updates must not cause any downtime for application users.\\n\\nThe deployment must forward a specified percentage of incoming client traffic to a new application version during an evaluation period.\\n\\nWhich deployment type will meet these requirements?","choices":{"D":"immutable","B":"traffic-splitting","C":"in-place","A":"rolling"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152955-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-13 03:43:00","unix_timestamp":1734057780,"discussion_count":2,"discussion":[{"timestamp":"1735330980.0","content":"Selected Answer: B\\nTraffic splitting \u2013 A canary testing deployment method. Suitable if you want to test the health of your new application version using a portion of incoming traffic, while keeping the rest of the traffic served by the old application version.","upvote_count":"3","poster":"xdeveloper","comment_id":"1332605"},{"comment_id":"1325973","timestamp":"1734057780.0","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html#environments-cfg-trafficsplitting-method","upvote_count":"1","poster":"ShakthiGCP"}],"answer_description":"","extracted_at":"2025-12-24T09:10:27.268Z","extraction_method":"api_direct_v1"},{"question_id":"d5pMkOUap9OHTRzw17p6","question_number":425,"page":85,"question_text":"A developer is making changes to a custom application that uses AWS Elastic Beanstalk.\\n\\nWhich solutions will update the Elastic Beanstalk environment with the new application version after the developer completes the changes? (Choose two.)","choices":{"A":"Package the application code into a zip file. Use the AWS Management Console to upload the .zip file and deploy the packaged application.","E":"Package the application code into a .zip file. Use the AWS Management Console to create a new application version from the .zip file. Rebuild the environment by using the AWS CLI.","B":"Package the application code into a .tar file. Use the AWS Management Console to create a new application version from the .tar file. Update the environment by using the AWS CLI.","C":"Package the application code into a .tar file. Use the AWS Management Console to upload the .tar file and deploy the packaged application.","D":"Package the application code into a .zip file. Use the AWS CL to create a new application version from the .zip file and to update the environment."},"correct_answer":"AD","answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156652-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:53:00","unix_timestamp":1739782380,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","content":"Selected Answer: AD\\nA: Puedes empaquetar el c\xf3digo en un archivo .zip, subirlo mediante la consola de Elastic Beanstalk y desplegar la nueva versi\xf3n directamente desde la consola.\\nD: Tambi\xe9n es posible empaquetar el c\xf3digo en un archivo .zip y utilizar la AWS CLI para crear una nueva versi\xf3n de la aplicaci\xf3n","upvote_count":"2","timestamp":"1739782380.0","comment_id":"1357681"}],"answer_description":"","extracted_at":"2025-12-24T09:10:27.268Z","extraction_method":"api_direct_v1"},{"question_id":"qmXZ5RjEoBpwfZMGqL1K","question_number":426,"page":86,"question_text":"A developer needs to write an AWS CloudFormation template on a local machine and deploy a CloudFormation stack to AWS.\\n\\nWhat must the developer do to complete these tasks?","choices":{"A":"Install the AWS CLI. Configure the AWS CLI by using an IAM user name and password.","D":"Install an AWS software development kit (SDK). Configure the SDK by using an X.509 certificate.","B":"Install the AWS CLI. Configure the AWS CLI by using an SSH key.","C":"Install the AWS CLI, Configure the AWS CLI by using an IAM user access key and secret key."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156653-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:53:00","unix_timestamp":1739782380,"discussion_count":1,"discussion":[{"content":"Selected Answer: C\\nPara desplegar una plantilla de CloudFormation desde una m\xe1quina local, debes tener instalada la AWS CLI y configurarla con las credenciales de un usuario IAM","upvote_count":"1","timestamp":"1739782380.0","comment_id":"1357682","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:10:38.224Z","extraction_method":"api_direct_v1"},{"question_id":"5pDEWu9WcblGSS05nOov","question_number":427,"page":86,"question_text":"A developer is updating an Amazon API Gateway REST API to have a mock endpoint. The developer wants to update the integration request mapping template so the endpoint will respond to mock integration requests with specific HTTP status codes based on various conditions.\\n\\nWhich statement will meet these requirements?","choices":{"B":"","D":"","A":"","C":""},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","C (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156656-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:01:00","unix_timestamp":1739782860,"discussion_count":3,"discussion":[{"poster":"thalasi","comment_id":"1570499","timestamp":"1747717980.0","upvote_count":"1","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html"},{"comment_id":"1365807","timestamp":"1741250280.0","upvote_count":"4","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html","poster":"0bdf3af"},{"comment_id":"1357687","timestamp":"1739782860.0","upvote_count":"1","content":"Selected Answer: C\\nCreo que est\xe1 bien formada y utiliza #if/#else de Velocity para decidir qu\xe9 c\xf3digo HTTP queremos devolver en funci\xf3n de si existe o no el campo integration en el path.\\nEs la forma t\xedpica de \u201cmaquetar\u201d un mock response en API Gateway, retornando distintos statusCode seg\xfan la condici\xf3n.","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:10:38.224Z","extraction_method":"api_direct_v1"},{"question_id":"uPaBKyxdF1jbKEYDp37a","question_number":428,"page":86,"question_text":"A large company has its application components distributed across multiple AWS accounts. The company needs to collect and visualize trace data across these accounts.\\n\\nWhat should be used to meet these requirements?","choices":{"D":"Amazon OpenSearch Service","C":"Amazon VPC flow logs","B":"Amazon CloudWatch","A":"AWS X-Ray"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156654-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:57:00","unix_timestamp":1739782620,"discussion_count":1,"discussion":[{"poster":"0bdf3af","upvote_count":"2","content":"Selected Answer: A\\nTo trace data - x-ray","comment_id":"1365810","timestamp":"1741250580.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:38.224Z","extraction_method":"api_direct_v1"},{"question_id":"DSpn10gsavYrFBMS1bdY","question_number":429,"page":86,"question_text":"A developer must cache dependent artifacts from Maven Central, a public package repository, as part of an application\u2019s build pipeline. The build pipeline has an AWS CodeArtifact repository where artifacts of the build are published. The developer needs a solution that requires minimum changes to the build pipeline.\\n\\nWhich solution meets these requirements?","choices":{"D":"Modify the CodeAnifact repository resource policy to allow artifacts to be fetched from the public package repository.","A":"Modify the existing CodeAriifact repository to associate an upstream repository with the public package repository.","B":"Create a new CodeAtfact repository that has an external connection to the public package repository.","C":"Create a new CodeAifact domain that contains a new repository that has an external connection to the public package repository."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156655-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 09:59:00","unix_timestamp":1739782740,"discussion_count":1,"discussion":[{"content":"Selected Answer: A\\nB\xe1sicamente, solo tienes que modificar el repositorio actual para agregar Maven Central como repositorio \\"upstream\\", lo que minimiza los cambios en la pipeline.","upvote_count":"1","poster":"italiancloud2025","comment_id":"1357686","timestamp":"1739782740.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:38.224Z","extraction_method":"api_direct_v1"},{"question_id":"Rvjwa36EScF9Vn9KGK8f","question_number":430,"page":86,"question_text":"A developer is creating an AWS Step Functions state machine to handle an order processing workflow. When the state machine receives an order, the state machine pauses until the order has been confirmed. A record that is added to an Amazon DynamoDB table by another service confirms each order.\\n\\nThe developer must complete the order processing workflow.\\n\\nWhich solution will meet this requirement?","choices":{"B":"Subscribe an AWS Lambda function to a DynamoDB table stream. Configure the Lambda function to run when a new record is added to the table. When the Lambda function receives the appropriate record, run the redrive execution command on the running state machine.","C":"Subscribe an AWS Lambda function to the DynamoDB table stream. Configure the Lambda function to run when a new record is added to the table. When the Lambda function receives the appropriate record, stop the current state machine invocation and start a new invocation.","A":"Update the state machine to query the DynamoDB table by using the DynamoDB GetItem state to determine whether a record exists. If the record does exist, continue to the next state. If the record does not exist, wait 5 minutes and check again.","D":"Invoke an AWS Lambda function from the state machine. Configure the Lambda function to continuously poll the DynamoDB table for the appropriate record and to return when a record exists. Continue the state machine invocation when the Lambda function returns. If the Lambda function times out, then fail the state machine."},"correct_answer":"B","answer_ET":"B","answers_community":["B (75%)","A (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/154337-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-10 21:16:00","unix_timestamp":1736540160,"discussion_count":2,"discussion":[{"comment_id":"1365812","timestamp":"1741251060.0","upvote_count":"3","content":"Selected Answer: B\\nB. Use DynamoDB streams, then lambda subscribe the stream and redrive state machine","poster":"0bdf3af"},{"timestamp":"1736540160.0","poster":"Arad","content":"Selected Answer: A\\nA is the correct answer.\\nBecause AWS Step Functions provides native integration with Amazon DynamoDB, allowing the state machine to directly query a DynamoDB table using the DynamoDB GetItem state. This approach enables a wait-and-retry mechanism, which is ideal for workflows where the state machine needs to wait for a confirmation record to appear in the DynamoDB table.\\nB is wrong.\\nBecause while this could work, it adds unnecessary complexity. The redrive execution command involves restarting the state machine, which is not ideal for workflows designed to wait for an event.","comment_id":"1338969","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:10:38.224Z","extraction_method":"api_direct_v1"},{"question_id":"EZnVCwmoFP6u8CJH8Fc1","question_number":431,"page":87,"question_text":"A developer is writing a web application that must share secure documents with end users. The documents are stored in a private Amazon S3 bucket. The application must allow only authenticated users to download specific documents when requested, and only for a duration of 15 minutes.\\n\\nHow can the developer meet these requirements?","choices":{"B":"Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes.","A":"Copy the documents to a separate S3 bucket that has a lifecycle policy for deletion after 15 minutes.","D":"Modify the S3 bucket policy to only allow specific users to download the documents. Revert the change after 15 minutes.","C":"Use server-side encryption with AWS KMS managed keys (SSE-KMS) and download the documents using HTTPS."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156657-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:03:00","unix_timestamp":1739782980,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","content":"Selected Answer: B\\nsar un presigned URL con expiraci\xf3n de 15 minutos es la forma m\xe1s sencilla de dar acceso temporal a objetos en un bucket privado de S3.","upvote_count":"1","comment_id":"1357688","timestamp":"1739782980.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:49.284Z","extraction_method":"api_direct_v1"},{"question_id":"jI368Wj5KnRzevZNKscf","question_number":432,"page":87,"question_text":"A company is developing a set of AWS Lambda functions to process data. The Lambda functions need to use a common third-party library as a dependency. The library is frequently updated with new features and bug fixes. The company wants to ensure that the Lambda functions always use the latest version of the library.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"D":"Create a new Lambda function to load the library. Configure the existing Lambda functions to invoke the new Lambda function when the existing functions need to use the library.","B":"Create a Lambda layer that includes the library. Attach the layer to each Lambda function.","C":"Install the dependency in an Amazon Elastic File System (Amazon EFS) file system. Attach the file system to each Lambda function.","A":"Store the dependency and the function code in an Amazon S3 bucket."},"correct_answer":"C","answer_ET":"C","answers_community":["C (75%)","B (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156658-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:04:00","unix_timestamp":1739783040,"discussion_count":3,"discussion":[{"upvote_count":"1","comment_id":"1570501","poster":"thalasi","timestamp":"1747718760.0","content":"Selected Answer: C\\nLambda Layers primarily support static content. Once a layer is deployed, its contents are immutable, meaning they cannot be changed without creating a new version of the layer. This makes them suitable for storing things like libraries, configuration files, and custom code that doesn\'t change frequently. Dynamic content, like frequently updated data, is generally better suited for other storage options like S3 or ephemeral storage."},{"upvote_count":"2","comment_id":"1365817","content":"Selected Answer: C\\nC. EFS is for library which is being changed and we need the latest version always for our lambda function.\\nLambda layers won\'t work in this case because they are static and the loaded library version is frozen","timestamp":"1741252620.0","poster":"0bdf3af"},{"poster":"italiancloud2025","upvote_count":"1","timestamp":"1739783040.0","content":"Selected Answer: B\\nEs la mejor pr\xe1ctica para compartir dependencias entre m\xfaltiples Lambdas, cuando haya una actualizaci\xf3n, solo actualizas la capa con la nueva versi\xf3n de la librer\xeda","comment_id":"1357689"}],"answer_description":"","extracted_at":"2025-12-24T09:10:49.284Z","extraction_method":"api_direct_v1"},{"question_id":"5YUpDux50iNM93Xrolqs","question_number":433,"page":87,"question_text":"A company\u2019s application includes an Amazon DynamoDB table for product orders. The table has a primary partition key of orderId and has no sort key. The company is adding a new feature that requires the application to query the table by using the customerId attribute.\\n\\nWhich solution will provide this query functionality?","choices":{"A":"Change the existing primary key by setting customerId as the sort key.","D":"Create a new local secondary index (LSI) on the table with a partition key of orderId and a sort key of customerId.","B":"Create a new global secondary index (GSI) on the table with a partition key of customerId.","C":"Create a new local secondary index (LSI) on the table with a partition key of customerId."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156659-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:05:00","unix_timestamp":1739783100,"discussion_count":1,"discussion":[{"upvote_count":"1","timestamp":"1741252680.0","poster":"0bdf3af","comment_id":"1365819","content":"Selected Answer: B\\nB. We can add Global Secondary Index only to existing table in DynamoDB"}],"answer_description":"","extracted_at":"2025-12-24T09:10:49.284Z","extraction_method":"api_direct_v1"},{"question_id":"aIFW7VCPPrUCbsSA2VpX","question_number":434,"page":87,"question_text":"A developer has written the following IAM policy to provide access to an Amazon S3 bucket:\\n//IMG//\\n\\nWhich access does the policy allow regarding the s3:GetObject and s3:PutObject actions?","choices":{"C":"Access on all objects in the \u201cDOC-EXAMPLE-BUCKET\u201d bucket along with access to all S3 actions for objects in the \u201cDOC-EXAMPLE-BUCKET\u201d bucket that start with \u201csecrets\u201d","D":"Access on all objects in the \u201cDOC-EXAMPLE-BUCKET\u201d bucket except on objects that start with \u201csecrets\u201d","A":"Access on all buckets except the \u201cDOC-EXAMPLE-BUCKET\u201d bucket","B":"Access on all buckets that start with \u201cDOC-EXAMPLE-BUCKET\u201d except the \u201cDOC-EXAMPLE-BUCKET/secrets\u201d bucket"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103919-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image3.png"],"answer_images":[],"timestamp":"2023-03-26 02:46:00","unix_timestamp":1679795160,"discussion_count":5,"discussion":[{"content":"Selected Answer: D\\nD\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-with-s3-actions.html","timestamp":"1679795160.0","upvote_count":"12","comment_id":"850614","poster":"Untamables"},{"timestamp":"1734973500.0","poster":"sumanshu","upvote_count":"1","content":"Selected Answer: D\\nThe condition restricts access to objects that start with the prefix secrets","comment_id":"1330884"},{"poster":"guidosolano","content":"Me toco en el examen","comment_id":"1239488","timestamp":"1719714000.0","upvote_count":"1"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","comment_id":"1215122","timestamp":"1716312060.0","poster":"65703c1"},{"upvote_count":"2","content":"Selected Answer: D\\nD\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-with-s3-actions.html","poster":"nmc12","comment_id":"1022227","timestamp":"1696162320.0"}],"answer_description":"","extracted_at":"2025-12-24T09:10:49.284Z","extraction_method":"api_direct_v1"},{"question_id":"gHPWX6ld2n11wv3w7a1I","question_number":435,"page":87,"question_text":"A company hosts applications on premises. The on-premises servers generate audit logs that are available through an HTTP endpoint.\\n\\nThe company needs an automated solution to regularly ingest and store large volumes of audit data from the on-premises servers. The company also needs to perform queries on the audit data.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"B":"Create an AWS Lambda function to call the HTTP endpoint to fetch audit logs. Configure an Amazon EventBridge scheduled rule to invoke the Lambda function. Configure the Lambda function to push the logs to AWS CloudTrail Lake.","D":"Install the Amazon CloudWatch agent on the on-premises servers. Give the agent the ability to push audit logs to CloudWatch. Use CloudWatch Insights to query the logs.","C":"Use AWS DataSync to transfer audit logs to an Amazon S3 bucket. Load the logs into an Amazon S3 bucket. Use Amazon Athena to query the bucket.","A":"Export the audit logs. Upload the logs to Amazon S3. Import the logs to an Amazon RDS DB instance."},"correct_answer":"B","answer_ET":"C","answers_community":["B (33%)","C (33%)","D (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153147-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-18 03:57:00","unix_timestamp":1734490620,"discussion_count":3,"discussion":[{"timestamp":"1749114300.0","comment_id":"1574998","poster":"robotgeek","upvote_count":"1","content":"Selected Answer: D\\nOperationally efficient is to use the program specifically designed for this: the CloudWatch Agent, which ships log files to the cloud.\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\\n\\nIs AWS trying to evangelize CloudTrail Lake here? Maybe. But I can\'t imagine pulling logs from HTTP on-premises endpoints... Operationally, it just doesn\'t make sense to me."},{"content":"Selected Answer: C\\nAWS DataSync is an online data movement and discovery service that simplifies and accelerates data migrations to AWS as well as moving data to and from on-premises storage, edge locations, other cloud providers, and AWS Storage services.\\n\\nhttps://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html","timestamp":"1741252980.0","comment_id":"1365821","poster":"0bdf3af","upvote_count":"1"},{"upvote_count":"1","comment_id":"1357692","timestamp":"1739783220.0","content":"Selected Answer: B\\nuna funci\xf3n Lambda programada mediante EventBridge, se puede invocar peri\xf3dicamente para llamar al endpoint HTTP y extraer los logs, sin tener que instalar nada en los servidores on premises. Con CLoudtrail lake tampoco tienes que instalar nada","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:10:49.284Z","extraction_method":"api_direct_v1"},{"question_id":"1TXnIM0WFuzK54KJpV0X","question_number":436,"page":88,"question_text":"A developer is building an application that includes an AWS Lambda function that is written in .NET Core. The Lambda function\u2019s code needs to interact with Amazon DynamoDB tables and Amazon S3 buckets. The developer must minimize the Lambda function\u2019s deployment time and invocation duration.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Increase the Lambda function\u2019s memory.","B":"Include the entire AWS SDK for .NET in the Lambda function\u2019s deployment package.","C":"Include only the AWS SDK for .NET modules for DynamoDB and Amazon S3 in the Lambda function\u2019s deployment package.","D":"Configure the Lambda function to download the AWS SDK for .NET from an S3 bucket at runtime."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156660-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:08:00","unix_timestamp":1739783280,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","upvote_count":"1","comment_id":"1357693","timestamp":"1739783280.0","content":"Selected Answer: C\\nIncluyendo \xfanicamente los m\xf3dulos para DynamoDB y S3, se reduce el tama\xf1o del paquete, lo que disminuye el tiempo de despliegue e invocaci\xf3n de la funci\xf3n."}],"answer_description":"","extracted_at":"2025-12-24T09:11:00.149Z","extraction_method":"api_direct_v1"},{"question_id":"V1hjKqm8feRJiyCGcBYm","question_number":437,"page":88,"question_text":"A development team has an Amazon API Gateway REST API that is backed by an AWS Lambda function.\\n\\nUsers have reported performance issues for the Lambda function. The development team identified the source of the issues as a cold start of the Lambda function. The development team needs to reduce the time needed for the Lambda function to initialize.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Change the Lambda concurrency to reserved concurrency.","D":"Configure provisioned concurrency for the Lambda function.","C":"Increase the memory allocation of the Lambda function.","B":"Increase the timeout of the Lambda function."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156661-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:09:00","unix_timestamp":1739783340,"discussion_count":1,"discussion":[{"upvote_count":"1","poster":"italiancloud2025","comment_id":"1357695","timestamp":"1739783340.0","content":"Selected Answer: D\\nConfigurar provisioned concurrency mantiene contenedores de Lambda \\"calentitos\\" y listos para responder,"}],"answer_description":"","extracted_at":"2025-12-24T09:11:00.149Z","extraction_method":"api_direct_v1"},{"question_id":"AjZaKGWncWIIxFjeZraW","question_number":438,"page":88,"question_text":"A video streaming company has a pipe in Amazon EventBridge Pipes that uses an Amazon Simple Queue Service (Amazon SQS) queue as an event source. The pipe publishes all source events to a target EventBridge event bus. Before events are published, the pipe uses an AWS Lambda function to retrieve the stream status of each event from a database and adds the stream status to each source event.\\n\\nThe company wants the pipe to publish events to the event bus only if the video stream has a status of ready.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Add an input transformer to the pipe output that filters streams that have a status of ready.","A":"Add a filter step to the pipe that will match on a stream status of ready.","C":"Include a filter for a status of ready in all EventBridge rules that subscribe to the event bus.","B":"Update the Lambda function to return only video streams that have a status of ready."},"correct_answer":"A","answer_ET":"A","answers_community":["A (50%)","B (50%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156662-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:10:00","unix_timestamp":1739783400,"discussion_count":2,"discussion":[{"comment_id":"1365824","poster":"0bdf3af","upvote_count":"2","timestamp":"1741254060.0","content":"Selected Answer: B\\nB. Lambda is for retrieve status from database. Only lambda know the status.\\nThe filtering can be done by addingone line in the code of the lambda function.\\nA. In Filtering step we don\'t have information about the status (status is in the database and the lambda has the access to it)\\nC. It\'s too late. Event is already sent to eventbus and then rule can be invoked."},{"content":"Selected Answer: A\\nEventBridge Pipes permite agregar un paso de filtro para que solo los eventos que cumplan con ciertas condiciones (como tener un estado \\"ready\\") sean enviados al bus de eventos. Esto se configura sin cambiar la funci\xf3n Lambda ni afectar otros componentes,","comment_id":"1357696","timestamp":"1739783400.0","upvote_count":"2","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:11:00.149Z","extraction_method":"api_direct_v1"},{"question_id":"fW4jfxnDepxIVzItuzw1","question_number":439,"page":88,"question_text":"A developer needs to build a workflow to handle messages that are sent to an Amazon Simple Queue Service (Amazon SQS) queue. When a message reaches the queue, the workflow must implement a delay before invoking an AWS Lambda function to process the message.\\n\\nWhich solution will meet this requirement in the MOST operationally efficient way?","choices":{"D":"Set the Visibility Timeout value of the SQS queue to be the number of seconds required to delay delivery of the messages. Add an event source mapping for the Lambda function. Specify the SQS queue as a source.","C":"Set the DelaySeconds value of the SQS queue to be the number of seconds required to delay delivery of the messages. Add an event source mapping for the Lambda function. Specify the SQS queue as a source.","A":"Create an AWS Step Functions state machine to process the SQS queue. Use a Wait state to delay the Lambda function\u2019s processing for the required number of seconds after message delivery to the SQS queue. Use Amazon EventBridge to invoke the state machine every 5 minutes.","B":"Configure the Lambda function to poll the SQS queue. Update the Lambda code to republish each message with a custom attribute that contains a future time when the message should be fully processed. Update the Lambda code to fully process messages when the custom attribute\u2019s future time has passed."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156663-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:11:00","unix_timestamp":1739783460,"discussion_count":1,"discussion":[{"comment_id":"1357697","timestamp":"1739783460.0","upvote_count":"1","poster":"italiancloud2025","content":"Selected Answer: C\\nAl configurar el par\xe1metro DelaySeconds de la cola SQS, se retrasa la entrega de los mensajes a la lambda y eso hace que est\xe9 el tiempo necesario"}],"answer_description":"","extracted_at":"2025-12-24T09:11:00.149Z","extraction_method":"api_direct_v1"},{"question_id":"w5nfndcJa6kYmZwcqCsA","question_number":440,"page":88,"question_text":"A company is building an application to accept data from customers. The data must be encrypted at rest and in transit.\\n\\nThe application uses an Amazon API Gateway API that resolves to AWS Lambda functions. The Lambda functions store the data in an Amazon Aurora MySQL DB cluster. The application worked properly during testing.\\n\\nA developer configured an Amazon CloudFront distribution with field-level encryption that uses an AWS Key Management Service (AWS KMS) key. After the configuration of the distribution, the application behaved unexpectedly. All the data in the database changed from plaintext to ciphertext.\\n\\nThe developer must ensure that the data is not stored in the database as the ciphertext from the CloudFront field-level encryption.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Enable encryption on the DB cluster by using the same KMS key that is used in CloudFront.","B":"Add a Lambda function that uses the KMS key to decrypt the data fields before saving the data to the database.","A":"Change the CloudFront Viewer protocol policy from \u201cHTTP and HTTPS\u201d to \u201cHTTPS only.\u201d","D":"Request and deploy a new SSL certificate to use with the CloudFront distribution."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156664-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:12:00","unix_timestamp":1739783520,"discussion_count":1,"discussion":[{"timestamp":"1739783520.0","upvote_count":"1","poster":"italiancloud2025","comment_id":"1357698","content":"Selected Answer: B\\nAl usar CloudFront con field-level encryption, los datos se cifran en el borde y llegan cifrados al origen. Para evitar que se almacenen en la base de datos como texto cifrado, debes incluir una funci\xf3n (o l\xf3gica en la Lambda) que, usando la misma clave de KMS, descifre esos campos antes de guardarlos."}],"answer_description":"","extracted_at":"2025-12-24T09:11:00.149Z","extraction_method":"api_direct_v1"},{"question_id":"BdVszEE5rBYVi8qdDkfq","question_number":441,"page":89,"question_text":"A company offers a business-to-business software service that runs on dedicated infrastructure deployed in each customer\u2019s AWS account. Before a feature release, the company needs to run integration tests on real AWS test infrastructure. The test infrastructure consists of Amazon EC2 instances and an Amazon RDS database.\\n\\nA developer must set up a continuous delivery process that will provision the test infrastructure across the different AWS accounts. The developer then must run the integration tests.\\n\\nWhich solution will meet these requirements with the LEAST administrative effort?","choices":{"C":"Use AWS CodePipeline with AWS CloudFormation change sets to deploy the infrastructure. Use a CloudFormation custom resource to run the tests.","A":"Use AWS CodeDeploy with AWS CloudFormation StackSets to deploy the infrastructure. Use Amazon CodeGuru to run the tests.","D":"Use AWS Serverless Application Model (AWS SAM) templates with AWS CloudFormation change sets to deploy the infrastructure. Use AWS CodeDeploy to run the tests.","B":"Use AWS CodePipeline with AWS CloudFormation StackSets to deploy the infrastructure. Use AWS CodeBuild to run the tests."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153523-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-27 22:24:00","unix_timestamp":1735334640,"discussion_count":3,"discussion":[{"upvote_count":"1","content":"Selected Answer: B\\nCodePipeline junto con CloudFormation StackSets facilita el despliegue de infraestructura en m\xfaltiples cuentas, y CodeBuild se adapta perfectamente para ejecutar los tests de integraci\xf3n. Minimo esfuerzo administrativo","timestamp":"1739783580.0","poster":"italiancloud2025","comment_id":"1357699"},{"comment_id":"1340069","content":"Selected Answer: B\\nAnswer should be B.","upvote_count":"1","timestamp":"1736805660.0","poster":"bp07"},{"upvote_count":"3","poster":"xdeveloper","timestamp":"1735334640.0","content":"Selected Answer: B\\nStackSets handle the deployment of resources to multiple accounts without the need for complex configurations.\\nCodePipeline and CodeBuild integrate seamlessly for CI/CD, providing a low-maintenance, fully managed solution.","comment_id":"1332627"}],"answer_description":"","extracted_at":"2025-12-24T09:11:11.198Z","extraction_method":"api_direct_v1"},{"question_id":"bIkDQ4inu3yRGhTZf7eU","question_number":442,"page":89,"question_text":"A developer is creating an application that uses an AWS Lambda function to transform and load data from an Amazon S3 bucket. When the developer tests the application, the developer finds that some invocations of the Lambda function are slower than others.\\n\\nThe developer needs to update the Lambda function to have predictable invocation durations that run with low latency. Any initialization activities, such as loading libraries and instantiating clients, must run during allocation time rather than during actual function invocations.\\n\\nWhich combination of steps will meet these requirements? (Choose two.)","choices":{"C":"Use the $LATEST version of the Lambda function.","D":"Configure reserved concurrency for the Lambda function to have the necessary number of execution environments.","A":"Create a schedule group in Amazon EventBridge Scheduler to invoke the Lambda function.","E":"Deploy changes, and publish a new version of the Lambda function.","B":"Configure provisioned concurrency for the Lambda function to have the necessary number of execution environments."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156665-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:15:00","unix_timestamp":1739783700,"discussion_count":1,"discussion":[{"comment_id":"1357701","poster":"italiancloud2025","timestamp":"1739783700.0","content":"Selected Answer: BE\\nB garantiza que las instancias de la funci\xf3n se inicialicen y est\xe9n listas y E pone una nueva versi\xf3n de la funci\xf3n pero no a LATEST","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:11:11.198Z","extraction_method":"api_direct_v1"},{"question_id":"pT8yLNxJ8tFMgES9DW0k","question_number":443,"page":89,"question_text":"A developer created an AWS Lambda function named ProcessMessages. The Lambda function is invoked asynchronously when a message is published to an Amazon Simple Notification Service (Amazon SNS) topic named InputTopic. The developer uses a second SNS topic named ErrorTopic to handle alerts of failures for other services.\\n\\nThe developer wants to receive notifications from the ErrorTopic SNS topic when the ProcessMessages Lambda function fails to process a message.\\n\\nWhich solution will meet this requirement?","choices":{"A":"Configure a subscription for the ErrorTopic SNS topic. Configure a filter policy for failures. Specify the ProcessMessages Lambda function as the endpoint.","D":"Configure a delivery policy on the ErrorTopic SNS topic. Configure a filter policy for failures. Specify the Lambda function as the input endpoint.","C":"Configure a trigger for the ProcessMessages Lambda function. Specify the ErrorTopic SNS topic as the trigger topic. Configure a filter policy on the topic for failures","B":"Configure a failure destination for the ProcessMessages Lambda function. Specify the Amazon Resource Name (ARN) of the ErrorTopic SNS topic as the destination ARN."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156666-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:16:00","unix_timestamp":1739783760,"discussion_count":1,"discussion":[{"upvote_count":"1","poster":"italiancloud2025","timestamp":"1739783760.0","content":"Selected Answer: B\\nPuedes configurar un destino de error (failure destination) para llamadas Lambda y cuando la funci\xf3n falle, se enviar\xe1 un mensaje al ErrorTopic SNS, permitiendo recibir notificaciones de fallo.","comment_id":"1357702"}],"answer_description":"","extracted_at":"2025-12-24T09:11:11.198Z","extraction_method":"api_direct_v1"},{"question_id":"prn37LeSmI9pPrVOiotr","question_number":444,"page":89,"question_text":"A company is developing a new application that uses Amazon EC2, Amazon S3, and AWS Lambda resources. The company wants to allow employees to access the AWS Management Console by using existing credentials that the company stores and manages in an on-premises Microsoft Active Directory. Each employee must have a specific level of access to the AWS resources that is based on the employee\u2019s role.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"C":"Implement a custom identity broker to authenticate users into the on-premises Active Directory. Configure the identity broker to use AWS Security Token Service (AWS STS) to grant authorized users IAM role based access to the AWS resources.","D":"Configure Amazon Cognito to federate users into the on-premises Active Directory. Use Cognito user pools to manage user identities and to manage user access to the AWS resources.","B":"Use LDAP to directly integrate the on-premises Active Directory with AWS Identity and Access Management (IAM). Map Active Directory groups to IAM roles to control access to AWS resources.","A":"Configure AWS Directory Service to create an Active Directory in AWS Directory Service for Microsoft Active Directory. Establish a trust relationship with the on-premises Active Directory. Configure IAM roles and trust policies to give the employees access to the AWS resources."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156667-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:17:00","unix_timestamp":1739783820,"discussion_count":1,"discussion":[{"timestamp":"1741255860.0","content":"Selected Answer: A\\nAWS Directory Service to connect to existing Microsoft AD","upvote_count":"1","poster":"0bdf3af","comment_id":"1365836"}],"answer_description":"","extracted_at":"2025-12-24T09:11:11.198Z","extraction_method":"api_direct_v1"},{"question_id":"yt1vYzBTPzYFIjB5RykV","question_number":445,"page":89,"question_text":"A developer has created an AWS Lambda function that is written in Python. The Lambda function reads data from objects in Amazon S3 and writes data to an Amazon DynamoDB table. The function is successfully invoked from an S3 event notification when an object is created. However, the function fails when it attempts to write to the DynamoDB table.\\nWhat is the MOST likely cause of this issue?","choices":{"A":"The Lambda function\'s concurrency limit has been exceeded.","B":"DynamoDB table requires a global secondary index (GSI) to support writes.","D":"The DynamoDB table is not running in the same Availability Zone as the Lambda function.","C":"The Lambda function does not have IAM permissions to write to DynamoDB."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102783-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 09:58:00","unix_timestamp":1678957080,"discussion_count":32,"discussion":[{"comments":[{"comment_id":"1329476","upvote_count":"1","comments":[{"comment_id":"1329477","timestamp":"1734701940.0","poster":"sumanshu","content":"D) Eliminated - AWS services, including Lambda and DynamoDB, are designed to work across Availability Zones without issues.","upvote_count":"1"}],"timestamp":"1734701880.0","poster":"sumanshu","content":"B) Eliminated - If the function was invoked successfully from the S3 event notification but fails during the write operation, this is less likely to be the issue"}],"content":"Selected Answer: C\\nA) Eliminated - If the function was invoked successfully from the S3 event notification but fails during the write operation, this is less likely to be the issue","poster":"sumanshu","comment_id":"1329475","timestamp":"1734701820.0","upvote_count":"1"},{"timestamp":"1733913000.0","poster":"trieudo","upvote_count":"3","content":"Selected Answer: C\\nkeywords: \\n- fails when it attempts to write => discard A (when invoke success, not due to rate limit) \\n\\nKnowlege:\\n- GSI relevant to read action, not write => discard B\\n- DynamoDB is global server, so AZ is not effect on it => discard D","comment_id":"1324973"},{"comment_id":"1322205","timestamp":"1733369340.0","content":"Selected Answer: C\\nCreate an IAM policy that grants your Lambda function read and write permissions to a specific DynamoDB table by defining the actions dynamodb:GetItem, dynamodb:PutItem, and others as needed","poster":"gomodhara","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\\nAnswer is B","timestamp":"1728204900.0","comment_id":"1293797","poster":"Aditya_bb_sharma"},{"poster":"ACurryDeveloper","upvote_count":"1","timestamp":"1722590880.0","comment_id":"1259798","content":"Its c, who on earth would vote for D??"},{"poster":"nkroker","comment_id":"1242191","content":"C is correct because the question does not contain any details about the placement of the resources in different availability zones hence making it obvious for users to assume they al are running in the same region and that\'s the reason why it makes sense that the Lambda execution role does not have the write permission for dynomodb table.","upvote_count":"1","timestamp":"1720112460.0"},{"timestamp":"1718690880.0","content":"Selected Answer: C\\nC is correct","upvote_count":"1","comment_id":"1232271","poster":"MessiVN"},{"timestamp":"1716295800.0","upvote_count":"1","comment_id":"1214951","poster":"65703c1","content":"Selected Answer: C\\nC is the correct answer."},{"comment_id":"1192317","poster":"Dikshika","content":"Selected Answer: C\\nit mentions lambda is unable to write to Dynamodb and C seems most logical answer here","timestamp":"1712671020.0","upvote_count":"1"},{"poster":"vinfo","comment_id":"1190632","upvote_count":"1","content":"Selected Answer: C\\nC. es correcto. En general para estos comportamientos, se debe a temas de permisos.","timestamp":"1712440380.0"},{"upvote_count":"1","poster":"apa_1","content":"Selected Answer: C\\nC is correct","comment_id":"1183977","timestamp":"1711533240.0"},{"timestamp":"1711376100.0","content":"Selected Answer: C\\nIt is C","upvote_count":"1","comment_id":"1182553","poster":"ibratoev"},{"timestamp":"1701411840.0","comment_id":"1084985","poster":"alven_alinan","content":"Selected Answer: C\\nAnswer is C","upvote_count":"1"},{"timestamp":"1700979000.0","poster":"dongocanh272","upvote_count":"3","comment_id":"1080506","content":"Why the correct anwser is D? All of us think C must be the correct answer"},{"content":"Am i missing something? Why in God\'s name are the answer\'s provided wrong? It says D is the right answer. Its obviously C..","upvote_count":"3","comment_id":"1066510","poster":"liddym2","timestamp":"1699544520.0"},{"comment_id":"1061935","upvote_count":"1","timestamp":"1699079760.0","poster":"dongocanh272","content":"Selected Answer: C\\nI think C is correct."},{"upvote_count":"3","poster":"chvtejaswi","content":"Selected Answer: C\\ncorrect answer is C","timestamp":"1694313660.0","comment_id":"1003631"},{"comment_id":"1002791","upvote_count":"3","poster":"hsinchang","timestamp":"1694220660.0","content":"Selected Answer: C\\nIt is clearly something about permissions. So not A or B. Lambda functions can run in multiple Availability Zones (AZs) to ensure high availability and resilience. So it is not D."},{"comment_id":"981856","upvote_count":"1","timestamp":"1692118800.0","poster":"kvpa","content":"Selected Answer: C\\ncorrect answer is C"},{"content":"Selected Answer: C\\nsurely C","timestamp":"1691733780.0","poster":"ssoratroi","upvote_count":"1","comment_id":"978314"},{"poster":"elfinka9","upvote_count":"2","comment_id":"968784","timestamp":"1690871520.0","content":"Does anyone know how the correct answer is determined? \\nOption C is the most voted and correct according to https://www.examtopics.com/discussions/amazon/view/88237-exam-aws-certified-developer-associate-topic-1-question-164/"},{"comment_id":"890864","content":"Got this question in exam. Correct answer is C.","timestamp":"1683390120.0","upvote_count":"4","poster":"geekdamsel"},{"timestamp":"1682378640.0","upvote_count":"1","poster":"MrTee","content":"Selected Answer: C\\nThe Lambda function needs to have the appropriate IAM permissions to write to the DynamoDB table. If the function does not have these permissions, it will fail when it attempts to write to the table.","comment_id":"879770"},{"poster":"zk1200","timestamp":"1681212240.0","comment_id":"867245","upvote_count":"2","content":"Selected Answer: C\\nC is the simples answer"},{"poster":"khaled1123","content":"Selected Answer: C\\nof course C","comment_id":"861253","upvote_count":"2","timestamp":"1680623220.0"},{"upvote_count":"2","timestamp":"1680496260.0","content":"Selected Answer: C\\nNo doubt C","poster":"TungNNS","comment_id":"859533"},{"upvote_count":"2","poster":"ihta_2031","content":"Selected Answer: C\\nC is the answer","comment_id":"857917","timestamp":"1680353940.0"},{"content":"Selected Answer: C\\nNo doubt C","poster":"Untamables","timestamp":"1679363760.0","upvote_count":"2","comment_id":"845440"},{"timestamp":"1679355480.0","content":"Selected Answer: C\\nIt is C","comment_id":"845353","upvote_count":"2","poster":"svrnvtr"},{"content":"I will go for C too","comment_id":"844758","upvote_count":"2","timestamp":"1679308500.0","poster":"prabhay786"},{"poster":"haaris786","upvote_count":"3","content":"I will go for C with this one.","timestamp":"1678958280.0","comment_id":"840745"},{"upvote_count":"3","timestamp":"1678957080.0","content":"C\\nhttps://www.examtopics.com/discussions/amazon/view/88237-exam-aws-certified-developer-associate-topic-1-question-164/","poster":"aragon_saa","comment_id":"840717"}],"answer_description":"","extracted_at":"2025-12-24T09:11:11.198Z","extraction_method":"api_direct_v1"},{"question_id":"Bx1nlRA4dMVEbL4WGl4I","question_number":446,"page":90,"question_text":"A developer is creating a mobile app that calls a backend service by using an Amazon API Gateway REST API. For integration testing during the development phase, the developer wants to simulate different backend responses without invoking the backend service.\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"D":"Use a request mapping template to select the mock integration response.","C":"Customize the API Gateway stage to select a response type based on the request.","A":"Create an AWS Lambda function. Use API Gateway proxy integration to return constant HTTP responses.","B":"Create an Amazon EC2 instance that serves the backend REST API by using an AWS CloudFormation template."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103619-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 00:47:00","unix_timestamp":1679528820,"discussion_count":10,"discussion":[{"timestamp":"1679795460.0","content":"Selected Answer: D\\nD\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html","comment_id":"850617","poster":"Untamables","upvote_count":"17"},{"comment_id":"847602","upvote_count":"6","timestamp":"1679528820.0","content":"Chatgpt said D","poster":"Dun6"},{"upvote_count":"3","comment_id":"1330887","poster":"sumanshu","content":"Selected Answer: D\\nC) Eliminated - Stages are not designed for selecting mock responses dynamically.\\n\\nD) Correct - API Gateway provides a mock integration feature where request mapping templates can simulate responses.","timestamp":"1734973680.0"},{"comment_id":"1231692","content":"This appear at 17 Jun exam","poster":"tsangckl","timestamp":"1718595420.0","upvote_count":"1"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716312300.0","comment_id":"1215123"},{"content":"D. Use a request mapping template to select the mock integration response.\\n\\nOption D allows you to use a request mapping template in API Gateway to select the mock integration response. This approach allows you to simulate different backend responses without invoking the actual backend service. It provides flexibility and control over the responses without the need for additional AWS resources like Lambda functions or EC2 instances, thus minimizing operational overhead.","upvote_count":"5","timestamp":"1696509720.0","comment_id":"1025654","poster":"Umuntu"},{"timestamp":"1694345280.0","content":"without invoking backend service -> mock","poster":"hsinchang","upvote_count":"2","comment_id":"1003939"},{"timestamp":"1692436320.0","poster":"ninomfr64","content":"Selected Answer: D\\nD as per doc https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-mock-integration.html\\n\\nWording confused me a bit, with mapping template you do not \\"select\\" a response, instead you actually craft it in this case","comment_id":"985079","upvote_count":"1"},{"timestamp":"1683621840.0","upvote_count":"1","comment_id":"892930","content":"Selected Answer: D\\nit\'s D","poster":"KhyatiChhajed"},{"timestamp":"1679623920.0","upvote_count":"4","comment_id":"848861","content":"Selected Answer: D\\nI\'m going with D as well.","poster":"March2023"}],"answer_description":"","extracted_at":"2025-12-24T09:11:22.122Z","extraction_method":"api_direct_v1"},{"question_id":"1ZlrJUCdMBrvC8EMMa4o","question_number":447,"page":90,"question_text":"A company has an Amazon DynamoDB table that contains records of users that have signed up for a trial of the company\u2019s product. The company is using a spreadsheet to track data about the product trial. The company needs to ensure the spreadsheet is automatically updated with the latest information when individual trials begin, are updated, or finish.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Enable a DynamoDB stream for the table. Set the view type to old image. Create an AWS Lambda function that uses the stream data to update the spreadsheet. Subscribe the Lambda function to the stream.","A":"Create a DynamoDB Accelerator (DAX) cluster from the table. Set the view type to old image. Create an AWS Lambda function that uses the cluster data to update the spreadsheet. Subscribe the Lambda function to the cluster.","C":"Enable a DynamoDB stream for the table. Set the view type to new image. Create an AWS Lambda function that uses the stream data to update the spreadsheet. Subscribe the Lambda function to the stream.","B":"Create a DynamoDB Accelerator (DAX) cluster from the table. Set the view type to new image. Create an AWS Lambda function that uses the cluster data to update the spreadsheet. Subscribe the Lambda function to the cluster."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156668-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:18:00","unix_timestamp":1739783880,"discussion_count":1,"discussion":[{"upvote_count":"1","comment_id":"1357704","timestamp":"1739783880.0","content":"Selected Answer: C\\nHabilitar un stream de DynamoDB con el view type configurado en new image permite que la funci\xf3n Lambda reciba la versi\xf3n actualizada del registro y puede actuar sin intervenci\xf3n","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:11:22.122Z","extraction_method":"api_direct_v1"},{"question_id":"Br4JmdWFciS6zNgRfYFJ","question_number":448,"page":90,"question_text":"A developer is launching a global application that delivers content to multiple countries. The developer needs to serve specific content based on the country of each user and each user\u2019s primary language. The developer must ensure that content is served reliably and with low latency.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create an Amazon API Gateway REST API. Connect the REST API to AWS WAF. Use geo match statements and regex match statements to allow or deny requests based on the labels returned from web request evaluations.","A":"Create an Amazon API Gateway REST API. Create an AWS Global Accelerator standard accelerator to resolve requests to the API. Configure endpoint groups on the accelerator. Attach listeners for each country and language.","D":"Configure an Amazon CloudFront distribution that uses the application as an origin. Configure the distribution to forward the Accept-Language header and the CloudFront-Viewer-Country header to the origin.","B":"Store the content in a centralized Amazon S3 bucket. Enable S3 Transfer Acceleration on the bucket. Create an Amazon Route 53 hosted zone that includes the endpoint for the S3 bucket. Create records in Route 53 that use geoproximity and geolocation routing policies."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152773-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:21:00","unix_timestamp":1733800860,"discussion_count":2,"discussion":[{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/adding-cloudfront-headers.html\\n\\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/reduce-latency-for-end-users-with-multi-region-apis-with-cloudfront/","comment_id":"1326164","timestamp":"1734101160.0","poster":"ShakthiGCP","upvote_count":"2"},{"comment_id":"1324354","content":"Selected Answer: D\\ncache based on header/attribute","upvote_count":"4","poster":"Dahlia9524","timestamp":"1733800860.0"}],"answer_description":"","extracted_at":"2025-12-24T09:11:22.122Z","extraction_method":"api_direct_v1"},{"question_id":"BtRMETQCYPu4JgrkNj5z","question_number":449,"page":90,"question_text":"A company generates SSL certificates from a third-party provider. The company imports the certificates into AWS Certificate Manager (ACM) to use with public web applications.\\n\\nA developer must implement a solution to notify the company\u2019s security team 90 days before an imported certificate expires. The company already has configured an Amazon Simple Queue Service (Amazon SQS) queue. The company also has configured an Amazon Simple Notification Service (Amazon SNS) topic that has the security team\u2019s email address as a subscriber.\\n\\nWhich solution will provide the security team with the required notification about certificates?","choices":{"D":"Configure AWS Config with the acm-certificate-expiration-check managed rule to run every 24 hours. Create an Amazon EventBridge rule that includes an event pattern that specifies the Config Rules Compliance Change detail type and the configured rule. Set the SNS topic as the EventBridge rule\u2019s target.","A":"Create an Amazon EventBridge rule that specifies the ACM Certificate Approaching Expiration event type. Set the SNS topic as the EventBridge rule\u2019s target.","B":"Create an AWS Lambda function to search for all certificates that are expiring within 90 days. Program the Lambda function to send each identified certificate\u2019s Amazon Resource Name (ARN) in a message to the SQS queue.","C":"Create an AWS Step Functions workflow that is invoked by each certificate\u2019s expiration notification from AWS CloudTrail. Create an AWS Lambda function to send each certificate\'s Amazon Resource Name (ARN) in a message to the SQS queue."},"correct_answer":"A","answer_ET":"A","answers_community":["A (67%)","D (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152774-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:30:00","unix_timestamp":1733801400,"discussion_count":5,"discussion":[{"comment_id":"1575974","timestamp":"1749465060.0","content":"Selected Answer: D\\nITs D , the certs are imported , not ACM issued : \\n\\nEventBridge rule for ACM Certificate Approaching Expiration:\\n\\nThis event type is only for ACM-issued certificates, not imported ones from third-party providers.","upvote_count":"1","poster":"AlmeroSenior"},{"upvote_count":"2","content":"Selected Answer: A\\nManage certificate expiration events\\n\\nAn Amazon EventBridge event will be published when your certificates near expiration. You can configure the \\"days to expiration\\" value when these events are first published for your certificates. ACM automatically attempts to renew an ACM generated certificate 60 days prior to certificate expiration. Hence, these events only show up for certificates that have not yet been, or could not be, renewed. Events are published for both issued and imported certificates.\\n\\nFor example, when set to 45, the first event will be published when a certificate is 45 days away from its expiration date, followed by one event per day until expiration.","timestamp":"1740991320.0","poster":"0bdf3af","comment_id":"1364335"},{"poster":"e886835","upvote_count":"2","timestamp":"1738827360.0","content":"Selected Answer: A\\nAmazon EventBridge can be used to track specific events, such as the approaching expiration of SSL certificates in AWS Certificate Manager (ACM). AWS publishes events like ACM Certificate Approaching Expiration to EventBridge, which allows you to trigger specific actions when such events occur.","comment_id":"1352239"},{"poster":"Arad","upvote_count":"2","content":"Selected Answer: D\\nD is the correct answer.\\n\\nBoth options A and D are viable solutions for monitoring certificate expirations. Option A leverages ACM\'s built-in event for certificates approaching expiration, while Option D uses AWS Config\'s managed rule acm-certificate-expiration-check to assess certificate compliance and trigger notifications via EventBridge and SNS.\\n\\nBy default, ACM\'s \\"Certificate Approaching Expiration\\" event starts 45 days before expiration. If you require notifications earlier than 45 days, AWS Config\'s managed rule allows you to specify a custom number of days for the check.\\nhttps://docs.aws.amazon.com/acm/latest/APIReference/API_ExpiryEventsConfiguration.html?utm_source=chatgpt.com\\n\\nQuestion is asking for 90 days earlier than expiration, so D is the right answer.","timestamp":"1736959740.0","comment_id":"1341132"},{"comment_id":"1340082","poster":"bp07","content":"Selected Answer: A\\nAmazon EventBridge provides a set of predefined events, and one of these events is related to ACM certificates. Specifically, there is an event type called ACM Certificate Approaching Expiration, which is emitted when an ACM certificate is approaching expiration.","upvote_count":"2","timestamp":"1736809620.0"}],"answer_description":"","extracted_at":"2025-12-24T09:11:22.122Z","extraction_method":"api_direct_v1"},{"question_id":"INK9hGcsUSM1FYbF7ebl","question_number":450,"page":90,"question_text":"A developer has an AWS Lambda function that needs to access an Amazon DynamoDB table named DailyOrders. The Lambda function must be able to perform read operations on the table. The Lambda function must not be able to perform write operations on the table.\\n\\nThe developer needs to create an IAM policy to associate with the Lambda function\'s execution role.\\n\\nWhich IAM policy statement will meet these requirements?","choices":{"A":"","C":"","B":"","D":""},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152775-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:31:00","unix_timestamp":1733801460,"discussion_count":3,"discussion":[{"poster":"PawanShetty","upvote_count":"3","comment_id":"1330012","content":"Selected Answer: D\\nLambda Function must not be able to write","timestamp":"1734785340.0"},{"poster":"jasonkym","upvote_count":"2","comment_id":"1326377","content":"Selected Answer: D\\nThe Lambda function must NOT BE ABLE TO PERFORM WRITE operations on the table. The answer is D.","timestamp":"1734160320.0"},{"comment_id":"1324862","content":"Selected Answer: D\\n\'put\' needs to be denied","timestamp":"1733893380.0","upvote_count":"3","poster":"Wonjin7"}],"answer_description":"","extracted_at":"2025-12-24T09:11:22.122Z","extraction_method":"api_direct_v1"},{"question_id":"JA3FRFgkN87Nl2nSBDt2","question_number":451,"page":91,"question_text":"A developer is working on a new authorization mechanism for an application. The developer must create an Amazon API Gateway API and must test JSON Web Token (JWT) authorization on the API.\\n\\nThe developer must use the built-in authorizer and must avoid managing the code with custom logic. The developer needs to define an API route that is available at /auth to test the authorizer configuration.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create a WebSocket API and the /auth route. Configure and attach the JWT authorizer to the API. Deploy the API.","C":"Create an HTTP API and the /auth route. Create and configure an AWS Lambda authorizer. Attach the Lambda authorizer to the /auth route. Deploy the API.","D":"Create an HTTP API and the /auth route. Configure the JWT authorizer. Attach the JWT authorizer to the /auth route. Deploy the API.","B":"Create a WebSocket API and the /auth route. Create and configure an AWS Lambda authorizer. Attach the Lambda authorizer to the API. Deploy the API."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152776-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:35:00","unix_timestamp":1733801700,"discussion_count":4,"discussion":[{"poster":"e886835","content":"Selected Answer: D\\nTo test JWT authorization using the built-in capabilities of Amazon API Gateway, you should create an HTTP API, configure the JWT authorizer, and attach it to the /auth route.","timestamp":"1738827660.0","upvote_count":"1","comment_id":"1352242"},{"content":"Selected Answer: D\\nWebSocket APIs in API Gateway do not support the built-in JWT authorizer. This option is invalid.\\nLambda authorizers require custom code, which contradicts the requirement to avoid managing custom logic.","upvote_count":"1","timestamp":"1735305600.0","comment_id":"1332417","poster":"xdeveloper"},{"content":"Selected Answer: D\\nIt narrow downs to C and D . But for C , we need to create a Lambda function , whereas for D - JWT authorizer, it uses the token.","poster":"ShakthiGCP","upvote_count":"1","comment_id":"1326172","timestamp":"1734103260.0"},{"upvote_count":"3","content":"Selected Answer: D\\nnot needs interactive chat like communication to verify the token. So no web-socket?","poster":"Dahlia9524","timestamp":"1733801700.0","comment_id":"1324361"}],"answer_description":"","extracted_at":"2025-12-24T09:11:33.240Z","extraction_method":"api_direct_v1"},{"question_id":"2Q0nMiGZfehTQenlmo9M","question_number":452,"page":91,"question_text":"A company is creating a new application that gives users the ability to upload and share short video files. The average size of the video files is 10 MB. After a user uploads a file, a message needs to be placed into an Amazon Simple Queue Service (Amazon SQS) queue so the file can be processed. The files need to be accessible for processing within 5 minutes.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"D":"Write messages that contain the contents of the uploaded files to the SQS queue.","B":"Write the files to Amazon S3 Standard. Add the S3 location of the files to the SQS queue.","C":"Write the files to an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD volume. Add the EBS location of the files to the SQS queue.","A":"Write the files to Amazon S3 Glacier Deep Archive. Add the S3 location of the files to the SQS queue."},"correct_answer":"B","answer_ET":"B","answers_community":["B (89%)","11%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152777-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:36:00","unix_timestamp":1733801760,"discussion_count":5,"discussion":[{"comment_id":"1570869","timestamp":"1747807020.0","poster":"AlmeroSenior","upvote_count":"1","content":"Selected Answer: B\\nSince 10meg is more than SQS can handle ( 256kb ) , you need to send the file location of where actual data is stored on S3 , to the SQS queue ."},{"content":"Selected Answer: B\\nAmazon S3 Standard is the most appropriate storage class for frequently accessed data, such as video files that need to be processed quickly (within 5 minutes).","comment_id":"1352244","poster":"e886835","upvote_count":"2","timestamp":"1738827960.0"},{"upvote_count":"2","poster":"ShakthiGCP","content":"Selected Answer: B\\ns3 is cost effective compared to EBS","timestamp":"1734720540.0","comment_id":"1329612"},{"comment_id":"1326174","timestamp":"1734103620.0","content":"Selected Answer: C\\nAns: C ,. s3 is cost effective compared to EBS","upvote_count":"1","poster":"ShakthiGCP","comments":[{"comment_id":"1329611","poster":"ShakthiGCP","content":"Sorry. Answer is \'B\' .","upvote_count":"1","timestamp":"1734720480.0"}]},{"upvote_count":"3","comment_id":"1324362","poster":"Dahlia9524","content":"Selected Answer: B\\nS3 so it still can be accessed.","timestamp":"1733801760.0"}],"answer_description":"","extracted_at":"2025-12-24T09:11:33.240Z","extraction_method":"api_direct_v1"},{"question_id":"p5wwWPRvSYp6DzupB5WI","question_number":453,"page":91,"question_text":"A developer is updating the code for an AWS Lambda function to add new capabilities. The Lambda function has version aliases for production and development environments that run separate versions of the function. The developer needs to configure a staging environment for the Lambda function to handle invocations to both the development version and the production version.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create a tag for the Lambda function that contains the production version and updated version of the code.","C":"Use AWS CodeDeploy to create a linear traffic shifting deployment","B":"Add a Network Load Balancer. Add the production version of the function and updated version of the function as targets.","A":"Create a weighted alias that references the production version of the function and the updated version of the function."},"correct_answer":"A","answer_ET":"A","answers_community":["A (83%)","C (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152778-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 04:37:00","unix_timestamp":1733801820,"discussion_count":3,"discussion":[{"upvote_count":"1","content":"Selected Answer: C\\nAWS CodeDeploy allows you to set up linear traffic shifting deployments for AWS Lambda. This enables you to safely shift traffic gradually between the production and staging versions of the Lambda function, handling calls to both environments effectively.","timestamp":"1734330360.0","poster":"YUICH","comment_id":"1327186"},{"upvote_count":"2","comment_id":"1326379","timestamp":"1734160620.0","poster":"jasonkym","content":"Selected Answer: A\\n\\"The developer needs to configure a staging environment for the Lambda function to handle invocations to both the development version and the production version.\\" A weighted alias can divert traffic to both version."},{"content":"Selected Answer: A\\nAlias can mix different version","poster":"Dahlia9524","comment_id":"1324363","timestamp":"1733801820.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:11:33.240Z","extraction_method":"api_direct_v1"},{"question_id":"91JqBHfHbNaisnEuGS8q","question_number":454,"page":91,"question_text":"A developer has implemented an AWS Lambda function that inserts new customers into an Amazon RDS database. The function is expected to run hundreds of times each hour. The function and RDS database are in the same VPC. The function is configured to use 512 MB of RAM and is based on the following pseudo code:\\n\\n//IMG//\\n\\n\\nAfter successfully testing the function multiple times, the developer notices that the execution time is longer than expected.\\n\\nWhat should the developer do to improve performance?","choices":{"A":"Increase the reserved concurrency of the Lambda function.","C":"Move the database connection and close statement out of the handler. Place the connection in the global space.","D":"Replace Amazon RDS with Amazon DynamoDB to implement control over the number of writes per second.","B":"Increase the size of the RDS database to facilitate an increased number of database connections each hour."},"correct_answer":"C","answer_ET":"C","answers_community":["C (75%)","A (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156018-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image38.png"],"answer_images":[],"timestamp":"2025-02-06 09:17:00","unix_timestamp":1738829820,"discussion_count":3,"discussion":[{"comment_id":"1364344","upvote_count":"1","poster":"0bdf3af","content":"Selected Answer: C\\nconnection to database as global variable outside the handler","timestamp":"1740993060.0"},{"content":"Selected Answer: C\\nThe best answer is C: Move the database connection and close statement out of the handler. Place the connection in the global space.\\nThis solution would:\\n\\nCreate the connection once when the Lambda container initializes\\nReuse that same connection across multiple invocations\\nSignificantly reduce the overhead of establishing new connections\\nImprove execution time and resource usage\\nFollow AWS best practices for Lambda-RDS connections","poster":"LingZ","upvote_count":"2","timestamp":"1740187560.0","comment_id":"1359969"},{"comment_id":"1352268","upvote_count":"1","content":"Selected Answer: A\\nReserved concurrency defines the maximum number of concurrent executions for a Lambda function. If the function is expected to run hundreds of times each hour, it could be hitting concurrency limits, causing delays due to Lambda being throttled, which would lead to longer execution times.","timestamp":"1738829820.0","poster":"e886835"}],"answer_description":"","extracted_at":"2025-12-24T09:11:33.240Z","extraction_method":"api_direct_v1"},{"question_id":"Dg1wx1o4XOtrZQTc3Dn7","question_number":455,"page":91,"question_text":"A developer is troubleshooting the permissions of an application that needs to make changes to an Amazon RDS database. The developer has access to the IAM role that the application is using.\\n\\nWhich command structure should the developer use to test the role permissions?","choices":{"A":"aws sts assume-role","D":"aws rds add-role-to-db-cluster","C":"aws ssm resume-session","B":"aws iam attach-role-policy"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156019-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 09:20:00","unix_timestamp":1738830000,"discussion_count":1,"discussion":[{"timestamp":"1738830000.0","content":"Selected Answer: A\\nThis command is used to test assuming a role to determine if the IAM role has the appropriate permissions","poster":"e886835","upvote_count":"1","comment_id":"1352271"}],"answer_description":"","extracted_at":"2025-12-24T09:11:33.240Z","extraction_method":"api_direct_v1"},{"question_id":"a2FrOXdrctnpx45bRfM1","question_number":456,"page":92,"question_text":"A gaming company has deployed a web portal on AWS Elastic Beanstalk. The company sometimes needs to deploy new versions three or four times in a day. The company needs to deploy new features for all users as quickly as possible. The solution must minimize performance impact and must maximize availability.\\n\\nWhat solution will meet these requirements?","choices":{"D":"Use a-canary deployment strategy to deploy changes to Amazon EC2 instances.","B":"Use an immutable deployment policy to deploy to Amazon EC2 instances.","C":"Use an all-at-once deployment policy to deploy to Amazon EC2 instances.","A":"Use a rolling deployment policy to deploy to Amazon EC2 instances."},"correct_answer":"B","answer_ET":"B","answers_community":["B (80%)","D (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153213-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-20 00:46:00","unix_timestamp":1734651960,"discussion_count":3,"discussion":[{"upvote_count":"2","content":"Selected Answer: B\\nB is the correct answer.\\nD is wrong because though it\'s useful for testing new features on a limited scale, it does not minimize the overall deployment duration and availability as effectively as immutable deployments.","timestamp":"1736873580.0","poster":"Arad","comment_id":"1340451"},{"content":"Selected Answer: D\\nA canary deployment is a strategy where a new version of an application is deployed to a small subset of instances first. Once it has been validated as stable, it is gradually rolled out to the remaining instances. This approach provides the following benefits:\\n\\nMinimal performance impact: Issues with the new version can be identified early before it affects all users.\\nMaximum availability: Problems can be quickly rolled back, minimizing downtime or service interruptions.\\nFast delivery of features: By deploying incrementally, new features reach all users promptly after initial validation.","timestamp":"1734879300.0","upvote_count":"1","comment_id":"1330423","poster":"YUICH"},{"timestamp":"1734651960.0","content":"Selected Answer: B\\nImmutable deployment creates a new set of instances with the updated version of the application. Once the new instances are verified as healthy, they replace the old instances. This strategy ensures high availability and minimizes the risk of performance impact since the old instances remain untouched until the new instances are validated.","upvote_count":"2","comment_id":"1329200","poster":"lht"}],"answer_description":"","extracted_at":"2025-12-24T09:11:44.156Z","extraction_method":"api_direct_v1"},{"question_id":"jonF7SVAmjkYEnrE32Ni","question_number":457,"page":92,"question_text":"A developer has a legacy application that is hosted on-premises. Other applications hosted on AWS depend on the on-premises application for proper functioning. In case of any application errors, the developer wants to be able to use Amazon CloudWatch to monitor and troubleshoot all applications from one place.\\nHow can the developer accomplish this?","choices":{"D":"Upload log files from the on-premises server to an Amazon EC2 instance and have the instance forward the logs to CloudWatch.","A":"Install an AWS SDK on the on-premises server to automatically send logs to CloudWatch.","B":"Download the CloudWatch agent to the on-premises server. Configure the agent to use IAM user credentials with permissions for CloudWatch.","C":"Upload log files from the on-premises server to Amazon S3 and have CloudWatch read the files."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103772-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-24 12:27:00","unix_timestamp":1679657220,"discussion_count":6,"discussion":[{"poster":"Untamables","upvote_count":"14","timestamp":"1679795820.0","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-premise.html","comment_id":"850623"},{"comment_id":"849253","upvote_count":"6","poster":"Dun6","content":"Selected Answer: B\\nWe need cloudwatchagent","timestamp":"1679657220.0"},{"timestamp":"1735016940.0","content":"Selected Answer: B\\nA) Eliminated - Using the AWS SDK means you must write custom code to capture and send logs to CloudWatch via the PutLogEvents API. This is not automatic as mentioned in option\\n\\nB) CloudWatch agent is specifically designed for collecting logs and metrics from both AWS and on-premises environments.\\n\\nC) Eliminated - unnecessary complexity.\\n\\nD) Eliminated - unnecessarily complex and costly.","comment_id":"1331025","upvote_count":"3","poster":"sumanshu"},{"upvote_count":"2","poster":"Saudis","timestamp":"1728477660.0","comment_id":"1295148","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html"},{"timestamp":"1716313980.0","upvote_count":"1","comment_id":"1215145","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"timestamp":"1686059400.0","comment_id":"916302","poster":"Baba_Eni","upvote_count":"2","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html"}],"answer_description":"","extracted_at":"2025-12-24T09:11:44.156Z","extraction_method":"api_direct_v1"},{"question_id":"DCF6MDYeTqy36wEK9kpi","question_number":458,"page":92,"question_text":"An AWS Lambda function generates a 3 MB JSON file and then uploads it to an Amazon S3 bucket daily. The file contains sensitive information, so the developer must ensure that it is encrypted before uploading to the bucket.\\n\\nWhich of the following modifications should the developer make to ensure that the data is encrypted before uploading it to the bucket?","choices":{"D":"Use an AWS Key Management Service (AWS KMS) customer managed key for Amazon S3 in the Lambda function code.","B":"Use the S3 managed key and call the GenerateDataKey API to encrypt the file.","A":"Use the default AWS Key Management Service (AWS KMS) key for Amazon S3 in the Lambda function code.","C":"Use the GenerateDataKey API, then use that data key to encrypt the file in the Lambda function code."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152782-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 05:52:00","unix_timestamp":1733806320,"discussion_count":2,"discussion":[{"content":"Selected Answer: C\\ngenerating a data key, then enc # Generate a data key\\n response = kms.generate_data_key(KeyId=key_id, KeySpec=\'AES_256\')\\n plaintext_key = response[\'Plaintext\']\\n ciphertext_key = response[\'CiphertextBlob\']rypting and decrypting a small string using that data key","comment_id":"1326197","timestamp":"1734110280.0","upvote_count":"2","poster":"ShakthiGCP"},{"comment_id":"1324385","timestamp":"1733806320.0","upvote_count":"3","content":"Selected Answer: C\\nto make sure encrypt before upload","poster":"Dahlia9524"}],"answer_description":"","extracted_at":"2025-12-24T09:11:44.156Z","extraction_method":"api_direct_v1"},{"question_id":"NF3GxbUCMbqmGIGT1f8T","question_number":459,"page":92,"question_text":"A company is building a social media application. A developer is modifying an AWS Lambda function that updates a database with data that tracks each user\'s online activity. A web application server uses the AWS SDK to invoke the Lambda function.\\n\\nThe developer has tested the new Lambda code and is ready to deploy the code into production. However, the developer wants to allow only a small percentage of the invocations from the AWS SDK to call the new code.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Create a Network Load Balancer. Specify weighted target groups for the original Lambda function and the updated Lambda function.","B":"Create an alias for the Lambda function. Configure a specific weight value for the updated version.","A":"Configure a Lambda version that has a specific weight value for the updated Lambda function.","C":"Create an Application Load Balancer. Specify weighted target groups for the original Lambda function and the updated Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156672-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:33:00","unix_timestamp":1739784780,"discussion_count":1,"discussion":[{"content":"Selected Answer: B\\nLa mejor forma de hacer un despliegue gradual es usar un alias de la funci\xf3n Lambda y configurar un routing configuration que direccione solo un peque\xf1o porcentaje del tr\xe1fico a la nueva versi\xf3n","comment_id":"1357712","upvote_count":"1","timestamp":"1739784780.0","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:11:44.156Z","extraction_method":"api_direct_v1"},{"question_id":"kW8qq5RlKuTEwHn5V5V2","question_number":460,"page":92,"question_text":"An Amazon Data Firehose delivery stream is receiving customer data that contains personally identifiable information. A developer needs to remove pattern-based customer identifiers from the data and store the modified data in an Amazon S3 bucket.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Launch an Amazon EC2 instance. Set the EC2 instance as the destination of the delivery stream. Run an application on the EC2 instance to remove the customer identifiers. Store the transformed data in an Amazon S3 bucket.","D":"Create an AWS Step Functions workflow to remove the customer identifiers. As the last step in the workflow, store the transformed data in an Amazon S3 bucket. Set the workflow as the destination of the delivery stream.","A":"Implement Firehose data transformation as an AWS Lambda function. Configure the function to remove the customer identifiers. Set an Amazon S3 bucket as the destination of the delivery stream.","C":"Create an Amazon OpenSearch Service instance. Set the OpenSearch Service instance as the destination of the delivery stream. Use search and replace to remove the customer identifiers. Export the data to an Amazon S3 bucket."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153149-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-18 04:56:00","unix_timestamp":1734494160,"discussion_count":1,"discussion":[{"timestamp":"1734494160.0","content":"Selected Answer: A\\nData Anonymization:\\n\\nRemove or obfuscate sensitive information for compliance or security reasons.\\nExample: Mask personally identifiable information (PII) like email addresses or phone numbers.","poster":"ShakthiGCP","upvote_count":"2","comment_id":"1328253"}],"answer_description":"","extracted_at":"2025-12-24T09:11:44.156Z","extraction_method":"api_direct_v1"},{"question_id":"YkH4uFpBZLx0lv6VKYQr","question_number":461,"page":93,"question_text":"A developer is building a three-tier web application that should be able to handle a minimum of 5000 requests per minute. Requirements state that the web tier should be completely stateless while the application maintains session state for the users.\\n\\nHow can session data be externalized, keeping latency at the LOWEST possible value?","choices":{"D":"Create an Amazon DynamoDB table, then implement session handling at the application level to leverage the table for session data storage.","C":"Create an Amazon ElastiCache (Memcached) cluster, then implement session handling at the application level to leverage the cluster for session data storage.","B":"Implement a shared file system solution across the underlying Amazon EC2 instances, then implement session handling at the application level to leverage the shared file system for session data storage.","A":"Create an Amazon RDS instance, then implement session handling at the application level to leverage a database inside the RDS database instance for session data storage."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156673-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:34:00","unix_timestamp":1739784840,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","upvote_count":"1","content":"Selected Answer: C\\nAl externalizar la sesi\xf3n en un cl\xfaster de ElastiCache con Memcached, se obtiene un almacenamiento en memoria de baja latencia, ideal para manejar un alto volumen de solicitudes","timestamp":"1739784840.0","comment_id":"1357713"}],"answer_description":"","extracted_at":"2025-12-24T09:11:55.129Z","extraction_method":"api_direct_v1"},{"question_id":"bsjsMRtgc30nyDGj12KQ","question_number":462,"page":93,"question_text":"A developer has deployed an AWS Lambda function that is subscribed to an Amazon Simple Notification Service (Amazon SNS) topic. The developer must implement a solution to add a record of each Lambda function invocation to an Amazon Simple Queue Service (Amazon SQS) queue.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Add two asynchronous invocation destinations to the Lambda function: one destination for successful invocations and one destination for failed invocations. Configure the SQS queue as the destination for each type. Create an Amazon CloudWatch alarm based on the DestinationDeliveryFailures metric to catch any message that cannot be delivered.","A":"Configure the SQS queue as a dead-letter queue for the Lambda function.","B":"Create code that uses the AWS SDK to call the SQS SendMessage operation to add the invocation details to the SQS queue. Add the code to the end of the Lambda function.","D":"Add a single asynchronous invocation destination to the Lambda function to capture successful invocations. Configure the SQS queue as the destination. Create an Amazon CloudWatch alarm based on the DestinationDeliveryFailures metric to catch any message that cannot be delivered."},"correct_answer":"C","answer_ET":"C","answers_community":["C (42%)","B (33%)","D (25%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152781-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 05:46:00","unix_timestamp":1733805960,"discussion_count":8,"discussion":[{"comment_id":"1570539","timestamp":"1747733880.0","content":"Selected Answer: C\\nCapturing both successful and failed invocations ensures complete tracking of the Lambda function\'s activity. No manual code changes are required in the Lambda function, reducing development effort.Amazon CloudWatch alarms can monitor DestinationDeliveryFailures, ensuring visibility into messages that fail to reach SQS.","upvote_count":"2","poster":"thalasi"},{"upvote_count":"1","content":"Selected Answer: B\\nCreate code that uses the AWS SDK to call the SQS SendMessage operation.","comment_id":"1359972","poster":"LingZ","timestamp":"1740188580.0"},{"timestamp":"1739785140.0","content":"Selected Answer: C\\nDudo entre la B y la C porque aunque la B no registra todo, los fallos reintentables no son estados definitivos, hay reintento y la C es un poco demasiado esfuerzo, no es eficiente operacionalmente, aunque tampoco se pide eso","comment_id":"1357716","poster":"italiancloud2025","upvote_count":"1"},{"comment_id":"1352276","content":"Selected Answer: B\\nusing the AWS SDK within the Lambda function code to call SendMessage to SQS, the developer can ensure that the invocation details are logged in the queue.","poster":"e886835","upvote_count":"1","timestamp":"1738830960.0"},{"poster":"Arad","content":"Selected Answer: B\\nB is the correct answer.\\nWhen using asynchronous invocations, there are three types of potential states: success, failure and retryable failure. this option only logs first 2, not all.\\nA is wrong because it only logs the failure invocations, not all.\\nC is wrong because it only logs success and failure invocations, not all.\\nD is wrong because it logs only successful invocations, not all.","upvote_count":"2","comment_id":"1339938","timestamp":"1736780640.0"},{"content":"Selected Answer: D\\nRequirements:\\nLambda function is invoked via Amazon SNS.\\nYou need to log each invocation (successful or failed) to an Amazon SQS queue.","poster":"YUICH","upvote_count":"2","comments":[{"poster":"GGGApigateway","comment_id":"1349935","upvote_count":"2","content":"I see that option D only captures successful invocations, but the question asks for all invocations (both successful and failed). How does D ensure that all invocations are recorded in the SQS queue?","timestamp":"1738421100.0"}],"timestamp":"1734327060.0","comment_id":"1327166"},{"upvote_count":"1","comment_id":"1326204","poster":"ShakthiGCP","timestamp":"1734111840.0","content":"Selected Answer: D\\nOne SQS for success is sufficient and when the undelivered message will be monitored via cloudwatch."},{"timestamp":"1733805960.0","poster":"Dahlia9524","comment_id":"1324384","upvote_count":"2","content":"Selected Answer: C\\nLambda Destination supported for both success and failure"}],"answer_description":"","extracted_at":"2025-12-24T09:11:55.129Z","extraction_method":"api_direct_v1"},{"question_id":"EpQ8TPGVGimPZxi4gSvA","question_number":463,"page":93,"question_text":"An AWS Lambda function that handles application requests uses the default Lambda logging mechanism to log the timestamp, processing time, and status of requests.\\n\\nA developer needs to create Amazon CloudWatch metrics based on the logs. The developer needs to write the metrics to a custom CloudWatch metrics namespace.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Use the CloudWatch embedded metric format (EMF) for the structure of the log statements to generate custom CloudWatch metrics.","B":"Use Amazon CloudWatch RUM to generate custom metrics from the logs by using CloudWatch embedded metric format (EMF).","A":"Use Amazon CloudWatch Logs Insights to generate custom metrics from the logs by using CloudWatch embedded metric format (EMF).","C":"Use Amazon CloudWatch Logs Insights to generate custom metrics from the logs by using JSON format."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156674-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:40:00","unix_timestamp":1739785200,"discussion_count":1,"discussion":[{"content":"Selected Answer: D\\nAl formatear las declaraciones de log con el CloudWatch Embedded Metric Format (EMF), CloudWatch extraer\xe1 autom\xe1ticamente los valores y crear\xe1 m\xe9tricas personalizadas en el namespace que especifiques, sin necesidad de procesamiento adicional","poster":"italiancloud2025","timestamp":"1739785200.0","upvote_count":"2","comment_id":"1357717"}],"answer_description":"","extracted_at":"2025-12-24T09:11:55.129Z","extraction_method":"api_direct_v1"},{"question_id":"Jouc0fM4yV5j7GF6vQ8f","question_number":464,"page":93,"question_text":"A developer needs to configure an AWS Lambda function to make HTTP POST requests to an internal application. The application is in the same AWS account that hosts the function. The internal application runs on Amazon EC2 instances in a private subnet within a VPC.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Attach the Lambda function to the VPC and to the private subnet.","D":"Configure the VPC route table to include the Lambda function\u2019s IP address.","C":"Configure a VPN connection between the Lambda function and the private subnet. Attach the VPN to the Lambda function.","A":"Configure a VPC endpoint to connect to the private subnet. Attach the endpoint to the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","D (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153024-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-16 06:33:00","unix_timestamp":1734327180,"discussion_count":3,"discussion":[{"poster":"thalasi","upvote_count":"1","comment_id":"1570524","content":"Selected Answer: B\\nLambda functions do not have fixed IP addresses, making it impractical to add them to a route table","timestamp":"1747728300.0"},{"poster":"xdeveloper","content":"Selected Answer: B\\nWhen your Lambda function needs to access resources within a VPC, such as Amazon EC2 instances in a private subnet, you need to configure the Lambda function to run within that VPC. This is done by specifying the VPC, subnet(s), and security group(s) in the Lambda configuration. Once attached to the VPC and subnet, the Lambda function can make HTTP requests to the internal application running on the EC2 instances in the private subnet.","comment_id":"1332446","upvote_count":"4","timestamp":"1735311060.0"},{"content":"Selected Answer: D\\nLambda Function logs request information (e.g., timestamp, processing time, status) using the default logging mechanism.\\nCreate custom CloudWatch metrics in a specific namespace based on these logs.","poster":"YUICH","timestamp":"1734327180.0","comment_id":"1327167","upvote_count":"1","comments":[{"timestamp":"1735199340.0","content":"Sorry I changed my opinion. The answer is B. Lambda functions do not have fixed IP addresses, making it impractical to add them to a route table. Instead, attaching the Lambda function to the VPC and configuring security groups appropriately is the recommended approach.","comment_id":"1331830","poster":"YUICH","upvote_count":"3"}]}],"answer_description":"","extracted_at":"2025-12-24T09:11:55.129Z","extraction_method":"api_direct_v1"},{"question_id":"ElQIJ0RbejsDb4LLZ7fQ","question_number":465,"page":93,"question_text":"A company has an application that processes audio files for different departments. When audio files are saved to an Amazon S3 bucket, an AWS Lambda function receives an event notification and processes the audio input.\\n\\nA developer needs to update the solution so that the application can process the audio files for each department independently. The application must publish the audio file location for each department to each department\'s existing Amazon Simple Queue Service (Amazon SQS) queue.\\n\\nWhich solution will meet these requirements with no changes to the Lambda function code?","choices":{"B":"Update the Lambda function to write the file location to a single shared SQS queue. Configure the shared SQS queue to send the file reference to each department\u2019s SQS queue.","C":"Update the Lambda function to send the file location to each department\u2019s SQS queue.","D":"Configure the S3 bucket to send the event notifications to each department\u2019s SQS queue.","A":"Configure the S3 bucket to send the event notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe each department\u2019s SQS queue to the SNS topic. Configure subscription filter policies."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157450-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-03 10:50:00","unix_timestamp":1740995400,"discussion_count":1,"discussion":[{"content":"Selected Answer: A\\nThe correct answer is:\\n\\nA. Configure the S3 bucket to send the event notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe each department\u2019s SQS queue to the SNS topic. Configure subscription filter policies.\\nExplanation:\\n\\n The goal is to route events from S3 to multiple SQS queues (one per department) without changing the existing Lambda function code.\\n\\n SNS supports fan-out messaging, meaning one message can be sent to multiple subscribers (SQS queues in this case).\\n\\n Subscription filter policies allow messages to be selectively routed to specific queues based on attributes (like department).","upvote_count":"1","timestamp":"1746019800.0","comment_id":"1565109","poster":"vbloise"}],"answer_description":"","extracted_at":"2025-12-24T09:11:55.129Z","extraction_method":"api_direct_v1"},{"question_id":"P35ADuDEvzA4c9E6lk94","question_number":466,"page":94,"question_text":"Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table.\\n\\nHow can each microservice be granted the minimum privileges?","choices":{"C":"Set ECS_ENABLE_TASK_IAM ROLE to true on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.","D":"Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.","B":"Set ECS_ENABLE_TASK_IAM ROLE to false on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.","A":"Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156675-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:42:00","unix_timestamp":1739785320,"discussion_count":2,"discussion":[{"content":"Selected Answer: C\\nECS_ENABLE_TASK_IAM - This role allows your application code (on the container) to use other AWS services. The task role is required when your application accesses other AWS services, such as Amazon S3.","comment_id":"1364352","timestamp":"1740995760.0","upvote_count":"1","poster":"0bdf3af"},{"timestamp":"1739785320.0","upvote_count":"1","poster":"italiancloud2025","content":"Selected Answer: C\\nAl establecer ECS_ENABLE_TASK_IAM_ROLE en true, cada tarea (microservicio) puede asumir un rol IAM distinto","comment_id":"1357718"}],"answer_description":"","extracted_at":"2025-12-24T09:12:06.196Z","extraction_method":"api_direct_v1"},{"question_id":"u9ueCi50P1JqkMi7E6br","question_number":467,"page":94,"question_text":"A developer is writing a mobile application that allows users to view images from an S3 bucket. The users must be able to log in with their Amazon login, as well as supported social media accounts.\\n\\nHow can the developer provide this authentication functionality?","choices":{"B":"Use Amazon Cognito with SAML-based identity federation.","D":"Use AWS STS AssumeRole in the application code and assume a role with Get* permissions on the S3 bucket.","C":"Use IAM access keys and secret keys in the application code to allow Get* on the S3 bucket.","A":"Use Amazon Cognito with web identity federation."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152780-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 05:11:00","unix_timestamp":1733803860,"discussion_count":2,"discussion":[{"comment_id":"1364354","poster":"0bdf3af","content":"Selected Answer: A\\nCognito User Pool\\n\u2022 Create a serverless database of user for your web & mobile apps\\n\u2022 Simple login: Username (or email) / password combination\\n\u2022 Password reset\\n\u2022 Email & Phone Number Verification\\n\u2022 Multi-factor authentication (MFA)\\n\u2022 Federated Identities: users from Facebook, Google, SAML\u2026\\n\u2022 Feature: block users if their credentials are compromised elsewhere\\n\u2022 Login sends back a JSON Web Token (JWT)\\n\xa9 Stephane Maarek","timestamp":"1740996060.0","upvote_count":"1"},{"content":"Selected Answer: A\\nCognito user pool","poster":"Dahlia9524","comment_id":"1324371","upvote_count":"3","timestamp":"1733803860.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:06.196Z","extraction_method":"api_direct_v1"},{"question_id":"inz4iCiwCH5TWrOoB9Rx","question_number":468,"page":94,"question_text":"An Amazon Kinesis Data Firehose delivery stream is receiving customer data that contains personally identifiable information. A developer needs to remove pattern-based customer identifiers from the data and store the modified data in an Amazon S3 bucket.\\nWhat should the developer do to meet these requirements?","choices":{"B":"Launch an Amazon EC2 instance. Set the EC2 instance as the destination of the delivery stream. Run an application on the EC2 instance to remove the customer identifiers. Store the transformed data in an Amazon S3 bucket.","A":"Implement Kinesis Data Firehose data transformation as an AWS Lambda function. Configure the function to remove the customer identifiers. Set an Amazon S3 bucket as the destination of the delivery stream.","D":"Create an AWS Step Functions workflow to remove the customer identifiers. As the last step in the workflow, store the transformed data in an Amazon S3 bucket. Set the workflow as the destination of the delivery stream.","C":"Create an Amazon OpenSearch Service instance. Set the OpenSearch Service instance as the destination of the delivery stream. Use search and replace to remove the customer identifiers. Export the data to an Amazon S3 bucket."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103922-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 03:31:00","unix_timestamp":1679794260,"discussion_count":5,"discussion":[{"poster":"Untamables","timestamp":"1695691860.0","comment_id":"850642","upvote_count":"15","content":"Selected Answer: A\\nA\\nhttps://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html"},{"poster":"lucasbbs","upvote_count":"1","comment_id":"1580628","timestamp":"1750871820.0","content":"Selected Answer: A\\nA) Correct - AWS Firehose supports Lambda transforms natively. This is scalable, cost-effective, and integrates seamlessly to remove PII before storing in S3.\\n\\nB) Incorrect - EC2 adds cost, maintenance, and complexity. Not suitable for a real-time, serverless transformation workflow.\\n\\nC) Incorrect - OpenSearch is not designed for stream processing or PII removal. It\u2019s primarily for search and analytics, not transformation.\\n\\nD) Incorrect - Step Functions are not supported as a Firehose destination, and this adds unnecessary orchestration overhead."},{"poster":"sumanshu","comment_id":"1331026","content":"Selected Answer: A\\nKinesis Data Firehose supports the use of an AWS Lambda function for data transformation before delivering the data to a destination","upvote_count":"3","timestamp":"1735017360.0"},{"upvote_count":"1","poster":"65703c1","timestamp":"1732219320.0","comment_id":"1215149","content":"Selected Answer: A\\nA is the correct answer."},{"poster":"tttamtttam","content":"Selected Answer: A\\nIt supports custom data transformation using AWS Lambda","comment_id":"952219","upvote_count":"3","timestamp":"1705317840.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:06.196Z","extraction_method":"api_direct_v1"},{"question_id":"46T37KFE1NYeNq9u1ttH","question_number":469,"page":94,"question_text":"An application that is running on Amazon EC2 instances stores data in an Amazon S3 bucket. All the data must be encrypted in transit.\\n\\nHow can a developer ensure that all traffic to the S3 bucket is encrypted?","choices":{"D":"Create an S3 bucket policy that denies traffic when the value for the aws:SecureTransport condition key is false.","C":"Configure the S3 bucket with server-side encryption with AWS KMS managed encryption keys (SSE-KMS).","B":"Create a private VPC endpoint.","A":"Install certificates on the EC2 instances."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156676-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:43:00","unix_timestamp":1739785380,"discussion_count":1,"discussion":[{"upvote_count":"1","content":"Selected Answer: D\\nConfigurar una pol\xedtica de bucket que deniegue el tr\xe1fico cuando aws:SecureTransport sea falso asegura que solo se permitan conexiones seguras (HTTPS) al bucket","timestamp":"1739785380.0","poster":"italiancloud2025","comment_id":"1357719"}],"answer_description":"","extracted_at":"2025-12-24T09:12:06.196Z","extraction_method":"api_direct_v1"},{"question_id":"rcirzrvfRC2pYoNoBlVs","question_number":470,"page":94,"question_text":"A company is hosting an Amazon AP! Gateway REST API that calls a single AWS Lambda function. The function is infrequently invoked by multiple clients at the same time.\\n\\nThe code performance is optimal, but the company wants to optimize the startup time of the function\\n\\nWhat can a developer do to optimize the initialization of the function?","choices":{"D":"Configure AWS Global Accelerator for the Lambda function.","C":"Use Lambda proxy integration for the REST API.","A":"Enable API Gateway caching for the REST API.","B":"Configure provisioned concurrency for the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153503-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-27 16:16:00","unix_timestamp":1735312560,"discussion_count":2,"discussion":[{"comment_id":"1352349","content":"Selected Answer: B\\nProvisioned concurrency addresses this by pre-warming a specified number of function instances, ensuring that these instances are always ready to handle invocations. This reduces the initialization time (cold start) for the Lambda function.","upvote_count":"2","timestamp":"1738843080.0","poster":"e886835"},{"poster":"xdeveloper","timestamp":"1735312560.0","content":"Selected Answer: B\\nProvisioned concurrency \u2013 This is the number of pre-initialized execution environments allocated to your function. These execution environments are ready to respond immediately to incoming function requests. Provisioned concurrency is useful for reducing cold start latencies for functions. Configuring provisioned concurrency incurs additional charges to your AWS account.","upvote_count":"2","comment_id":"1332459"}],"answer_description":"","extracted_at":"2025-12-24T09:12:06.196Z","extraction_method":"api_direct_v1"},{"question_id":"tarJ0VNPo6Z6ch69V1qn","question_number":471,"page":95,"question_text":"A developer is building a three-tier application with an Application Load Balancer (ALB), Amazon EC2 instances, and Amazon RDS. There is an alias record in Amazon Route 53 that points to the ALB. When the developer tries to access the ALB from a laptop, the request times out.\\n\\nWhich logs should the developer investigate to verify that the request is reaching the AWS network?","choices":{"A":"VPC Flow Logs","B":"Amazon Route 53 logs","D":"Amazon CloudWatch agent logs","C":"AWS Systems Manager Agent logs"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156020-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 09:38:00","unix_timestamp":1738831080,"discussion_count":1,"discussion":[{"comment_id":"1352277","poster":"e886835","content":"Selected Answer: A\\nIt will provide information about the IP traffic going to and from network interfaces in your VPC.","timestamp":"1738831080.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:12:17.128Z","extraction_method":"api_direct_v1"},{"question_id":"wwqwGc3pspWi3ohBdJZz","question_number":472,"page":95,"question_text":"A developer has an application that uses AWS Security Token Service (AWS STS). The application calls the STS AssumeRole API operation to provide trusted users with temporary security credentials. The application calls AWS STS at the service\'s default endpoint: https://sts.amazonaws.com.\\n\\nThe application is deployed in an Asia Pacific AWS Region. The application is experiencing errors that are related to intermittent latency when the application calls AWS STS.\\n\\nWhat should the developer do to resolve this issue?","choices":{"A":"Update the application to use the GetSessionToken API operation.","B":"Update the application to use the AssumeRoleWithSAML API operation.","D":"Update the application to use the AssumeRoleWithWebldentity API operation. Move the STS endpoint to a global endpoint.","C":"Update the application to use a Regional STS endpoint that is closer to the application deployment."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156021-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 09:41:00","unix_timestamp":1738831260,"discussion_count":1,"discussion":[{"content":"Selected Answer: C\\nTo resolve the intermittent latency issues, the developer should modify the application to call the appropriate Regional STS endpoint that is closer to the application\'s deployment region, rather than relying on the global endpoint.","comment_id":"1352280","poster":"e886835","timestamp":"1738831260.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:12:17.128Z","extraction_method":"api_direct_v1"},{"question_id":"fzHLic6II5DMUgtk60eL","question_number":473,"page":95,"question_text":"A company is launching a photo sharing application on AWS. Users use the application to upload images to an Amazon S3 bucket. When users upload images, an AWS Lambda function creates thumbnail versions of the images and stores the thumbnail versions in another S3 bucket.\\n\\nDuring development, a developer notices that the Lambda function takes more than 2 minutes to complete the thumbnail process. The company needs alll images to be processed in less than 30 seconds.\\n\\nWhat should the developer do to meet these requirements?","choices":{"B":"Change Lambda function instance type to use m6a.4xlarge.","A":"Increase the virtual CPUs (vCPUs) for the Lambda function to use 10 vCPUs.","D":"Configure burstable performance for the Lambda function.","C":"Configure the Lambda function to increase the amount of memory."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156677-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:44:00","unix_timestamp":1739785440,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","timestamp":"1739785440.0","content":"Selected Answer: C\\naumentar la memoria asignada a la funci\xf3ntambi\xe9n asigna m\xe1s potencia de CPU proporcionalmente","comment_id":"1357720","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:12:17.128Z","extraction_method":"api_direct_v1"},{"question_id":"V0xAprsZRyulu4J156Sf","question_number":474,"page":95,"question_text":"A development team is designing a mobile app that requires multi-factor authentication.\\n\\nWhich steps should be taken to achieve this? (Choose two.)","choices":{"C":"Enable multi-factor authentication for the Amazon Cognito user pool.","E":"Enable multifactor authentication for the users created in AWS IAM.","D":"Use AWS IAM to create IAM users.","A":"Use Amazon Cognito to create a user pool and create users in the user pool.","B":"Send multi-factor authentication text codes to users with the Amazon SNS Publish API call in the app code."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157451-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-03 11:25:00","unix_timestamp":1740997500,"discussion_count":1,"discussion":[{"timestamp":"1740997500.0","poster":"0bdf3af","comment_id":"1364357","content":"Selected Answer: AC\\nCognito User Pool for users and for MFA","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:12:17.128Z","extraction_method":"api_direct_v1"},{"question_id":"4u48mw8QDSNrYadjBl0F","question_number":475,"page":95,"question_text":"A developer is building an application that will process messages from an Amazon Simple Queue Service (Amazon SQS) standard queue. The application needs to process the messages in an Amazon Elastic Container Service (Amazon ECS) task.\\n\\nWhich actions will result in the MOST cost-effective processing of the messages? (Choose two.)","choices":{"B":"Use short polling to query the queue for new messages.","A":"Use long polling to query the queue for new messages.","C":"Use message batching to retrieve messages from the queue.","D":"Use Amazon ElastiCache to cache messages in the queue.","E":"Use an SQS FIFO queue to manage the messages."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153619-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-29 18:30:00","unix_timestamp":1735493400,"discussion_count":1,"discussion":[{"upvote_count":"2","comment_id":"1333642","timestamp":"1735493400.0","poster":"jheimar","content":"Selected Answer: AC\\nA. Long polling (reduces unnecessary requests).\\nC. Message batching (reduces the number of requests by processing multiple messages"}],"answer_description":"","extracted_at":"2025-12-24T09:12:17.128Z","extraction_method":"api_direct_v1"},{"question_id":"xOlsW0BHGz49cJQxa1E8","question_number":476,"page":96,"question_text":"A developer is writing an application in AWS Lambda. To simplify testing and deployments, the developer needs the database connection string to be easily changed without modifying the Lambda code.\\n\\nHow can this requirement be met?","choices":{"B":"Store the connection string in an IAM user account.","A":"Store the connection string as a secret in AWS Secrets Manager.","D":"Store the connection string as a Lambda layer.","C":"Store the connection string in AWS KMS."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156678-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:46:00","unix_timestamp":1739785560,"discussion_count":1,"discussion":[{"timestamp":"1739785560.0","upvote_count":"1","content":"Selected Answer: A\\nen AWS Secrets Manager, el desarrollador puede cambiar la configuraci\xf3n sin modificar el c\xf3digo Lambda","poster":"italiancloud2025","comment_id":"1357721"}],"answer_description":"","extracted_at":"2025-12-24T09:12:28.220Z","extraction_method":"api_direct_v1"},{"question_id":"UBI8VEzssp1bL0lDDWaZ","question_number":477,"page":96,"question_text":"A developer is building an ecommerce application that uses multiple AWS Lambda functions. Each function performs a specific step in a customer order workflow, such as order processing and inventory management.\\n\\nThe developer must ensure that the Lambda functions run in a specific order.\\n\\nWhich solution will meet this requirement with the LEAST operational overhead?","choices":{"B":"Configure an Amazon Simple Notification Service (Amazon SNS) topic to contain notifications about each step a function must perform. Subscribe the Lambda functions to the SNS topic. Use subscription filters based on the step each function must perform.","A":"Configure an Amazon Simple Queue Service (Amazon SQS) queue to contain messages about each step a function must perform. Configure the Lambda functions to run sequentially based on the order of messages in the SQS queue.","D":"Configure Amazon EventBridge Scheduler schedules to invoke the Lambda functions in a specific order.","C":"Configure an AWS Step Functions state machine to invoke the Lambda functions in a specific order."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/152779-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-12-10 05:02:00","unix_timestamp":1733803320,"discussion_count":3,"discussion":[{"timestamp":"1735313580.0","poster":"xdeveloper","upvote_count":"1","comment_id":"1332476","content":"Selected Answer: C\\nLEAST operational overhead , its Step Functions."},{"comment_id":"1326215","timestamp":"1734114360.0","upvote_count":"3","content":"Selected Answer: C\\nOrchestration is done by Step functions","poster":"ShakthiGCP"},{"comment_id":"1324963","poster":"YUICH","upvote_count":"1","content":"Selected Answer: C\\nC. AWS Step Functions\\nAWS Step Functions is designed to orchestrate workflows, making it ideal for ensuring Lambda functions execute in a specific order. It allows you to define a state machine that explicitly specifies the sequence of execution, handles errors, and minimizes operational overhead. This makes it the most suitable choice.","timestamp":"1733912160.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:28.220Z","extraction_method":"api_direct_v1"},{"question_id":"BsNTFJul4mhbH0X5yA5L","question_number":478,"page":96,"question_text":"A developer is building an image-processing application that includes an AWS Lambda function. The Lambda function moves images from one AWS service to another AWS service for image processing. For images that are larger than 2 MB, the Lambda function returns the following error: \u201cTask timed out after 3.01 seconds.\u201d\\n\\nThe developer needs to resolve the error without modifying the Lambda function code.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Configure provisioned concurrency for the Lambda function.","C":"Request a concurrency quota increase for the Lambda function.","A":"Increase the Lambda function\u2019s timeout value.","B":"Configure the Lambda function to not move images that are larger than 2 MB."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156680-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:47:00","unix_timestamp":1739785620,"discussion_count":1,"discussion":[{"upvote_count":"1","comment_id":"1565117","poster":"vbloise","content":"Selected Answer: A\\nThe correct answer is:\\n\\nA. Increase the Lambda function\u2019s timeout value.\\nExplanation:\\n\\nThe error message \\"Task timed out after 3.01 seconds\\" clearly indicates that the Lambda function is not being given enough time to complete its task \u2014 specifically, moving images larger than 2 MB. This is a timeout configuration issue, not a concurrency issue or a problem with the code logic.\\n\\n A is correct because increasing the timeout allows the function more time to complete processing.\\n\\n B avoids the problem rather than solving it.\\n\\n C (concurrency quota increase) deals with how many instances can run simultaneously, not execution time.\\n\\n D (provisioned concurrency) ensures a function is pre-initialized but doesn\'t fix timeout errors.","timestamp":"1746021900.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:28.220Z","extraction_method":"api_direct_v1"},{"question_id":"0xgqcbFDc68B93Qnomnw","question_number":479,"page":96,"question_text":"A developer is using an AWS Lambda function to generate avatars for profile pictures that are uploaded to an Amazon S3 bucket. The Lambda function is automatically invoked for profile pictures that are saved under the /original/ S3 prefix. The developer notices that some pictures cause the Lambda function to time out. The developer wants to implement a fallback mechanism by using another Lambda function that resizes the profile picture.\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"C":"Create an AWS Step Functions state machine that invokes the avatar generator Lambda function and uses the image resize Lambda function as a fallback. Create an Amazon EventBridge rule that matches events from the S3 bucket to invoke the state machine.","D":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Set the SNS topic as a destination with an on failure condition for the avatar generator Lambda function. Subscribe the image resize Lambda function to the SNS topic.","B":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Set the SQS queue as a destination with an on failure condition for the avatar generator Lambda function. Configure the image resize Lambda function to poll from the SQS queue.","A":"Set the image resize Lambda function as a destination of the avatar generator Lambda function for the events that fail processing."},"correct_answer":"A","answer_ET":"A","answers_community":["A (65%)","C (18%)","B (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103723-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-24 03:27:00","unix_timestamp":1679624820,"discussion_count":27,"discussion":[{"upvote_count":"14","comment_id":"848870","timestamp":"1679624820.0","poster":"March2023","content":"Selected Answer: A\\nWouldn\'t A be the Least Effort"},{"poster":"jingle4944","upvote_count":"10","timestamp":"1695802020.0","comment_id":"1018592","content":"Selected Answer: A\\nPreviously, you needed to write the SQS/SNS/EventBridge handling code within your Lambda function and manage retries and failures yourself.\\n\\nWith Destinations, you can route asynchronous function results as an execution record to a destination resource without writing additional code.\\n\\nhttps://aws.amazon.com/ru/blogs/compute/introducing-aws-lambda-destinations/"},{"comment_id":"1331028","timestamp":"1735018500.0","upvote_count":"2","content":"Selected Answer: A\\nAWS Lambda supports Destinations for asynchronous invocations. You can configure a failure destination that triggers a fallback mechanism, such as invoking another Lambda function. This removes the need for additional services like SQS, SNS, or Step Functions, simplifying the architecture.","poster":"sumanshu"},{"comment_id":"1322623","timestamp":"1733465880.0","content":"Selected Answer: B\\nLeast development effort does not mean incomplete solution. what happens when the number of such issues are high and request needs to be queued. does not sound convincing","upvote_count":"1","poster":"f271c23"},{"poster":"lambdaFun","timestamp":"1728698940.0","upvote_count":"2","comment_id":"1296299","content":"A is the correct Answer if we read the question in the last part \\"The developer wants to implement a fallback mechanism by using another Lambda function\\""},{"upvote_count":"1","comment_id":"1236168","poster":"PrinceMughal","timestamp":"1719212580.0","content":"Selected Answer: A\\nI will go with A as it is the simplest solution among other three option"},{"timestamp":"1718439180.0","comment_id":"1230826","poster":"fabiomonta18","upvote_count":"1","content":"Selected Answer: B\\nThis seems to be a tricky one. It\'s true that you can set Lambda destination, but you better set SQS as destination, exactly what the article suggests, go check it. The correct one is B.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations"},{"comment_id":"1215152","timestamp":"1716314760.0","upvote_count":"1","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer."},{"comments":[{"upvote_count":"2","content":"With AWS Lambda destinations you don\'t need to interact with code to change this","comment_id":"1249485","poster":"Tluszczyk","timestamp":"1721207640.0"}],"upvote_count":"2","content":"B is right.\\n A.wrong because \\nLambda Function Chaining: While Lambda function chaining is possible, it would require modifying the avatar generation Lambda function to include the resize function as a destination for failed events. This might involve additional coding and potentially more complex error handling within the Lambda function.","poster":"vipyodha","comment_id":"1183229","timestamp":"1711450020.0"},{"comments":[{"comment_id":"1157849","upvote_count":"2","timestamp":"1708775400.0","comments":[{"content":"The article says \\"For each execution status such as Success or Failure you can choose one of four destinations: another Lambda function, SNS, SQS, or EventBridge.\\" It hink for this reason the correct one is B.","comments":[{"upvote_count":"1","timestamp":"1718439660.0","content":"I mean, which destination other then SQS can you set in this case?","comment_id":"1230833","poster":"fabiomonta18"}],"comment_id":"1230831","upvote_count":"2","timestamp":"1718439540.0","poster":"fabiomonta18"}],"content":"https://aws.amazon.com/ru/blogs/compute/introducing-aws-lambda-destinations/ this link justifies the answer","poster":"KarBiswa"}],"poster":"KarBiswa","comment_id":"1098700","timestamp":"1702794840.0","content":"Selected Answer: A\\nLeast development effort no emphasis on orchestration","upvote_count":"3"},{"content":"Selected Answer: A\\nA. Defina a fun\xe7\xe3o Lambda de redimensionamento de imagem como um destino da fun\xe7\xe3o Lambda do gerador de avatar para os eventos que falham no processamento","upvote_count":"1","timestamp":"1698364440.0","poster":"Jonalb","comment_id":"1054983"},{"poster":"appuNBablu","content":"A, because we can map another Lambda function as destination alongside (SQS, SNS, Event Bridge)","timestamp":"1695496440.0","upvote_count":"1","comment_id":"1015260"},{"poster":"ninomfr64","content":"Selected Answer: A\\nA is the easiest option \\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations","comment_id":"985116","upvote_count":"1","timestamp":"1692441540.0"},{"comment_id":"978125","content":"Option B is the right answer. Can someone say why B cannot be the right answer for this question?\\n\\nOption A fails when there are huge amounts of requests coming to the lambda functions. There is every chance for lambda to throw ProvisionedThrougputExceeded Exception because of the throttling issues. Which is almost the similar reason why Option C will also fail at some point.\\n\\nHowever, you could use SNS but it is not the best solution. \\n\\nDefinitely Option B.","timestamp":"1691707920.0","poster":"jayvarma","upvote_count":"8"},{"timestamp":"1690420620.0","poster":"backfringe","comment_id":"964266","content":"Selected Answer: A\\nleast amount of effort to set up destination on failure events to REsize Lambda","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\\nI agree with the explanation for option B. Scalability is the key","timestamp":"1689936540.0","comment_id":"958348","poster":"AWSdeveloper08"},{"poster":"[Removed]","timestamp":"1689706680.0","comments":[{"poster":"jipark","content":"your explanation looks correct.\\nLambda \\"Denstination\\" seems exact solution for this.\\nit explains how to handle success, failed case.","comment_id":"966994","upvote_count":"1","timestamp":"1690709100.0"}],"content":"Selected Answer: A\\nA is a simplest solution\\nhttps://aws.amazon.com/ru/blogs/compute/introducing-aws-lambda-destinations/\\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations","upvote_count":"3","comment_id":"955798"},{"upvote_count":"3","poster":"umer1998","comment_id":"933754","timestamp":"1687710420.0","content":"I agree with B because I am considering scalability in my mind if we have thousands/millions of requests at the same time. because of the quota limit, the lambda can fail if we continuously call two functions (step function) together, which may result in another function doing a throttling issue.\\nIf we pass the message to the SQS, our function will never face this issue with throttling.\\nand since the question asks us to do the least development efforts.\\nSeparation of concerns will make development easier."},{"poster":"ScherbakovMike","comment_id":"911366","timestamp":"1685543760.0","upvote_count":"1","content":"SQS or SNS can be assigned as \'TargetArn\' in the \'DeadLetterConfig\'. \\nI think, D variant is more appropriate: in case of timeout (image is too large), there will be push to SNS and to subscribed resizing function. Subscribed resizing function writes the resized image to S3 and original Lambda function processes the resized image again."},{"poster":"rlnd2000","content":"Selected Answer: B\\nB is the best option in my opinion, I agree with Nagendhar and junrun3 explanations and because decoupling using SQS is a best practice, I think when they say ... with the LEAST development effort that imply following the best practices in AWS.","timestamp":"1684668660.0","comment_id":"903144","upvote_count":"3"},{"content":"Selected Answer: C\\nThe key in the question is \\"LEAST development effort\\", which indicates that we should choose step functions.","upvote_count":"4","timestamp":"1684394760.0","comment_id":"900876","poster":"marijabtw"},{"timestamp":"1684117620.0","comment_id":"898005","content":"Ans: B\\n\\nOption B involves creating an Amazon SQS queue and setting the SQS queue as a destination with an on failure condition for the avatar generator Lambda function. The image resize Lambda function is then configured to poll from the SQS queue. This approach ensures that the image resize Lambda function is invoked in case of a timeout, and using an SQS queue is a common pattern for decoupling services. This approach requires the least development effort because it involves setting up an SQS queue and configuring the Lambda functions to use it, which is a simple process.","upvote_count":"4","poster":"Nagendhar"},{"comment_id":"897054","upvote_count":"1","poster":"junrun3","content":"Selected Answer: B\\nIn case B, the SQS queue can be used to send a message containing a failure condition for the avatar generator Lambda function. The image resize Lambda function can then be configured to poll the SQS queue. This will ensure that the image resize Lambda function is retried as needed, reducing costs.","timestamp":"1684010400.0"},{"comment_id":"876588","timestamp":"1682083860.0","upvote_count":"2","poster":"Rpod","content":"Selected Answer: A\\nChatgpt says A","comments":[{"comment_id":"884117","content":"mine says B","poster":"ihebchorfi","timestamp":"1682752260.0","upvote_count":"4"}]},{"poster":"MrTee","content":"Selected Answer: A\\nA. Set the image resize Lambda function as a destination of the avatar generator Lambda function for the events that fail processing. This will allow the developer to implement a fallback mechanism by using another Lambda function that resizes the profile picture with the least development effort.","timestamp":"1681822680.0","upvote_count":"4","comment_id":"873632"},{"content":"Selected Answer: C\\nC\\nBefore execute the recovery Lambda function, the fallback mechanism must catch the timeout error of the generator Lambda function.\\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-error-handling.html","timestamp":"1679795700.0","upvote_count":"8","comment_id":"850661","poster":"Untamables"},{"upvote_count":"3","comment_id":"849254","timestamp":"1679657400.0","poster":"Dun6","content":"Selected Answer: B\\nWas thinking to use SQS and it can go to DLQ"}],"answer_description":"","extracted_at":"2025-12-24T09:12:28.220Z","extraction_method":"api_direct_v1"},{"question_id":"kCtWOEUyJNWqDlKW4DrZ","question_number":480,"page":96,"question_text":"A developer has an application container, an AWS Lambda function, and an Amazon Simple Queue Service (Amazon SQS) queue. The Lambda function uses the SQS queue as an event source. The Lambda function makes a call to a third-party machine learning API when the function is invoked. The response from the third-party API can take up to 60 seconds to return.\\n\\nThe Lambda function\'s timeout value is currently 65 seconds. The developer has noticed that the Lambda function sometimes processes duplicate messages from the SQS queue.\\n\\nWhat should the developer do to ensure that the Lambda function does not process duplicate messages?","choices":{"A":"Configure the Lambda function with a larger amount of memory.","C":"Configure the SQS queue\u2019s delivery delay value to be greater than the maximum time it takes to call the third-party API.","D":"Configure the SQS queue\u2019s visibility timeout value to be greater than the maximum time it takes to call the third-party API.","B":"Configure an increase in the Lambda function\u2019s timeout value."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156681-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:48:00","unix_timestamp":1739785680,"discussion_count":2,"discussion":[{"content":"Selected Answer: D\\nThe correct answer is:\\n\\nD. Configure the SQS queue\u2019s visibility timeout value to be greater than the maximum time it takes to call the third-party API.\\nExplanation:\\n\\nWhen a Lambda function reads a message from an SQS queue, the message becomes invisible for the duration of the visibility timeout. If the Lambda function doesn\u2019t finish processing (or doesn\u2019t delete the message from the queue) before the visibility timeout expires, the message becomes visible again and may be reprocessed, causing duplicates.\\n\\nSince the third-party API can take up to 60 seconds, the visibility timeout should be set to greater than 60 seconds to ensure that the message remains hidden from other consumers until the Lambda function finishes processing it.","poster":"vbloise","timestamp":"1746022080.0","comment_id":"1565119","upvote_count":"1"},{"upvote_count":"1","timestamp":"1739785680.0","poster":"italiancloud2025","comment_id":"1357724","content":"Selected Answer: D\\nel tiempo de visibilidad del mensaje en la cola SQS es demasiado corto"}],"answer_description":"","extracted_at":"2025-12-24T09:12:28.220Z","extraction_method":"api_direct_v1"},{"question_id":"CtkxhC7dWUjJaS4tUJHC","question_number":481,"page":97,"question_text":"A company has an application that runs on Amazon EC2 instances. The application needs to use dynamic feature flags that will be shared with other applications. The application must poll on an interval for new feature flag values. The values must be cached when they are retrieved.\\n\\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"B":"Store the feature flag values in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) to cache the values by using a lazy loading strategy in the application. Update the application to poll for the values on an interval from DynamoDB.","D":"Store the feature flag values in AWS Systems Manager Parameter Store. Configure the application to poll on an interval. Configure the application to use the AWS SDK to retrieve the values from Parameter Store and to store the values in memory.","C":"Store the feature flag values in AWS AppConfig. Configure AWS AppConfig Agent on the EC2 instances to poll for the values on an interval. Update the application to retrieve the values from the AppConfig Agent localhost endpoint.","A":"Store the feature flag values in AWS Secrets Manager. Configure an Amazon ElastiCache node to cache the values by using a lazy loading strategy in the application. Update the application to poll for the values on an interval from ElastiCache."},"correct_answer":"C","answer_ET":"C","answers_community":["C (67%)","B (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157496-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 09:01:00","unix_timestamp":1741075260,"discussion_count":2,"discussion":[{"comment_id":"1458072","content":"Selected Answer: C\\n\uc815\ub2f5\uc740 C\uc785\ub2c8\ub2e4. EC2 \uc778\uc2a4\ud134\uc2a4\uc5d0\uc11c AWS AppConfig Agent\ub97c \uad6c\uc131\ud558\uc5ec \uac04\uaca9\uc5d0 \ub530\ub77c \uac12\uc744 \ud3f4\ub9c1\ud569\ub2c8\ub2e4. AppConfig Agent \ub85c\uceec \ud638\uc2a4\ud2b8 \uc5d4\ub4dc\ud3ec\uc778\ud2b8\uc5d0\uc11c \uac12\uc744 \uac80\uc0c9\ud558\ub3c4\ub85d \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4. \uc785\ub2c8\ub2e4.","timestamp":"1743757980.0","poster":"devOpsihc","upvote_count":"2"},{"upvote_count":"1","poster":"0bdf3af","content":"Selected Answer: B\\nDAX as a cache requires no application changes.\\nDynamoDB is a way to share values between applications","comment_id":"1364794","timestamp":"1741075260.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:39.157Z","extraction_method":"api_direct_v1"},{"question_id":"sEm1htux317KbIAvXOFA","question_number":482,"page":97,"question_text":"A team deploys an AWS CloudFormation template to update a stack that already included an Amazon DynamoDB table. However, before the deployment of the update, the team changed the name of the DynamoDB table on the template by mistake. The DeletionPolicy attribute for all resources has the default value.\\n\\nWhat will be the result of this mistake?","choices":{"C":"CloudFormation will overwrite the existing table and will rename the existing table.","D":"CloudFormation will keep the existing table and will not create a new table.","B":"CloudFormation will create a new table and will keep the existing table.","A":"CloudFormation will create a new table and will delete the existing table."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156682-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:50:00","unix_timestamp":1739785800,"discussion_count":1,"discussion":[{"poster":"italiancloud2025","upvote_count":"1","content":"Selected Answer: A\\nAl cambiar el nombre en la template, CloudFormation crea un nuevo recurso con el nombre modificado y no hay retenci\xf3n de lo antiguo","timestamp":"1739785800.0","comment_id":"1357725"}],"answer_description":"","extracted_at":"2025-12-24T09:12:39.157Z","extraction_method":"api_direct_v1"},{"question_id":"117XrjhVOWQs6l1wW2AR","question_number":483,"page":97,"question_text":"A developer is deploying an application on an Amazon Elastic Container Service (Amazon ECS) cluster that uses AWS Fargate. The developer is using a Docker container with an Ubuntu image.\\n\\nThe developer needs to implement a solution to store application data that is available from multiple ECS tasks. The application data must remain accessible after the container is terminated.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Specify the DockerVolumeConfiguration parameter in the ECS task definition to attach a Docker volume.","C":"Create an Amazon Elastic File System (Amazon EFS) file system. Specify the mountPoints attribute and the efsVolumeConfiguration attribute in the ECS task definition.","A":"Attach an Amazon FSx for Windows File Server volume to the container definition.","D":"Create an Amazon Elastic Block Store (Amazon EBS) volume. Specify the mount point configuration in the ECS task definition."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156683-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:51:00","unix_timestamp":1739785860,"discussion_count":1,"discussion":[{"timestamp":"1741075740.0","upvote_count":"1","content":"Selected Answer: C\\nEFS is the right approach","poster":"0bdf3af","comment_id":"1364800"}],"answer_description":"","extracted_at":"2025-12-24T09:12:39.157Z","extraction_method":"api_direct_v1"},{"question_id":"pPmmvOrLfNKHBZ5yF6q8","question_number":484,"page":97,"question_text":"A developer is creating an AWS Lambda function that needs network access to private resources in a VPC.\\n\\nWhich solution will provide this access with the LEAST operational overhead?","choices":{"A":"Attach the Lambda function to the VPC through private subnets. Create a security group that allows network access to the private resources. Associate the security group with the Lambda function.","D":"Configure an AWS PrivateLink endpoint for the private resources. Configure the Lambda function to reference the PrivateLink endpoint.","C":"Configure a VPC endpoint connection for the Lambda function. Set up the VPC endpoint to route traffic through a NAT gateway.","B":"Configure the Lambda function to route traffic through a VPN connection. Create a security group that allows network access to the private resources. Associate the security group with the Lambda function."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156684-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 10:52:00","unix_timestamp":1739785920,"discussion_count":1,"discussion":[{"upvote_count":"1","comment_id":"1364801","timestamp":"1741075860.0","poster":"0bdf3af","content":"Selected Answer: A\\nAttach Lambda to VPC"}],"answer_description":"","extracted_at":"2025-12-24T09:12:39.157Z","extraction_method":"api_direct_v1"},{"question_id":"BmWCbsm2eQ3YXyYK77dC","question_number":485,"page":97,"question_text":"A developer needs to automate deployments for a serverless, event-based workload. The developer needs to create standardized templates to define the infrastructure and to test the functionality of the workload locally before deployment\\n\\nThe developer already uses a pipeline in AWS CodePipeline. The developer needs to incorporate any other infrastructure changes into the existing pipeline.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create an AWS Step Functions workflow template based on the infrastructure by using the Amazon States Language. Start the Step Functions state machine from the existing pipeline.","C":"Create an AWS CloudFormation template. Use the existing pipeline workflow to build a pipeline for AWS CloudFormation stacks.","A":"Create an AWS Serverless Application Model (AWS SAM) template. Configure the pipeline stages in CodePipeline to run the necessary AWS SAM CLI commands to deploy the serverless workload.","D":"Create an AWS Serverless Application Model (AWS SAM) template. Use an automated script to deploy the serverless workload by using the AWS SAM CLI deploy command."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156695-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:39:00","unix_timestamp":1739788740,"discussion_count":1,"discussion":[{"timestamp":"1741076700.0","comment_id":"1364806","upvote_count":"1","content":"Selected Answer: A\\nSAM is for serverless applications and it helps with local testing","poster":"0bdf3af"}],"answer_description":"","extracted_at":"2025-12-24T09:12:39.157Z","extraction_method":"api_direct_v1"},{"question_id":"trMS8vvXXTk2d24Xe7it","question_number":486,"page":98,"question_text":"A developer is creating a stock trading application. The developer needs a solution to send text messages to application users to confirmation when a trade has been completed.\\n\\nThe solution must deliver messages in the order a user makes stock trades. The solution must not send duplicate messages.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Configure a pipe in Amazon EventBridge Pipes. Connect the application to the pipe as a source. Configure the pipe to use each user\u2019s mobile phone number as a target. Configure the pipe to send incoming events to the users.","B":"Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Use the SendMessageIn API call to send the trade confirmation messages to the queue. Use the SendMessageOut API to send the messages to users by using the information provided in the trade confirmation message.","A":"Configure the application to publish messages to an Amazon Data Firehose delivery stream. Configure the delivery stream to have a destination of each user\u2019s mobile phone number that is passed in the trade confirmation message.","D":"Create an Amazon Simple Notification Service (SNS) FIFO topic. Configure the application to use the AWS SDK to publish notifications to the SNS topic to send SMS messages to the users."},"correct_answer":"D","answer_ET":"D","answers_community":["D (63%)","B (38%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156696-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:41:00","unix_timestamp":1739788860,"discussion_count":5,"discussion":[{"content":"Selected Answer: B\\nSorry, amazon SNS FIFO does not natively support SMS delivery","comment_id":"1570541","poster":"thalasi","upvote_count":"1","timestamp":"1747734900.0"},{"upvote_count":"1","timestamp":"1747729740.0","comment_id":"1570528","poster":"thalasi","content":"Selected Answer: D\\nonly \\nSendMessage\\nSendMessageBatch in SQS"},{"content":"Selected Answer: D\\nSend SMS","timestamp":"1747729620.0","poster":"thalasi","upvote_count":"1","comment_id":"1570527"},{"upvote_count":"3","comment_id":"1364810","content":"Selected Answer: D\\nThought one.\\nI would say D - using SNS but it costs operation work.\\nB seems right but there is no SendMessageIn and SendMessageOut API operations","timestamp":"1741077540.0","poster":"0bdf3af"},{"comment_id":"1357755","content":"Selected Answer: B\\nLa opci\xf3n D no es viable porque, aunque SNS permite enviar mensajes SMS, no ofrece temas FIFO ni garant\xedas de orden en la entrega de SMS. Adem\xe1s, no se proporciona un mecanismo de deduplicaci\xf3n para SMS en SNS, lo que significa que podr\xeda haber mensajes duplicados o fuera de orden","upvote_count":"2","poster":"italiancloud2025","timestamp":"1739788860.0"}],"answer_description":"","extracted_at":"2025-12-24T09:12:50.130Z","extraction_method":"api_direct_v1"},{"question_id":"huikDJXIsevDOfVvaM8f","question_number":487,"page":98,"question_text":"A developer is deploying a new Node.js AWS Lambda function that is not connected to a VPC. The Lambda function needs to connect to and query an Amazon Aurora database that is not publicly accessible. The developer is expecting unpredictable surges in database traffic.\\n\\nWhat should the developer do to give the Lambda function access to the database?","choices":{"B":"Configure a NAT gateway. Attach the NAT gateway to the Lambda function.","C":"Enable public access on the Aurora database. Configure a security group on the database to allow outbound access for the database engine\u2019s port.","A":"Configure the Lambda function to use an Amazon RDS proxy.","D":"Enable VPC access for the Lambda function. Attach the Lambda function to a new security group that does not have rules."},"correct_answer":"A","answer_ET":"A","answers_community":["A (60%)","D (40%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156697-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:42:00","unix_timestamp":1739788920,"discussion_count":5,"discussion":[{"timestamp":"1754206740.0","content":"Selected Answer: A\\nasdsasdfasdff","comment_id":"1593861","upvote_count":"1","poster":"fe600c8"},{"upvote_count":"1","content":"Selected Answer: A\\nD is incorrect\\n\\nThis would attach Lambda to a VPC, but without proper networking rules, it wouldn\u2019t allow connections to Aurora","timestamp":"1747735200.0","poster":"thalasi","comment_id":"1570542"},{"comment_id":"1570529","poster":"thalasi","content":"Selected Answer: D\\nQuestion is \\n\\nWhat should the developer do to give the Lambda function access to the database?","timestamp":"1747729920.0","upvote_count":"1"},{"timestamp":"1741077660.0","poster":"0bdf3af","comment_id":"1364815","upvote_count":"1","content":"Selected Answer: D\\nLambda connects to private subnet only when is configured as a part in user VPC"},{"timestamp":"1739788920.0","poster":"italiancloud2025","upvote_count":"1","content":"Selected Answer: A\\nRDS Proxy permite que la funci\xf3n Lambda tenga un gran rendimiento y gesti\xf3n de picos en \\nAurora","comment_id":"1357756"}],"answer_description":"","extracted_at":"2025-12-24T09:12:50.130Z","extraction_method":"api_direct_v1"},{"question_id":"ID8z3MkTMIiBCAlPAkIV","question_number":488,"page":98,"question_text":"A company generates SSL certificates from a third-party provider. The company imports the certificates into AWS Certificate Manager (ACM) to use with public web applications.\\n\\nA developer must implement a solution to notify the company\u2019s security team 90 days before an imported certificate expires. The company already has configured an Amazon Simple Queue Service (Amazon SQS) queue. The company also has configured an Amazon Simple Notification Service (Amazon SNS) topic that has the security team\u2019s email address as a subscriber.\\n\\nWhich solution will provide the security team with the required notification about certificates?","choices":{"D":"Configure AWS Config with the acm-certificate-expiration-check managed rule to run every 24 hours. Create an Amazon EventBridge rule that includes an event pattern that specifies the Config Rules Compliance Change detail type and the configured rule. Set the SNS topic as the EventBridge rule\u2019s target.","B":"Create an AWS Lambda function to search for all certificates that are expiring within 90 days. Program the Lambda function to send each identified certificate\u2019s Amazon Resource Name (ARN) in a message to the SQS queue.","A":"Create an Amazon EventBridge rule that specifies the ACM Certificate Approaching Expiration event type. Set the SNS topic as the EventBridge rule\u2019s target.","C":"Create an AWS Step Functions workflow that is invoked by each certificate\u2019s expiration notification from AWS CloudTrail. Create an AWS Lambda function to send each certificate\'s Amazon Resource Name (ARN) in a message to the SQS queue."},"correct_answer":"D","answer_ET":"D","answers_community":["D (56%)","A (44%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156029-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 13:07:00","unix_timestamp":1738843620,"discussion_count":5,"discussion":[{"comment_id":"1582819","timestamp":"1751546400.0","content":"Selected Answer: A\\nThis is the same question as the #502, but with a different answer","upvote_count":"1","poster":"lucasbbs"},{"poster":"thalasi","content":"Selected Answer: A\\nEventBridge rule + SNS notifications is the best approach! It provides automated expiration alerts, minimal setup, and direct integration with ACM expiration events\\n\\nAWS Config tracks compliance violations but does not directly monitor ACM certificate expirations.","comment_id":"1570543","timestamp":"1747735320.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"1365037","poster":"Dadasar","timestamp":"1741110180.0","content":"Selected Answer: D\\nA resposta correta \xe9:D.\\nA. Errado, porque esse evento s\xf3 \xe9 gerado para certificados emitidos pelo ACM. Como a empresa est\xe1 usando certificados importados, esse evento nunca ser\xe1 disparado.\\nB. Ineficiente, pois exigiria que o Lambda varresse manualmente todos os certificados periodicamente. O AWS Config j\xe1 faz isso automaticamente.\\nC. Errado, porque o AWS CloudTrail n\xe3o gera eventos de expira\xe7\xe3o de certificados no ACM."},{"content":"Selected Answer: D\\nAunque Amazon EventBridge puede capturar ciertos eventos de ACM, en la pr\xe1ctica el evento ACM Certificate Approaching Expiration se genera \xfanicamente para certificados emitidos y administrados por ACM. Los certificados importados, que son aquellos generados por terceros y luego importados a ACM, no generan ese evento. Por ello, utilizar una regla de EventBridge para capturar el evento de expiraci\xf3n no funcionar\xeda para certificados importados, lo que hace que la opci\xf3n A no cumpla con el requisito en este caso.","timestamp":"1739789040.0","comment_id":"1357757","upvote_count":"3","poster":"italiancloud2025"},{"comment_id":"1352355","poster":"e886835","upvote_count":"2","timestamp":"1738843620.0","content":"Selected Answer: A\\nAmazon EventBridge can capture events such as the expiration of SSL certificates imported into AWS Certificate Manager (ACM).\\nThe specific event type you are interested in is the ACM Certificate Approaching Expiration event, which is triggered when a certificate in ACM is approaching its expiration date.\\nEventBridge allows you to define rules for such events and trigger actions such as sending a notification to an SNS topic."}],"answer_description":"","extracted_at":"2025-12-24T09:12:50.130Z","extraction_method":"api_direct_v1"},{"question_id":"gn1ReoWcFT2vUWKKOP6b","question_number":489,"page":98,"question_text":"A company uses two AWS accounts: production and development. The company stores data in an Amazon S3 bucket that is in the production account. The data is encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The company plans to copy the data to another S3 bucket that is in the development account.\\n\\nA developer needs to use a KMS key to encrypt the data in the S3 bucket that is in the development account. The KMS key in the development account must be accessible from the production account,\\n\\nWhich solution will meet these requirements?","choices":{"C":"Create a new AWS managed KMS key for Amazon S3 in the development account. Specify the production account in the key policy.","B":"Create a new customer managed KMS key in the development account. Specify the production account in the key policy.","A":"Replicate the customer managed KMS key from the production account to the development account. Specify the production account in the key policy.","D":"Replicate the default AWS managed KMS key for Amazon S3 from the production account to the development account. Specify the production account in the key policy."},"correct_answer":"C","answer_ET":"B","answers_community":["C (50%)","B (50%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157497-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 09:55:00","unix_timestamp":1741078500,"discussion_count":3,"discussion":[{"poster":"AlmeroSenior","timestamp":"1748503380.0","content":"Selected Answer: B\\nAWS managed keys (aws/s3) cannot be modified \u2014 you cannot add cross-account permissions to their key policies.","upvote_count":"1","comment_id":"1573251"},{"comment_id":"1565300","poster":"yusan","content":"Selected Answer: B\\nC\uff1aAWS \u7ba1\u7406\u30ad\u30fc\uff08AWS \u30de\u30cd\u30fc\u30b8\u30c9\u30ad\u30fc\uff09\u306f\u30ad\u30fc\u306e\u7ba1\u7406\u3084\u30dd\u30ea\u30b7\u30fc\u5909\u66f4\u304c\u3067\u304d\u305a\u3001\u304b\u3064\u30a2\u30ab\u30a6\u30f3\u30c8\u9593\u3067\u5171\u6709\u3067\u304d\u306a\u3044\u305f\u3081\u3001\u8981\u4ef6\u3092\u6e80\u305f\u305b\u307e\u305b\u3093\u3002\\n\u3088\u3063\u3066\u3001B\u304c\u2019\u6b63\u89e3\u3068\u306a\u308b","timestamp":"1746066960.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"1364819","timestamp":"1741078500.0","content":"Selected Answer: C\\nC or B \\nI would say C. We don\'t know exactly which type of KMS key will be used in development account.. KMS cusutomer key or KMS AWS menaged key? I guess the second one so it could be just default aws/s3 key.\\nThe other thing is that production account should have access tho this new key but development account should not have access to AWS customer key in production account. Is is quite logical.\\nSharing acceess to key with other accaount is to specify the account in KMS key policy.","poster":"0bdf3af"}],"answer_description":"","extracted_at":"2025-12-24T09:12:50.130Z","extraction_method":"api_direct_v1"},{"question_id":"ZTwz2mbhURtkBgYOJWpz","question_number":490,"page":98,"question_text":"A developer needs to migrate an online retail application to AWS to handle an anticipated increase in traffic. The application currently runs on two servers: one server for the web application and another server for the database. The web server renders webpages and manages session state in memory. The database server hosts a MySQL database that contains order details. When traffic to the application is heavy, the memory usage for the web server approaches 100% and the application slows down considerably.\\nThe developer has found that most of the memory increase and performance decrease is related to the load of managing additional user sessions. For the web server migration, the developer will use Amazon EC2 instances with an Auto Scaling group behind an Application Load Balancer.\\nWhich additional set of changes should the developer make to the application to improve the application\'s performance?","choices":{"B":"Use Amazon ElastiCache for Memcached to store and manage the session data. Use an Amazon RDS for MySQL DB instance to store the application data.","A":"Use an EC2 instance to host the MySQL database. Store the session data and the application data in the MySQL database.","C":"Use Amazon ElastiCache for Memcached to store and manage the session data and the application data.","D":"Use the EC2 instance store to manage the session data. Use an Amazon RDS for MySQL DB instance to store the application data."},"correct_answer":"B","answer_ET":"B","answers_community":["B (97%)","3%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103757-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-24 09:35:00","unix_timestamp":1679646900,"discussion_count":8,"discussion":[{"content":"Selected Answer: B\\nOption B ,\\nhow can you image using an EC2 as cache ....","poster":"clarksu","upvote_count":"10","timestamp":"1695537300.0","comment_id":"849114"},{"poster":"Untamables","timestamp":"1695695820.0","comment_id":"850675","upvote_count":"10","content":"Selected Answer: B\\nB\\nSession stores are easy to create with Amazon ElastiCache for Memcached.\\nhttps://aws.amazon.com/elasticache/memcached/\\nWith Amazon RDS, you can deploy scalable MySQL servers in minutes with cost-efficient and resizable hardware capacity.\\nhttps://aws.amazon.com/rds/mysql/"},{"poster":"sumanshu","timestamp":"1735019940.0","comment_id":"1331034","upvote_count":"1","content":"Selected Answer: B\\nB) - in-memory data store for managing session state\\nC) Eliminated - ElastiCache is not a suitable replacement for a relational database like MySQL when dealing with structured data and complex queries."},{"comment_id":"1215170","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732221660.0","poster":"65703c1","upvote_count":"1"},{"content":"Selected Answer: B\\nThe additional requirement for the faster retrieval of data","timestamp":"1718599080.0","upvote_count":"1","poster":"KarBiswa","comment_id":"1098703"},{"comment_id":"980447","timestamp":"1707892080.0","poster":"Aws_aspr","upvote_count":"1","content":"Selected Answer: B\\nB is correct"},{"timestamp":"1705255620.0","content":"Selected Answer: A\\nI choose A.\\nIt says that the most of the memory increase is related to the load of managing additional user sessions. So I think Memcached doesn\'t make sense.\\nAlso, isn\'t bad practice to store session information in db.","comment_id":"951655","comments":[{"upvote_count":"3","poster":"ninomfr64","timestamp":"1708346580.0","comment_id":"985119","content":"Session Store is one of the main use case for ElastiCache for Memcached as pwe AWS website https://aws.amazon.com/elasticache/memcached/#:~:text=ElastiCache%20for%20Memcached.-,Session%20Store,-Session%20stores%20are"}],"upvote_count":"1","poster":"nkelesidis"},{"poster":"Dun6","timestamp":"1695548100.0","comment_id":"849257","upvote_count":"6","content":"Selected Answer: B\\nB it is"}],"answer_description":"","extracted_at":"2025-12-24T09:12:50.130Z","extraction_method":"api_direct_v1"},{"question_id":"7Jp8xBgWr6JQ7rhksR2D","question_number":491,"page":99,"question_text":"A developer is using AWS CodeDeploy to launch an application onto Amazon EC2 instances. The application deployment fails during testing. The developer notices an IAM_ROLE_PERMISSIONS error code in Amazon CloudWatch logs.\\n\\nWhat should the developer do to resolve the error?","choices":{"B":"Attach the AWSCodeDeployRoleECS policy to the CodeDeploy service role.","A":"Ensure that the deployment group is using the correct role name for the CodeDeploy service role.","C":"Attach the AWSCodeDeployRole policy to the CodeDeploy service role.","D":"Ensure the CodeDeploy agent is installed and running on all instances in the deployment group."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156698-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:45:00","unix_timestamp":1739789100,"discussion_count":1,"discussion":[{"upvote_count":"1","timestamp":"1739789100.0","content":"Selected Answer: C\\nIAM_ROLE_PERMISSIONS indica que el rol que CodeDeploy utiliza no tiene los permisos necesarios. La pol\xedtica est\xe1ndar para CodeDeploy en instancias EC2 es AWSCodeDeployRole, la cual debe estar adjunta al rol del servicio de CodeDeploy.","comment_id":"1357758","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:13:01.283Z","extraction_method":"api_direct_v1"},{"question_id":"54aTYSt7arZrxx8wNzq2","question_number":492,"page":99,"question_text":"A company wants to send notifications to customers to advertise a sale on the company\u2019s products. The company needs to use Amazon Simple Notification Service (Amazon SNS) FIFO topics.\\n\\nThe company needs to examine the rate at which the topics send notifications and the latency with which the topics send notifications.\\n\\nWhich solution will meet these requirements with the MOST operational efficiency?","choices":{"D":"Use Amazon GuardDuty. Enable runtime monitoring.","B":"Use the Amazon CloudWatch NumberOfNotificationsFailed metric.","A":"Use AWS X-Ray. Enable active tracing for Amazon SNS.","C":"Use AWS CloudTrail to log all Amazon SNS API calls."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/153933-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-06 10:01:00","unix_timestamp":1736154060,"discussion_count":3,"discussion":[{"poster":"LingZ","timestamp":"1740210120.0","content":"Selected Answer: A\\nA. AWS X-Ray with active tracing:\\nThis is exactly what we need because:\\n\\nX-Ray provides detailed tracing of messages through the SNS FIFO topics\\nIt shows the complete path of each message, including timing information\\nYou can see exactly how long each notification takes to process and deliver\\nIt provides visualization tools to help spot bottlenecks and issues\\nYou can track both throughput and latency in real-time\\n\u2705 CORRECT","upvote_count":"1","comment_id":"1360044"},{"upvote_count":"1","poster":"bp07","content":"Selected Answer: A\\nD can\'t be as Amazon GuardDuty is a threat detection service, not a monitoring tool for performance metrics like notification rate or latency.","comment_id":"1340191","timestamp":"1736834760.0"},{"poster":"Ibra992","content":"Selected Answer: A\\nI vote A: https://docs.aws.amazon.com/xray/latest/devguide/xray-services-sns.html\\n\\nBoth B and C don\'t make sense to me\\nD is not suitable as its Designed for security threat detection.","upvote_count":"1","timestamp":"1736154060.0","comment_id":"1337042"}],"answer_description":"","extracted_at":"2025-12-24T09:13:01.283Z","extraction_method":"api_direct_v1"},{"question_id":"wlezwPVv84nNvisHVq36","question_number":493,"page":99,"question_text":"A cloud-based video surveillance company is developing an application that analyzes video files. After the application analyzes the files, the company can discard the files.\\n\\nThe company stores the files in an Amazon S3 bucket. The files are 1 GB in size on average. No file is larger than 2 GB. An AWS Lambda function will run one time for each video file that is processed. The processing is very I/O intensive, and the application must read each file multiple times.\\n\\nWhich solution will meet these requirements in the MOST performance-optimized way?","choices":{"A":"Attach an Amazon Elastic Block Store (Amazon EBS) volume that is larger than 1 GB to the Lambda function. Copy the files from the S3 bucket to the EBS volume.","D":"Configure the Lambda function code to read the video files directly from the S3 bucket.","C":"Increase the ephemeral storage size to 2 GB. Copy the files from the S3 bucket to the /tmp directory of the Lambda function.","B":"Attach an Elastic Network Adapter (ENA) to the Lambda function. Use the ENA to read the video files from the S3 bucket."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156699-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:47:00","unix_timestamp":1739789220,"discussion_count":1,"discussion":[{"comment_id":"1357760","upvote_count":"2","content":"Selected Answer: C\\nLambda permite aumentar el almacenamiento ef\xedmero (/tmp) hasta 10 GB. Al aumentar este almacenamiento a 2 GB y copiar el archivo desde S3 a /tmp, el procesamiento I/O intensivo se realiza localmente, reduciendo la latencia y evitando m\xfaltiples lecturas directamente desde S3","timestamp":"1739789220.0","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:13:01.283Z","extraction_method":"api_direct_v1"},{"question_id":"UTsKzHcxHv37maCuiGrS","question_number":494,"page":99,"question_text":"A company has an AWS Step Functions state machine named myStateMachine. The company configured a service role for Step Functions.\\n\\nThe developer must ensure that only the myStateMachine state machine can assume the service role.\\n\\nWhich statement should the developer add to the trust policy to meet this requirement?","choices":{"D":"","C":"","B":"","A":""},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157498-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 10:10:00","unix_timestamp":1741079400,"discussion_count":1,"discussion":[{"content":"Selected Answer: A\\nA: the \\"myStateMachine\\" from specific account.","upvote_count":"1","comment_id":"1364824","timestamp":"1741079400.0","poster":"0bdf3af"}],"answer_description":"","extracted_at":"2025-12-24T09:13:01.283Z","extraction_method":"api_direct_v1"},{"question_id":"OlHDLnxD1QPzw6BFQVe8","question_number":495,"page":99,"question_text":"A company stores customer credit reports in an Amazon S3 bucket. An analytics service uses standard Amazon S3 GET requests to access the reports.\\n\\nA developer must implement a solution to redact personally identifiable information (PII) from the reports before the reports reach the analytics service.\\n\\nWhich solution will meet this requirement with the MOST operational efficiency?","choices":{"C":"Use AWS Key Management Service (AWS KMS) to implement encryption in the S3 bucket. Re-upload all the existing S3 objects. Give the kms:Decrypt permission to the analytics service.","B":"Set up an S3 Object Lambda function. Attach the function to an S3 Object Lambda Access Point. Program the function to call a PII redaction API.","A":"Load the S3 objects into Amazon Redshift by using a COPY command. Implement dynamic data masking. Refactor the analytics service to read from Amazon Redshift.","D":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Implement message data protection. Refactor the analytics service to publish data access requests to the SNS topic."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156700-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:52:00","unix_timestamp":1739789520,"discussion_count":2,"discussion":[{"poster":"BasselBuzz","timestamp":"1740039900.0","upvote_count":"2","comment_id":"1359169","content":"Selected Answer: B\\nB is the correct answer"},{"upvote_count":"1","timestamp":"1739789520.0","content":"Selected Answer: B\\nCon S3 Object Lambda puedes interceptar las solicitudes GET a objetos en S3 y ejecutar Lambda para cambios antes de que lleguen al consumidor.","comment_id":"1357761","poster":"italiancloud2025"}],"answer_description":"","extracted_at":"2025-12-24T09:13:01.283Z","extraction_method":"api_direct_v1"},{"question_id":"vfev3oNf6cH7M1WPHE2N","question_number":496,"page":100,"question_text":"A company is using the AWS Serverless Application Model (AWS SAM) to develop a social media application. A developer needs a quick way to test AWS Lambda functions locally by using test event payloads. The developer needs the structure of these test event payloads to match the actual events that AWS services create.\\n\\nWhich solution will meet these requirements with the LEAST development effort?","choices":{"B":"Store manually created test event payloads locally. Use the sam local invoke command with the file path to the payloads.","D":"Use the sam local generate-event command to create test payloads for local testing.","C":"Store manually created test event payloads in an Amazon S3 bucket. Use the sam local invoke command with the S3 path to the payloads.","A":"Create shareable test Lambda events. Use these test Lambda events for local testing."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156701-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-17 11:53:00","unix_timestamp":1739789580,"discussion_count":1,"discussion":[{"upvote_count":"1","poster":"italiancloud2025","timestamp":"1739789580.0","content":"Selected Answer: D\\nobvio sam local generate-event te permite generar payloads de eventos de prueba","comment_id":"1357762"}],"answer_description":"","extracted_at":"2025-12-24T09:13:12.239Z","extraction_method":"api_direct_v1"},{"question_id":"bMCnOZ98fY91CQwvmEYd","question_number":497,"page":100,"question_text":"A developer is building the authentication mechanism for a new mobile app. Users need to be able to sign up, sign in, and access secured backend AWS resources.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Use AWS Identity and Access Management Access Analyzer to generate IAM policies. Create an IAM role. Attach the policies to the role. Integrate the IAM role with an identity provider that the mobile app uses.","D":"Create an Amazon Cognito user pool. Configure the security requirements by choosing a password policy, multi-factor authentication (MFA) requirements, and user account recovery options. Create an app client. Integrate the app client with the mobile app.","C":"Create an Amazon Cognito identity pool. Configure permissions by choosing a default IAM role for authenticated users or guest users in the identity pool. Associate the identity pool with an identity provider. Integrate the identity pool with the mobile app.","B":"Create an IAM policy that grants access to the backend resources. Create an IAM role. Attach the policy to the role. Create an Amazon API Gateway endpoint. Attach the role to the endpoint. Integrate the endpoint with the mobile app."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/154507-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-14 18:13:00","unix_timestamp":1736874780,"discussion_count":3,"discussion":[{"upvote_count":"2","timestamp":"1740211200.0","comment_id":"1360051","poster":"LingZ","content":"Selected Answer: D\\nUsing Amazon Cognito User Pools:\\nThis is the correct solution because User Pools provide everything we need:\\n\\nComplete user directory management\\nBuilt-in sign-up and sign-in flows\\nCustomizable security policies\\nPassword management and recovery\\nMFA support\\nEasy mobile SDK integration\\nCan be combined with Identity Pools for AWS resource access"},{"upvote_count":"2","timestamp":"1739789700.0","poster":"italiancloud2025","comment_id":"1357763","content":"Selected Answer: D\\nIdentity pool es para termporales, efectivamente es user pool"},{"content":"Selected Answer: D\\nD is the correct answer.\\nAmazon Cognito User Pools provide a fully managed authentication mechanism. They enable user sign-up, sign-in, and user management.\\n\\nC is wrong, because identity pool does not provide user sign-up and sign-in features.","comment_id":"1340462","timestamp":"1736874780.0","poster":"Arad","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:13:12.239Z","extraction_method":"api_direct_v1"},{"question_id":"k2GIx1IabsdJF6tXqmA0","question_number":498,"page":100,"question_text":"A developer is designing an event-driven architecture. An AWS Lambda function that processes data needs to push processed data to a subset of four consumer Lambda functions. The data must be routed based on the value of one field in the data.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"C":"Create a separate Amazon Simple Notification Service (Amazon SNS) topic and subscription for each consumer Lambda function. Add message routing logic to the data-processing Lambda function to publish to the appropriate topic.","B":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the four consumer Lambda functions to the topic. Add message filtering logic to each consumer Lambda function. Subscribe the data-processing Lambda function to the SNS topic.","D":"Create a single Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the four consumer Lambda functions to the topic. Add SNS subscription filter policies to each subscription. Configure the data-processing Lambda function to publish to the topic.","A":"Create an Amazon Simple Queue Service (Amazon SQS) queue and event source mapping for each consumer Lambda function. Add message routing logic to the data-processing Lambda function."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157499-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 10:40:00","unix_timestamp":1741081200,"discussion_count":1,"discussion":[{"comment_id":"1364832","upvote_count":"1","content":"Selected Answer: D\\nD is the correct answear\\nSNS with Subscription filter policy\\n\\nSQS vs. SNS: It\'s easy to confuse SQS and SNS. SQS is a queuing service for decoupling and asynchronous communication, guaranteeing message delivery. SNS is a publish-subscribe service for broadcasting messages to multiple subscribers.","timestamp":"1741081200.0","poster":"0bdf3af"}],"answer_description":"","extracted_at":"2025-12-24T09:13:12.239Z","extraction_method":"api_direct_v1"},{"question_id":"0DT23czb0oEjjRDTzE5n","question_number":499,"page":100,"question_text":"A developer is creating a new application that will give users the ability to upload documents to Amazon S3. The contents of the documents must not be accessible to any third party.\\n\\nWhich type of encryption will meet this requirement?","choices":{"C":"Server-side encryption with AWS KMS keys (SSE-KMS)","D":"Dual-layer server-side encryption with AWS KMS keys (DSSE-KMS)","B":"Server-side encryption with S3 managed keys (SSE-S3)","A":"Client-side encryption by using the S3 Encryption Client with a Raw RSA wrapping key that is stored on the user\u2019s device"},"correct_answer":"C","answer_ET":"C","answers_community":["C (63%)","A (38%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/154460-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-13 18:20:00","unix_timestamp":1736788800,"discussion_count":6,"discussion":[{"upvote_count":"1","poster":"acea5d5","comment_id":"1578881","content":"Selected Answer: A\\nBecause the documents can\'t be accessible to any third party (include AWS, ... )","timestamp":"1750336140.0"},{"comment_id":"1570544","timestamp":"1747736100.0","content":"Selected Answer: C\\nenabling server-side encryption with AWS KMS, restricting access through IAM policies, and leveraging features like CloudFront for content delivery and API Gateway for authentication and authorization","poster":"thalasi","upvote_count":"1"},{"poster":"Dadasar","upvote_count":"1","timestamp":"1741052160.0","content":"Selected Answer: C\\nProtege os dados com chaves gerenciadas pelo AWS KMS, oferecendo um n\xedvel extra de controle e auditoria sobre as chaves.Al\xe9m disso, o SSE-KMS permite logs detalhados de acessos e tentativas de descriptografia no AWS CloudTrail. \\nA. Errado, pois essa abordagem exige que os usu\xe1rios gerenciem suas pr\xf3prias chaves. Se um usu\xe1rio perder a chave, os dados n\xe3o poder\xe3o ser recuperados. Al\xe9m disso, essa abordagem n\xe3o aproveita os recursos de controle de acesso e auditoria do AWS KMS.\\nB. Errado, pois o SSE-S3 usa chaves gerenciadas pelo pr\xf3prio Amazon S3 e n\xe3o permite controle detalhado sobre quem pode descriptografar os dados. \\nD. Errado, porque o DSSE-KMS (Dual-layer Server-Side Encryption with AWS KMS) \xe9 mais adequado para FINRA e CJIS","comment_id":"1364665"},{"content":"Selected Answer: A\\nA. Client-side encryption using the S3 Encryption Client with a Raw RSA key:\\nThis is the correct answer because it ensures complete end-to-end protection. Here\'s why:\\n\\nThe document is encrypted on the user\'s device before transmission\\nThe encryption key never leaves the user\'s control\\nEven AWS cannot access the unencrypted contents\\nThe data remains protected throughout its entire lifecycle","timestamp":"1740211500.0","comment_id":"1360055","upvote_count":"2","poster":"LingZ"},{"poster":"italiancloud2025","timestamp":"1739789820.0","content":"Selected Answer: C\\nEs una soluci\xf3n robusta y administrativamente sencilla, sin la complejidad del cifrado del lado del cliente (opci\xf3n A) y con un nivel de seguridad superior al de SSE-S3 (opci\xf3n B). La opci\xf3n D implicar\xeda una doble capa de cifrado innecesaria para este caso.","upvote_count":"1","comment_id":"1357764"},{"timestamp":"1736788800.0","content":"Selected Answer: C\\nC is the correct answer.\\nA is too complex.\\nB is not the most secure way as there\'s no integration with IAM for access control policies specific to the key.\\nD is overkill.","comment_id":"1339987","poster":"Arad","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:13:12.239Z","extraction_method":"api_direct_v1"},{"question_id":"ksPwh6vRwZs0Xrkhs53x","question_number":500,"page":100,"question_text":"A developer is building an application that consists of many AWS Lambda functions. The Lambda functions connect to a single Amazon RDS database.\\n\\nThe developer needs to implement a solution to store the database credentials securely. When the credentials are updated, the Lambda functions must be able to use the new credentials without requiring a code update or a configuration update.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Store the credentials as a secret in AWS Secrets Manager. Access the secret at runtime from within the Lambda functions.","D":"Store the credentials as a SecureString parameter in AWS Systems Manager Parameter Store. Add a reference to the parameter in an environment variable in the Lambda functions.","C":"Store the credentials as a SecureString parameter in AWS Systems Manager Parameter Store. Add a trigger to pass the credentials to the Lambda functions when the Lambda functions run.","B":"Store the credentials as a secret in AWS Secrets Manager. Access the credentials in environment variables by using the containerDefinitions and valueFrom elements in reference to the secret value."},"correct_answer":"A","answer_ET":"A","answers_community":["A (67%)","D (33%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157490-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 02:27:00","unix_timestamp":1741051620,"discussion_count":3,"discussion":[{"timestamp":"1747736160.0","content":"Selected Answer: A\\nUsing Parameter Store with Environment variables do not auto-refresh, requiring redeployment or reloading functions for updated credentials. \\n\\n Secrets Manager is explicitly designed for credential management, while Parameter Store is more general-purpose","upvote_count":"1","comment_id":"1570546","poster":"thalasi"},{"comment_id":"1364841","poster":"0bdf3af","upvote_count":"1","timestamp":"1741082640.0","content":"Selected Answer: D\\nD\\nWe can store the credentials in SSM Parameter Store with encryption.\\nThen we can add a environment variable \\"db_password\\" in lambda with proper credential name from SSM Parameter Store\\nIn the code in Lambda we can import ssm and call ssm.get_parameters(os.environ(\\"db_password\\"))"},{"timestamp":"1741051620.0","upvote_count":"1","content":"Selected Answer: A\\nSecret manager \xe9 para essa finalidade","comment_id":"1364659","poster":"Dadasar"}],"answer_description":"","extracted_at":"2025-12-24T09:13:12.239Z","extraction_method":"api_direct_v1"},{"question_id":"W0CX1hdh6EtoEaSWuzI4","question_number":501,"page":101,"question_text":"An application uses Lambda functions to extract metadata from files uploaded to an S3 bucket; the metadata is stored in Amazon DynamoDB. The application starts behaving unexpectedly, and the developer wants to examine the logs of the Lambda function code for errors.\\nBased on this system configuration, where would the developer find the logs?","choices":{"D":"Amazon DynamoDB","C":"Amazon CloudWatch","A":"Amazon S3","B":"AWS CloudTrail"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103931-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 06:48:00","unix_timestamp":1679806080,"discussion_count":5,"discussion":[{"timestamp":"1679806080.0","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/implementing-logging-monitoring-cloudwatch/lambda-logging-metrics.html","poster":"Untamables","comment_id":"850728","upvote_count":"10"},{"comment_id":"1231693","poster":"tsangckl","content":"This appear at 17 Jun exam","upvote_count":"5","timestamp":"1718595540.0"},{"timestamp":"1735020300.0","upvote_count":"2","content":"Selected Answer: C\\nC) - AWS Lambda automatically sends logs generated by your function to Amazon CloudWatch Logs.\\n\\nB) Eliminated - CloudTrail logs API activity and management operations across AWS, such as who invoked the Lambda function. However, it does not provide the function\'s execution logs.","poster":"sumanshu","comment_id":"1331037"},{"timestamp":"1716316920.0","comment_id":"1215172","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","poster":"65703c1"},{"timestamp":"1693301340.0","content":"Answer is C","poster":"AhmedAliHashmi","comment_id":"992948","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:13:23.198Z","extraction_method":"api_direct_v1"},{"question_id":"EyvTFJkzgko9JXCVUIuT","question_number":502,"page":101,"question_text":"A developer is building an application that stores sensitive user data. The application includes an Amazon CloudFront distribution and multiple AWS Lambda functions that handle user requests.\\n\\nThe user requests contain over 20 data fields. Each application transaction contains sensitive data that must be encrypted. Only specific parts of the application need to have the ability to decrypt the data.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Configure the CloudFront distribution to use WebSockets by forwarding all viewer request headers to the origin. Create an asymmetric AWS KMS key. Configure the CloudFront distribution to use field-level encryption. Use the AWS KMS key.","D":"Configure the cache behavior in the CloudFront distribution to require HTTPS for communication between viewers and CloudFront. Configure GoudFront to require users to access the files by using either signed URLs or signed cookies.","B":"Integrate AWS WAF with CloudFront to protect the sensitive data. Use a Lambda function and self-managed keys to perform the encryption and decryption processes.","A":"Associate the CloudFront distribution with a Lambda@Edge function. Configure the function to perform field-level asymmetric encryption by using a user-defined RSA public key that is stored in AWS Key Management Service (AWS KMS)."},"correct_answer":"A","answer_ET":"A","answers_community":["A (60%)","D (20%)","C (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157510-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-04 14:14:00","unix_timestamp":1741094040,"discussion_count":5,"discussion":[{"poster":"AlmeroSenior","timestamp":"1748505660.0","comment_id":"1573255","upvote_count":"1","content":"Selected Answer: A\\nAnswer is A \\n\\nC not correct : \\nCloudFront does support field-level encryption, but it does not use AWS KMS keys directly for this. Instead, it uses its own mechanism with public keys you upload."},{"content":"Selected Answer: C\\nField-level encryption allows specific fields in user requests to be encrypted while leaving other fields readable.\\n\\n Encryption is performed at the edge (CloudFront), ensuring data is protected before reaching the application backend.","poster":"thalasi","upvote_count":"1","comments":[],"comment_id":"1570549","timestamp":"1747736520.0"},{"timestamp":"1744714740.0","content":"Selected Answer: A\\n\uc815\ub2f5\uc740 A\ub2e4","poster":"sungtae","comment_id":"1560863","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\\n\uc815\ub2f5\uc740 a\uc785\ub2c8\ub2e4.","timestamp":"1742890380.0","poster":"devOpsihc","comment_id":"1409945"},{"poster":"0bdf3af","upvote_count":"1","timestamp":"1741094040.0","comment_id":"1364910","content":"Selected Answer: D\\nsecure transaction - ssl"}],"answer_description":"","extracted_at":"2025-12-24T09:13:23.198Z","extraction_method":"api_direct_v1"},{"question_id":"JovNbdNH8zrzK70JufpR","question_number":503,"page":101,"question_text":"An application includes an Amazon DynamoDB table that is named orders. The table has a primary partition key of id and a global secondary index (GSI) that is named an accountIndex. The GSI has a partition key of accountId and a sort key of orderDateTime.\\n\\nA developer needs to create an AWS Lambda function to retrieve the orders that have an accountId of 100.\\n\\nWhich solution will meet this requirement by using the LEAST read capacity?","choices":{"D":"Define a DynamoDB API request for the Query action with the following parameters:","B":"Define a DynamoDB API request for the BatchGetItem action with the following parameters:","A":"Define a DynamoDB API request for the GetItem action with the following parameters:","C":"Define a DynamoDB API request for the Scan action with the following parameters:"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156015-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 08:22:00","unix_timestamp":1738826520,"discussion_count":1,"discussion":[{"poster":"e886835","comment_id":"1352228","timestamp":"1738826520.0","upvote_count":"2","content":"Selected Answer: D\\nThe Query action is the most efficient for retrieving items from DynamoDB when you want to retrieve data based on a partition key or both a partition key and sort key"}],"answer_description":"","extracted_at":"2025-12-24T09:13:23.198Z","extraction_method":"api_direct_v1"},{"question_id":"oAKweiJh18SRvvJHL9b4","question_number":504,"page":101,"question_text":"A company stores data in an Amazon S3 bucket. The data is updated multiple times every day from an application that runs on a server in the company\u2019s on-premises data center.\\n\\nThe company enables S3 Versioning on the S3 bucket. After some time, the company observes multiple versions of the same objects in the S3 bucket.\\n\\nThe company needs the S3 bucket to keep the current version of each object and the version immediately previous to the current version.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Enable S3 Object Lock. Configure an S3 Object Lock policy to retain one newer noncurrent version of the objects.","D":"Suspend S3 Versioning. Modify the application code to check the number of object versions before updating the objects.","A":"Configure an S3 bucket policy to retain one newer noncurrent version of the objects.","B":"Configure an S3 Lifecycle rule to retain one newer noncurrent version of the objects."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157448-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-03 08:48:00","unix_timestamp":1740988080,"discussion_count":2,"discussion":[{"comment_id":"1566236","poster":"vbloise","content":"Selected Answer: B\\nCorrect answer: B. Configure an S3 Lifecycle rule to retain one newer noncurrent version of the objects.\\nExplanation:\\n\\n S3 Versioning keeps all versions of an object, including deleted versions, which can lead to storage cost growth.\\n\\n To retain only the current and the immediately previous version of each object, use an S3 Lifecycle rule.\\n\\n The lifecycle rule should be configured to delete noncurrent versions after 1 day and retain only 1 noncurrent version.\\n\\nWhy the other options are incorrect:\\n\\n A. S3 bucket policies control access, not version retention.\\n\\n C. S3 Object Lock is used for WORM (Write Once Read Many) compliance and legal holds, not for version count control.\\n\\n D. Suspending versioning stops new versions from being created, but does not help manage or limit existing versions.","upvote_count":"1","timestamp":"1746374340.0"},{"poster":"0bdf3af","timestamp":"1740988080.0","content":"Selected Answer: B\\nLifecycle rule to remove old versions","comment_id":"1364312","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:13:23.198Z","extraction_method":"api_direct_v1"},{"question_id":"tWJMGhcolBlVAIP7b5kG","question_number":505,"page":101,"question_text":"A company is creating a new feature for existing software. Before the company fully releases a new version of the software, the company wants to test the feature.\\n\\nThe company needs to gather feedback about the feature from a small group of users while the current software version remains deployed. If the testing validates the feature, the company needs to deploy the new software version to all other users at the same time.\\n\\nWhich deployment strategy will meet these requirements?","choices":{"C":"In-place deployment","B":"Canary deployment","A":"All-at-once deployment","D":"Linear deployment"},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157447-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-03 08:46:00","unix_timestamp":1740987960,"discussion_count":2,"discussion":[{"poster":"vbloise","content":"Selected Answer: B\\nThe correct answer is:\\n\\nB. Canary deployment\\nExplanation:\\n\\nA canary deployment allows the company to release a new feature to a small subset of users first, gather feedback, and validate that the feature works correctly. If successful, the company can then roll out the new version to all users.\\n\\nThis fits the scenario described:\\n\\n Testing with a small group of users \u2714\\n\\n Keeping the current version deployed for most users \u2714\\n\\n Deploying to all users at once after validation \u2714","timestamp":"1746374520.0","comment_id":"1566238","upvote_count":"1"},{"timestamp":"1740987960.0","comment_id":"1364310","upvote_count":"1","poster":"0bdf3af","content":"Selected Answer: B\\nCanary deployment"}],"answer_description":"","extracted_at":"2025-12-24T09:13:23.198Z","extraction_method":"api_direct_v1"},{"question_id":"U73x9otI3DmKVP9CqLyJ","question_number":506,"page":102,"question_text":"A developer has an application that runs in AWS Account A. The application must retrieve an AWS Secrets Manager secret that is encrypted by an AWS Key Management Service (AWS KMS) key from AWS Account B. The application\u2019s role has permissions to access the secret in Account B.\\n\\nThe developer must add a statement to the KMS key\u2019s key policy to allow the role in Account A to use the KMS key in Account B. The permissions must grant least privilege access to the role.\\n\\nWhich permissions will meet these requirements?","choices":{"A":"kms:Decrypt and kms:DescribeKey","D":"secretsmanager:*","C":"kms:*","B":"secretsmanager:DescribeSecret and secretsmanager:GetSecretValue"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/157446-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-03-03 08:46:00","unix_timestamp":1740987960,"discussion_count":2,"discussion":[{"poster":"Dadasar","timestamp":"1741050840.0","upvote_count":"1","comment_id":"1364656","content":"Selected Answer: A\\nPadr\xe3o de menor privil\xe9gios. O acesso \xe9 a chave KMS e n\xe3o a secret"},{"upvote_count":"1","comment_id":"1364309","timestamp":"1740987960.0","poster":"0bdf3af","content":"Selected Answer: A\\nleast priviliges"}],"answer_description":"","extracted_at":"2025-12-24T09:13:34.153Z","extraction_method":"api_direct_v1"},{"question_id":"BhiFaHBcXywFEuaHvQWn","question_number":507,"page":102,"question_text":"A developer created several AWS Lambda functions that write data to a single Amazon S3 bucket. The developer configured all the Lambda functions to send logs and metrics to Amazon CloudWatch.\\n\\nThe developer receives reports that one of the Lambda functions writes data to the bucket very slowly. The developer needs to measure the latency between the problematic Lambda function and the S3 bucket.\\n\\nWhich solution will meet this requirement?","choices":{"D":"Enable AWS X-Ray on the Lambda function. Select Amazon S3 in the latency graph to view the latency histogram.","C":"Enable CloudWatch Lambda Insights on the function. View the latency graph that CloudWatch Lambda Insights provides.","A":"Enable AWS X-Ray on the Lambda function. In the generated trace map, select the line between Lambda and Amazon S3.","B":"Query the Lambda function\u2019s log file in Amazon CloudWatch Logs Insights. Return the average of the auto-discovered @duration field."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/154534-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-01-15 08:09:00","unix_timestamp":1736924940,"discussion_count":3,"discussion":[{"upvote_count":"1","timestamp":"1747733100.0","content":"Selected Answer: A\\nOption A (AWS X-Ray trace map) is the most effective method! It enables precise measurement of latency between Lambda and S3, helping pinpoint performance issues efficiently","comment_id":"1570538","poster":"thalasi"},{"poster":"LingZ","timestamp":"1740212700.0","content":"Selected Answer: A\\nAWS X-Ray provides distributed tracing that helps you visualize the service map of your application. By enabling X-Ray on your Lambda function, you can trace its calls to external services\u2014in this case, Amazon S3. In the generated trace map, clicking the connection (or line) between the Lambda function and S3 shows you detailed timing information, including the latency for the S3 calls. This makes it possible to pinpoint where delays are occurring.","upvote_count":"2","comment_id":"1360060"},{"poster":"bp07","content":"Selected Answer: A\\nAnswer should be A. As want to trace latency between a lambda and S3bucket , not an average of latency of events between them.","comment_id":"1340708","timestamp":"1736924940.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:13:34.153Z","extraction_method":"api_direct_v1"},{"question_id":"kS7S58zce6js5Nl9WdIa","question_number":508,"page":102,"question_text":"A company\u2019s developer needs to activate Amazon CloudWatch Logs Insights for an application\u2019s AWS Lambda functions. The company uses an AWS Serverless Application Model (AWS SAM) template to deploy the application. The SAM template includes a logical resource that is named CloudWatchLogGroup.\\n\\nHow should the developer modify the SAM template to activate CloudWatch Logs Insights for the Lambda functions?","choices":{"B":"Add a parameter named CloudWatchLogGroupNamePrefix that contains a value of the application name. Reference the new parameter in the CloudWatchLogGroup resource.","C":"For each Lambda function, add the layer for the Lambda Insights extension and the CloudWatchLambdaInsightsExecutionRolePolicy AWS managed policy.","D":"For each Lambda function, set Tracing mode to Active and add the CloudWatchLambdaInsightsExecutionRolePolicy AWS managed policy.","A":"Add an output named CloudWatchinsightRule that contains a value of the Amazon Resource Name (ARN) for the CloudWatchLogGroup resource."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/303273-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-05-04 18:11:00","unix_timestamp":1746375060,"discussion_count":2,"discussion":[{"upvote_count":"1","timestamp":"1749961140.0","content":"Selected Answer: C\\nI think correct statement is \\"CloudWatch Lambda Insights\\", NOT \\"CloudWatch Logs Insights\\"","poster":"053081f","comment_id":"1577639"},{"content":"Selected Answer: C\\nCorrect answer: C.\\n\\n For each Lambda function, add the layer for the Lambda Insights extension and the CloudWatchLambdaInsightsExecutionRolePolicy AWS managed policy.\\n\\nExplanation:\\nTo enable CloudWatch Lambda Insights, you need to:\\n\\n Attach the Lambda Insights extension layer to the function.\\n\\n Ensure the function\'s IAM role has the CloudWatchLambdaInsightsExecutionRolePolicy policy.\\n\\nThis enables enhanced monitoring and insights in CloudWatch Logs Insights for Lambda.","comment_id":"1566239","poster":"vbloise","timestamp":"1746375060.0","upvote_count":"1"}],"answer_description":"","extracted_at":"2025-12-24T09:13:34.153Z","extraction_method":"api_direct_v1"},{"question_id":"ItCr2SZq482Co0qsldMa","question_number":509,"page":102,"question_text":"A developer is designing a game that stores data in an Amazon DynamoDB table. The partition key of the table is the country of the player. After a sudden increase in the number of players in a specific country, the developer notices ProvisionedThroughputExceededException errors.\\n\\nWhat should the developer do to resolve these errors?","choices":{"A":"Use strongly consistent table reads.","B":"Revise the primary key to use more unique identifiers.","D":"Use the Scan operation to retrieve the data.","C":"Use pagination to reduce the size of the items that the queries return."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/156016-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2025-02-06 08:32:00","unix_timestamp":1738827120,"discussion_count":3,"discussion":[{"upvote_count":"2","comment_id":"1566240","timestamp":"1746375240.0","content":"Selected Answer: B\\nB. Revise the primary key to use more unique identifiers.\\nExplanation:\\n\\nThe ProvisionedThroughputExceededException occurs when too many requests are made to a single partition key, which causes hot partitioning in DynamoDB. In this case, since the partition key is \\"country\\", a spike in players from a single country will overload that partition.\\n\\nTo resolve this, the developer should revise the primary key to distribute read/write traffic more evenly\u2014for example, by including a more granular identifier like a user ID along with the country (e.g., a composite key or a more randomized key structure).\\nWhy not the others:\\n\\n A. Strongly consistent reads actually require more throughput, worsening the issue.\\n\\n C. Pagination helps with large result sets but doesn\'t resolve partition throughput limits.\\n\\n D. Scan operations are less efficient and consume more throughput than queries.","poster":"vbloise"},{"content":"Selected Answer: B\\nProblema de Hot partition, resolve adicionando uma chave de parti\xe7\xe3o mais aleat\xf3ria para o DynamoDb executar consultas mais eficientes.","comment_id":"1364652","upvote_count":"1","timestamp":"1741049940.0","poster":"Dadasar"},{"poster":"e886835","timestamp":"1738827120.0","content":"Selected Answer: B\\nwhen the request rate exceeds the provisioned throughput for a specific partition key in DynamoDB. This means that the partition key (country in this case) has become a hot spot, as many players from the same country are causing an overload of requests to that partition.\\n\\nTo resolve this issue, the developer should revise the primary key to distribute the traffic more evenly","upvote_count":"3","comment_id":"1352234"}],"answer_description":"","extracted_at":"2025-12-24T09:13:34.153Z","extraction_method":"api_direct_v1"},{"question_id":"ZQwtPirAaekbjOep8Vdg","question_number":510,"page":102,"question_text":"A company is using an AWS Lambda function to process records from an Amazon Kinesis data stream. The company recently observed slow processing of the records. A developer notices that the iterator age metric for the function is increasing and that the Lambda run duration is constantly above normal.\\nWhich actions should the developer take to increase the processing speed? (Choose two.)","choices":{"B":"Decrease the timeout of the Lambda function.","A":"Increase the number of shards of the Kinesis data stream.","D":"Decrease the number of shards of the Kinesis data stream.","C":"Increase the memory that is allocated to the Lambda function.","E":"Increase the timeout of the Lambda function."},"correct_answer":"AC","answer_ET":"AC","answers_community":["AC (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103932-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 07:03:00","unix_timestamp":1679806980,"discussion_count":6,"discussion":[{"content":"Selected Answer: AC\\nA and C\\nhttps://repost.aws/knowledge-center/lambda-iterator-age","comment_id":"850732","timestamp":"1679806980.0","upvote_count":"15","poster":"Untamables"},{"content":"Selected Answer: AC\\nA) Kinesis uses shards to process data in parallel. If the data stream has a high volume of records, increasing the number of shards enables parallelism, allowing more Lambda instances to process data simultaneously\\n\\nC) Allocating more memory to a Lambda function also increases the available CPU power","upvote_count":"2","poster":"sumanshu","comment_id":"1331038","timestamp":"1735020420.0"},{"upvote_count":"2","timestamp":"1730205060.0","content":"AC\\nFor those wondering why A is correct, quote:\\nIncreasing the number of shards in a stream increases the number of concurrent Lambda functions consuming from your stream, which decreases a function\'s iterator age.","comment_id":"1304442","poster":"nbxyzd"},{"poster":"65703c1","upvote_count":"1","timestamp":"1716317040.0","content":"Selected Answer: AC\\nAC is the correct answer.","comment_id":"1215173"},{"poster":"KarBiswa","timestamp":"1702795380.0","content":"Selected Answer: AC\\nAs the lambda has no timing issue","upvote_count":"1","comment_id":"1098704"},{"timestamp":"1701084240.0","poster":"gcmrjbr","content":"CE\\nShards (option A) works on the parallelism part and not on the function\'s execution time.","upvote_count":"1","comment_id":"1081460","comments":[{"upvote_count":"2","comment_id":"1083305","timestamp":"1701249060.0","content":"A and C.\\nI would like to change my answer. More shards means more parallel processing.","poster":"gcmrjbr"}]}],"answer_description":"","extracted_at":"2025-12-24T09:13:34.153Z","extraction_method":"api_direct_v1"},{"question_id":"N6zPgbd71TqHRffbrITR","question_number":511,"page":103,"question_text":"A company needs to harden its container images before the images are in a running state. The company\'s application uses Amazon Elastic Container Registry (Amazon ECR) as an image registry. Amazon Elastic Kubernetes Service (Amazon EKS) for compute, and an AWS CodePipeline pipeline that orchestrates a continuous integration and continuous delivery (CI/CD) workflow.\\nDynamic application security testing occurs in the final stage of the pipeline after a new image is deployed to a development namespace in the EKS cluster. A developer needs to place an analysis stage before this deployment to analyze the container image earlier in the CI/CD pipeline.\\nWhich solution will meet these requirements with the MOST operational efficiency?","choices":{"B":"Create a new CodePipeline stage that occurs after the container image is built. Configure ECR basic image scanning to scan on image push. Use an AWS Lambda function as the action provider. Configure the Lambda function to check the scan results and to fail the pipeline if there are findings.","D":"Add an action to the deployment stage of the pipeline so that the action occurs before the deployment to the EKS cluster. Configure ECR basic image scanning to scan on image push. Use an AWS Lambda function as the action provider. Configure the Lambda function to check the scan results and to fail the pipeline if there are findings.","A":"Build the container image and run the docker scan command locally. Mitigate any findings before pushing changes to the source code repository. Write a pre-commit hook that enforces the use of this workflow before commit.","C":"Create a new CodePipeline stage that occurs after source code has been retrieved from its repository. Run a security scanner on the latest revision of the source code. Fail the pipeline if there are findings."},"correct_answer":"B","answer_ET":"B","answers_community":["B (83%)","D (17%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/104013-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-27 00:59:00","unix_timestamp":1679871540,"discussion_count":9,"discussion":[{"poster":"Untamables","comment_id":"851551","timestamp":"1695769140.0","upvote_count":"18","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning-basic.html\\nThe below blog post refers to the solution using Amazon Inspector and ECS, but the architecture is almost same as required in this scenario. The built in image scanning in Amazon ECR provides a simpler solution.\\nhttps://aws.amazon.com/blogs/security/use-amazon-inspector-to-manage-your-build-and-deploy-pipelines-for-containerized-applications/"},{"comment_id":"990296","poster":"love777","upvote_count":"10","content":"Selected Answer: B\\nThis approach integrates security scanning directly into the CI/CD pipeline and leverages AWS services for image scanning. Here\'s how it works:\\n\\nA new CodePipeline stage is added after the container image is built, but before it\'s pushed to Amazon ECR.\\n\\nECR basic image scanning is configured to scan the image automatically upon push. This ensures that security scanning is part of the process.\\n\\nAn AWS Lambda function is used as an action provider in the pipeline. This Lambda function can be configured to analyze the scan results of the image.\\n\\nIf the Lambda function detects any security findings in the scan results, it can fail the pipeline, preventing the deployment of images with security vulnerabilities.","timestamp":"1708891200.0"},{"comment_id":"1331055","timestamp":"1735028940.0","poster":"sumanshu","content":"Selected Answer: B\\nC) Eliminated - Scanning the source code directly does not analyze vulnerabilities specific to the container image\\n\\nD) Eliminated - Adding the scan at the deployment stage is too late in the pipeline. It defeats the purpose of early detection and could allow vulnerable images to proceed further in the pipeline before being flagged","upvote_count":"2"},{"poster":"trieudo","timestamp":"1734252180.0","upvote_count":"1","comment_id":"1326756","content":"Selected Answer: B\\nB vs D:\\n\\nB: scan before pushing ECR (after the container image is built)\\nD: scan after pushing ECR (before the deployment to the EKS cluster)"},{"upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215176","timestamp":"1732222140.0","poster":"65703c1"},{"comment_id":"985137","poster":"ninomfr64","content":"Selected Answer: B\\nB as per https://docs.aws.amazon.com/amplify/latest/userguide/running-tests.html\\nYou can run end-to-end (E2E) tests in the test phase of your Amplify app to catch regressions before pushing code to production. The test phase can be configured in the build specification YAML. Currently, you can run only the Cypress testing framework during a build.\\n\\nbuild specification is provided in the amplify.yml file","upvote_count":"2","timestamp":"1708348200.0"},{"timestamp":"1700851440.0","upvote_count":"5","poster":"imvb88","comments":[{"timestamp":"1701955620.0","content":"The question states \\"A developer needs to place an analysis stage\\" therefore I\'d go with B.","upvote_count":"4","comment_id":"917154","poster":"Toby_S"}],"comment_id":"906051","content":"Selected Answer: D\\nSo it narrows down to option B and D which using ECR basic image scanning. \\nB: create a stage \\nD: add an action to the existing stage \\n\\nI\'d go with D since executing an additional action will be faster than executing a whole stage."},{"comment_id":"877249","poster":"Rpod","comments":[{"timestamp":"1706365320.0","content":"ChatGPT says option B","comment_id":"964695","upvote_count":"1","poster":"Umman"}],"content":"Selected Answer: D\\nChat GPT says D","timestamp":"1697976540.0","upvote_count":"3"},{"timestamp":"1697636100.0","comment_id":"873670","content":"Selected Answer: B\\nThe developer should choose option B. Create a new CodePipeline stage that occurs after the container image is built. Configure ECR basic image scanning to scan on image push. Use an AWS Lambda function as the action provider. Configure the Lambda function to check the scan results and to fail the pipeline if there are findings. This will allow the developer to place an analysis stage before deployment to analyze the container image earlier in the CI/CD pipeline with the most operational efficiency. \\nCHATGPT","poster":"MrTee","upvote_count":"5"}],"answer_description":"","extracted_at":"2025-12-24T09:13:45.235Z","extraction_method":"api_direct_v1"},{"question_id":"IeNSyw5fv1possim6u6w","question_number":512,"page":103,"question_text":"A developer is testing a new file storage application that uses an Amazon CloudFront distribution to serve content from an Amazon S3 bucket. The distribution accesses the S3 bucket by using an origin access identity (OAI). The S3 bucket\'s permissions explicitly deny access to all other users.\\nThe application prompts users to authenticate on a login page and then uses signed cookies to allow users to access their personal storage directories. The developer has configured the distribution to use its default cache behavior with restricted viewer access and has set the origin to point to the S3 bucket. However, when the developer tries to navigate to the login page, the developer receives a 403 Forbidden error.\\nThe developer needs to implement a solution to allow unauthenticated access to the login page. The solution also must keep all private content secure.\\nWhich solution will meet these requirements?","choices":{"B":"Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to *, and make viewer access restricted. Change the default cache behavior\'s path pattern to the path of the login page, and make viewer access unrestricted.","C":"Add a second origin as a failover origin to the default cache behavior. Point the failover origin to the S3 bucket. Set the path pattern for the primary origin to *, and make viewer access restricted. Set the path pattern for the failover origin to the path of the login page, and make viewer access unrestricted.","D":"Add a bucket policy to the S3 bucket to allow read access. Set the resource on the policy to the Amazon Resource Name (ARN) of the login page object in the S3 bucket. Add a CloudFront function to the default cache behavior to redirect unauthorized requests to the login page\'s S3 URL.","A":"Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to the path of the login page, and make viewer access unrestricted. Keep the default cache behavior\'s settings unchanged."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/104014-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-27 01:24:00","unix_timestamp":1679873040,"discussion_count":8,"discussion":[{"content":"Selected Answer: A\\nA\\nIf you create additional cache behaviors, the default cache behavior is always the last to be processed.\\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesCacheBehavior","timestamp":"1695770640.0","poster":"Untamables","comment_id":"851562","upvote_count":"12"},{"content":"Selected Answer: A\\nA) Adding a second cache behavior allows you to define specific rules for the login page while keeping the default settings for private content unchanged.\\n\\nB) Eliminated - Changing the default cache behavior to allow unrestricted access to the login page affects other private content, potentially compromising security.\\n\\nD) Eliminated - Adding a bucket policy to allow public access to the login page directly contradicts the requirement to use CloudFront for secure content delivery.","timestamp":"1735032360.0","upvote_count":"2","comment_id":"1331066","poster":"sumanshu"},{"upvote_count":"1","poster":"65703c1","comment_id":"1215179","timestamp":"1732222320.0","content":"Selected Answer: A\\nA is the correct answer."},{"poster":"ShinobiGrappler","timestamp":"1718804280.0","upvote_count":"1","content":"Answer is A. --The original way the developer had designed this application was too restrictive and didn\'t allow someone to even authenticate to get a signed cookie. By caching the second behavior, it allows the person authenticating to retrieve a cookie to access their personal data.","comment_id":"1100762"},{"poster":"LR2023","timestamp":"1717363620.0","content":"D cloud front function acts as lamda function","upvote_count":"1","comment_id":"1086467"},{"comment_id":"985148","upvote_count":"2","content":"Selected Answer: A\\nB) you cannot override the path pattern of the default Cache behavior\\nC) the origin failover is used when the primary origin is not available, this is not our case\\nD) with this configuration I think users wil get 403 Forbidden error and then redirected to the login page\'s S3 URL\\n\\nA is a workable approach in my opinion","poster":"ninomfr64","timestamp":"1708349220.0"},{"poster":"Harddiver","content":"Should it be D? In case s3 bucket restricts permissions, those should be open for login.","timestamp":"1702278960.0","comment_id":"920427","upvote_count":"3"},{"poster":"MrTee","timestamp":"1698202680.0","upvote_count":"3","content":"Selected Answer: A\\nBy adding a second cache behavior with unrestricted viewer access to the login page\'s path pattern, unauthenticated users will be allowed to access the login page. At the same time, the default cache behavior\'s settings remain unchanged, and private content remains secure because it still requires signed cookies for access.","comment_id":"879841"}],"answer_description":"","extracted_at":"2025-12-24T09:13:45.235Z","extraction_method":"api_direct_v1"},{"question_id":"9j8hMMjN6A6qqetw0tHp","question_number":513,"page":103,"question_text":"A developer is using AWS Amplify Hosting to build and deploy an application. The developer is receiving an increased number of bug reports from users. The developer wants to add end-to-end testing to the application to eliminate as many bugs as possible before the bugs reach production.\\nWhich solution should the developer implement to meet these requirements?","choices":{"A":"Run the amplify add test command in the Amplify CLI.","C":"Add a test phase to the amplify.yml build settings for the application.","B":"Create unit tests in the application. Deploy the unit tests by using the amplify push command in the Amplify CLI.","D":"Add a test phase to the aws-exports.js file for the application."},"correct_answer":"C","answer_ET":"C","answers_community":["C (91%)","9%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/104015-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-27 01:32:00","unix_timestamp":1679873520,"discussion_count":10,"discussion":[{"poster":"gpt_test","content":"Selected Answer: C\\nExplanation: Adding a test phase to the amplify.yml build settings allows the developer to define and execute end-to-end tests as part of the build and deployment process in AWS Amplify Hosting. This will help ensure that bugs are caught and fixed before the application reaches production, improving the overall quality of the application.","upvote_count":"17","timestamp":"1680565740.0","comment_id":"860469"},{"comments":[{"upvote_count":"2","content":"ton of thanks !!\\ndocument commented \'End to End Test\'","poster":"jipark","timestamp":"1690710840.0","comment_id":"967017"}],"content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/amplify/latest/userguide/running-tests.html","poster":"Untamables","upvote_count":"10","comment_id":"851565","timestamp":"1679873520.0"},{"comment_id":"1364040","content":"Selected Answer: C\\nA. Eliminado: Esse comando n\xe3o existe na Amplify CLI. O Amplify n\xe3o tem um comando direto para adicionar testes, ent\xe3o essa alternativa est\xe1 errada.\\nB. Eliminado: Testes unit\xe1rios s\xe3o importantes, mas eles n\xe3o s\xe3o testes de ponta a ponta (E2E). Al\xe9m disso, amplify push serve para implantar mudan\xe7as na infraestrutura, n\xe3o para rodar testes.\\nD. Eliminado: O arquivo aws-exports.js cont\xe9m configura\xe7\xf5es do Amplify para conectar o front-end aos servi\xe7os da AWS. Ele n\xe3o \xe9 usado para definir fases de teste.\\nPortanto, a melhor solu\xe7\xe3o \xe9 a alternativa C, pois ela permite adicionar testes ao processo de build e evitar que bugs cheguem \xe0 produ\xe7\xe3o.","poster":"Dadasar","timestamp":"1740933780.0","upvote_count":"1"},{"comment_id":"1364039","poster":"Dadasar","upvote_count":"1","content":"Selected Answer: C\\nA. Eliminado: Esse comando n\xe3o existe na Amplify CLI. O Amplify n\xe3o tem um comando direto para adicionar testes, ent\xe3o essa alternativa est\xe1 errada.\\nB. Eliminado: Testes unit\xe1rios s\xe3o importantes, mas eles n\xe3o s\xe3o testes de ponta a ponta (E2E). Al\xe9m disso, amplify push serve para implantar mudan\xe7as na infraestrutura, n\xe3o para rodar testes.\\nD. Eliminado: O arquivo aws-exports.js cont\xe9m configura\xe7\xf5es do Amplify para conectar o front-end aos servi\xe7os da AWS. Ele n\xe3o \xe9 usado para definir fases de teste.\\nPortanto, a melhor solu\xe7\xe3o \xe9 a alternativa C, pois ela permite adicionar testes ao processo de build e evitar que bugs cheguem \xe0 produ\xe7\xe3o.","timestamp":"1740933720.0"},{"upvote_count":"2","comment_id":"1331068","timestamp":"1735032960.0","poster":"sumanshu","content":"Selected Answer: C\\nTo implement end-to-end (E2E) testing before deployment, you can add a test phase to the amplify.yml file. \\n\\nA) Eliminated - Amplify CLI does not have a command named amplify add test."},{"poster":"tsangckl","comment_id":"1231694","content":"This appear at 17 Jun exam","upvote_count":"1","timestamp":"1718595600.0"},{"comment_id":"1215180","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","timestamp":"1716317640.0","poster":"65703c1"},{"poster":"ninomfr64","comment_id":"985138","upvote_count":"1","timestamp":"1692443460.0","content":"Selected Answer: B\\nB as per https://docs.aws.amazon.com/amplify/latest/userguide/running-tests.html\\nYou can run end-to-end (E2E) tests in the test phase of your Amplify app to catch regressions before pushing code to production. The test phase can be configured in the build specification YAML. Currently, you can run only the Cypress testing framework during a build.\\n\\nbuild specification is provided in the amplify.yml file"},{"timestamp":"1689959640.0","comment_id":"958741","content":"Selected Answer: B\\nI\'LL GO WITH B","upvote_count":"1","poster":"SachinR28"},{"poster":"rlnd2000","upvote_count":"1","comment_id":"904402","timestamp":"1684795080.0","content":"Selected Answer: B\\nWe can use amplify.yml file to run any test commands at build time. Since the test must run while the program is being deployed (E2E) I\'ll go with B."}],"answer_description":"","extracted_at":"2025-12-24T09:13:45.235Z","extraction_method":"api_direct_v1"},{"question_id":"0F6xTB4WKgyMeBVsslmH","question_number":514,"page":103,"question_text":"A developer is creating an AWS CloudFormation template to deploy Amazon EC2 instances across multiple AWS accounts. The developer must choose the EC2 instances from a list of approved instance types.\\nHow can the developer incorporate the list of approved instance types in the CloudFormation template?","choices":{"C":"In the CloudFormation template, create a separate parameter for each EC2 instance type in the list.","D":"In the CloudFormation template, create a parameter with the list of EC2 instance types as AllowedValues.","B":"In the Resources section of the CloudFormation template, create resources for each EC2 instance type in the list.","A":"Create a separate CloudFormation template for each EC2 instance type in the list."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102784-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 09:59:00","unix_timestamp":1678957140,"discussion_count":16,"discussion":[{"poster":"Bibay","comments":[{"content":"quite much clear explanation !!!","poster":"jipark","comment_id":"971608","timestamp":"1691113740.0","upvote_count":"2"}],"content":"Selected Answer: D\\nOption D is the correct answer. In the CloudFormation template, the developer should create a parameter with the list of approved EC2 instance types as AllowedValues. This way, users can select the instance type they want to use when launching the CloudFormation stack, but only from the approved list.\\n\\nOption A is not a scalable solution as it requires creating a separate CloudFormation template for each EC2 instance type, which can become cumbersome and difficult to manage as the number of approved instance types grows.\\n\\nOption B is not necessary as creating resources for each EC2 instance type in the list would not enforce the requirement to choose only from the approved list. It would also increase the complexity of the template and make it difficult to manage.\\n\\nOption C is not ideal as it would require creating a separate parameter for each EC2 instance type, which can become difficult to manage as the number of approved instance types grows. Also, it does not enforce the requirement to choose only from the approved list.","upvote_count":"28","timestamp":"1683371760.0","comment_id":"890697"},{"timestamp":"1683390180.0","comment_id":"890865","content":"Got this question in exam.Correct answer is D.","poster":"geekdamsel","upvote_count":"8"},{"poster":"anandkg","timestamp":"1744822920.0","content":"Selected Answer: D\\nlist is the solution","comment_id":"1561185","upvote_count":"1"},{"upvote_count":"1","comment_id":"1329520","timestamp":"1734706920.0","poster":"sumanshu","content":"Selected Answer: D\\nA) Eliminated - higher maintenance overhead for maintaining multiple templates\\nB) Eliminated - This would create multiple EC2 instances unnecessarily, which does not align with the requirement to choose a single instance type from a list."},{"timestamp":"1733916120.0","upvote_count":"1","content":"Selected Answer: D\\n==> Discard A: duplicate code, hard to maintain\\n==> Discard B: all resource wil be created instead of it is neccessary or not\\n==> Discard C: multiple param ==> when have larger param count, hard to maintain\\n\\nD for dynamic for fixed parameter ==> most generic","poster":"trieudo","comment_id":"1324997"},{"poster":"LocNV","content":"Selected Answer: D\\nParameters:\\n InstanceType:\\n Type: String\\n Default: \'t2.micro\'\\n AllowedValues:\\n - \'t2.micro\'\\n - \'t2.small\'\\n - \'t2.medium\'\\n - \'t3.micro\'\\n - \'t3.small\'\\n - \'t3.medium\'\\n Description: \'Select the EC2 instance type for deployment.\'\\n\\nResources:\\n MyEC2Instance:\\n Type: \'AWS::EC2::Instance\'\\n Properties:\\n ImageId: ami-12345678\\n InstanceType: !Ref InstanceType","comment_id":"1110346","timestamp":"1727238060.0","upvote_count":"4"},{"timestamp":"1718690940.0","comment_id":"1232273","poster":"MessiVN","content":"Selected Answer: D\\nD is correct","upvote_count":"1"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","poster":"65703c1","comment_id":"1214954","timestamp":"1716296100.0"},{"timestamp":"1712440620.0","content":"Selected Answer: D\\nCorrecta D. Con este par\xe1metro se permite dar permisos de elegir el tipo de instancia.","upvote_count":"1","poster":"vinfo","comment_id":"1190634"},{"upvote_count":"1","poster":"apa_1","content":"Selected Answer: D\\noption D is correct","comment_id":"1183979","timestamp":"1711533300.0"},{"comment_id":"1086520","timestamp":"1701568380.0","upvote_count":"1","content":"Selected Answer: D\\nD is correct","poster":"payireb682"},{"content":"Selected Answer: D\\nD is the correct, because you are restricting the possible options to that parameter","timestamp":"1700092080.0","comment_id":"1072016","upvote_count":"1","poster":"leonardoliveros"},{"upvote_count":"1","timestamp":"1688070000.0","content":"Why B instead of C? Each AWS SDK implements retry logic automatically. Most AWS SDKs now support exponential backoff and jitter as part of their retry behavior\\nThen D to increase capacity https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TroubleshootingThrottling.html\\nC&D","comments":[{"poster":"Pupina","content":"This answer is for question 7 not 6","timestamp":"1688070120.0","upvote_count":"1","comment_id":"938552"}],"poster":"Pupina","comment_id":"938549"},{"upvote_count":"4","content":"Selected Answer: D\\nD looks about right","comment_id":"863314","poster":"NanaDanso","timestamp":"1680814080.0"},{"content":"It should be D","poster":"prabhay786","upvote_count":"4","timestamp":"1679308440.0","comment_id":"844757"},{"poster":"aragon_saa","upvote_count":"3","comment_id":"840719","timestamp":"1678957140.0","content":"D\\nhttps://www.examtopics.com/discussions/amazon/view/88788-exam-aws-certified-developer-associate-topic-1-question-343/"}],"answer_description":"","extracted_at":"2025-12-24T09:13:45.235Z","extraction_method":"api_direct_v1"},{"question_id":"hMxGntHSZXyhhpRSDzYH","question_number":515,"page":103,"question_text":"An ecommerce company is using an AWS Lambda function behind Amazon API Gateway as its application tier. To process orders during checkout, the application calls a POST API from the frontend. The POST API invokes the Lambda function asynchronously. In rare situations, the application has not processed orders. The Lambda application logs show no errors or failures.\\nWhat should a developer do to solve this problem?","choices":{"D":"Make sure that caching is disabled for the POST API in API Gateway.","C":"Inspect the Lambda logs in Amazon CloudWatch for possible errors. Fix the errors.","B":"Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.","A":"Inspect the frontend logs for API failures. Call the POST API manually by using the requests from the log file."},"correct_answer":"B","answer_ET":"B","answers_community":["B (57%)","A (28%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103807-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-24 23:59:00","unix_timestamp":1679698740,"discussion_count":21,"discussion":[{"content":"Selected Answer: B\\nExplanation: By configuring a dead-letter queue (DLQ) for the Lambda function, you can capture asynchronous invocation events that were not successfully processed. This allows you to troubleshoot the failed functions and reprocess the events, ensuring that orders are not missed. The DLQ will hold information about the failed events, allowing you to analyze and resolve the issue.","upvote_count":"13","comment_id":"860466","poster":"gpt_test","timestamp":"1680565560.0","comments":[{"comment_id":"893090","content":"as you said \\"... events that were not successfully processed.\\" but there is not failure in Lambda log, so the lambda was not invoked by the POST API event. B is id not the answer.","comments":[{"poster":"kavi00203","comment_id":"923751","content":"Its an asynchronous invocation events, that\'s y there is no log.\\nBecause in asynchronous its not mandatory to get the result after invocation events.","comments":[{"timestamp":"1690412520.0","comment_id":"964212","upvote_count":"5","content":"Asynchronous invocation means that the caller of the lambda does not wait for a response. The type of invocation has no effect on the lambda having logs or not. I picked A, because the lambda not having logs suggests something\u2019s gone wrong upstream of the lambda.","poster":"TeeTheMan"}],"timestamp":"1686808200.0","upvote_count":"2"}],"poster":"rlnd2000","upvote_count":"5","timestamp":"1683636000.0"}]},{"upvote_count":"12","poster":"Untamables","comments":[{"timestamp":"1706716800.0","poster":"konieczny69","comment_id":"1136943","content":"Read it carefully: \\"The Lambda application logs show no errors or failures\\"\\nThere are logs, so the lambda was called\\n\\nanswer B","upvote_count":"1"}],"comment_id":"851579","timestamp":"1679875140.0","content":"Selected Answer: A\\nA\\nThe Lambda function might have not been called since the Lambda logs show no errors or failures. The cause might be that the frontend application does not call the API or an error occurs in the API Gateway processing."},{"poster":"Dadasar","comment_id":"1364042","timestamp":"1740934200.0","upvote_count":"1","content":"Selected Answer: B\\nA.Eliminada: O problema ocorre no backend (Lambda), e n\xe3o no frontend. Como a invoca\xe7\xe3o \xe9 ass\xedncrona, o frontend n\xe3o tem controle sobre falhas no processamento.\\nC. Eliminada: J\xe1 foi mencionado que os logs do Lambda n\xe3o mostram erros ou falhas, ent\xe3o apenas inspecionar os logs do CloudWatch n\xe3o ajudaria a encontrar a causa do problema.\\nD. Eliminada: O cache no API Gateway n\xe3o afeta requisi\xe7\xf5es POST, pois o cache s\xf3 \xe9 aplicado para m\xe9todos GET. Ent\xe3o essa alternativa n\xe3o faz sentido."},{"content":"Selected Answer: B\\nsince there are no logs of errors or failures, the issue is likely due to dropped asynchronous events. Configuring a DLQ will capture these dropped events for further analysis and reprocessing.\\n\\nA) Eliminated - While inspecting frontend logs can help diagnose client-side issues, the problem here involves unprocessed events in Lambda.\\n\\nC) Eliminated - The question states that there are no errors or failures in the Lambda logs\\n\\nD) Eliminated - API Gateway caching is not related to this issue. Even with caching enabled, events would still invoke the Lambda function.","timestamp":"1735033320.0","poster":"sumanshu","comment_id":"1331069","upvote_count":"3"},{"upvote_count":"1","poster":"mallikarjun_angadi","comment_id":"1312495","timestamp":"1731660720.0","content":"Answer : B\\nLambda has a concurrency limit and in some cases, if the limit is reached, Lambda could throttle incoming requests without throwing an error, which means some invocations may be lost or delayed. Those will be moved to DLQ"},{"timestamp":"1730251560.0","upvote_count":"1","content":"Selected Answer: B\\nOption A is obviously wrong. Remember, it\'s an asynchronous labmda, so replaying the POST API returns no info instrumental to issue diagnosis. If you know how AWS usually designs a quiz, you\'ll know B is definitely the answer.","comment_id":"1304798","poster":"nbxyzd"},{"upvote_count":"1","poster":"65703c1","timestamp":"1716317880.0","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215183"},{"comment_id":"1098910","poster":"KarBiswa","timestamp":"1702817760.0","upvote_count":"1","content":"Selected Answer: B\\nhttps://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-dead-letter-queues/"},{"upvote_count":"1","timestamp":"1698366780.0","content":"Selected Answer: B\\nB. Crie e inspecione a fila de mensagens mortas do Lambda. Solucione os problemas das fun\xe7\xf5es com falha. Reprocesse os eventos. Mais Votados","comment_id":"1055004","poster":"Jonalb"},{"timestamp":"1697105640.0","comments":[{"poster":"daicoso","comment_id":"1044452","upvote_count":"1","timestamp":"1697406480.0","content":"if the application code doesn\'t log errors and doesn\'t throw exceptions, no error or failure will be logged"}],"poster":"mr_swal","comment_id":"1041653","upvote_count":"1","content":"Selected Answer: A\\nThe Lambda application logs show no errors or failures. - So Lambda function was not invoked at all"},{"poster":"nmc12","content":"Selected Answer: B\\nThe Lambda Dead Letter Queue is a feature that helps in troubleshooting events that failed processing by a Lambda function. When an asynchronous invocation of a Lambda function fails, AWS Lambda can direct the failed event to an Amazon SNS topic or an Amazon SQS queue (the dead-letter queue), where the event is stored and can be analyzed or reprocessed.","comment_id":"1023039","upvote_count":"1","timestamp":"1696245540.0"},{"timestamp":"1695369480.0","content":"Selected Answer: C\\nI don\'t like B which has reprocess the errors, which will make a whole load of errors be process creating orders which could be months old","upvote_count":"3","comment_id":"1013789","poster":"norris81"},{"timestamp":"1694336640.0","upvote_count":"1","poster":"misa27","comment_id":"1003851","content":"Selected Answer: B\\nB\\nhttps://aws.amazon.com/what-is/dead-letter-queue/"},{"content":"Selected Answer: B\\nA) asynchronous invocations doe not return result to the caller, thus I do not expect errors in frontend log\\nC) the scenario question rules out the option to have error messages in the Lambda log\\nD) I do not see how caching can have impact in this scenario\\n\\nB) having a dead-letter queue is a viable option to troubleshoot asynchronous lambda invocation error, another option would be using Destination","upvote_count":"1","poster":"ninomfr64","timestamp":"1692445200.0","comment_id":"985156"},{"poster":"backfringe","comment_id":"964283","timestamp":"1690424820.0","upvote_count":"2","content":"Selected Answer: C\\nOption C is the appropriate choice because it involves inspecting the Lambda logs in Amazon CloudWatch to identify any potential issues or errors that might be causing the orders not to be processed\\n\\nOption B is not the most appropriate choice because the dead-letter queue is generally used to capture events that cannot be processed by a Lambda function. In this scenario, it seems that the Lambda function is executing without apparent errors. Thus, the issue might not be related to dead-letter queue failures."},{"comments":[{"content":"Caching is only for GET Requests not for POST Requests. Correct answer is B","poster":"Saurabh04","timestamp":"1723860360.0","upvote_count":"2","comment_id":"1267407"},{"content":"Absolutely agree, D is the answer","comment_id":"1104572","poster":"xdkonorek2","upvote_count":"1","timestamp":"1703419980.0"}],"upvote_count":"3","timestamp":"1690354860.0","content":"Selected Answer: D\\nI think D should be the correct answer to this question. The logs have no indications of errors or failed events, so if some transactions are not being processed, that probably means that the lambda function wasn\'t invoked for those calls. One reason could be that caching is enabled in API gateway for the POST request, so the lambda function isn\'t triggered for any cache hits.\\n\\n- A is not correct as the frontend would be getting 202s for all asynchronous post requests.\\n- B is not correct because lambda logs have no errors => no lambda execution errors => DLQ won\'t get any requests of interest if we enable it. A comment below mentioned that asynchronous lambda invocations don\'t generate logs, but that is not true.\\n- C is obviously incorrect. The premise explicitly mentions that there aren\'t any errors in the logs.","comment_id":"963472","poster":"redfivedog"},{"upvote_count":"1","content":"https://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-dead-letter-queues/","timestamp":"1687851300.0","comment_id":"935108","poster":"gomurali"},{"comments":[{"poster":"rn5357","comment_id":"1007220","timestamp":"1694669160.0","upvote_count":"1","content":"How can you tell from this context that the POST API call was successful?"}],"upvote_count":"3","content":"Selected Answer: B\\nIt\'s B. Apparently C & D are wrong. \\n\\nAlso it\'s not A because the call is async. Meaning that the response code from the lambda service is 202. Since generally frontend can make POST requests, the problem should be visible somewhere in the backed. Dead-letter queues are for debugging and further analysis. Hence should be B.","comment_id":"915403","poster":"csG13","timestamp":"1685965740.0"},{"poster":"Nagendhar","upvote_count":"3","content":"Ans: B\\n\\nB. Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.\\n\\nSince the Lambda application logs show no errors or failures, it is possible that the asynchronous invocation is not being processed successfully. In this case, the best solution would be to inspect the Lambda dead-letter queue, which stores failed asynchronous invocations. By doing this, the developer can troubleshoot any failed functions and reprocess the events.","comment_id":"896012","timestamp":"1683903840.0"},{"upvote_count":"2","content":"Selected Answer: A\\nB is wrong, if send to DLQ, there should be failed and try logs for lambda before sending to DLQ","timestamp":"1679724180.0","poster":"clarksu","comment_id":"849825"},{"poster":"Dun6","upvote_count":"4","content":"Selected Answer: B\\nUse DLQ","comment_id":"849662","timestamp":"1679698740.0"}],"answer_description":"","extracted_at":"2025-12-24T09:13:45.235Z","extraction_method":"api_direct_v1"},{"question_id":"n1WHxVdmZ5JymLhx5mOX","question_number":516,"page":104,"question_text":"A company is building a web application on AWS. When a customer sends a request, the application will generate reports and then make the reports available to the customer within one hour. Reports should be accessible to the customer for 8 hours. Some reports are larger than 1 MB. Each report is unique to the customer. The application should delete all reports that are older than 2 days.\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"B":"Generate the reports and then store the reports in an Amazon S3 bucket that uses server-side encryption. Attach the reports to an Amazon Simple Notification Service (Amazon SNS) message. Subscribe the customer to email notifications from Amazon SNS.","D":"Generate the reports and then store the reports in an Amazon RDS database with a date stamp. Generate an URL that retrieves the reports from the RDS database. Provide the URL to customers through the web application. Schedule an hourly AWS Lambda function to delete database records that have expired date stamps.","A":"Generate the reports and then store the reports as Amazon DynamoDB items that have a specified TTL. Generate a URL that retrieves the reports from DynamoDB. Provide the URL to customers through the web application.","C":"Generate the reports and then store the reports in an Amazon S3 bucket that uses server-side encryption. Generate a presigned URL that contains an expiration date Provide the URL to customers through the web application. Add S3 Lifecycle configuration rules to the S3 bucket to delete old reports."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103904-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-25 23:52:00","unix_timestamp":1679784720,"discussion_count":9,"discussion":[{"upvote_count":"15","poster":"gpt_test","content":"Selected Answer: C\\nExplanation: Storing the reports in an Amazon S3 bucket provides a cost-effective and scalable solution for handling files larger than 1 MB. Server-side encryption ensures data security. Generating a presigned URL with an expiration date allows the customer to access the report for 8 hours, and S3 Lifecycle configuration rules automatically delete the reports older than 2 days, reducing operational overhead.","comment_id":"860463","timestamp":"1696376640.0"},{"upvote_count":"8","comment_id":"850532","content":"Selected Answer: C\\nPresigned URL","poster":"March2023","timestamp":"1695675120.0"},{"poster":"sumanshu","comment_id":"1331074","upvote_count":"1","timestamp":"1735034160.0","comments":[{"poster":"sumanshu","upvote_count":"1","content":"B) Eliminated - Attaching reports to SNS messages is impractical because SNS is not designed for large file attachments.","comment_id":"1331075","timestamp":"1735034220.0"}],"content":"Selected Answer: C\\nS3 Lifecycle rules can automatically delete objects after 2 days, reducing operational overhead by eliminating the need for custom cleanup logic\\n\\nA) Eliminated - DynamoDB is not designed to store large objects (e.g., reports larger than 1 MB).\\n\\nD) Eliminated - Storing large reports in a relational database like RDS is inefficient and costly compared to S3."},{"comment_id":"1215313","poster":"65703c1","timestamp":"1732244040.0","content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1"},{"content":"Selected Answer: C\\nThe 1MB condition denies the TTL option so C is best","poster":"KarBiswa","upvote_count":"2","comment_id":"1098916","timestamp":"1718622180.0"},{"timestamp":"1717364820.0","content":"C\\npresigned and lifecycle rules to move","upvote_count":"1","poster":"LR2023","comment_id":"1086477"},{"upvote_count":"6","timestamp":"1708351380.0","poster":"ninomfr64","comment_id":"985168","content":"A) DynamoDB cannot store object larger than 400K\\nB) SNS cannot send email with attachment - https://repost.aws/questions/QUOvaKJVb3QzOqVENONBZUag/sns-send-file-attachment\\nD) the nature or format of the report is not specified, however RDS doent look like a great place to store large document file. Also generating a url to the reports from the RDS database requires some work while it is a native capabilities in S3\\n\\nC) is a workable solution as S3 is designed to store file objects, it allows to easily generate pre-signed url, and provide lifecycle management rule that allows to expire objects"},{"upvote_count":"5","poster":"imvb88","timestamp":"1700854980.0","content":"Selected Answer: C\\nDynamo DB cannot store object > 400KB -> option A is out immediately. \\nLimited access to S3 calls for presigned URL which is option C. C also has lifecycle config to delete old object while B does not have that. \\nD is possible but too much effort compared to design pattern in C.","comment_id":"906073"},{"upvote_count":"5","comment_id":"851582","poster":"Untamables","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html","timestamp":"1695773400.0"}],"answer_description":"","extracted_at":"2025-12-24T09:13:56.375Z","extraction_method":"api_direct_v1"},{"question_id":"b6z5ZnbpS7k1CUgEq5VT","question_number":517,"page":104,"question_text":"A company has deployed an application on AWS Elastic Beanstalk. The company has configured the Auto Scaling group that is associated with the Elastic Beanstalk environment to have five Amazon EC2 instances. If the capacity is fewer than four EC2 instances during the deployment, application performance degrades. The company is using the all-at-once deployment policy.\\nWhat is the MOST cost-effective way to solve the deployment issue?","choices":{"C":"Change the deployment policy to rolling with additional batch. Specify a batch size of 1.","A":"Change the Auto Scaling group to six desired instances.","B":"Change the deployment policy to traffic splitting. Specify an evaluation time of 1 hour.","D":"Change the deployment policy to rolling. Specify a batch size of 2."},"correct_answer":"C","answer_ET":"C","answers_community":["C (95%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/104016-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-27 02:20:00","unix_timestamp":1679876400,"discussion_count":9,"discussion":[{"poster":"gpt_test","content":"Selected Answer: C\\nExplanation: The rolling with additional batch deployment policy allows Elastic Beanstalk to launch additional instances in a new batch before terminating the old instances. In this case, specifying a batch size of 1 means that Elastic Beanstalk will deploy the application updates to 1 new instance at a time, ensuring that there are always at least 4 instances available during the deployment process. This method maintains application performance while minimizing the additional cost.","comment_id":"860462","upvote_count":"19","timestamp":"1696376580.0"},{"content":"Selected Answer: C\\n1. Rolling with additional batch deployment: This type of deployment maintains full capacity while new application versions are deployed. It launches a new batch of instances with the new application version, and if the new batch is healthy, it terminates a batch of instances running the old application version.\\n\\n2. Batch size of 1: This will ensure that one new instance is launched with the new version of the application. Once it is deemed healthy, one of the old instances will be terminated. This will continue until all instances are running the new version, ensuring the capacity is never less than four instances. This approach will add only a minimal additional cost for the temporary overlapping instances during deployment.","upvote_count":"13","poster":"gagol14","timestamp":"1702984260.0","comment_id":"927329"},{"timestamp":"1735035000.0","comments":[{"timestamp":"1735035120.0","content":"C) Batch Size of 1: Specifies that only one instance will be updated at a time, minimizing downtime and maintaining the required instance capacity for performance.\\n\\nRolling with additional Batch - This deployment strategy adds an extra batch of EC2 instances during deployment. After updating one batch, the additional instances are terminated, ensuring cost efficiency.","comment_id":"1331078","poster":"sumanshu","upvote_count":"1"}],"content":"Selected Answer: C\\nA) Eliminated - Permanently increasing the desired capacity to six EC2 instances incurs unnecessary ongoing costs.\\n\\nB) Eliminated - Traffic splitting is primarily used for canary testing or gradual traffic shifting. It does not guarantee maintaining the desired instance capacity during deployment.\\n\\nD) Eliminated - A rolling deployment with a batch size of 2 means two instances are replaced at a time. With a fixed capacity of 5 instances, this would temporarily reduce the number of running instances to 3, causing performance degradation.","upvote_count":"2","poster":"sumanshu","comment_id":"1331077"},{"poster":"65703c1","timestamp":"1732244400.0","upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","comment_id":"1215316"},{"poster":"Alearn","comment_id":"1104688","upvote_count":"2","content":"Selected Answer: D\\nOption D is the best solution because it allows the company to update the application without losing service or reducing availability significantly, and without increasing the cost or complexity of the solution.","timestamp":"1719235620.0","comments":[{"content":"the requirement is not to go below 4 instances. Option D specifies a batch size of 2 which would lead to 3 running instances. The correct option is C","upvote_count":"1","poster":"poklakni","comment_id":"1197052","timestamp":"1729148700.0","comments":[{"content":"@Alern - option D mentioned: Option D only mentions \\"Rolling\\" and not \\"Rolling with Additional Batch...\\n\\nIf it;s mentioned Rolling with Additional Batch - Then \\"D\\" is the answer and fastest...","poster":"sumanshu","comment_id":"1350595","upvote_count":"1","comments":[{"upvote_count":"1","content":"Even if it mentions rolling with additional batches, D would still not be the correct answer. The question asks what is the MOST COST EFFECTIVE way, rolling with additional batch of 2 means the instance count goes to 6 at some moments as opose to the 5 in option C, which makes it still more cost effective","timestamp":"1741368900.0","comment_id":"1366341","poster":"Shamalka"}],"timestamp":"1738519560.0"}]}]},{"comment_id":"1098929","timestamp":"1718622600.0","poster":"KarBiswa","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","upvote_count":"2"},{"content":"Selected Answer: C\\nThe correct answer is: C","poster":"quangphungdev218","timestamp":"1706519220.0","upvote_count":"1","comment_id":"966192"},{"comments":[{"upvote_count":"2","poster":"nmc12","comment_id":"1023091","timestamp":"1712061540.0","content":"If batch size of 1:\\nDuring the time the new instances are being deployed and are not yet in service, there are only 5 - 2 = 3 old instances available to serve the traffic, which violates the requirement to maintain at least 4 instances to avoid performance degradation.\\nso, i go with A answer."},{"poster":"jipark","timestamp":"1706708700.0","comment_id":"968036","content":"C: cost 1 additional EC2\\nD : degrade performance\\nit looks exam gave key \\"2 batch\\" meaning - do not choose this answer.","upvote_count":"1"}],"timestamp":"1701979980.0","comment_id":"917501","content":"The correct answer is: D. Change the deployment policy to rolling. Specify a batch size of 2.\\n\\nA rolling deployment policy will deploy the new application version to one batch of instances at a time, while the other batches continue to serve traffic. This ensures that the application always has at least four instances available during the deployment.\\n\\nSpecifying a batch size of 2 means that two instances will be deployed at a time. This is the most cost-effective option because it minimizes the number of instances that are needed to maintain application performance during the deployment.\\n\\nThe other options are not as cost-effective because they require more instances to be running during the deployment. Option A requires six instances, option B requires at least five instances, and option C requires at least four instances.","upvote_count":"2","poster":"Prem28"},{"upvote_count":"4","content":"Selected Answer: C\\nC\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","poster":"Untamables","comment_id":"851586","timestamp":"1695774000.0"}],"answer_description":"","extracted_at":"2025-12-24T09:13:56.375Z","extraction_method":"api_direct_v1"},{"question_id":"EQGUa5ZgaFK0DHkvYuTF","question_number":518,"page":104,"question_text":"A developer is incorporating AWS X-Ray into an application that handles personal identifiable information (PII). The application is hosted on Amazon EC2 instances. The application trace messages include encrypted PII and go to Amazon CloudWatch. The developer needs to ensure that no PII goes outside of the EC2 instances.\\nWhich solution will meet these requirements?","choices":{"C":"Use Amazon Macie to detect and hide PII. Call the X-Ray API from AWS Lambda.","D":"Use AWS Distro for Open Telemetry.","B":"Use the X-Ray auto-instrumentation agent.","A":"Manually instrument the X-Ray SDK in the application code."},"correct_answer":"A","answer_ET":"A","answers_community":["A (81%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103955-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-26 14:25:00","unix_timestamp":1679833500,"discussion_count":19,"discussion":[{"upvote_count":"25","comment_id":"860460","poster":"gpt_test","content":"Selected Answer: A\\nExplanation: By manually instrumenting the X-Ray SDK in the application code, the developer can have full control over which data is included in the trace messages. This way, the developer can ensure that no PII is sent to X-Ray by carefully handling the PII within the application and not including it in the trace messages.","timestamp":"1696376460.0"},{"comment_id":"851623","content":"Selected Answer: A\\nA\\nNot to send any PII to AWS X-Ray service, add instrumentation code in your application at each location to send trace information that PII is eliminated.\\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-instrumenting-your-app.html","timestamp":"1695780000.0","upvote_count":"7","poster":"Untamables"},{"comment_id":"1334474","poster":"Niluka","upvote_count":"1","comments":[{"content":"Wrong question","comment_id":"1581780","upvote_count":"1","poster":"DamuKeesh","timestamp":"1751242740.0"}],"timestamp":"1735600800.0","content":"Selected Answer: D\\nCurrently, with the all-at-once deployment policy, Elastic Beanstalk updates all EC2 instances simultaneously. This can cause issues with application performance, as the entire fleet of instances is replaced at once, leading to potential downtime or degraded performance if the number of available instances falls below the necessary threshold (fewer than four EC2 instances in your case).\\n\\nSwitching to a rolling deployment with a batch size of 2 will allow Elastic Beanstalk to update the instances in smaller batches. During each batch update, only two instances will be updated at a time, which means that there will always be a sufficient number of EC2 instances running (at least three instances at all times). This avoids the performance degradation caused by having fewer than four EC2 instances available."},{"poster":"sumanshu","content":"Selected Answer: A\\nC) Eliminated - Amazon Macie is designed for identifying and securing sensitive data stored in AWS services like S3\\n\\nA) A (manual instrumentation) is the best solution because it gives the developer full control over what data is sent to X-Ray, ensuring that no PII leaves the EC2 instances.\\n\\nB) Eliminated - Auto-instrumentation automatically captures data without offering granular control over what is sent to X-Ray. This approach could inadvertently send sensitive PII data to X-Ray, violating the requirements.","upvote_count":"1","timestamp":"1735035300.0","comment_id":"1331080"},{"timestamp":"1732245960.0","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1215326"},{"content":"Selected Answer: A\\nX-Ray auto-instrumentation agent itself does not inherently remove or redact Personally Identifiable Information (PII). The primary purpose of the auto-instrumentation agent is to automate the process of instrumenting supported frameworks and libraries for tracing with AWS X-Ray.\\n\\nWhen dealing with PII or any sensitive information, the responsibility for ensuring that such data is not exposed in traces lies with the application code and configuration, rather than the X-Ray auto-instrumentation agent.\\n\\nWhile the X-Ray auto-instrumentation agent simplifies the instrumentation process, the need for precise control over PII and the ability to implement custom security measures make manual instrumentation more suitable in this scenario.","comment_id":"1165891","timestamp":"1725467760.0","poster":"TheFivePips","upvote_count":"2"},{"comment_id":"1159453","upvote_count":"1","timestamp":"1724648820.0","poster":"SerialiDr","content":"Selected Answer: A\\nA.To ensure that no personally identifiable information (PII) goes outside of the EC2 instances while incorporating AWS X-Ray into an application that handles PII, the developer should manually instrument the X-Ray SDK in the application code. This approach allows for precise control over what data is captured and sent to X-Ray, enabling the developer to exclude or anonymize PII before it leaves the application environment, thereby meeting the requirement to ensure that no PII goes outside of the EC2 instances."},{"comment_id":"1118984","content":"Selected Answer: A\\nThis approach allows for granular control over what data is captured and sent to AWS X-Ray. The developer can instrument the code to ensure that PII is either not included in the trace data or is properly encrypted before being sent. This method provides the necessary control to meet the requirement.","timestamp":"1720632780.0","poster":"SerialiDr","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\\nThe X-Ray auto-instrumentation agent can help ensure that sensitive information like PII is not transmitted outside of the EC2 instances. It automatically instruments the application without requiring manual intervention, making it easier to maintain traceability without risking the exposure of sensitive data.\\n\\nOptions A and D involve manual or custom instrumentations, which might inadvertently expose PII if not implemented correctly. Option C, using Amazon Macie to detect and hide PII and calling the X-Ray API from Lambda, might add complexity to the architecture and doesn\'t directly address the prevention of PII leaving the EC2 instances.","timestamp":"1719283800.0","comment_id":"1105017","poster":"a_win"},{"poster":"chewasa","content":"Selected Answer: B\\nOption B, using the X-Ray auto-instrumentation agent, is the most appropriate solution for ensuring that no PII goes outside of the EC2 instances.","upvote_count":"5","timestamp":"1717928220.0","comment_id":"1091790","comments":[{"upvote_count":"1","content":"A. Manually instrumenting the X-Ray SDK in the application code might lead to the possibility of inadvertently including PII in trace messages, and it may not be as foolproof as the auto-instrumentation agent.\\n\\nB. The X-Ray auto-instrumentation agent automatically instruments the supported runtime environments, making it less error-prone and ensuring that sensitive information like PII is not leaked.","comment_id":"1091791","poster":"chewasa","comments":[{"content":"C. Amazon Macie is a service designed for discovering, classifying, and protecting sensitive data, but using it to detect and hide PII in combination with X-Ray is not a standard approach. It\'s more focused on data discovery and classification.\\n\\nD. AWS Distro for OpenTelemetry is an observability project but may not provide the same level of automation for ensuring that no PII goes outside of the EC2 instances as the X-Ray auto-instrumentation agent.","comment_id":"1091792","upvote_count":"1","timestamp":"1717928280.0","poster":"chewasa"}],"timestamp":"1717928280.0"}]},{"upvote_count":"2","poster":"love777","comment_id":"992163","timestamp":"1709130780.0","content":"Selected Answer: B\\nThe X-Ray auto-instrumentation agent is designed to automatically trace and collect data from AWS resources and services without requiring manual instrumentation in your application code.\\nIt helps ensure that sensitive information, such as PII, remains within the EC2 instances by not transmitting the data outside explicitly. The agent focuses on tracing the application behavior and performance without directly sending PII to external services.\\nThis solution is suitable for ensuring compliance and data security while still benefiting from X-Ray\'s tracing and insights."},{"poster":"r3mo","content":"Option \\"B\\" : Because. Avoids human error.","upvote_count":"2","timestamp":"1706587380.0","comment_id":"966787"},{"poster":"Umman","content":"Using the X-Ray auto-instrumentation agent (Option B) is the best choice in this scenario because it will automatically instrument the application without requiring any manual code changes. Additionally, when using X-Ray with auto-instrumentation, you can control the sampling rate to ensure that only a subset of trace data (and encrypted PII) is sent to X-Ray and CloudWatch, reducing the risk of sensitive data being exposed outside of the instances.","upvote_count":"2","comment_id":"965159","timestamp":"1706405580.0"},{"poster":"jasper_pigeon","content":"For non-Java applications running on EC2 instances, you will need to use the appropriate X-Ray SDKs to manually instrument the application code. You can\'t use auto-agent","comment_id":"962607","upvote_count":"2","timestamp":"1706187720.0"},{"content":"Its very clear from Macie definition that it also provides automated protection as well apart from findings the PII data","upvote_count":"1","poster":"kris_jec","timestamp":"1705992900.0","comment_id":"960074"},{"content":"Selected Answer: A\\nI think B is incorrect as the auto instrument cannot hide it, right?","upvote_count":"1","poster":"tttamtttam","timestamp":"1705351260.0","comment_id":"952604"},{"comment_id":"881642","timestamp":"1698325800.0","poster":"dan80","upvote_count":"3","content":"Selected Answer: A\\nC is wrong, Amazon Macie discover PII but dont hide it"},{"comment_id":"851528","timestamp":"1695765540.0","content":"c https://docs.aws.amazon.com/macie/latest/user/data-classification.html","poster":"macross","upvote_count":"1"},{"content":"C : Amazon Macie is a data security service that discovers sensitive data using machine learning and pattern matching, provides visibility into data security risks, and enables you to automate protection against those risks.\\nhttps://aws.amazon.com/macie/features/?nc1=h_ls","comments":[{"comment_id":"968097","poster":"jipark","content":"exactly sayed there.","timestamp":"1706711160.0","upvote_count":"2","comments":[{"comment_id":"985176","poster":"ninomfr64","timestamp":"1708352100.0","upvote_count":"3","content":"It is my understanding that Macie only supports S3"}]}],"upvote_count":"3","timestamp":"1695731100.0","poster":"StarLoard","comment_id":"850987"}],"answer_description":"","extracted_at":"2025-12-24T09:13:56.375Z","extraction_method":"api_direct_v1"},{"question_id":"ViC2emWgBeY2yDKjUAx3","question_number":519,"page":104,"question_text":"A developer is migrating some features from a legacy monolithic application to use AWS Lambda functions instead. The application currently stores data in an Amazon Aurora DB cluster that runs in private subnets in a VPC. The AWS account has one VPC deployed. The Lambda functions and the DB cluster are deployed in the same AWS Region in the same AWS account.\\nThe developer needs to ensure that the Lambda functions can securely access the DB cluster without crossing the public internet.\\nWhich solution will meet these requirements?","choices":{"C":"Configure a NAT gateway and a security group for the Lambda functions.","A":"Configure the DB cluster\'s public access setting to Yes.","D":"Configure the VPC, subnets, and a security group for the Lambda functions.","B":"Configure an Amazon RDS database proxy for he Lambda functions."},"correct_answer":"D","answer_ET":"D","answers_community":["D (92%)","8%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103687-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 18:38:00","unix_timestamp":1679593080,"discussion_count":10,"discussion":[{"comment_id":"978153","upvote_count":"17","timestamp":"1691713440.0","poster":"jayvarma","content":"Option D is the right answer. When we want the lambda to privately access the DB cluster instead of moving the traffic over the public internet, we need to have the lambda and db cluster to be in the same VPC.\\n\\nWhen we configure the VPC, subnets, and a security group for the lambda function, the lambda function will be able to communicate with the db cluster using the private IPs that are associated to the VPC.\\n\\nNAT gateway comes into use when you have the lambda deployed in a private subnet and you would want to provide internet access to it."},{"upvote_count":"8","poster":"gpt_test","content":"Selected Answer: D\\nExplanation: To securely access the Amazon Aurora DB cluster without crossing the public internet, the Lambda functions need to be configured to run within the same VPC as the DB cluster. This involves configuring the VPC, subnets, and a security group for the Lambda functions. This setup ensures that the Lambda functions can communicate with the DB cluster using private IP addresses within the VPC.","comment_id":"860457","timestamp":"1680565140.0"},{"timestamp":"1735045980.0","poster":"sumanshu","comment_id":"1331122","upvote_count":"1","content":"Selected Answer: D\\nLambda functions can be configured to run within a VPC. By assigning the Lambda functions to the same VPC and private subnets as the Aurora DB cluster, the communication remains internal to the VPC and does not cross the public internet. Configuring the security group ensures that the Lambda functions can securely connect to the Aurora DB cluster by allowing appropriate inbound/outbound rules."},{"comment_id":"1294656","timestamp":"1728378420.0","upvote_count":"1","content":"Selected Answer: D\\nAns is D.","poster":"AmitRanchi"},{"content":"Selected Answer: D\\nD is the correct answer.","upvote_count":"1","timestamp":"1716341280.0","poster":"65703c1","comment_id":"1215327"},{"comment_id":"1072163","comments":[{"timestamp":"1711564080.0","upvote_count":"1","content":"Actually Proxy should be on the same VPC as the database and since lambda is in another vpc it doesnt have access unless a connection happens between these two vpc or just option D","comment_id":"1184288","poster":"maurice2005"}],"upvote_count":"2","content":"B\\nhttps://repost.aws/questions/QULXSqEPGbQx6qiyBa1D1Udg/lambda-to-db-connectivity-best-practices","poster":"Wendy1113","timestamp":"1700112960.0"},{"content":"Selected Answer: B\\nhttps://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/36527788#overview\\n\\nhttps://aws.amazon.com/ru/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/","comment_id":"1023694","timestamp":"1696316040.0","poster":"alex_heavy","upvote_count":"1"},{"timestamp":"1688448180.0","poster":"eberhe900","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","comment_id":"942407","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"1255334","timestamp":"1721959800.0","poster":"ejlp","content":"After reading doc in the link that you mention, my conclusion is D\\nNAT GW is required if Lamba in the user VPC need to access internet"}]},{"timestamp":"1679883540.0","upvote_count":"5","comment_id":"851630","content":"Selected Answer: D\\nD\\nhttps://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html","poster":"Untamables"},{"content":"Selected Answer: D\\nD is correct, NATGateway is for when we want Lambda to access the public when it is in a private VPC","upvote_count":"6","comment_id":"848515","timestamp":"1679593080.0","poster":"Dun6"}],"answer_description":"","extracted_at":"2025-12-24T09:13:56.375Z","extraction_method":"api_direct_v1"},{"question_id":"syItg8ckIjYYgSZZQtXU","question_number":520,"page":104,"question_text":"A developer is building a new application on AWS. The application uses an AWS Lambda function that retrieves information from an Amazon DynamoDB table. The developer hard coded the DynamoDB table name into the Lambda function code. The table name might change over time. The developer does not want to modify the Lambda code if the table name changes.\\nWhich solution will meet these requirements MOST efficiently?","choices":{"B":"Store the table name in a file. Store the file in the /tmp folder. Use the SDK for the programming language to retrieve the table name.","D":"Create a global variable that is outside the handler in the Lambda function to store the table name.","C":"Create a file to store the table name. Zip the file and upload the file to the Lambda layer. Use the SDK for the programming language to retrieve the table name.","A":"Create a Lambda environment variable to store the table name. Use the standard method for the programming language to retrieve the variable."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103686-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-23 18:36:00","unix_timestamp":1679592960,"discussion_count":7,"discussion":[{"timestamp":"1695483360.0","content":"Selected Answer: A\\nYou need to use environment variables","poster":"Dun6","comment_id":"848509","upvote_count":"9"},{"upvote_count":"7","poster":"Untamables","timestamp":"1695781380.0","comment_id":"851632","content":"Selected Answer: A\\nA\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html"},{"comment_id":"1331124","content":"Selected Answer: A\\nEnvironment variables are a built-in feature of AWS Lambda","poster":"sumanshu","timestamp":"1735046520.0","upvote_count":"1"},{"content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1732246140.0","poster":"65703c1","upvote_count":"1","comment_id":"1215328"},{"comment_id":"1076495","upvote_count":"1","poster":"mma34","timestamp":"1716305460.0","content":"Selected Answer: A\\nWhy are some answers wrong on here?"},{"upvote_count":"2","timestamp":"1704353220.0","poster":"eberhe900","comment_id":"942409","content":"Selected Answer: A\\nYou can use environment variables to adjust your function\'s behavior without updating code. An environment variable is a pair of strings that is stored in a function\'s version-specific configuration. The Lambda runtime makes environment variables available to your code and sets additional environment variables that contain information about the function and invocation request."},{"comment_id":"860455","timestamp":"1696376280.0","upvote_count":"5","poster":"gpt_test","content":"Selected Answer: A\\nExplanation: Using Lambda environment variables allows you to store configuration information separate from your code, which makes it easy to update the table name without changing the Lambda function code. AWS Lambda provides built-in support for environment variables, making it the most efficient solution."}],"answer_description":"","extracted_at":"2025-12-24T09:13:56.375Z","extraction_method":"api_direct_v1"},{"question_id":"AuZncl0pQxGGlkJcYVWS","question_number":521,"page":105,"question_text":"A company has a critical application on AWS. The application exposes an HTTP API by using Amazon API Gateway. The API is integrated with an AWS Lambda function. The application stores data in an Amazon RDS for MySQL DB instance with 2 virtual CPUs (vCPUs) and 64 GB of RAM.\\n\\nCustomers have reported that some of the API calls return HTTP 500 Internal Server Error responses. Amazon CloudWatch Logs shows errors for \u201ctoo many connections.\u201d The errors occur during peak usage times that are unpredictable.\\n\\nThe company needs to make the application resilient. The database cannot be down outside of scheduled maintenance hours.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Add a CloudWatch alarm that changes the DB instance class when the number of connections increases to more than 1,000.","A":"Decrease the number of vCPUs for the DB instance. Increase the max_connections setting.","D":"Add an Amazon EventBridge rule that increases the max_connections setting of the DB instance when CPU utilization is above 75%.","B":"Use Amazon RDS Proxy to create a proxy that connects to the DB instance. Update the Lambda function to connect to the proxy."},"correct_answer":"B","answer_ET":"B","answers_community":["B (93%)","7%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107437-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 14:35:00","unix_timestamp":1682426100,"discussion_count":10,"discussion":[{"comment_id":"880370","timestamp":"1698237300.0","upvote_count":"11","content":"Selected Answer: B\\nThe best solution to meet these requirements would be to use Amazon RDS Proxy to create a proxy that connects to the DB instance and update the Lambda function to connect to the proxy.","poster":"MrTee"},{"comment_id":"1331128","timestamp":"1735046940.0","upvote_count":"3","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - Decreasing the number of vCPUs will worsen performance.\\n\\nB) When your Lambda function wants to query the database, instead of opening a new connection every time (which is what causes \\"too many connections\\"), it talks to the RDS Proxy. For example, if 100 Lambda functions try to connect at the same time, instead of opening 100 database connections, the RDS Proxy might only open 10 and reuse them.\\n\\nC) Eliminated - It incurs unnecessary costs for increased capacity, even if the issue is caused by connection management."},{"content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732246320.0","upvote_count":"1","comment_id":"1215329","poster":"65703c1"},{"poster":"SerialiDr","content":"Selected Answer: B\\nAmazon RDS Proxy is designed to handle a large number of simultaneous connections efficiently. It sits between your application and your RDS database to pool and share database connections, improving database efficiency and application scalability. This approach can reduce the number of connections to the database and handle unpredictable peak loads more effectively.","comment_id":"1119452","upvote_count":"3","timestamp":"1720675260.0"},{"upvote_count":"1","timestamp":"1710161580.0","poster":"hsinchang","comment_id":"1004650","content":"Selected Answer: B\\nB: RDS Proxy establishes and manages the necessary connection pools to your database so that your Lambda function creates fewer database connections\xb9. RDS Proxy also handles failovers and retries automatically, which improves the availability of your application.\\n\\nA will reduce the performance and capacity of the database.\\nC may incur additional charges for scaling up the DB instance. It may also cause downtime during the scaling process, which violates the requirement that the database cannot be down outside of scheduled maintenance hours.\\nD may not react fast enough to handle unpredictable peak usage times. It may also cause memory issues if the max_connections setting is too high."},{"comment_id":"994189","timestamp":"1709222760.0","poster":"love777","upvote_count":"2","content":"Selected Answer: B\\nAdding an Amazon EventBridge rule to increase the max_connections setting based on CPU utilization is not directly addressing the issue of too many connections. Additionally, focusing solely on CPU utilization might not be the best metric for handling connection-related issues."},{"timestamp":"1705352100.0","upvote_count":"1","comment_id":"952609","poster":"tttamtttam","content":"Selected Answer: B\\nI think D is incorrect because it increases the number of connections based on the CPU consumption not the number of connections."},{"content":"Selected Answer: D\\nhttps://repost.aws/knowledge-center/rds-mysql-max-connections","timestamp":"1704880500.0","poster":"Naj_64","upvote_count":"1","comment_id":"947878"},{"comment_id":"915668","content":"Selected Answer: B\\nIt\u2019s B. RDS proxy can handle many open connections to the database.","timestamp":"1701807240.0","poster":"csG13","upvote_count":"3"},{"poster":"awsdummie","upvote_count":"1","comment_id":"909722","timestamp":"1701299160.0","content":"Selected Answer: D\\nThere should not be any downtime. Create an Event bridge rule to update the max_connections parameter in Parameter group of DB instance."}],"answer_description":"","extracted_at":"2025-12-24T09:14:07.346Z","extraction_method":"api_direct_v1"},{"question_id":"NMIVj6v7egGLbPJuCthz","question_number":522,"page":105,"question_text":"A company has installed smart meters in all its customer locations. The smart meters measure power usage at 1-minute intervals and send the usage readings to a remote endpoint for collection. The company needs to create an endpoint that will receive the smart meter readings and store the readings in a database. The company wants to store the location ID and timestamp information.\\n\\nThe company wants to give its customers low-latency access to their current usage and historical usage on demand. The company expects demand to increase significantly. The solution must not impact performance or include downtime while scaling.\\n\\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"B":"Store the smart meter readings in an Amazon DynamoDB table. Create a composite key by using the location ID and timestamp columns. Use the columns to filter on the customers\' data.","A":"Store the smart meter readings in an Amazon RDS database. Create an index on the location ID and timestamp columns. Use the columns to filter on the customers\' data.","D":"Store the smart meter readings in Amazon S3. Partition the data by using the location ID and timestamp columns. Use Amazon Athena to filter on the customers\' data.","C":"Store the smart meter readings in Amazon ElastiCache for Redis. Create a SortedSet key by using the location ID and timestamp columns. Use the columns to filter on the customers\' data."},"correct_answer":"B","answer_ET":"B","answers_community":["B (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107439-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 14:39:00","unix_timestamp":1682426340,"discussion_count":9,"discussion":[{"content":"Selected Answer: B\\nThe most cost-effective solution to meet these requirements would be to store the smart meter readings in an Amazon DynamoDB table and create a composite key using the location ID and timestamp columns","timestamp":"1698237540.0","comment_id":"880379","upvote_count":"9","poster":"MrTee"},{"timestamp":"1738601160.0","poster":"pinkynose","content":"Selected Answer: D\\nI miss you Ruchi","upvote_count":"1","comment_id":"1351028"},{"comment_id":"1331132","content":"Selected Answer: B\\nDynamoDB is purpose-built for low-latency, scalable storage of high-frequency, time-series data.\\nComposite key design (location ID + timestamp) enables efficient querying.\\nAutomatically scales without downtime or performance impact.","upvote_count":"1","poster":"sumanshu","timestamp":"1735047540.0"},{"poster":"65703c1","timestamp":"1732246500.0","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215332","upvote_count":"1"},{"content":"Selected Answer: B\\nThis solution provides low-latency access to real-time and historical data, scales seamlessly to accommodate increased demand without downtime, and is likely to be more cost-effective than the alternatives for this specific use case. DynamoDB\'s managed service nature also reduces the administrative burden of managing the database.","upvote_count":"2","timestamp":"1720675680.0","poster":"SerialiDr","comment_id":"1119462"},{"comment_id":"1048166","timestamp":"1713548940.0","content":"C is the right answer","poster":"Gold07","upvote_count":"2"},{"content":"Selected Answer: B\\nGoing with B. DynamoDB is the most cost-effective solution.","comment_id":"964336","poster":"Naj_64","timestamp":"1706337780.0","upvote_count":"3"},{"upvote_count":"2","content":"You need to use Athena as well to do partitoning","comment_id":"961111","poster":"jasper_pigeon","timestamp":"1706076720.0"},{"comment_id":"917650","content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-sort-keys.html","timestamp":"1701995160.0","upvote_count":"1","poster":"HuiHsin"}],"answer_description":"","extracted_at":"2025-12-24T09:14:07.346Z","extraction_method":"api_direct_v1"},{"question_id":"Hx9YIwMcxvgQCHVJfYU7","question_number":523,"page":105,"question_text":"A company is building a serverless application that uses AWS Lambda functions. The company needs to create a set of test events to test Lambda functions in a development environment. The test events will be created once and then will be used by all the developers in an IAM developer group. The test events must be editable by any of the IAM users in the IAM developer group.\\n\\nWhich solution will meet these requirements?","choices":{"B":"Create the test events. Configure the event sharing settings to make the test events shareable.","D":"Create the test events. Configure the event sharing settings to make the test events private.","C":"Create and store the test events in Amazon DynamoDB. Allow access to DynamoDB by using IAM roles.","A":"Create and store the test events in Amazon S3 as JSON objects. Allow S3 bucket access to all IAM users."},"correct_answer":"B","answer_ET":"B","answers_community":["B (81%)","Other"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106484-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-17 15:33:00","unix_timestamp":1681738380,"discussion_count":18,"discussion":[{"timestamp":"1683334620.0","upvote_count":"30","poster":"renekton","comment_id":"890394","content":"Selected Answer: B\\nUnder the \\"Test\\" tab there\'s an option. (Shareable)\\nThis event is available to IAM users within the same account who have permissions to access and use shareable events.\\n\\nYou can check this by yourself on the Lambda\\nAlso, here\'s a documentation \\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-functions.html#creating-shareable-events"},{"timestamp":"1684788840.0","comment_id":"904373","poster":"delak","content":"Selected Answer: B\\nSince March of this year, this is now possible to share test events within the same account with different users.","upvote_count":"6"},{"content":"Selected Answer: B\\n(Shareable events) directly leverages AWS Lambda\'s built-in functionality, reducing the need for custom storage and retrieval mechanisms.","timestamp":"1735047780.0","comment_id":"1331134","poster":"sumanshu","upvote_count":"2"},{"upvote_count":"1","timestamp":"1721196600.0","poster":"Anandesh","content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-functions.html","comment_id":"1249420"},{"comment_id":"1215334","timestamp":"1716341880.0","content":"Selected Answer: B\\nB is the correct answer.","upvote_count":"1","poster":"65703c1"},{"poster":"SerialiDr","comment_id":"1160022","timestamp":"1708975980.0","content":"Selected Answer: A\\nThis option is the most straightforward and aligns with AWS practices for managing shared resources like test events. IAM policies can be configured to grant the necessary permissions to the developer group, ensuring that all members can access and edit the test events stored in S3. This method leverages the scalability and security features of S3, along with the granular permission control provided by IAM, to meet the requirements.","upvote_count":"1"},{"poster":"manngupta007","content":"Answer: B\\nhttps://aws.amazon.com/about-aws/whats-new/2022/03/aws-lambda-console-test-events/","timestamp":"1706536560.0","upvote_count":"1","comment_id":"1135019"},{"upvote_count":"1","content":"Selected Answer: A\\nThis option is viable. Amazon S3 can store JSON objects (test events), and access to these objects can be controlled through S3 bucket policies or IAM policies. By setting the correct permissions, all IAM users in the developer group can read and write to the S3 bucket, enabling them to edit and use the test events.","poster":"SerialiDr","timestamp":"1704958560.0","comment_id":"1119476"},{"upvote_count":"1","poster":"ez_24","content":"Selected Answer: A\\nThe key Concept here is Sharing - test events in the Lambda console are for individual account can\'t be used by other developers","comment_id":"1114209","timestamp":"1704422400.0"},{"comment_id":"1105021","poster":"a_win","upvote_count":"1","timestamp":"1703480640.0","content":"Selected Answer: A\\nThis approach ensures that the test events are stored centrally in an S3 bucket where all IAM users within the developer group have access. By granting access to the S3 bucket to all IAM users, any user within the group can create, edit, and retrieve the test events, meeting the requirement for collaborative access and editing.\\n\\nOptions B and D don\'t directly address the need for IAM users to edit the test events; sharing settings might allow access, but they might not allow editing by all IAM users in the group. Option C, using DynamoDB, requires specific IAM role configurations for each user, which could become complex to manage and might not provide the same level of straightforward access and editing capability for all users within the IAM group."},{"poster":"tqiu654","timestamp":"1701499860.0","upvote_count":"1","comment_id":"1085804","content":"Selected Answer: A\\nBased on ChatGPT:A"},{"comment_id":"1055055","timestamp":"1698372480.0","content":"Selected Answer: B\\nNo AWS Lambda, voc\xea pode criar eventos de teste no console da AWS para invocar sua fun\xe7\xe3o e ver a resposta. Esses eventos de teste podem ser salvos e compartilhados com outros usu\xe1rios IAM. Ao definir as configura\xe7\xf5es de compartilhamento de eventos para tornar os eventos de teste compartilh\xe1veis, voc\xea permite que todos os desenvolvedores do grupo de desenvolvedores IAM os usem e editem.","poster":"Jonalb","upvote_count":"1"},{"poster":"DUBERS","comment_id":"967734","content":"Would this not be C just because that\'s the only one that has the added security of the IAM roles?","upvote_count":"1","timestamp":"1690776300.0"},{"comment_id":"878515","poster":"Cloud_Cloud","upvote_count":"1","timestamp":"1682262600.0","content":"Selected Answer: B\\nthere is an option in lambda console to share the event with other users"},{"poster":"MrTee","upvote_count":"3","comment_id":"875674","timestamp":"1681999020.0","content":"Selected Answer: A\\nI meant to select A"},{"comment_id":"875673","timestamp":"1681998960.0","content":"Selected Answer: B\\nTo create a set of test events that can be used by all developers in an IAM developer group and that are editable by any of the IAM users in the group, the company should create and store the test events in Amazon S3 as JSON objects and allow S3 bucket access to all IAM users (Option A). This will allow all developers in the IAM developer group to access and edit the test events as needed. The other options do not provide a way for multiple developers to access and edit the test events.","poster":"MrTee","upvote_count":"1"},{"comment_id":"874396","timestamp":"1681892340.0","poster":"Fyssy","content":"Selected Answer: C\\nUse roles. Not all IAM users","upvote_count":"1"},{"upvote_count":"2","timestamp":"1681738380.0","poster":"Fyssy","content":"Selected Answer: A\\nTo create test events that can be edited by any IAM user in a developer group, the company can create an Amazon S3 bucket and store the test event data as JSON files in the bucket.","comments":[{"content":"A is wrong. To edit a test you only need IAM permissions.\\n\\n\\"To see, share, and edit shareable test events, you must have permissions for all of the following...\\"\\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-functions.html#creating-shareable-events\\n\\nI\'ll go with B.","upvote_count":"3","timestamp":"1688976420.0","comment_id":"947889","poster":"Naj_64"}],"comment_id":"872730"}],"answer_description":"","extracted_at":"2025-12-24T09:14:07.346Z","extraction_method":"api_direct_v1"},{"question_id":"ICurKZ5wZFmgypsGl7uo","question_number":524,"page":105,"question_text":"A developer is configuring an application\'s deployment environment in AWS CodePipeline. The application code is stored in a GitHub repository. The developer wants to ensure that the repository package\'s unit tests run in the new deployment environment. The developer has already set the pipeline\'s source provider to GitHub and has specified the repository and branch to use in the deployment.\\n\\nWhich combination of steps should the developer take next to meet these requirements with the LEAST overhead? (Choose two.)","choices":{"B":"Create an AWS CodeBuild project. Add the repository package\'s build and test commands to the project\'s buildspec.","C":"Create an AWS CodeDeploy project. Add the repository package\'s build and test commands to the project\'s buildspec.","E":"Add a new stage to the pipeline after the source stage. Add an action to the new stage. Specify the newly created project as the action provider. Specify the source artifact as the action\'s input artifact.","D":"Add an action to the source stage. Specify the newly created project as the action provider. Specify the build artifact as the action\'s input artifact.","A":"Create an AWS CodeCommit project. Add the repository package\'s build and test commands to the project\'s buildspec."},"correct_answer":"BE","answer_ET":"BE","answers_community":["BE (96%)","4%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107440-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 14:49:00","unix_timestamp":1682426940,"discussion_count":9,"discussion":[{"timestamp":"1682426940.0","upvote_count":"21","poster":"MrTee","content":"The correct answer is B and E\\nThe buildspec file is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build. By adding the build and test commands to the buildspec file, the developer can ensure that these commands are executed as part of the build process. Option E will ensure that the CodeBuild project is triggered as part of the pipeline and that the unit tests are run in the new deployment environment.","comment_id":"880388"},{"timestamp":"1684952760.0","comment_id":"906095","content":"Selected Answer: BE\\nFor those who just skim the question, keyword between D and E is \\"unit tests run in the new deployment environment.\\", which signifies a new stage should be created instead of just adding an action.","poster":"imvb88","upvote_count":"14"},{"comment_id":"1331142","timestamp":"1735049220.0","upvote_count":"3","poster":"sumanshu","content":"Selected Answer: BE\\nAWS CodeBuild is specifically designed for building and testing code in CI/CD pipelines. The buildspec file is where the developer can specify commands to build and run unit tests for the application package.\\n\\nA new stage after the source stage ensures that the unit tests run on the package retrieved from GitHub."},{"content":"This appear at 17 Jun exam","poster":"tsangckl","comment_id":"1231695","upvote_count":"3","timestamp":"1718595720.0"},{"content":"Selected Answer: BE\\nBE is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716342060.0","comment_id":"1215335"},{"timestamp":"1704959100.0","content":"Selected Answer: BE\\nE. Add a new stage to the pipeline after the source stage: This is the correct step. The developer should add a new stage to the pipeline specifically for building and testing the code. Within this stage, an action should be added that specifies the AWS CodeBuild project (created in step B) as the action provider. The source artifact (code fetched from GitHub) should be specified as the action\'s input artifact.\\n\\nSo, the combination of steps that should be taken next to meet these requirements with the least overhead are:\\n\\nB. Create an AWS CodeBuild project. Add the repository package\'s build and test commands to the project\'s buildspec.\\n\\nE. Add a new stage to the pipeline after the source stage. Add an action to the new stage. Specify the newly created CodeBuild project as the action provider. Specify the source artifact as the action\'s input artifact.","upvote_count":"3","poster":"SerialiDr","comment_id":"1119485"},{"timestamp":"1702081620.0","comments":[{"comment_id":"1091452","content":"Sorry will go with BE after ding more research as unit tests cannot be run in source stage as an action","timestamp":"1702094880.0","upvote_count":"2","poster":"LR2023"}],"upvote_count":"1","poster":"LR2023","content":"Selected Answer: BD\\nChoosing D as that is the least overhead. There is already a stage and you need to add an action test","comment_id":"1091382"},{"comment_id":"983057","poster":"marolisa","content":"B e D.\\nhttps://docs.aws.amazon.com/pt_br/codebuild/latest/userguide/how-to-create-pipeline-add-test.html","timestamp":"1692222780.0","upvote_count":"3"},{"content":"Selected Answer: BE\\nAs MrTee says.","comment_id":"892772","upvote_count":"3","poster":"aaok","timestamp":"1683609540.0"}],"answer_description":"","extracted_at":"2025-12-24T09:14:07.346Z","extraction_method":"api_direct_v1"},{"question_id":"8ApWfBL7c9JZe4v8fo27","question_number":525,"page":105,"question_text":"A developer has an application that makes batch requests directly to Amazon DynamoDB by using the BatchGetItem low-level API operation. The responses frequently return values in the UnprocessedKeys element.\\nWhich actions should the developer take to increase the resiliency of the application when the batch response includes values in UnprocessedKeys? (Choose two.)","choices":{"C":"Update the application to use an AWS software development kit (AWS SDK) to make the requests.","A":"Retry the batch operation immediately.","B":"Retry the batch operation with exponential backoff and randomized delay.","E":"Increase the provisioned write capacity of the DynamoDB tables that the operation accesses.","D":"Increase the provisioned read capacity of the DynamoDB tables that the operation accesses."},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (60%)","BC (37%)","2%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102785-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 10:00:00","unix_timestamp":1678957200,"discussion_count":61,"discussion":[{"poster":"brandon87","upvote_count":"24","timestamp":"1680439200.0","comment_id":"858836","content":"Selected Answer: BD\\n(B) If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed. \\n(D) The most likely cause of a failed read or a failed write is throttling. For BatchGetItem, one or more of the tables in the batch request does not have enough provisioned read capacity to support the operation\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff"},{"timestamp":"1679370960.0","content":"Selected Answer: BC\\nB & C\\nhttps://docs.aws.amazon.com/general/latest/gr/api-retries.html","comment_id":"845502","comments":[{"timestamp":"1706549160.0","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1560619","timestamp":"1744643340.0","content":"Note that this is not a combination of two, these are two separate options that could work - choose SDK over low level API which, as you said, handles retries or implement retries yourself.","poster":"test_test_raf"}],"poster":"konieczny69","comment_id":"1135146","content":"C already handles retries, why would want to to do that manually?"}],"poster":"Untamables","upvote_count":"19"},{"upvote_count":"2","content":"Selected Answer: BD\\nBatchWriteItem\\n\u2022 UnprocessedItems for failed write operations (exponential backoff or add WCU)\\n BatchGetItem\\n\u2022 UnprocessedKeys for failed read operations (exponential backoff or add RCU) \\nSo answer is B & D","comment_id":"1340681","timestamp":"1736918100.0","poster":"wtf3344"},{"timestamp":"1736283000.0","upvote_count":"1","content":"Selected Answer: BC\\nD also could be an answer.But is not the most suitable since there is a posibility of getting this result intermittently eventhouth we have necessary capacity.","comment_id":"1337706","poster":"Hasitha99"},{"content":"Selected Answer: BC\\nBC is correct answer.","upvote_count":"1","comment_id":"1332129","timestamp":"1735251480.0","poster":"Arad"},{"timestamp":"1734707640.0","content":"Selected Answer: BD\\nDynamoDB BatchGetItem API operation, the request fetches multiple items in one operation. However, DynamoDB has limits on the resources it allocates for processing requests. If it cannot process some items within a batch request due to these limits, it returns the processed items (the ones it successfully retrieved), and for the remaining items, it includes them in the UnprocessedKeys element in the response.","upvote_count":"2","poster":"sumanshu","comment_id":"1329525"},{"upvote_count":"1","timestamp":"1733917380.0","comment_id":"1325003","poster":"trieudo","content":"Selected Answer: BC\\nKeyword: increase, resiliency, application, response, UnprocessedKeys(Unprocessed due to be not enough infra)\\n\\n==> Discard A: horrible way, push so many traffic to busy system\\n==> Discard D, E: Error due to huge traffic, it can be unlimited. Don\'t come from lacking resource ==> Your resource, your money is limit >< unpredicted huge traffic\\n\\nB: is good way to call x2 times after failed, call again after 1s -> 2s -> 4s -> 8s -> ... until success\\n\\nC: is intergrate method of \'B\' option automaically inside SDK"},{"poster":"9d8dd9c","timestamp":"1729159020.0","upvote_count":"1","content":"Selected Answer: BD\\nBD\\nC handles retry but using SDK is not necessary here","comment_id":"1299137"},{"timestamp":"1727238120.0","content":"Selected Answer: BD\\nI vote for B,D\\nScroll down to the bottom of this page and you will see the reason. I paste some of words here.\\n\\nThe most likely cause of a failed read or a failed write is throttling. For BatchGetItem, one or more of the tables in the batch request does not have enough provisioned read capacity to support the operation. For BatchWriteItem, one or more of the tables does not have enough provisioned write capacity.\\n\\nIf DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html","upvote_count":"3","comment_id":"938802","poster":"Phongsanth"},{"content":"Selected Answer: BD\\nBackoff and Retry Strategy:\\n\\nImplement a backoff and retry strategy to prevent overwhelming the DynamoDB service with repeated requests.\\nApply an exponential backoff algorithm, where you progressively increase the delay between each retry attempt.\\nConsider implementing a maximum number of retries to avoid an infinite retry loop.\\nFine-Tuning DynamoDB Provisioned Capacity:\\n\\nIf you consistently encounter unprocessed items during batch operations, it may indicate that your DynamoDB table\'s provisioned capacity is insufficient.\\nMonitor the table\'s consumed capacity and adjust the provisioned capacity (read capacity units) accordingly to handle the load and reduce the occurrence of unprocessed items.\\nBy implementing these steps, you can effectively handle unprocessed items returned by the BatchGetItem operation in DynamoDB and ensure that all items are processed successfully.","upvote_count":"2","comment_id":"944320","timestamp":"1727238120.0","poster":"eberhe900"},{"timestamp":"1727238060.0","comment_id":"1096666","content":"Selected Answer: BD\\nB & D.\\nB is correct. Because in the question, it is mentioned that low-level API is being used.It means exponential backoff can be implemented manually.\\nD is correct. Because there is a frequently keyword in the question. If UnprocessedKeys error occurs frequently, DynamoDB doesn\'t have enough capacity to process requests. So read capacity should be increased.","poster":"SherzodBek","upvote_count":"3"},{"upvote_count":"1","poster":"TheFivePips","comment_id":"1165599","content":"Selected Answer: BD\\nExponential backoff with randomized delay is a common technique used to handle transient failures and throttle errors in distributed systems like DynamoDB. This approach involves retrying the failed operation after waiting for an increasing amount of time, which helps reduce the load on the service and increases the likelihood of success during periods of high demand or throttling.\\n\\nIf the BatchGetItem operation frequently returns values in the UnprocessedKeys element, it indicates that the table\'s read capacity might be insufficient to handle the requested workload. By increasing the provisioned read capacity for the DynamoDB tables, the application can better handle the read throughput requirements and reduce the likelihood of encountering UnprocessedKeys in batch responses.\\n\\nAWS SDK might provide additional features and simplifications for making requests, it does not directly address the issue of UnprocessedKeys in batch responses. This option might be beneficial for improving code maintainability and leveraging SDK features however.","timestamp":"1727238060.0"},{"content":"BC is the correct answer.","upvote_count":"1","poster":"phongnx8","comment_id":"1260553","timestamp":"1722756660.0"},{"content":"Selected Answer: BC\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","comment_id":"1248772","poster":"Anandesh","upvote_count":"1","timestamp":"1721119320.0"},{"upvote_count":"1","content":"Selected Answer: BC\\nBC is the correct answer.","poster":"65703c1","timestamp":"1716296640.0","comment_id":"1214958"},{"comment_id":"1191816","timestamp":"1712607420.0","upvote_count":"1","content":"Selected Answer: BC\\namong B C D, it is hard to say D copes with the problem directly I guess. Increasing RCU will affects the ratio of unprocessed items but that does not mean it handles the unprocessed items.","poster":"drycleansing"},{"comment_id":"1190636","timestamp":"1712440860.0","upvote_count":"1","content":"Selected Answer: BD\\nB,D. La combinaci\xf3n de estrategias es ideal para este comportamiento","poster":"vinfo"},{"poster":"apa_1","upvote_count":"1","timestamp":"1711533420.0","content":"Selected Answer: BD\\nB,D is correct","comment_id":"1183980"},{"timestamp":"1711532040.0","comment_id":"1183970","upvote_count":"2","content":"Selected Answer: BC\\nthe aws documentation for unprocessedkeys reads:\\n\\"If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.\\"\\n\\nTherefore I am taking the two options that provide this functionality.\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","poster":"DeaconStJohn"},{"content":"Selected Answer: BD\\nB & D is correct","poster":"ibratoev","comment_id":"1182556","upvote_count":"1","timestamp":"1711376280.0"},{"poster":"HayLLlHuK","upvote_count":"1","content":"Selected Answer: BD\\nAccording to AWS docs, the answer is B and D","comment_id":"1175081","timestamp":"1710605100.0"},{"upvote_count":"1","content":"BC ...No discussion","timestamp":"1708784760.0","poster":"badsati","comment_id":"1157987"},{"upvote_count":"2","timestamp":"1706850180.0","content":"Why it\'s suggesting using SDK in the question from below link but not using C in this question?\\nhttps://www.examtopics.com/discussions/amazon/view/96246-exam-aws-certified-developer-associate-topic-1-question-437/","comment_id":"1138115","poster":"CrescentShared"},{"timestamp":"1705923480.0","content":"Correct answer is B & D \\nB- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.BatchOperations\\nD - https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","comment_id":"1128551","upvote_count":"2","poster":"Sisanda_giiven"},{"poster":"Cambrian","comment_id":"1123644","upvote_count":"1","timestamp":"1705350480.0","content":"Selected Answer: BC\\nRetry with exponential backoff and randomized delay (Option B) helps prevent overwhelming the system with repeated immediate requests and increases the likelihood of successful retries during intermittent issues.\\nUsing an AWS SDK (Option C) can provide built-in features for handling transient errors and retries, making the application more resilient to issues like UnprocessedKeys in batch responses."},{"upvote_count":"1","timestamp":"1698891120.0","poster":"Abdlhince","comment_id":"1060192","content":"Selected Answer: BC\\nB. This is a good practice to handle throttling errors and avoid overwhelming the server with too many requests at the same time. Exponential backoff means increasing the waiting time between retries exponentially, such as 1 second, 2 seconds, 4 seconds, and so on. Randomized delay means adding some randomness to the waiting time, such as 1.2 seconds, 2.5 seconds, 3.8 seconds, and so on. This can help reduce the chance of collisions and spikes in the network traffic.\\nC.This is a recommended way to interact with DynamoDB, as AWS SDKs provide high-level abstractions and convenience methods for working with DynamoDB. AWS SDKs also handle low-level details such as authentication, retry logic, error handling, and pagination for you."},{"comment_id":"1060022","content":"BC\\nThe question only states that there are UnprocessedKeys. \\nThat means that the batch operation occurred correctly most of the time. It states that frequently\\nthe batch contains more keys than can be returned with the present RCUs. \\nThe does not state that any single key has violated the ProvisionedThroughputExceededException (in which case D would be necessary).\\nSo D would only make it more performant because of less Retries. However B and C are examples of resilience","timestamp":"1698867660.0","poster":"ronn555","upvote_count":"2"},{"timestamp":"1697892780.0","comment_id":"1049490","upvote_count":"1","content":"Selected Answer: BC\\nOption B & C.","poster":"Rameez1"},{"timestamp":"1697049360.0","upvote_count":"1","poster":"ashley369534","comment_id":"1041027","content":"B&C\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\\nfirst thing first, this question ask for dealing with error. B&C\\nin the doc, error handling has 2 part: 1. Error handling in your application(The AWS SDKs perform their own retries and error checking.) 2.Error retries and exponential backoff\\n(If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed. which is b option) d is irrelevant"},{"poster":"cai123456","timestamp":"1695821880.0","comment_id":"1018842","upvote_count":"1","content":"between C and B I choose C because of the key work \\"frequently\\". using AWS SDK we update the code and do not need to retry frequently."},{"poster":"misa27","timestamp":"1694424720.0","content":"Selected Answer: BD\\nA single operation can retrieve up to 16 MB of data, which can contain as many as 100 items. BatchGetItem returns a partial result if the response size limit is exceeded, the table\'s provisioned throughput is exceeded, more than 1MB per partition is requested, or an internal processing failure occurs. If a partial result is returned, the operation returns a value for UnprocessedKeys. You can use this value to retry the operation starting with the next item to get.\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","upvote_count":"3","comment_id":"1004587"},{"upvote_count":"1","poster":"chvtejaswi","content":"Selected Answer: BD\\nB and D","comment_id":"1003637","timestamp":"1694314080.0"},{"comment_id":"991024","poster":"mrsoa","timestamp":"1693080420.0","content":"Selected Answer: BD\\nB D \\n\\nFrom Stephan\'s maarek course \\n\\nBatchGetItem\\n\u2022 Return items from one or more tables\\n\u2022 Up to 100 items, up to 16 MB of data\\n\u2022 Items are retrieved in parallel to minimize latency\\n\u2022 UnprocessedKeys for failed read operations (exponential backoff or add RCU)","upvote_count":"9"},{"timestamp":"1692972780.0","upvote_count":"1","comment_id":"990145","content":"Selected Answer: BC\\nB. Retry with Exponential Backoff: When the batch response includes values in UnprocessedKeys, it indicates that some items could not be processed due to limitations like provisioned capacity or system overload. Retry the batch operation with an exponential backoff strategy, which means progressively increasing the time between retries. This helps prevent overwhelming the DynamoDB service and improves the chances of successfully processing the items in subsequent retries.\\n\\nC. Use AWS SDK: AWS SDKs provide built-in retry mechanisms that handle transient errors like UnprocessedKeys. When using an AWS SDK, you don\'t need to implement the retry logic yourself. The SDK will automatically handle retries with appropriate backoff strategies, making your application more resilient and reducing the burden of error handling.","poster":"love777"},{"timestamp":"1692695640.0","upvote_count":"6","content":"Selected Answer: BD\\nB and D is correct answer. AWS SDK automatically takes care of both retry and exponential backoff. If we choose C, selecting only C will answer our question(no need of B) but We need to choose 2 answer. In addition, question doesnot specifically say to change core logic from low level api to SDK. by choosing B and D we can improve resiliency. \\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","poster":"aanataliya","comment_id":"987261"},{"timestamp":"1692246240.0","poster":"ninomfr64","comment_id":"983210","upvote_count":"1","content":"Selected Answer: BC\\nIf DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.\\n\\nthus b) and c) as the \\"AWS SDK implements an exponential backoff algorithm for better flow control\\" https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff:~:text=each%20AWS%20SDK%20implements%20an%20exponential%20backoff%20algorithm%20for%20better%20flow%20control"},{"content":"Selected Answer: BC\\nB: for batch, exponential backoff looks answer\\nC: direct to DynamoDB do not recommend","timestamp":"1691115000.0","upvote_count":"1","comment_id":"971616","poster":"jipark"},{"timestamp":"1689361440.0","poster":"KillThemWithKindness","comment_id":"951780","upvote_count":"2","content":"Selected Answer: BD\\nC. Using an AWS SDK can simplify making requests and handling responses, but on its own, it does not address the underlying issue of unprocessed keys."},{"upvote_count":"3","content":"Selected Answer: BD\\n(B) If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.\\n(D) The most likely cause of a failed read or a failed write is throttling. For BatchGetItem, one or more of the tables in the batch request does not have enough provisioned read capacity to support the operation\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","comment_id":"951370","timestamp":"1689323100.0","poster":"awsstark"},{"content":"Selected Answer: BC\\nThe hint is it is using the low-level API operation currently. Using AWS SDK, retries and optimization will be done by the SDK.","upvote_count":"4","timestamp":"1689072780.0","poster":"tttamtttam","comment_id":"948901"},{"content":"Selected Answer: BC\\nD don\'t solve the problem","poster":"MrPie","upvote_count":"1","comment_id":"944908","timestamp":"1688666640.0"},{"poster":"Pupina","upvote_count":"3","timestamp":"1688149380.0","comment_id":"939318","content":"I completely agree on D. My question is why develop the exponential backoff algorithm (that is B) instead of using the automatic functionality of backoff in SDK (option C). Why BD instead of CD"},{"comment_id":"938551","content":"Why B instead of C? Each AWS SDK implements retry logic automatically. Most AWS SDKs now support exponential backoff and jitter as part of their retry behavior\\nThen D to increase capacity https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TroubleshootingThrottling.html\\nC&D","upvote_count":"2","timestamp":"1688070060.0","poster":"Pupina"},{"poster":"MatthewHuiii","comment_id":"930368","upvote_count":"1","timestamp":"1687428420.0","content":"Selected Answer: BC\\nRetry behavior includes settings regarding how the SDKs attempt to recover from failures resulting from requests made to AWS services."},{"comments":[{"content":"\\"The most likely cause of a failed read or a failed write is throttling. For BatchGetItem, one or more of the tables in the batch request does not have enough provisioned read capacity to support the operation.\\"\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.BatchOperations","upvote_count":"2","poster":"Naj_64","comment_id":"926665","timestamp":"1687089720.0"}],"upvote_count":"3","content":"BD is correct answer. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.BatchOperations","comment_id":"924311","poster":"Kaushik287","timestamp":"1686842040.0"},{"comment_id":"919053","poster":"tuongthuy","content":"Selected Answer: BC\\nCorrect answer: B & C\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff\\n\u279c \\"The AWS SDKs implement automatic retry logic and exponential backoff.\\"\\n\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.BatchOperations\\n\u279c \\"If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.\\"","timestamp":"1686296220.0","upvote_count":"1"},{"comment_id":"910144","poster":"ezredame","upvote_count":"2","content":"Selected Answer: BC\\nIf DynamoDB returns any unprocessed items, you should retry the batch operation on those items. AWS SDKs typically include functionality for retrying requests with exponential backoff.\\n\\nIf questions indicate ProvisionedThroughputExceededException, then we should try to RCU, WCU.","timestamp":"1685441820.0"},{"content":"Selected Answer: BD\\nC could be beneficial but not necessary. AWS SDKs typically include functionality for retrying requests with exponential backoff and some of them do it automatically, but it is not a direct solution to the UnprocessedKeys problem.","poster":"loctong","upvote_count":"3","comment_id":"900540","timestamp":"1684363680.0"},{"upvote_count":"1","comment_id":"893251","poster":"Devon_Fazekas","content":"While increasing the provisioned read capacity of the DynamoDB table can help reduce the likelihood of encountering UnprocessedKeys errors due to throttling, it does not directly address the issue of how to handle the UnprocessedKeys responses. To handle UnprocessedKeys, the application should implement retry logic with exponential backoff and randomized delay, as well as consider other solutions like pagination, limiting the number of items per batch, and optimizing the request patterns.","timestamp":"1683646080.0"},{"comment_id":"892580","timestamp":"1683591180.0","content":"Ans: B & C\\n\\nThe two actions that the developer should take to increase the resiliency of the application when the batch response includes values in UnprocessedKeys are B, \\"Retry the batch operation with exponential backoff and randomized delay,\\" and C, \\"Update the application to use an AWS software development kit (AWS SDK) to make the requests.\\"","poster":"Nagendhar","upvote_count":"1"},{"upvote_count":"2","content":"Got this question in exam.","timestamp":"1683390180.0","poster":"geekdamsel","comment_id":"890866"},{"poster":"rlnd2000","content":"Selected Answer: BD\\nI go with BD. \\n\\nFrom https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\\n\\nIf DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed.","comment_id":"886451","timestamp":"1682956260.0","upvote_count":"2"},{"poster":"ihebchorfi","content":"Selected Answer: BD\\nI would go with BD.\\nNote that CD is also correct, but would require the developer to modify his application code.","comment_id":"883813","upvote_count":"2","timestamp":"1682705880.0"},{"timestamp":"1682379120.0","poster":"MrTee","upvote_count":"2","content":"B and C","comment_id":"879775"},{"upvote_count":"2","poster":"Rpod","content":"C or AWS SDK usage does exponential back off by default so if B is right , C essentially does the same thing so should be correct . B and C","comment_id":"875438","timestamp":"1681981980.0"},{"content":"the answers do not apply\\none gets the unprocessedkeys only if the data exceeds 16mb\\nyou just need to retry again","comment_id":"865878","upvote_count":"1","timestamp":"1681081920.0","poster":"alecs_adam"},{"poster":"Krok","timestamp":"1680677340.0","content":"Selected Answer: BC\\nI think that B and C.","comment_id":"861816","upvote_count":"3"},{"poster":"anhike","comment_id":"853960","timestamp":"1680060120.0","upvote_count":"1","content":"Selected Answer: CD\\nLook at the question \\"Which actions should the developer take to\\" -> BCD is right but B no need to do."},{"poster":"Kristijan92","upvote_count":"2","timestamp":"1679895480.0","content":"Selected Answer: CD\\nThe AWS SDKs implement automatic retry logic and exponential backoff.\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","comment_id":"851757"},{"upvote_count":"3","timestamp":"1679308560.0","content":"I think it should B and C since C offers what we need to do for B","comment_id":"844760","poster":"prabhay786"},{"comment_id":"840720","upvote_count":"3","timestamp":"1678957200.0","content":"BD\\nhttps://www.examtopics.com/discussions/amazon/view/88817-exam-aws-certified-developer-associate-topic-1-question-273/","poster":"aragon_saa"}],"answer_description":"","extracted_at":"2025-12-24T09:14:07.346Z","extraction_method":"api_direct_v1"},{"question_id":"P0iT4Dpxzp354zghdmAE","question_number":526,"page":106,"question_text":"An engineer created an A/B test of a new feature on an Amazon CloudWatch Evidently project. The engineer configured two variations of the feature (Variation A and Variation B) for the test. The engineer wants to work exclusively with Variation A. The engineer needs to make updates so that Variation A is the only variation that appears when the engineer hits the application\'s endpoint.\\n\\nWhich solution will meet this requirement?","choices":{"C":"Add an experiment to the project. Set the identifier of the experiment to Variation B. Set the variation to 0%.","A":"Add an override to the feature. Set the identifier of the override to the engineer\'s user ID. Set the variation to Variation A.","B":"Add an override to the feature. Set the identifier of the override to Variation A. Set the variation to 100%.","D":"Add an experiment to the project. Set the identifier of the experiment to the AWS account\'s account ISet the variation to Variation A."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106488-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-17 16:14:00","unix_timestamp":1681740840,"discussion_count":9,"discussion":[{"upvote_count":"15","timestamp":"1681740840.0","content":"Selected Answer: A\\nOverrides let you pre-define the variation for selected users. to always receive the editable variation. https://aws.amazon.com/blogs/aws/cloudwatch-evidently/","comment_id":"872770","poster":"Fyssy","comments":[{"comment_id":"969053","content":"the key looks \\"override\\" and allow only \\"userID\\"","poster":"jipark","timestamp":"1690892460.0","upvote_count":"1"}]},{"upvote_count":"10","comment_id":"921359","timestamp":"1686567480.0","content":"Selected Answer: A\\nCheck Bullet point 9 in the link below\\n\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Evidently-newfeature.html","poster":"Baba_Eni"},{"timestamp":"1735049580.0","upvote_count":"2","poster":"sumanshu","comment_id":"1331144","content":"Selected Answer: A\\nAn override allows you to force specific variations of a feature for a subset of users based on identifiers like user ID. This is useful for testing or debugging without affecting other users or the experiment as a whole."},{"timestamp":"1730299200.0","poster":"nbxyzd","upvote_count":"1","content":"Selected Answer: A\\nQuote: To specify that certain users always see a certain variation, choose Overrides, Add override. Then, specify a user by entering their user ID, account ID, or some other identifier in Identifier, and specify which variation they should see.\\n\\nThis can be useful for members of your own testing team or other internal users when you want to make sure they see a specific variation. The sessions of users who are assigned overrides do not contribute to launch or experiment metrics.","comment_id":"1305035"},{"poster":"michele740","upvote_count":"1","comment_id":"1232389","content":"Therefore, option A is the best choice to meet the requirement of ensuring the engineer exclusively sees Variation A.","timestamp":"1718709180.0"},{"timestamp":"1716342180.0","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","comment_id":"1215336","poster":"65703c1"},{"poster":"badsati","timestamp":"1712858040.0","comment_id":"1193950","upvote_count":"1","content":"Selected Answer: A\\nBy adding an override to the feature and setting the identifier to the engineer\'s user ID, the engineer ensures that only their requests are directed to Variation A.\\nSetting the variation to Variation A explicitly assigns the desired variation to the engineer\'s requests, effectively ensuring they only experience Variation A.\\nTherefore, the correct solution is Option A."},{"upvote_count":"2","poster":"hsinchang","timestamp":"1694430660.0","content":"Set the variation to 0% or 100% makes no sense. Plus, the identifier should not be an account.","comment_id":"1004663"},{"timestamp":"1689576300.0","comment_id":"953899","content":"Selected Answer: A\\nYou have to give identifier","upvote_count":"1","poster":"ancomedian"}],"answer_description":"","extracted_at":"2025-12-24T09:14:18.294Z","extraction_method":"api_direct_v1"},{"question_id":"eZ59UbEsAklnUo7oiZvd","question_number":527,"page":106,"question_text":"A developer is working on an existing application that uses Amazon DynamoDB as its data store. The DynamoDB table has the following attributes: partNumber (partition key), vendor (sort key), description, productFamily, and productType. When the developer analyzes the usage patterns, the developer notices that there are application modules that frequently look for a list of products based on the productFamily and productType attributes.\\n\\nThe developer wants to make changes to the application to improve performance of the query operations.\\n\\nWhich solution will meet these requirements?","choices":{"C":"Recreate the table. Add partNumber as the partition key and vendor as the sort key. During table creation, add a local secondary index (LSI) with productFamily as the partition key and productType as the sort key.","D":"Update the queries to use Scan operations with productFamily as the partition key and productType as the sort key.","B":"Create a local secondary index (LSI) with productFamily as the partition key and productType as the sort key.","A":"Create a global secondary index (GSI) with productFamily as the partition key and productType as the sort key."},"correct_answer":"A","answer_ET":"A","answers_community":["A (97%)","3%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106490-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-17 16:19:00","unix_timestamp":1681741140,"discussion_count":7,"discussion":[{"upvote_count":"10","timestamp":"1697552340.0","poster":"Fyssy","content":"Selected Answer: A\\nreate a Global Secondary Index (GSI): The developer should create a new GSI on the DynamoDB table with the productFamily attribute as the partition key and the productType attribute as the sort key. This will allow the application to perform fast queries on these attributes without scanning the entire table.","comment_id":"872775"},{"poster":"Majong","content":"Selected Answer: A\\nLSI can\xb4t be created on an already existing table and as Fyssy says. A - create new GSI will make the querying faster and you do not need to recreate the whole table.","timestamp":"1700917620.0","upvote_count":"9","comment_id":"906590"},{"upvote_count":"2","comment_id":"1331547","content":"Selected Answer: A\\nA) Correct - GSI will give alternative Primary Key (HASH or HASH + Sort Key) from the base table.\\n\\n\\nB) Eliminated - An LSI shares the same partition key as the base table but allows a different sort key. LSIs must be defined at the time of table creation and cannot be added to an existing table.","timestamp":"1735132680.0","poster":"sumanshu"},{"comment_id":"1215337","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","timestamp":"1732247100.0"},{"content":"Selected Answer: C\\nOption C improve more performance. The question didn\'t care about effort","comment_id":"1181572","upvote_count":"1","timestamp":"1727176500.0","poster":"maurice2005"},{"comment_id":"1119670","poster":"SerialiDr","content":"Selected Answer: A\\nThis is a viable solution. A GSI allows you to query data using an alternate key, in this case, productFamily and productType. This would enable efficient queries based on these attributes, which is aligned with the observed usage patterns.","timestamp":"1720691640.0","upvote_count":"2"},{"poster":"winzzhhzzhh","upvote_count":"5","content":"Selected Answer: A\\nLSI: different sort key but the same partition key\\nGSI: different partition key and a different sort key","timestamp":"1709874540.0","comment_id":"1002052"}],"answer_description":"","extracted_at":"2025-12-24T09:14:18.294Z","extraction_method":"api_direct_v1"},{"question_id":"3HVkBfVhiphERqB83bYt","question_number":528,"page":106,"question_text":"A developer creates a VPC named VPC-A that has public and private subnets. The developer also creates an Amazon RDS database inside the private subnet of VPC-A. To perform some queries, the developer creates an AWS Lambda function in the default VPC. The Lambda function has code to access the RDS database. When the Lambda function runs, an error message indicates that the function cannot connect to the RDS database.\\n\\nHow can the developer solve this problem?","choices":{"C":"Create a security group for the Lambda function. Add a new rule in the RDS security group to allow traffic from the new Lambda security group.","A":"Modify the RDS security group. Add a rule to allow traffic from all the ports from the VPC CIDR block.","B":"Redeploy the Lambda function in the same subnet as the RDS instance. Ensure that the RDS security group allows traffic from the Lambda function.","D":"Create an IAM role. Attach a policy that allows access to the RDS database. Attach the role to the Lambda function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (72%)","C (28%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106491-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-17 16:23:00","unix_timestamp":1681741380,"discussion_count":30,"discussion":[{"comment_id":"880421","poster":"MrTee","content":"Selected Answer: B\\nTo solve this problem, the developer should redeploy the Lambda function in the same subnet as the RDS instance and ensure that the RDS security group allows traffic from the Lambda function. This will allow the Lambda function to access the RDS database within the private subnet of VPC-A. The developer should also make sure that the Lambda function is configured with the appropriate network settings and permissions to access resources within the VPC.","upvote_count":"16","timestamp":"1682429220.0"},{"content":"Selected Answer: B\\nRedeploy","comment_id":"872781","timestamp":"1681741380.0","poster":"Fyssy","upvote_count":"13"},{"timestamp":"1735133400.0","comment_id":"1331553","content":"Selected Answer: B\\nLambda function in the default VPC cannot communicate with the RDS in VPC-A, because they are in different VPCs with no connection (like a VPC peering or transit gateway).","upvote_count":"1","poster":"sumanshu"},{"upvote_count":"2","timestamp":"1731690840.0","content":"Selected Answer: C\\nB is InCorrect because Deploying the Lambda function in the same private subnet as the RDS instance is not feasible, Lambda function needs to access other resources or services outside the VPC.","comment_id":"1312728","poster":"mallikarjun_angadi"},{"upvote_count":"1","timestamp":"1731690720.0","poster":"mallikarjun_angadi","content":"B is incorrect because deploying lambda in private subnet. Cannot access other resources","comment_id":"1312725"},{"comment_id":"1279508","upvote_count":"1","poster":"raasankar","timestamp":"1725615960.0","content":"Selected Answer: B\\nC would need a vpc peering, \\nSo B is the best option as we are redeploying to same subnet."},{"timestamp":"1716342900.0","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215345","upvote_count":"1"},{"timestamp":"1714079340.0","upvote_count":"1","comment_id":"1202255","content":"they are in different VPC, hence C is not possible unless there is VPC Peering.","poster":"Vaibs099"},{"timestamp":"1712858640.0","poster":"badsati","comment_id":"1193955","content":"Selected Answer: B\\nBy deploying the Lambda function in the same subnet as the RDS instance (VPC-A), the Lambda function will have access to the resources within the same VPC, including the RDS database.\\nAdditionally, the RDS security group should be configured to allow inbound traffic from the Lambda function\'s security group.\\nTherefore, the correct solution is Option B.","upvote_count":"2"},{"timestamp":"1711547100.0","upvote_count":"1","comment_id":"1184139","poster":"DeaconStJohn","content":"Selected Answer: B\\nRedeploy as no access has been set up between VPCs"},{"timestamp":"1711289880.0","poster":"maurice2005","upvote_count":"1","content":"Selected Answer: B\\nA and B wont work since lambda is on default vpc which is not vpc-a\\nD won\'t work since since it\'s network access in the first place.","comment_id":"1181678"},{"upvote_count":"2","content":"Selected Answer: B\\nOption B (\\"Redeploy the Lambda function in the same subnet as the RDS instance. Ensure that the RDS security group allows traffic from the Lambda function.\\") is the most accurate approach if the Lambda function and RDS are to communicate within the same VPC. It directly addresses the need for the Lambda function to access the VPC and the security group configuration.","comment_id":"1160303","timestamp":"1709018340.0","poster":"SerialiDr"},{"poster":"cauchy06","content":"Selected Answer: C\\nNo need for redeploy. ChatGPT also says C.","comment_id":"1121987","comments":[{"content":"ChatGPT don\'t know anything. It\'s only read data","upvote_count":"5","poster":"toan_nguyen","timestamp":"1707911280.0","comment_id":"1150166"}],"timestamp":"1705173600.0","upvote_count":"1"},{"timestamp":"1704974880.0","comment_id":"1119683","content":"Selected Answer: B\\nB. Redeploy the Lambda function in the same subnet as the RDS instance. Ensure that the RDS security group allows traffic from the Lambda function: This is a viable solution. Placing the Lambda function in the same VPC as the RDS instance (preferably in a private subnet for security reasons) and ensuring the security groups are correctly configured to allow traffic between the Lambda function and the RDS instance will enable connectivity.\\n\\nC. Create a security group for the Lambda function. Add a new rule in the RDS security group to allow traffic from the new Lambda security group: This option would be correct if the Lambda function and the RDS instance were in the same VPC. However, since they are in different VPCs, simply adjusting security groups won\'t address the cross-VPC connectivity issue.","upvote_count":"6","poster":"SerialiDr"},{"upvote_count":"2","content":"Selected Answer: B\\nOption C would be the correct choice, but it doesn\'t include the route configuration between subnets needed to access the RDS. I chose option B, but according to architectural best practices, it\'s not the ideal solution.","comment_id":"1114042","poster":"nickolaj","timestamp":"1704398880.0"},{"upvote_count":"1","comment_id":"1105029","content":"Selected Answer: C\\nSeems more efficient solution.","poster":"a_win","timestamp":"1703481840.0"},{"content":"Selected Answer: B\\nhttps://docs.aws.amazon.com/vpc/latest/userguide/default-vpc.html\\nThe default VPC is the public subnet, this is the main trick","comments":[{"poster":"BaYaga","timestamp":"1703896800.0","comment_id":"1109303","upvote_count":"1","content":"Have you even read the documentation that you\'re providing. It says clearly:\\n\\nYou can use a default VPC as you would use any other VPC:\\n\\nAdd additional nondefault subnets.\\nModify the main route table.\\nAdd additional route tables.\\nAssociate additional security groups.\\nUpdate the rules of the default security group.\\nAdd AWS Site-to-Site VPN connections.\\nAdd more IPv4 CIDR blocks.\\nAccess VPCs in a remote Region by using a Direct Connect gateway. For information about Direct Connect gateway options, see Direct Connect gateways in the AWS Direct Connect User Guide.\\nYou can use a default subnet as you would use any other subnet; add custom route tables and set network ACLs. You can also specify a specific default subnet when you launch an EC2 instance."}],"upvote_count":"1","poster":"KarBiswa","comment_id":"1098965","timestamp":"1702821720.0"},{"timestamp":"1702821660.0","content":"Selected Answer: B\\nB is the option. Because they meant here A default VPC comes with a public subnet in each Availability Zone,\\nSo here default VPC they meant Public, so the lambda must be redployed to Private subnet.\\nhttps://docs.aws.amazon.com/vpc/latest/userguide/default-vpc.html","upvote_count":"1","comment_id":"1098963","poster":"KarBiswa"},{"poster":"Certified101","comment_id":"1093838","content":"Selected Answer: B\\nB is correct, the lambda function lives in a different VPC, so it needs a VPC peering connection from both VPC\'s and a route to VPC-A.\\n\\nIf you select C you will be assuming that the default VPC can communicate with VPC-A\\n\\nSo redeployment and amendment of the SG will fit the needs.","upvote_count":"2","timestamp":"1702327260.0"},{"upvote_count":"2","poster":"chewasa","timestamp":"1702126620.0","content":"Selected Answer: C\\nOption C is the recommended approach. By creating a security group for the Lambda function and adding a rule in the RDS security group to allow traffic from the new Lambda security group, you create a more controlled and secure configuration. This allows the Lambda function to communicate with the RDS database without exposing unnecessary access.","comment_id":"1091808"},{"comment_id":"1081649","upvote_count":"3","content":"Selected Answer: C\\nI dont know why we need redeploy lambda here,I will go with C","poster":"walala97","timestamp":"1701095460.0"},{"content":"Selected Answer: B\\nSecurity group cannot include services from different VPCs, the Lambda function needs to be redeployed.","comment_id":"1004693","timestamp":"1694431800.0","upvote_count":"2","poster":"hsinchang","comments":[{"content":"Exactly... VPC to VPC connection you must use VPC peering","timestamp":"1702139700.0","poster":"[Removed]","comment_id":"1091910","upvote_count":"1"}]},{"content":"Selected Answer: C\\nThe issue here is most likely due to the fact that the Lambda function, running in the default VPC, is trying to access the RDS database located in another VPC (VPC-A). By default, resources in different VPCs cannot communicate directly with each other.\\nTo enable communication between the Lambda function and the RDS database in a different VPC, you should create a security group for the Lambda function and configure the RDS security group to allow traffic from the Lambda security group.","comment_id":"992320","timestamp":"1693234740.0","poster":"love777","upvote_count":"3"},{"content":"Option \'C\' is better. Because it offers a more secure, flexible, and scalable solution for allowing communication between the Lambda function and the RDS database, without tightly coupling the Lambda function with the database\'s network configuration. It also follows best practices for security and access control.","timestamp":"1690341060.0","comment_id":"963296","upvote_count":"2","comments":[{"upvote_count":"1","poster":"jipark","content":"the key is \\"security group\\", not \\"IAM role\\"","comment_id":"969063","timestamp":"1690892820.0"}],"poster":"r3mo"},{"content":"Selected Answer: C\\nB and C are correct. Going with C though. C will take only a few minutes to implement while redeploying the Lambda function will definitely take more time to complete.","poster":"Naj_64","upvote_count":"3","comment_id":"947899","timestamp":"1688977560.0"},{"content":"C is the correct answer","timestamp":"1687700220.0","poster":"sum_la46","upvote_count":"1","comment_id":"933648"},{"poster":"hexie","content":"Selected Answer: C\\nC - well, I\'m going for C in this case because the question doesnt mention either that the Lambda function NEED to be on the default VPC, but also doesnt mention that the Lambda function will reach only the RDS on the specific VPC. \\nImagine if there are other RDS instances on other VPCs on the same project, he would need to deploy a Lambda Function in each of them? Creating a Security Group for the Lambda Function would make easier by just assign the Security Group to any VPC that has a RDS instance :)","upvote_count":"4","comment_id":"929383","timestamp":"1687345680.0"},{"content":"Selected Answer: C\\nOption A would allow all traffic from the VPC CIDR block to the RDS instance. This is not a secure configuration.\\nOption B would move the Lambda function to the same subnet as the RDS instance. This is a possible solution, but it is not the most efficient solution.\\nOption D would create an IAM role and attach a policy to the role that allows access to the RDS database. This would allow the Lambda function to access the RDS database, but it would not allow the Lambda function to connect to the RDS instance.","comment_id":"918673","upvote_count":"2","timestamp":"1686258180.0","poster":"Prem28"},{"comment_id":"911152","upvote_count":"1","timestamp":"1685532300.0","comments":[{"poster":"Prem28","upvote_count":"3","timestamp":"1685532540.0","content":"we know that the Lambda function is running in the default VPC, which is a public VPC. The RDS instance is running in a private subnet, which is not accessible from the public internet. In order for the Lambda function to connect to the RDS instance, the Lambda function must be able to access the private subnet. This can be done by creating a security group for the Lambda function and adding a rule to the RDS security group to allow traffic from the Lambda security group.","comment_id":"911161"}],"poster":"Prem28","content":"c is correct\\n\\nOption A would allow all traffic from the VPC CIDR block to the RDS instance. This is not a secure configuration.\\nOption B would move the Lambda function to the same subnet as the RDS instance. This is a possible solution, but it is not the most efficient solution.\\nOption D would create an IAM role and attach a policy to the role that allows access to the RDS database. This would allow the Lambda function to access the RDS database, but it would not allow the Lambda function to connect to the RDS instance."},{"comment_id":"897981","content":"Selected Answer: B\\na - no because they rds and lambda on different vpc\\nc - same as a \\nd - same as a and c\\n\\nb is the correct answer","poster":"Jamshif01","timestamp":"1684115640.0","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:14:18.294Z","extraction_method":"api_direct_v1"},{"question_id":"sAycUAslO5EufgKyU2qv","question_number":529,"page":106,"question_text":"A company runs an application on AWS. The company deployed the application on Amazon EC2 instances. The application stores data on Amazon Aurora.\\n\\nThe application recently logged multiple application-specific custom DECRYP_ERROR errors to Amazon CloudWatch logs. The company did not detect the issue until the automated tests that run every 30 minutes failed. A developer must implement a solution that will monitor for the custom errors and alert a development team in real time when these errors occur in the production environment.\\n\\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Configure the application to create a custom metric and to push the metric to CloudWatch. Create an AWS CloudTrail alarm. Configure the CloudTrail alarm to use an Amazon Simple Notification Service (Amazon SNS) topic to send notifications.","B":"Create an AWS Lambda function to run every 5 minutes to scan the CloudWatch logs for the keyword DECRYP_ERROR. Configure the Lambda function to use Amazon Simple Notification Service (Amazon SNS) to send a notification.","C":"Use Amazon CloudWatch Logs to create a metric filter that has a filter pattern for DECRYP_ERROR. Create a CloudWatch alarm on this metric for a threshold >=1. Configure the alarm to send Amazon Simple Notification Service (Amazon SNS) notifications.","D":"Install the CloudWatch unified agent on the EC2 instance. Configure the application to generate a metric for the keyword DECRYP_ERROR errors. Configure the agent to send Amazon Simple Notification Service (Amazon SNS) notifications."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106708-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-19 13:39:00","unix_timestamp":1681904340,"discussion_count":7,"discussion":[{"timestamp":"1697817420.0","content":"Selected Answer: C\\nTo monitor for custom DECRYP_ERROR errors and alert a development team in real time when these errors occur in the production environment with the least operational overhead, the developer should use Amazon CloudWatch Logs to create a metric filter that has a filter pattern for DECRYP_ERROR. The developer should then create a CloudWatch alarm on this metric for a threshold >=1 and configure the alarm to send Amazon Simple Notification Service (Amazon SNS) notifications (Option C). This solution will allow the developer to monitor for custom errors in real time and receive notifications when they occur with minimal operational overhead.","upvote_count":"9","poster":"MrTee","comment_id":"875765"},{"upvote_count":"1","poster":"sumanshu","comments":[{"upvote_count":"1","content":"A) Eliminated - Custom metric creation by the application requires code changes in the application, which introduces development overhead.\\n\\nB) Eliminated - Running a Lambda function periodically adds complexity, additional cost, and delays in detecting errors (up to 5 minutes).\\n\\nD) Eliminated - installing and maintaining the CloudWatch agent introduces operational complexity","timestamp":"1735136280.0","poster":"sumanshu","comment_id":"1331575"}],"timestamp":"1735136160.0","comment_id":"1331573","content":"Selected Answer: C\\nCloudWatch Logs Metric Filter allows you to directly track specific keywords (e.g., DECRYP_ERROR) in logs and generate metrics without additional code or infrastructure. After creating a metric filter, you can configure a CloudWatch Alarm to monitor the metric and send an alert if the threshold is exceeded (e.g., >=1 occurrence). Using Amazon SNS, the alarm can notify the development team in real time."},{"upvote_count":"1","comment_id":"1215347","timestamp":"1732247880.0","content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1"},{"timestamp":"1728670260.0","poster":"badsati","upvote_count":"1","comment_id":"1193960","content":"Selected Answer: C\\nOptions A, B, and D introduce additional complexity, operational overhead, and potential points of failure compared to Option C, which leverages native CloudWatch capabilities for log monitoring and alerting with minimal setup and maintenance overhead. Therefore, Option C is the most suitable choice for meeting the requirements with the least operational overhead."},{"timestamp":"1720693920.0","poster":"SerialiDr","comment_id":"1119715","upvote_count":"1","content":"Selected Answer: C\\nThis is a straightforward and effective solution. CloudWatch Logs allows you to create a metric filter for specific log patterns (such as DECRYP_ERROR) and then create an alarm based on that metric. When the alarm is triggered, it can send a notification through Amazon SNS. This approach provides real-time monitoring with minimal operational overhead."},{"poster":"hsinchang","upvote_count":"4","content":"Selected Answer: C\\nA and B are not real-time, and the CloudWatch unified agent in D is used to collect metrics and logs from EC2 instances and on-premises servers, not to send notifications.\\nSo C.","comment_id":"1004701","timestamp":"1710164100.0"},{"comment_id":"874559","timestamp":"1697715540.0","content":"Selected Answer: C\\nCloudWatch Logs can use filter expressions. For example, find a specific IP inside of a log Or count occurrences of \u201cERROR\u201d in your logs\u2022 Metric filters can be used to trigger CloudWatch alarms","poster":"Fyssy","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:14:18.294Z","extraction_method":"api_direct_v1"},{"question_id":"gcl4Db8s7yB8aa00mMkb","question_number":530,"page":106,"question_text":"A developer created an AWS Lambda function that accesses resources in a VPC. The Lambda function polls an Amazon Simple Queue Service (Amazon SQS) queue for new messages through a VPC endpoint. Then the function calculates a rolling average of the numeric values that are contained in the messages. After initial tests of the Lambda function, the developer found that the value of the rolling average that the function returned was not accurate.\\n\\nHow can the developer ensure that the function calculates an accurate rolling average?","choices":{"B":"Modify the function to store the values in Amazon ElastiCache. When the function initializes, use the previous values from the cache to calculate the rolling average.","D":"Modify the function to store the values in the function\'s layers. When the function initializes, use the previously stored values to calculate the rolling average.","A":"Set the function\'s reserved concurrency to 1. Calculate the rolling average in the function. Store the calculated rolling average in Amazon ElastiCache.","C":"Set the function\'s provisioned concurrency to 1. Calculate the rolling average in the function. Store the calculated rolling average in Amazon ElastiCache."},"correct_answer":"A","answer_ET":"A","answers_community":["A (57%)","B (42%)","1%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106711-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-19 13:43:00","unix_timestamp":1681904580,"discussion_count":34,"discussion":[{"content":"Selected Answer: A\\nYou need to set the reserved concurrency to 1 otherwise multiple functions could run at the same time causing the math to be off. Also there was a similar question in another practice exam set that stated the same thing","comment_id":"925725","poster":"eboehm","timestamp":"1686972540.0","upvote_count":"25","comments":[{"timestamp":"1690893660.0","upvote_count":"2","content":"reserve concurrency 1 means poll in order.\\nthis looks answer.","comment_id":"969073","poster":"jipark"}]},{"comment_id":"880436","upvote_count":"19","poster":"MrTee","content":"Selected Answer: B\\nBy using ElastiCache, the Lambda function can store the values of the previous messages it has received, which can be used to calculate an accurate rolling average.","timestamp":"1682430960.0"},{"upvote_count":"2","comment_id":"1331579","poster":"sumanshu","content":"Selected Answer: A\\nB) Eliminated - If multiple instances of the Lambda function run concurrently, they could retrieve or modify the same data in ElastiCache, leading to inaccuracies in the rolling average.\\n\\nC) Eliminated - Provisioned concurrency does not prevent concurrency issues\\n\\nD) Eliminated - Lambda layers are used to share common code or dependencies across Lambda functions but are not designed for storing or persisting data.","timestamp":"1735136460.0"},{"content":"Selected Answer: B\\nReserved concurrency: Setting reserved concurrency to 1 ensures only one instance of the function executes at a time. While this might prevent race conditions, it doesn\'t address the core issue of calculating the rolling average across multiple Lambda invocations.\\n u","poster":"ShakthiGCP","comment_id":"1328801","timestamp":"1734571860.0","upvote_count":"1"},{"timestamp":"1734353880.0","poster":"trieudo","comment_id":"1327363","upvote_count":"1","content":"Selected Answer: A\\n==> Discard B: There are not limit corrency in elastic cache, multiple lambda can access make race condition ==> wrong output"},{"poster":"AmitRanchi","timestamp":"1728432360.0","upvote_count":"1","comment_id":"1294898","content":"Selected Answer: A\\nReserved Concurrency of 1 ensures that only one instance of the Lambda function runs at a time, which is crucial for calculating an accurate rolling average. If multiple instances of the Lambda function run simultaneously (without concurrency control), each instance might have incomplete or inconsistent data, leading to incorrect results for the rolling average.\\n\\nStoring the rolling average in Amazon ElastiCache provides a persistent, in-memory storage that the function can access quickly during each invocation. ElastiCache can store the current state of the rolling average and any relevant historical data, ensuring that each invocation of the Lambda function has access to the most recent values for calculation"},{"poster":"Saurabh04","comment_id":"1261271","comments":[{"poster":"rue_","timestamp":"1730309820.0","upvote_count":"1","content":"layers are not meant to store dynamic data. it\'s for sharing libraries and static code across lambda functions","comment_id":"1305097"}],"timestamp":"1722899940.0","content":"Correct answer should be D. Storing values in the function\'s layers and using them during initialization is straightforward. This Approach avoids external services like Elasticache.","upvote_count":"1"},{"poster":"lozou","upvote_count":"1","timestamp":"1720449960.0","content":"Selected Answer: B\\nelasticache for keeping the values from previous invocation","comment_id":"1244415"},{"upvote_count":"1","comment_id":"1239791","poster":"guidosolano","timestamp":"1719773160.0","content":"Selected Answer: B\\nA y C limitan mucho la capacidad de Lamda. Voy con B"},{"comment_id":"1215348","poster":"65703c1","timestamp":"1716343380.0","upvote_count":"2","content":"Selected Answer: A\\nA is the correct answer."},{"upvote_count":"1","content":"Selected Answer: B\\nAs per Gemini below is why A is incorrect\\nA. Reserved concurrency: Setting reserved concurrency to 1 ensures only one instance of the function executes at a time. While this might prevent race conditions, it doesn\'t address the core issue of calculating the rolling average across multiple Lambda invocations.","poster":"SathyaJS","timestamp":"1711440180.0","comment_id":"1183117"},{"content":"Selected Answer: B\\nWhile limiting concurrency (A or C) can help manage the function\'s execution rate and scale and prevent throttling, it is not directly related to ensuring the accuracy of calculating rolling average. Instead, focusing on proper state management and data consistency mechanisms (using ElastiCache) is key to achieving accurate results in this scenario.","upvote_count":"2","comments":[{"comment_id":"1183697","content":"that\'s the correct way in real world but nothing about state management or data consistency is mentioned in B. But A has it although it\'s not the good real world to do so.","timestamp":"1711494900.0","upvote_count":"1","poster":"maurice2005"}],"timestamp":"1710726600.0","comment_id":"1176193","poster":"yingying920928"},{"poster":"SerialiDr","comment_id":"1160391","content":"Selected Answer: A\\nOption A (\\"Set the function\'s reserved concurrency to 1. Calculate the rolling average in the function. Store the calculated rolling average in Amazon ElastiCache.\\") is the most suitable solution. It ensures that only one instance of the Lambda function processes messages at any given time, maintaining the sequence of message processing which is crucial for an accurate rolling average calculation. Additionally, using Amazon ElastiCache to store and retrieve the rolling average across invocations addresses the statelessness of AWS Lambda, enabling stateful processing.","upvote_count":"4","timestamp":"1709027100.0"},{"comment_id":"1152964","content":"Selected Answer: A\\nWhat if one of the instances freezes and holds one of the vzlues for some time, not updating cache, while the others continue calculatinv the avg giving wrong output ?","timestamp":"1708216980.0","upvote_count":"3","poster":"d323bvmiqj"},{"upvote_count":"2","comment_id":"1119727","timestamp":"1704976800.0","content":"Selected Answer: B\\nBy storing individual message values in ElastiCache (a fast, in-memory data store), the Lambda function can retrieve these values upon initialization to calculate an accurate rolling average. This approach effectively maintains state across Lambda invocations.","poster":"SerialiDr"},{"upvote_count":"1","poster":"Chimzi","content":"Selected Answer: B\\nUsing ElastiCache allows you to maintain a shared state across all instances of your Lambda function","timestamp":"1704674460.0","comment_id":"1116282"},{"upvote_count":"4","poster":"ShinobiGrappler","timestamp":"1703082960.0","comment_id":"1101638","content":"Selected Answer: A\\nThis approach controls concurrency by ensuring only one instance runs at a time. Provisioned concurrency also has the added benefit of reducing cold start latency. Storing the rolling average in ElastiCache is a good practice for maintaining state. However, like option A, it may limit the function\'s throughput."},{"timestamp":"1703069700.0","upvote_count":"4","comment_id":"1101450","poster":"chewasa","content":"Selected Answer: B\\nBoth options A and B provide valid approaches to address potential issues, but they have different trade-offs. Option A focuses on limiting concurrency, while Option B suggests using a caching solution to store and retrieve intermediate values.\\n\\nIf avoiding concurrency problems is a top priority and the function\'s execution time is not a concern, Option A could be a suitable choice. However, if you are looking for a solution that allows for better scalability and doesn\'t impose strict concurrency limitations, Option B with Amazon ElastiCache provides a more scalable and distributed approach."},{"poster":"Certified101","upvote_count":"3","content":"Selected Answer: A\\nA is correct","timestamp":"1702840500.0","comment_id":"1099168"},{"upvote_count":"1","comment_id":"1091925","poster":"[Removed]","content":"Another tricky question. I go with A mainly because ElastiCache is mainly used along with databases. See this link https://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html#reserved-and-provisioned \\n\\nPulled from AWS Website --\x3e What is Amazon ElastiCache?\\nAmazon ElastiCache allows you to seamlessly set up, run, and scale an in-memory cache in the cloud. ElastiCache is compatible with both Redis and Memcached. Boost your application performance and achieve microsecond latency by caching alongside your existing databases. ElastiCache is a popular choice for real-time use cases like caching, session stores, gaming, geo-spatial services, real-time analytics, and queuing.","timestamp":"1702141140.0","comments":[{"timestamp":"1702141380.0","content":"Actually after reading the question more carefully... I change my answer to B","poster":"[Removed]","comment_id":"1091929","upvote_count":"1"}]},{"comment_id":"1085895","upvote_count":"1","timestamp":"1701503400.0","comments":[{"content":"ChatGPT is not the bible for aws","upvote_count":"2","comment_id":"1227241","poster":"beekeeper0101","timestamp":"1717929000.0"}],"content":"Selected Answer: B\\nChatGPT:B","poster":"tqiu654"},{"content":"Selected Answer: A\\nAo definir a simultaneidade reservada da fun\xe7\xe3o como 1, isso garante que apenas uma inst\xe2ncia da fun\xe7\xe3o Lambda ser\xe1 invocada ao mesmo tempo. Isso pode ajudar a evitar qualquer problema de concorr\xeancia que possa causar imprecis\xf5es na m\xe9dia m\xf3vel. Ao calcular a m\xe9dia m\xf3vel na fun\xe7\xe3o e armazen\xe1-la no Amazon ElastiCache, a fun\xe7\xe3o pode acessar e atualizar rapidamente a m\xe9dia sempre que for invocada.","poster":"Jonalb","upvote_count":"3","timestamp":"1698375600.0","comment_id":"1055079"},{"timestamp":"1697541060.0","comment_id":"1045888","content":"Selected Answer: D\\nD. Modify the function to store the values in the function\'s layers. When the function initializes, use the previously stored values to calculate the rolling average.\\n\\nThis is the best solution because it does not add any overhead to the function, and it does not increase the cost of running the function. Storing the values in the function\'s layers is a simple and effective way to ensure that the function calculates an accurate rolling average.","poster":"dexdinh91","upvote_count":"1"},{"upvote_count":"2","timestamp":"1695978300.0","content":"Selected Answer: B\\nThe best way for the developer to ensure that the function calculates an accurate rolling average is to modify the function to store the values in Amazon ElastiCache. When the function initializes, use the previous values from the cache to calculate the rolling average.\\n\\nThis solution is the best because it ensures that the rolling average is always calculated from the latest values, even if the Lambda function is scaled out to multiple instances.","comment_id":"1020653","poster":"nnecode"},{"timestamp":"1695741300.0","comment_id":"1017908","upvote_count":"2","content":"Selected Answer: B\\nThe correct answer is B. Modify the function to store the values in Amazon ElastiCache. When the function initializes, use the previous values from the cache to calculate the rolling average.\\n\\nThis solution will ensure that the Lambda function calculates an accurate rolling average, even if the function is invoked multiple times simultaneously.","poster":"nnecode"},{"timestamp":"1694566620.0","content":"Selected Answer: A\\nReserved concurrency is the maximum number of concurrent instances you want to allocate to your function.\\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html#reserved-and-provisioned","poster":"sofiatian","comment_id":"1006108","upvote_count":"2"},{"poster":"love777","content":"Selected Answer: B\\nExplanation: In a Lambda function, maintaining state across invocations can be challenging due to the stateless nature of the serverless architecture. Option B addresses this challenge by using Amazon ElastiCache (a managed in-memory data store) to store the necessary data between invocations. By storing the values in ElastiCache, the Lambda function can retrieve the previous values upon initialization and accurately calculate the rolling average.\\n\\nOptions A, C, and D are not the best choices for this scenario:\\n\\nA. Setting the function\'s reserved concurrency to 1 doesn\'t inherently solve the accuracy issue. While it might ensure sequential execution, it doesn\'t address the problem of maintaining state across multiple invocations.","comment_id":"994217","timestamp":"1693406340.0","upvote_count":"5"},{"poster":"redfivedog","upvote_count":"4","comment_id":"963744","content":"Selected Answer: A\\nA is correct. Calculating the rolling average requires the messages in the SQS queue to be processed in order, so concurrent lambda executions won\'t work.","timestamp":"1690376580.0"},{"content":"Selected Answer: A\\nNeed to set the reserved concurrency to 1.","comment_id":"946566","timestamp":"1688827800.0","poster":"MrPie","upvote_count":"2"},{"content":"Selected Answer: A\\nIt is A. You have to set reserved instances to 1 to prevent parallel calculations.","timestamp":"1688758620.0","upvote_count":"2","comment_id":"945962","poster":"awsazedevsh"},{"comment_id":"942210","timestamp":"1688418480.0","upvote_count":"2","content":"Selected Answer: A\\nFirst paragraph from https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html","poster":"qwan"},{"upvote_count":"2","timestamp":"1687714860.0","content":"C is the correct answer","comment_id":"933791","poster":"sum_la46"},{"comment_id":"933651","poster":"sum_la46","content":"Is B Correct answer??","upvote_count":"2","timestamp":"1687700400.0"},{"comment_id":"874564","poster":"Fyssy","timestamp":"1681904580.0","content":"Selected Answer: B\\nModify the function to store the values in Amazon ElastiCache. When the function initializes, use the previous values from the cache to calculate the rolling average.","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:14:18.294Z","extraction_method":"api_direct_v1"},{"question_id":"ir5vB4WYoodJlHdeTJi0","question_number":531,"page":107,"question_text":"A developer is writing unit tests for a new application that will be deployed on AWS. The developer wants to validate all pull requests with unit tests and merge the code with the main branch only when all tests pass.\\n\\nThe developer stores the code in AWS CodeCommit and sets up AWS CodeBuild to run the unit tests. The developer creates an AWS Lambda function to start the CodeBuild task. The developer needs to identify the CodeCommit events in an Amazon EventBridge event that can invoke the Lambda function when a pull request is created or updated.\\n\\nWhich CodeCommit event will meet these requirements?","choices":{"B":"","A":"","C":"","D":""},"correct_answer":"C","answer_ET":"C","answers_community":["C (87%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106717-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-19 13:58:00","unix_timestamp":1681905480,"discussion_count":10,"discussion":[{"comment_id":"915961","upvote_count":"8","content":"Selected Answer: C\\nIt\'s definitely C. Events in answer D are not real. A & B are clearly wrong since two events are required.","timestamp":"1701851220.0","poster":"csG13"},{"upvote_count":"1","poster":"sumanshu","timestamp":"1735136580.0","content":"Selected Answer: C\\nUsing both events together ensures that the Lambda function is invoked for both new pull requests and updates to existing pull requests.","comment_id":"1331583"},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","timestamp":"1732248360.0","comment_id":"1215351","poster":"65703c1"},{"poster":"Vaibs099","content":"https://aws.amazon.com/blogs/devops/automated-code-review-on-pull-requests-using-aws-codecommit-and-aws-codebuild/","upvote_count":"2","timestamp":"1729891560.0","comment_id":"1202261"},{"timestamp":"1709933940.0","poster":"Dushank","comment_id":"1002691","content":"Answer is C. There\'s no event call pullRequestUpdated","upvote_count":"4"},{"timestamp":"1700919660.0","content":"Selected Answer: C\\nTwo events is needed so A and B is no. \\nThe events mentioned in D does not exist as Zodraz says (just look in the link)","poster":"Majong","upvote_count":"4","comment_id":"906612"},{"upvote_count":"3","poster":"Prem28","timestamp":"1699603980.0","content":"Selected Answer: C\\nits c ,Event mentioned in D not Exist","comment_id":"893663"},{"upvote_count":"3","content":"Selected Answer: C\\nIt\' s C. Any of the events mentioned on D exist. https://docs.aws.amazon.com/codecommit/latest/userguide/monitoring-events.html#pullRequestSourceBranchUpdated","comment_id":"891939","poster":"zodraz","timestamp":"1699440660.0"},{"upvote_count":"2","poster":"zodraz","content":"It\' s C. Any of the events mentioned on D exist. https://docs.aws.amazon.com/codecommit/latest/userguide/monitoring-events.html#pullRequestSourceBranchUpdated","comment_id":"891932","timestamp":"1699440300.0"},{"upvote_count":"3","content":"Selected Answer: D\\n\\"detail\\": {\\n \\"event\\": [\\"pullRequestCreated\\", \\"pullRequestSourceBranchUpdated\\"]","comment_id":"874586","poster":"Fyssy","timestamp":"1697716680.0","comments":[{"comment_id":"1216568","timestamp":"1732372680.0","poster":"Arktos","upvote_count":"1","content":"you create a pull request and update a branch so the answer is C"}]}],"answer_description":"","extracted_at":"2025-12-24T09:14:29.148Z","extraction_method":"api_direct_v1"},{"question_id":"2NE2mHED3COwuWavnLJ3","question_number":532,"page":107,"question_text":"A developer deployed an application to an Amazon EC2 instance. The application needs to know the public IPv4 address of the instance.\\n\\nHow can the application find this information?","choices":{"A":"Query the instance metadata from http://169.254.169.254/latest/meta-data/.","D":"Check the hosts file of the operating system.","C":"Query the Amazon Machine Image (AMI) information from http://169.254.169.254/latest/meta-data/ami/.","B":"Query the instance user data from http://169.254.169.254/latest/user-data/."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108728-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 10:54:00","unix_timestamp":1683536040,"discussion_count":6,"discussion":[{"timestamp":"1704893220.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html","poster":"Naj_64","comment_id":"948039","upvote_count":"6"},{"comment_id":"1119992","timestamp":"1720710300.0","content":"Selected Answer: A\\nThis is the correct approach. The instance metadata includes details such as the instance\'s public IPv4 address. The application can make a request to this URL, specifically to http://169.254.169.254/latest/meta-data/public-ipv4, to retrieve the public IPv4 address of the instance.","poster":"SerialiDr","upvote_count":"6"},{"content":"Selected Answer: A\\nThe EC2 instance metadata service provides details about the instance, such as its public and private IP addresses. To find the public IPv4 address, you can query the metadata","poster":"sumanshu","upvote_count":"1","timestamp":"1735136700.0","comment_id":"1331584"},{"timestamp":"1732309140.0","comment_id":"1215925","upvote_count":"2","content":"Selected Answer: A\\nA is the correct answer.","poster":"65703c1"},{"upvote_count":"2","poster":"zodraz","timestamp":"1699441080.0","comment_id":"891948","content":"Selected Answer: A\\nYou can retrieve ip through http://169.254.169.254/latest/meta-data/local-ipv4 or http://169.254.169.254/latest/meta-data/public-ipv4\\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html"},{"poster":"zodraz","upvote_count":"2","timestamp":"1699440840.0","comments":[{"timestamp":"1699905360.0","comment_id":"896973","upvote_count":"4","content":"Please remove this comment @admin","poster":"zodraz"}],"content":"Selected Answer: A\\nIt\' s C. Any of the events mentioned on D exist. https://docs.aws.amazon.com/codecommit/latest/userguide/monitoring-events.html#pullRequestSourceBranchUpdated","comment_id":"891944"}],"answer_description":"","extracted_at":"2025-12-24T09:14:29.148Z","extraction_method":"api_direct_v1"},{"question_id":"kkZ1fVqkoGSb97IwRnzh","question_number":533,"page":107,"question_text":"An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file.\\n\\nHow should the developer code the application?","choices":{"B":"Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.","D":"Upload the data to an S3 bucket using server side-encryption with an AWS KMS key.","A":"Use the KMS Encrypt API to encrypt the data. Store the encrypted data key and data.","C":"Use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107443-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 16:01:00","unix_timestamp":1682431260,"discussion_count":6,"discussion":[{"content":"Selected Answer: C\\noption C: use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.","timestamp":"1698242460.0","comment_id":"880439","upvote_count":"12","poster":"MrTee"},{"content":"Selected Answer: C\\nA) Eliminated - The Encrypt API in AWS KMS is designed for small amounts of data (4 KB)\\n\\n\\nFor large files, it is more efficient and scalable to use data keys (using the GenerateDataKey API)","poster":"sumanshu","comments":[{"poster":"sumanshu","timestamp":"1735136940.0","upvote_count":"2","content":"D) Eliminated - this approach does not meet the requirement to encrypt data within the application prior to storage,","comment_id":"1331588"}],"timestamp":"1735136880.0","upvote_count":"2","comment_id":"1331586"},{"content":"Selected Answer: C\\nC is the correct answer.","upvote_count":"1","timestamp":"1732309380.0","poster":"65703c1","comment_id":"1215930"},{"poster":"SerialiDr","content":"Selected Answer: C\\nThis is the most suitable option. AWS KMS\'s GenerateDataKey API provides a unique data key for each invocation, which can be used to encrypt each video file. The data key itself is also returned in an encrypted form, which can be safely stored alongside the encrypted data. This approach satisfies the requirement of unique encryption for each file and securely manages the encryption keys.","comment_id":"1119995","timestamp":"1720710720.0","upvote_count":"3"},{"timestamp":"1714379220.0","comment_id":"1056744","content":"Option C seems correct","upvote_count":"1","poster":"Tinez"},{"upvote_count":"2","content":"Selected Answer: C\\nA and B cannot meet the requirement of having a unique key for each file, and D cannot meet the requirement of encrypting the data within the application.\\nC meets all requirements.","poster":"hsinchang","comment_id":"1004755","timestamp":"1710166440.0"}],"answer_description":"","extracted_at":"2025-12-24T09:14:29.148Z","extraction_method":"api_direct_v1"},{"question_id":"tTEOOMTVawiHZucnMGFL","question_number":534,"page":107,"question_text":"A company is planning to deploy an application on AWS behind an Elastic Load Balancer. The application uses an HTTP/HTTPS listener and must access the client IP addresses.\\n\\nWhich load-balancing solution meets these requirements?","choices":{"B":"Use a Network Load Balancer (NLB). Enable proxy protocol support on the NLB and the target application.","A":"Use an Application Load Balancer and the X-Forwarded-For headers.","C":"Use an Application Load Balancer. Register the targets by the instance ID.","D":"Use a Network Load Balancer and the X-Forwarded-For headers."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107444-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 16:11:00","unix_timestamp":1682431860,"discussion_count":6,"discussion":[{"comment_id":"880457","timestamp":"1698243060.0","content":"Selected Answer: A\\nUse an Application Load Balancer (ALB) and the X-Forwarded-For headers. When an ALB is used, the X-Forwarded-For header can be used to pass the client IP address to the backend servers.","poster":"MrTee","upvote_count":"10"},{"poster":"sumanshu","comment_id":"1331591","timestamp":"1735137180.0","upvote_count":"2","content":"Selected Answer: A\\nApplication Load Balancer (ALB) is a Layer 7 (HTTP/HTTPS) load balancer that supports handling HTTP headers, including the X-Forwarded-For header.\\n\\nB/D - Eliminated - Network Load Balancer (NLB) operates at Layer 4 (TCP) and does not inherently handle HTTP headers\\n\\nC) Eliminated - it does not address the requirement of accessing client IP addresses."},{"poster":"65703c1","comment_id":"1215933","upvote_count":"1","timestamp":"1732309500.0","content":"Selected Answer: A\\nA is the correct answer."},{"content":"Selected Answer: A\\nOption a","timestamp":"1729249620.0","poster":"topicsquestions","upvote_count":"1","comment_id":"1197895"},{"timestamp":"1720711020.0","content":"Selected Answer: A\\nAn Application Load Balancer (ALB) operates at the application layer (Layer 7) of the OSI model and supports HTTP/HTTPS traffic. It adds the X-Forwarded-For header to the request as it forwards it to the target, which contains the original client\'s IP address. This allows the application behind the ALB to access the client IP addresses.","poster":"SerialiDr","upvote_count":"4","comment_id":"1120001"},{"upvote_count":"4","timestamp":"1702343700.0","poster":"HuiHsin","content":"is A\\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/x-forwarded-headers.html\\nhttps://aws.amazon.com/elasticloadbalancing/features/?nc=sn&loc=2","comment_id":"921022"}],"answer_description":"","extracted_at":"2025-12-24T09:14:29.148Z","extraction_method":"api_direct_v1"},{"question_id":"Hg7nJ0IDQwZTg9rWbLgx","question_number":535,"page":107,"question_text":"A developer wants to debug an application by searching and filtering log data. The application logs are stored in Amazon CloudWatch Logs. The developer creates a new metric filter to count exceptions in the application logs. However, no results are returned from the logs.\\n\\nWhat is the reason that no filtered results are being returned?","choices":{"D":"Metric data points for logs groups can be filtered only after they are exported to an Amazon S3 bucket.","B":"CloudWatch Logs only publishes metric data for events that happen after the filter is created.","A":"A setup of the Amazon CloudWatch interface VPC endpoint is required for filtering the CloudWatch Logs in the VPC.","C":"The log group for CloudWatch Logs should be first streamed to Amazon OpenSearch Service before metric filtering returns the results."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108734-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 12:03:00","unix_timestamp":1683540180,"discussion_count":6,"discussion":[{"comment_id":"891990","upvote_count":"14","timestamp":"1699444980.0","content":"Selected Answer: B\\nFilters do not retroactively filter data. Filters only publish the metric data points for events that happen after the filter was created.\\n\\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html","poster":"zodraz"},{"comment_id":"1558274","poster":"anandkg","content":"Selected Answer: B\\nThe other option are not that related","upvote_count":"1","timestamp":"1743950280.0"},{"timestamp":"1735137360.0","poster":"sumanshu","content":"Selected Answer: B\\nMetric filters in Amazon CloudWatch Logs only work on new logs generated after the filter is created. If the filter was created, but no logs were generated afterward (or if you\'re trying to filter older log entries), no metric data points would be produced.","upvote_count":"1","comment_id":"1331592"},{"comment_id":"1215934","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732309620.0","upvote_count":"1"},{"upvote_count":"2","poster":"SerialiDr","content":"Selected Answer: B\\nCloudWatch Logs metric filters apply to new log events only after the filter is created. They do not retroactively analyze or filter log events that were ingested before the creation of the metric filter. Therefore, if the log events in question were ingested before the metric filter was created, they would not trigger the filter or generate metric data.","timestamp":"1720711560.0","comment_id":"1120009"},{"content":"Selected Answer: B\\nMetric filters in Amazon CloudWatch Logs are applied only to new log events. If you create a metric filter and are looking to count exceptions, the filter will only apply to log events generated after the metric filter was created. Existing logs are not scanned.","timestamp":"1710016260.0","comment_id":"1003417","poster":"Dushank","upvote_count":"4"}],"answer_description":"","extracted_at":"2025-12-24T09:14:29.148Z","extraction_method":"api_direct_v1"},{"question_id":"bnb2pdYiCIctuIKnVfLQ","question_number":536,"page":108,"question_text":"A company is running a custom application on a set of on-premises Linux servers that are accessed using Amazon API Gateway. AWS X-Ray tracing has been enabled on the API test stage.\\nHow can a developer enable X-Ray tracing on the on-premises servers with the LEAST amount of configuration?","choices":{"D":"Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTelemetryRecords API call.","A":"Install and run the X-Ray SDK on the on-premises servers to capture and relay the data to the X-Ray service.","C":"Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTraceSegments API call.","B":"Install and run the X-Ray daemon on the on-premises servers to capture and relay the data to the X-Ray service."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/102786-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-16 10:00:00","unix_timestamp":1678957200,"discussion_count":17,"discussion":[{"timestamp":"1679371800.0","poster":"Untamables","comment_id":"845507","content":"Selected Answer: B\\nB\\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html","upvote_count":"8"},{"comment_id":"1561186","poster":"anandkg","upvote_count":"1","timestamp":"1744823040.0","content":"Selected Answer: B\\nwithout x-ray demon not possible"},{"comment_id":"1329534","content":"Selected Answer: B\\nA) Eliminated - The X-Ray SDK is used to instrument your application code to create and send trace data to the X-Ray daemon.\\nHowever, this option alone is insufficient because the SDK only captures traces\u2014it still needs the X-Ray daemon to relay data to the X-Ray service.","upvote_count":"2","comments":[{"comment_id":"1329537","timestamp":"1734708480.0","upvote_count":"1","comments":[{"timestamp":"1734708480.0","comment_id":"1329538","poster":"sumanshu","content":"D) Eliminated - This API is not suitable for sending trace data.","upvote_count":"1"}],"poster":"sumanshu","content":"C) - Eliminated - While this could work, but involves more configuration and complexity"}],"poster":"sumanshu","timestamp":"1734708420.0"},{"upvote_count":"1","timestamp":"1734510480.0","comment_id":"1328345","content":"Selected Answer: B\\nB \\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html","poster":"aloksheth"},{"comment_id":"1325013","upvote_count":"1","poster":"trieudo","content":"Selected Answer: B\\nKeyword: LEAST amount of configuration; accessed using Amazon API Gateway. AWS X-Ray tracing has been enabled\\n\\n==> Discard C, D: must write logic in lamba funct extra \\n==> Discard A: must change code to add annotaion, ... . If not have keyword: \'accessed using Amazon API Gateway. AWS X-Ray tracing has been enabled\', it will be correct, because it easier than B\\n\\nB: despite you must know deeply X-Ray to using it (config JSON format, ...), but with conditon in keyword, you just run only cmd \'./xray --region us-east-1\' for working","timestamp":"1733919360.0"},{"content":"Selected Answer: B\\nB is correct according to Stephane maarek course","poster":"Hendrix944","timestamp":"1728238200.0","upvote_count":"1","comment_id":"1293923"},{"comment_id":"1214959","upvote_count":"1","timestamp":"1716296700.0","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"comment_id":"1190637","timestamp":"1712440980.0","poster":"vinfo","content":"Selected Answer: B\\nB. El daemon, es una capacidad propia de X-Ray, para instalar directamente","upvote_count":"1"},{"timestamp":"1711533600.0","upvote_count":"1","poster":"apa_1","content":"Selected Answer: B\\nB is correct","comment_id":"1183981"},{"upvote_count":"1","timestamp":"1700091900.0","poster":"leonardoliveros","content":"Selected Answer: B\\nB, you should to install the X-Ray daemon in on-premises without this all others option is wrong","comment_id":"1072015"},{"poster":"Ugo_22","upvote_count":"1","content":"Selected Answer: B\\nThe answer is obviously B.","timestamp":"1697123160.0","comment_id":"1041866"},{"timestamp":"1695883680.0","poster":"Kowalsky95","comment_id":"1019515","content":"From doc: The AWS X-Ray daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. The daemon works in conjunction with the AWS X-Ray SDKs and must be running so that data sent by the SDKs can reach the X-Ray service.\\nRunning just the daemon won\'t achieve anything.","upvote_count":"3"},{"comment_id":"890868","timestamp":"1683390240.0","upvote_count":"3","content":"Got this question in exam.Correct answer is B.","poster":"geekdamsel"},{"content":"Selected Answer: B\\n. Install and run the X-Ray daemon on the on-premises servers to capture and relay the data to the X-Ray service is the correct option. The X-Ray daemon can be installed and configured on the on-premises servers to capture data and send it to the X-Ray service. This requires minimal configuration and setup. Option A is incorrect because while the X-Ray SDK can be used to capture data on the on-premises servers, it requires more configuration and development effort than the X-Ray daemon. Option C and D are also incorrect because they involve setting up an AWS Lambda function, which is not necessary for enabling X-Ray tracing on the on-premises servers.","upvote_count":"2","comment_id":"890700","poster":"Bibay","timestamp":"1683372180.0"},{"comment_id":"857931","upvote_count":"4","timestamp":"1680354720.0","content":"Selected Answer: B\\nIt\'s B","poster":"ihta_2031"},{"comment_id":"840749","upvote_count":"3","poster":"haaris786","content":"B: It is Daemon which can be installed for Linux","timestamp":"1678958520.0"},{"upvote_count":"3","comment_id":"840722","content":"B\\nhttps://www.examtopics.com/discussions/amazon/view/28998-exam-aws-certified-developer-associate-topic-1-question-324/","poster":"aragon_saa","timestamp":"1678957200.0"}],"answer_description":"","extracted_at":"2025-12-24T09:14:40.129Z","extraction_method":"api_direct_v1"},{"question_id":"pOZvQ3oCc7uJEYfBYExe","question_number":537,"page":108,"question_text":"A company is planning to use AWS CodeDeploy to deploy an application to Amazon Elastic Container Service (Amazon ECS). During the deployment of a new version of the application, the company initially must expose only 10% of live traffic to the new version of the deployed application. Then, after 15 minutes elapse, the company must route all the remaining live traffic to the new version of the deployed application.\\n\\nWhich CodeDeploy predefined configuration will meet these requirements?","choices":{"B":"CodeDeployDefault.LambdaCanary10Percent5Minutes","D":"CodeDeployDefault.ECSLinear10PercentEvery1Minutes","C":"CodeDeployDefault.LambdaCanary10Percentl15Minutes","A":"CodeDeployDefault.ECSCanary10Percent15Minutes"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108735-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 12:13:00","unix_timestamp":1683540780,"discussion_count":6,"discussion":[{"content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html","poster":"zodraz","upvote_count":"9","timestamp":"1699445580.0","comment_id":"892000"},{"comment_id":"1558273","upvote_count":"1","timestamp":"1743950220.0","poster":"anandkg","content":"Selected Answer: A\\nIn two set only canary will help"},{"comment_id":"1331594","timestamp":"1735137540.0","content":"Selected Answer: A\\nB/C - Eliminated - This configuration is for Lambda deployments, not ECS deployments\\n\\nD) Eliminated - This configuration specifies a linear deployment, meaning that the traffic will be gradually shifted to the new version by 10% every 1 minute","upvote_count":"1","poster":"sumanshu"},{"comment_id":"1215938","poster":"65703c1","upvote_count":"1","timestamp":"1732309680.0","content":"Selected Answer: A\\nA is the correct answer."},{"upvote_count":"4","poster":"SerialiDr","content":"Selected Answer: A\\nThis configuration aligns with the company\'s requirement. It specifies a \\"canary\\" deployment where initially only 10% of live traffic is exposed to the new version of the application. After a period of 15 minutes, the remaining 90% of the traffic is shifted to the new version. This approach allows for monitoring the new version with a small portion of traffic before fully deploying it.","comment_id":"1120013","timestamp":"1720711740.0"},{"content":"Selected Answer: A\\nThis predefined deployment configuration for AWS CodeDeploy with Amazon ECS will initially shift 10% of the traffic to the new version and wait for 15 minutes before shifting the remaining 90% of the traffic to the new version.","timestamp":"1710016440.0","poster":"Dushank","upvote_count":"4","comment_id":"1003419"}],"answer_description":"","extracted_at":"2025-12-24T09:14:40.129Z","extraction_method":"api_direct_v1"},{"question_id":"aUNvJ78FnWZl2gWsU0bF","question_number":538,"page":108,"question_text":"A company hosts a batch processing application on AWS Elastic Beanstalk with instances that run the most recent version of Amazon Linux. The application sorts and processes large datasets.\\n\\nIn recent weeks, the application\'s performance has decreased significantly during a peak period for traffic. A developer suspects that the application issues are related to the memory usage. The developer checks the Elastic Beanstalk console and notices that memory usage is not being tracked.\\n\\nHow should the developer gather more information about the application performance issues?","choices":{"C":"Configure the Amazon CloudWatch agent to track the memory usage of the instances.","D":"Configure an Amazon CloudWatch dashboard to track the memory usage of the instances.","B":"Configure the Elastic Beanstalk .ebextensions directory to track the memory usage of the instances.","A":"Configure the Amazon CloudWatch agent to push logs to Amazon CloudWatch Logs by using port 443."},"correct_answer":"C","answer_ET":"C","answers_community":["C (63%)","B (38%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106899-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-21 14:04:00","unix_timestamp":1682078640,"discussion_count":25,"discussion":[{"timestamp":"1682078640.0","content":"Selected Answer: C\\nConfigure the Amazon CloudWatch agent to track the memory usage of the instances.","comment_id":"876494","comments":[{"upvote_count":"1","content":"Using elastic beanstalk .ebextensions dir","timestamp":"1703442840.0","poster":"xdkonorek2","comment_id":"1104781"}],"poster":"MrTee","upvote_count":"16"},{"poster":"eboehm","comment_id":"926205","timestamp":"1687029240.0","upvote_count":"15","content":"Selected Answer: B\\nfor elastic beanstalk you make this configuration in the .ebtextensions folder\\nhttps://repost.aws/knowledge-center/elastic-beanstalk-memory-metrics-windows","comments":[{"upvote_count":"3","comment_id":"928930","poster":"DumPisach","timestamp":"1687310640.0","comments":[{"comment_id":"966082","timestamp":"1690605300.0","content":"Applies to Linux as well:\\nhttps://medium.com/tomincode/cloudwatch-memory-monitoring-for-elastic-beanstalk-1caa98d57d5c","comments":[{"comment_id":"1180537","poster":"maurice2005","content":"ebextensions is deprecated for linux newest version which is mentioned in the question","timestamp":"1711167540.0","upvote_count":"4"}],"poster":"Naj_64","upvote_count":"1"}],"content":"But the question says Linux"}]},{"upvote_count":"3","comment_id":"1331802","poster":"sumanshu","timestamp":"1735191360.0","content":"Selected Answer: C\\nA) Eliminated - Logs provide insights into application behavior but won\'t help in monitoring resource usage such as memory.\\n\\nB) Eliminated - The .ebextensions directory is used for customizing Elastic Beanstalk environments, such as installing software or modifying instance configurations.\\n\\nC) Correct - The Amazon CloudWatch agent can collect system-level metrics like memory usage, which is not tracked by default in CloudWatch for EC2 instances \\n\\nD) Eliminated - A CloudWatch dashboard is used to visualize metrics that are already being tracked."},{"poster":"ShakthiGCP","comment_id":"1328804","timestamp":"1734572520.0","upvote_count":"2","content":"Selected Answer: C\\n.ebextensions is for customizing your Elastic Beanstalk environment. While you can use it to install monitoring tools, directly configuring it to track memory isn\'t the standard or most efficient approach. So Answer is \'C\'"},{"content":"Selected Answer: C\\nCloudWatch agent track the memory and any types of system component (hardware)","poster":"Saudis","comment_id":"1281629","upvote_count":"1","timestamp":"1725981240.0"},{"upvote_count":"1","poster":"65703c1","comment_id":"1215942","timestamp":"1716405060.0","content":"Selected Answer: C\\nC is the correct answer."},{"content":"Answer is : C\\nfrom Gemini here is why B is incorrect\\nB. .ebextensions directory: While .ebextensions can be used for configuration within Elastic Beanstalk, it\'s not designed to track memory usage directly.","upvote_count":"2","poster":"SathyaJS","timestamp":"1711444020.0","comment_id":"1183152"},{"poster":"SerialiDr","upvote_count":"4","comment_id":"1160426","timestamp":"1709029500.0","content":"Selected Answer: C\\nThis option allows the developer to gather detailed performance metrics, including memory usage, from the EC2 instances. By configuring the CloudWatch agent, the developer can monitor the memory usage in real-time and analyze historical data to identify trends or patterns that may be affecting the application\'s performance. This approach provides actionable insights with minimal overhead and without the need for custom logging or external tools."},{"comment_id":"1125998","timestamp":"1705591320.0","upvote_count":"1","content":"Selected Answer: C\\n..........","poster":"prathameshpathak"},{"comment_id":"1120019","timestamp":"1704994560.0","upvote_count":"1","content":"Selected Answer: C\\nThis is the most direct and appropriate solution. By installing and configuring the Amazon CloudWatch agent on the Elastic Beanstalk instances, the developer can collect detailed system-level metrics, such as memory usage, and send them to CloudWatch for monitoring and analysis.","poster":"SerialiDr"},{"content":"Selected Answer: C\\nThe .ebextensions directory is used for customizing the environment (installing packages, running scripts...) it can\'t track memory usage alone.","upvote_count":"2","timestamp":"1704751440.0","comment_id":"1117052","poster":"Chimzi"},{"poster":"Chimzi","timestamp":"1704751380.0","upvote_count":"1","comment_id":"1117051","content":"Selected Answer: C\\nNo Discussion"},{"upvote_count":"1","content":"Selected Answer: C\\nWe configure the agent not the directory itself.","timestamp":"1704615540.0","poster":"JohnPl","comment_id":"1115646"},{"timestamp":"1703485200.0","poster":"a_win","comment_id":"1105053","upvote_count":"1","content":"Selected Answer: C\\nThe Amazon CloudWatch agent can be configured to collect various metrics, including memory usage, from the instances. By setting up the CloudWatch agent to monitor memory metrics, the developer can get insights into the memory usage patterns during peak traffic periods. This data can help diagnose if memory constraints are causing the performance degradation."},{"comment_id":"1102694","content":"Selected Answer: B\\nit should be B:\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-cw.html#customize-containers-cw-update-roles","poster":"[Removed]","timestamp":"1703173920.0","upvote_count":"3"},{"poster":"KarBiswa","comment_id":"1099643","timestamp":"1702897020.0","content":"Selected Answer: C\\nGoing with C after going through this link:\\nhttps://repost.aws/knowledge-center/elastic-beanstalk-memory-cpu-issues","upvote_count":"1"},{"poster":"TallManDan","upvote_count":"1","comment_id":"1072555","timestamp":"1700150280.0","content":"It requires both B and C. I\'m guessing the question is supposed to say \\"Select Two\\".\\n\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-cw.html"},{"timestamp":"1699393560.0","comment_id":"1065186","upvote_count":"2","poster":"bala30","content":"Selected Answer: B\\nI m confused between B & C ,as for beanstalk we need to configure Amazon CloudWatch agent to track the memory usage of the instances in the .ebtextensions folder ."},{"content":"Selected Answer: B\\nI vote for B, since it is already available with .ebextensions and not required agent","upvote_count":"1","timestamp":"1697559360.0","poster":"Nagasoracle","comment_id":"1046190"},{"comment_id":"1003420","timestamp":"1694284560.0","content":"Selected Answer: C\\nAmazon CloudWatch does not collect memory metrics by default. You need to install the CloudWatch agent on your instances to collect this additional system-level metric like memory utilization.","poster":"Dushank","upvote_count":"5"},{"poster":"love777","comment_id":"994226","timestamp":"1693407120.0","content":"Selected Answer: C\\nThe .ebextensions directory is used for configuration and customization settings, but it doesn\'t directly enable tracking memory usage metrics.","upvote_count":"2"},{"comment_id":"993589","upvote_count":"1","poster":"fossil123","timestamp":"1693354200.0","content":"Selected Answer: B\\nYou can provision Elastic Beanstalk configuration files (.ebextensions) to monitor memory utilization with CloudWatch."},{"content":"You can use .ebextensions direcory which contains Cloudwatch Agent. Bit It didn\'t mention about CloudWatch Agent.","timestamp":"1690182600.0","poster":"jasper_pigeon","upvote_count":"2","comment_id":"961257"},{"timestamp":"1688419620.0","comment_id":"942217","content":"Selected Answer: B\\nThis is for linux\\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-cw.html","poster":"qwan","upvote_count":"3"},{"comment_id":"922325","upvote_count":"3","content":"Selected Answer: C\\nI will go with C\\n The questions said ...issues are related to the memory usage. it is talking about the memory in the instances the app is running, CloudWatch agent is needed in each instance.","poster":"rlnd2000","timestamp":"1686669060.0"}],"answer_description":"","extracted_at":"2025-12-24T09:14:40.129Z","extraction_method":"api_direct_v1"},{"question_id":"UUKTVIoieFVgSZgkFQsJ","question_number":539,"page":108,"question_text":"A developer is building a highly secure healthcare application using serverless components. This application requires writing temporary data to /tmp storage on an AWS Lambda function.\\n\\nHow should the developer encrypt this data?","choices":{"B":"Set up the Lambda function with a role and key policy to access an AWS KMS key. Use the key to generate a data key used to encrypt all data prior to writing to /tmp storage.","A":"Enable Amazon EBS volume encryption with an AWS KMS key in the Lambda function configuration so that all storage attached to the Lambda function is encrypted.","C":"Use OpenSSL to generate a symmetric encryption key on Lambda startup. Use this key to encrypt the data prior to writing to /tmp.","D":"Use an on-premises hardware security module (HSM) to generate keys, where the Lambda function requests a data key from the HSM and uses that to encrypt data on all requests to the function."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/107445-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-25 16:29:00","unix_timestamp":1682432940,"discussion_count":8,"discussion":[{"timestamp":"1735192140.0","upvote_count":"1","poster":"sumanshu","comment_id":"1331808","content":"Selected Answer: B\\nA) Eliminated - AWS Lambda does not use Amazon EBS volumes for its temporary /tmp storage.\\n\\nC) Eliminated - OpenSSL could theoretically generate a symmetric key, this approach is less secure and more error-prone compared to using AWS KMS\\n\\nD) Eliminated - Using an on-premises HSM adds unnecessary complexity and latency to a serverless application"},{"content":"Selected Answer: B\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": [\\n \\"kms:Encrypt\\",\\n \\"kms:Decrypt\\",\\n \\"kms:GenerateDataKey\\",\\n \\"kms:GenerateDataKeyWithoutPlaintext\\",\\n \\"kms:ReEncrypt*\\"\\n ],\\n \\"Resource\\": \\"arn:aws:kms:region:account-id:key/key-id\\"\\n }\\n ]\\n}","poster":"albert_kuo","upvote_count":"2","timestamp":"1726876500.0","comment_id":"1287075"},{"upvote_count":"2","timestamp":"1716405180.0","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","comment_id":"1215946"},{"comment_id":"1120122","poster":"SerialiDr","content":"Selected Answer: B\\nAWS Key Management Service (KMS) provides secure management of encryption keys. The Lambda function can use a KMS key to generate data keys for encrypting and decrypting data. The Lambda function would require appropriate permissions to access the KMS key. This approach provides a high level of security, which is essential for a healthcare application.","timestamp":"1705001880.0","upvote_count":"4"},{"poster":"Milan61","timestamp":"1696600800.0","upvote_count":"1","comment_id":"1026693","content":"B is the solution"},{"poster":"Yuxing_Li","upvote_count":"2","content":"Selected Answer: B\\nGo with B","comment_id":"992684","timestamp":"1693269360.0"},{"content":"Selected Answer: B\\nB is the best solution","upvote_count":"4","comment_id":"883956","poster":"abdelbz16","timestamp":"1682725260.0"},{"timestamp":"1682432940.0","upvote_count":"4","content":"Selected Answer: B\\nis the best solution for encrypting temporary data written to /tmp storage on an AWS Lambda function","comment_id":"880480","poster":"MrTee"}],"answer_description":"","extracted_at":"2025-12-24T09:14:40.129Z","extraction_method":"api_direct_v1"},{"question_id":"XyLWV0o4eiy79esEiR0a","question_number":540,"page":108,"question_text":"A developer has created an AWS Lambda function to provide notification through Amazon Simple Notification Service (Amazon SNS) whenever a file is uploaded to Amazon S3 that is larger than 50 MB. The developer has deployed and tested the Lambda function by using the CLI. However, when the event notification is added to the S3 bucket and a 3,000 MB file is uploaded, the Lambda function does not launch.\\n\\nWhich of the following is a possible reason for the Lambda function\'s inability to launch?","choices":{"D":"The S3 bucket needs to be made public.","B":"The resource-based policy for the Lambda function does not have the required permissions to be invoked by Amazon S3.","C":"Lambda functions cannot be invoked directly from an S3 event.","A":"The S3 event notification does not activate for files that are larger than 1,000 MB."},"correct_answer":"B","answer_ET":"B","answers_community":["B (94%)","6%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109005-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-11 23:12:00","unix_timestamp":1683839520,"discussion_count":8,"discussion":[{"comment_id":"898841","upvote_count":"12","poster":"Jamshif01","timestamp":"1700109420.0","content":"Selected Answer: B\\nB - is right answer\\n\\nA is incorrect because the size of the file should not affect whether the event notification is triggered. \\nC is incorrect because Lambda functions can indeed be invoked directly from an S3 event. \\nD is incorrect because the S3 bucket does not need to be made public for the Lambda function to be invoked.\\n(c)chatgpt"},{"upvote_count":"2","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - S3 event notifications do not have a size limitation for triggering Lambda functions.\\n\\nC) Eliminated - AWS Lambda functions can be triggered directly by S3 event notifications.\\n\\nD) Eliminated - Making the S3 bucket public is not required for it to trigger an event notification","comment_id":"1331877","timestamp":"1735208820.0"},{"comment_id":"1215948","upvote_count":"1","timestamp":"1732310100.0","content":"Selected Answer: B\\nB is the correct answer.","poster":"65703c1"},{"upvote_count":"1","comment_id":"1179028","timestamp":"1726895760.0","content":"Answer is A. The notification work normally. They should work for files up to 5TB but not once the dev uploads a file of 3000MB. Seems the dev did not set up the notification correctly for files of this size.","poster":"ec8or"},{"content":"Why answer B while dev deployed and tested via CLI is ok, but the reason would be lack of resource policy?","poster":"Melisa202401","comment_id":"1153283","comments":[{"timestamp":"1725482040.0","upvote_count":"1","comment_id":"1166067","poster":"TheFivePips","content":"The Lambda function, which reacts to an event and sends a message, can be invoked manually using the AWS CLI or other methods, even if there are issues with the S3 event triggering mechanism. This is because manual invocation typically bypasses the event source (S3 in this case) and directly triggers the Lambda function.\\n\\nWhile Lambda functions can be invoked manually, they also need the correct permissions to be triggered by specific event sources like S3. If the resource-based policy for the Lambda function does not have the necessary permissions, it may not be invoked by S3 events."}],"upvote_count":"1","timestamp":"1723979520.0"},{"content":"B\\nA. The S3 event notification does not activate for files that are larger than 1,000 MB. This is not the case. S3 event notifications can activate for files that are larger than 1,000 MB.\\nC. Lambda functions cannot be invoked directly from an S3 event. This is also not the case. Lambda functions can be invoked directly from an S3 event.\\nD. The S3 bucket needs to be made public. This is not necessary. The S3 bucket does not need to be made public in order for the Lambda function to be invoked.","timestamp":"1701432180.0","comment_id":"911945","upvote_count":"2","poster":"Prem28"},{"comment_id":"895941","timestamp":"1699802460.0","content":"Selected Answer: B\\nanser is B","upvote_count":"2","poster":"chumji"},{"poster":"junrun3","upvote_count":"1","content":"Selected Answer: A\\nAnsewer A","comments":[{"content":"not A, answer is B","upvote_count":"4","timestamp":"1699744440.0","comment_id":"895417","poster":"junrun3"}],"timestamp":"1699744320.0","comment_id":"895413"}],"answer_description":"","extracted_at":"2025-12-24T09:14:40.129Z","extraction_method":"api_direct_v1"},{"question_id":"KePAGvZEMDWeaTw3Bz9i","question_number":541,"page":109,"question_text":"A developer is creating a Ruby application and needs to automate the deployment, scaling, and management of an environment without requiring knowledge of the underlying infrastructure.\\n\\nWhich service would best accomplish this task?","choices":{"D":"AWS Elastic Beanstalk","C":"AWS OpsWorks","B":"AWS CloudFormation","A":"AWS CodeDeploy"},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108737-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 13:20:00","unix_timestamp":1683544800,"discussion_count":6,"discussion":[{"content":"answer- d\\nAWS CodeDeploy can automate the deployment of code to any instance, including Amazon EC2 instances and on-premises servers. However, it does not provide the same level of automation as Elastic Beanstalk, and it requires more manual intervention from developers.\\nAWS CloudFormation can help you model and set up your AWS resources. However, it does not provide any automation for deploying or managing applications.\\nAWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. However, it is not as easy to use as Elastic Beanstalk, and it does not provide the same level of automation for deploying or managing applications.","comment_id":"911952","upvote_count":"14","timestamp":"1685614080.0","poster":"Prem28"},{"poster":"zodraz","upvote_count":"6","content":"Selected Answer: D\\nhttps://www.examtopics.com/discussions/amazon/view/88659-exam-aws-certified-developer-associate-topic-1-question-197/","timestamp":"1683544800.0","comment_id":"892066"},{"content":"Selected Answer: D\\nA) Eliminated - It does not handle the environment\'s scaling or management\\nB) Eliminated - AWS CloudFormation is used to define and provision infrastructure as code\\nC) Eliminated -AWS OpsWorks is a configuration management service that supports Chef and Puppet to automate deployments and configurations\\nD) Correct","timestamp":"1735208880.0","poster":"sumanshu","comment_id":"1331878","upvote_count":"2"},{"timestamp":"1730428380.0","content":"Selected Answer: D\\nwithout requiring knowledge of the underlying infrastructure ---\x3e AWS Elastic Beanstalk","upvote_count":"1","comment_id":"1305643","poster":"nbxyzd"},{"comment_id":"1215951","poster":"65703c1","content":"Selected Answer: D\\nD is the correct answer.","timestamp":"1716405420.0","upvote_count":"1"},{"content":"Selected Answer: D\\nAWS Elastic Beanstalk is designed for developers like the one in your scenario who want to deploy and manage applications without worrying about the underlying infrastructure. It automates the deployment process and automatically handles capacity provisioning, load balancing, auto-scaling, and application health monitoring. You can use it with various platforms including Ruby.","poster":"Dushank","timestamp":"1694284860.0","upvote_count":"3","comment_id":"1003423"}],"answer_description":"","extracted_at":"2025-12-24T09:14:51.160Z","extraction_method":"api_direct_v1"},{"question_id":"BzwpFWJkM3Vmrph1W741","question_number":542,"page":109,"question_text":"A company has a web application that is deployed on AWS. The application uses an Amazon API Gateway API and an AWS Lambda function as its backend.\\n\\nThe application recently demonstrated unexpected behavior. A developer examines the Lambda function code, finds an error, and modifies the code to resolve the problem. Before deploying the change to production, the developer needs to run tests to validate that the application operates properly.\\n\\nThe application has only a production environment available. The developer must create a new development environment to test the code changes. The developer must also prevent other developers from overwriting these changes during the test cycle.\\n\\nWhich combination of steps will meet these requirements with the LEAST development effort? (Choose two.)","choices":{"E":"Create a new API Gateway API for the development environment. Add a resource and method with Lambda integration. Choose the Lambda function and the hotfix alias. Deploy to a new stage. Test the backend.","B":"Update the Lambda function in the API Gateway API integration request to use the hotfix alias. Deploy the API Gateway API to a new stage named hotfix. Test the backend.","D":"Modify the Lambda function by fixing the code. Test the Lambda function. When the Lambda function is working as expected, publish the Lambda function as a new version. Create the alias hotfix. Point the alias to the new version.","A":"Create a new resource in the current stage. Create a new method with Lambda proxy integration. Select the Lambda function. Add the hotfix alias. Redeploy the current stage. Test the backend.","C":"Modify the Lambda function by fixing the code. Test the Lambda function. Create the alias hotfix. Point the alias to the $LATEST version."},"correct_answer":"BD","answer_ET":"BD","answers_community":["BD (95%)","5%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108738-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 13:28:00","unix_timestamp":1683545280,"discussion_count":10,"discussion":[{"timestamp":"1735212780.0","comment_id":"1331894","upvote_count":"1","content":"Selected Answer: BD\\nA) Eliminated - If we create a new resource (e.g., an API path like /new-feature) The current stage (prod) is being modified, which is risky because the production environment is shared.\\n\\nC) Eliminated - $LATEST is not stable. It is always the most recent version of the code, and other developers can overwrite it with new changes during the testing phase.\\n\\n\\nE) Eliminated - Creating a completely new API Gateway API requires significant additional effort,","poster":"sumanshu"},{"comment_id":"1215954","content":"Selected Answer: BD\\nBD is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1732310460.0"},{"upvote_count":"2","timestamp":"1724259660.0","poster":"KillThemWithKindness","content":"Selected Answer: BD\\nNot C, you can\'t use an unqualified ARN ($LATEST) to create an alias.|\\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-versions.html\\n\\nE\\nAfter the initial deployment, you can add more stages and associate them with existing deployments. You can use the API Gateway console to create a new stage, or you can choose an existing stage while deploying an API. You can add a new stage to an API deployment before redeploying the API.\\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/stages.html","comment_id":"1155796"},{"content":"Selected Answer: BE\\nI cannot find another choice that meets this requirement.\\n\\"The developer must create a new development environment to test the code changes. \\"","comment_id":"1142857","timestamp":"1722982620.0","poster":"CrescentShared","upvote_count":"1"},{"poster":"SerialiDr","content":"Selected Answer: BD\\nThe order is D and than B","timestamp":"1720849500.0","comment_id":"1121389","upvote_count":"2"},{"content":"Selected Answer: BD\\nWhy D over C?\\nVersions are immutable. $Latest is mutable, which means anyone access to Lambda can edit and deploy a new code. The question simply doesn\'t want that.\\nWhy B over E?\\nYou don\'t need to create a whole new API to test some new feature. You can simply achieve this by deploying it to a different stage. Afterwards, you can redirect the users to a new stage or do A/B testing.","poster":"Ponyi","upvote_count":"3","timestamp":"1715008860.0","comment_id":"1064098"},{"timestamp":"1706299920.0","comment_id":"964083","poster":"r3mo","content":"C - D.\\nC vs B : option C is preferred over option B because it provides a more isolated and controlled environment for testing the hotfix without directly affecting the production environment. It gives you the flexibility to iterate on the hotfix if needed and promotes a safer development and testing process.\\n\\nD vs E : Option E is preferred over option D because it provides a more isolated and controlled environment for testing the hotfix. It avoids version management complexities and promotes a safer development and testing process by creating a dedicated development environment.","upvote_count":"4"},{"content":"Selected Answer: BD\\nD ==> change the lambda function.\\nB ==> update the API gateway to use the updated lambda function & deploy it into another(new) stage. so that developers can use the newly deployed API endpoint.","poster":"tttamtttam","upvote_count":"4","timestamp":"1705360980.0","comment_id":"952703"},{"timestamp":"1701875280.0","poster":"csG13","comment_id":"916271","content":"Selected Answer: BD\\nIt is B & D. \\n\\nClearly E isn\'t operationally efficient. So we got to choose from A & B one, and C & D the second. \\n\\nBetween A & B, we gotta pick B since in the question it clearly states that we don\'t want to touch the existing solution. \\n\\nRegarding C & D, seems like D is more thorough and also pointing to $LATEST is not sufficiently explicit when you troubleshoot.","upvote_count":"4"},{"content":"Selected Answer: BD\\nhttps://www.examtopics.com/discussions/amazon/view/89549-exam-aws-certified-developer-associate-topic-1-question-334/","timestamp":"1699450080.0","upvote_count":"2","comment_id":"892076","poster":"zodraz"}],"answer_description":"","extracted_at":"2025-12-24T09:14:51.160Z","extraction_method":"api_direct_v1"},{"question_id":"0PV18fKsbeP8xzkIw3Mi","question_number":543,"page":109,"question_text":"A developer is implementing an AWS Cloud Development Kit (AWS CDK) serverless application. The developer will provision several AWS Lambda functions and Amazon API Gateway APIs during AWS CloudFormation stack creation. The developer\'s workstation has the AWS Serverless Application Model (AWS SAM) and the AWS CDK installed locally.\\n\\nHow can the developer test a specific Lambda function locally?","choices":{"D":"Run the cdk synth and sam local start-lambda commands with the function construct identifier and the path to the synthesized CloudFormation template.","C":"Run the cdk synth and sam local invoke commands with the function construct identifier and the path to the synthesized CloudFormation template.","A":"Run the sam package and sam deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function.","B":"Run the cdk synth and cdk deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106939-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-21 17:28:00","unix_timestamp":1682090880,"discussion_count":11,"discussion":[{"timestamp":"1682090880.0","poster":"MrTee","comment_id":"876673","upvote_count":"13","content":"Selected Answer: C\\nThe developer can test a specific Lambda function locally by running the cdk synth command to synthesize the AWS CDK application into an AWS CloudFormation template. Then, the developer can use the sam local invoke command with the function construct identifier and the path to the synthesized CloudFormation template to test the Lambda function locally (option C)."},{"content":"Selected Answer: C\\no test a specific Lambda function locally when using the AWS Cloud Development Kit (AWS CDK), the developer can use the AWS Serverless Application Model (AWS SAM) CLI\'s local testing capabilities in conjunction with the CDK. The typical process would be:\\n\\nRun cdk synth to synthesize the AWS CDK app into a CloudFormation template.\\nUse sam local invoke to run the specific Lambda function locally, providing the function\'s logical identifier and the path to the synthesized CloudFormation template as arguments.","comment_id":"1003427","poster":"Dushank","timestamp":"1694285280.0","upvote_count":"5"},{"timestamp":"1735215180.0","upvote_count":"1","poster":"sumanshu","content":"Selected Answer: C\\nA) Eliminated - The sam package and sam deploy commands are used to upload the Lambda function code and deploy it to AWS.\\n\\nB) Eliminated - The cdk deploy command deploys the stack to AWS.\\n\\nC) Correct - The sam local invoke command uses this template to run the Lambda function locally, simulating the AWS Lambda execution environment.\\n\\nD) Eliminated","comment_id":"1331902"},{"content":"Selected Answer: C\\nNote that the sam local start-lambda subcommand starts a local endpoint to emulate AWS Lambda.","poster":"nbxyzd","timestamp":"1730462940.0","upvote_count":"2","comment_id":"1305785"},{"timestamp":"1721703120.0","poster":"Anandesh","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-cdk-testing.html","upvote_count":"1","comment_id":"1253374"},{"content":"Selected Answer: C\\nC is the correct answer.","poster":"65703c1","timestamp":"1716405960.0","comment_id":"1215955","upvote_count":"1"},{"upvote_count":"2","poster":"KillThemWithKindness","timestamp":"1708542720.0","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html\\n\\nsam local invoke: Invoke Lambda locally\\nsam local start-lambda: Integrating with automated-tests","comment_id":"1155800"},{"comment_id":"1075353","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-cdk-testing.html \\nC","poster":"NaghamAbdellatif","upvote_count":"1","timestamp":"1700479740.0"},{"content":"Selected Answer: C\\nUse the AWS SAM CLI sam local invoke subcommand to initiate a one-time invocation of an AWS Lambda function locally.\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/using-sam-cli-local-invoke.html","timestamp":"1693355340.0","upvote_count":"2","poster":"fossil123","comment_id":"993599"},{"upvote_count":"2","timestamp":"1691006520.0","content":"Selected Answer: C\\nAnswer is clearly C. If you say it\'s not C, you are wrong.","poster":"JamalDaBoss","comment_id":"970520"},{"comment_id":"892089","content":"Selected Answer: C\\nsam local invoke StackLogicalId/FunctionLogicalId\\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/using-sam-cli-local-invoke.html","timestamp":"1683546060.0","upvote_count":"4","poster":"zodraz"}],"answer_description":"","extracted_at":"2025-12-24T09:14:51.160Z","extraction_method":"api_direct_v1"},{"question_id":"sQSmxWkVuxIGDdd4vhQD","question_number":544,"page":109,"question_text":"A company\'s new mobile app uses Amazon API Gateway. As the development team completes a new release of its APIs, a developer must safely and transparently roll out the API change.\\n\\nWhat is the SIMPLEST solution for the developer to use for rolling out the new API version to a limited number of users through API Gateway?","choices":{"C":"Implement an Amazon CloudWatch alarm to trigger a rollback if the observed HTTP 500 status code rate exceeds a predetermined threshold.","D":"Use the canary release deployment option in API Gateway. Direct a percentage of the API traffic using the canarySettings setting.","B":"Validate the new API version and promote it to production during the window of lowest expected utilization.","A":"Create a new API in API Gateway. Direct a portion of the traffic to the new API using an Amazon Route 53 weighted routing policy."},"correct_answer":"D","answer_ET":"D","answers_community":["D (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108739-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 13:45:00","unix_timestamp":1683546300,"discussion_count":4,"discussion":[{"comment_id":"892099","upvote_count":"7","content":"Selected Answer: D\\nhttps://www.examtopics.com/discussions/amazon/view/51596-exam-aws-certified-developer-associate-topic-1-question-355/","poster":"zodraz","timestamp":"1699451100.0"},{"upvote_count":"2","timestamp":"1735215420.0","comment_id":"1331903","poster":"sumanshu","content":"Selected Answer: D\\nA) Eliminated - creating a new API in API Gateway requires managing two separate APIs, which adds unnecessary complexity.\\n\\nB) Eliminated - This is a direct cutover approach, not a gradual rollout to a limited number of users. If issues arise, all users are impacted, which is not safe or transparent.\\n\\nC) Eliminated - It is not relevant to the question\'s requirement\\n\\nD) Correct - It allows gradual exposure of the new API version to a subset of users, minimizing risk."},{"content":"Selected Answer: D\\nD is the correct answer.","poster":"65703c1","upvote_count":"1","timestamp":"1732310820.0","comment_id":"1215957"},{"comment_id":"1003428","poster":"Dushank","upvote_count":"4","content":"Selected Answer: D\\nCanary deployments allow you to divert a percentage of your API traffic to a new API version, enabling you to test how the new version will perform under real-world conditions without fully replacing the previous version. This is especially useful for reducing the risk associated with deploying new versions.","timestamp":"1710017400.0"}],"answer_description":"","extracted_at":"2025-12-24T09:14:51.160Z","extraction_method":"api_direct_v1"},{"question_id":"19IjiTXl1kc8lWGaPjdt","question_number":545,"page":109,"question_text":"A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table.\\n\\nWhat is the simplest way to do this?","choices":{"A":"Write a script that deletes old records; schedule the script as a cron job on an Amazon EC2 instance.","B":"Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.","D":"Add an attribute with the expiration time; name the attribute ItemExpiration.","C":"Each day, create a new table to hold session data; delete the previous day\'s table."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108740-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 13:47:00","unix_timestamp":1683546420,"discussion_count":5,"discussion":[{"timestamp":"1710017520.0","poster":"Dushank","comment_id":"1003431","upvote_count":"6","content":"Selected Answer: B\\nThe simplest way to automatically delete old items from an Amazon DynamoDB table is to use DynamoDB\'s Time to Live (TTL) feature. This feature allows you to define an attribute that stores the expiration time for each item. Once the specified time has passed, DynamoDB automatically deletes the expired items, freeing up storage and reducing costs without the need for custom scripts or manual intervention."},{"poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - no automation\\nC) Eliminated - Constantly creating and deleting tables is not practical and can lead to management and scaling issues.\\nD) Eliminated - Without enabling TTL, merely adding the attribute does not automate item deletion.","comment_id":"1331905","timestamp":"1735215600.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732311000.0","comment_id":"1215960","poster":"65703c1"},{"comment_id":"908679","upvote_count":"2","timestamp":"1701187860.0","poster":"catcatpunch","content":"https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/TTL.html"},{"comment_id":"892101","timestamp":"1699451220.0","poster":"zodraz","upvote_count":"4","content":"Selected Answer: B\\nhttps://www.examtopics.com/discussions/amazon/view/7225-exam-aws-certified-developer-associate-topic-1-question-107/"}],"answer_description":"","extracted_at":"2025-12-24T09:14:51.161Z","extraction_method":"api_direct_v1"},{"question_id":"GKV6mSi3DspxYDN9x2Z7","question_number":546,"page":110,"question_text":"A company is using an Amazon API Gateway REST API endpoint as a webhook to publish events from an on-premises source control management (SCM) system to Amazon EventBridge. The company has configured an EventBridge rule to listen for the events and to control application deployment in a central AWS account. The company needs to receive the same events across multiple receiver AWS accounts.\\n\\nHow can a developer meet these requirements without changing the configuration of the SCM system?","choices":{"B":"Deploy the API Gateway REST API to all the receiver AWS accounts. Create as many SCM webhooks as the number of AWS accounts.","A":"Deploy the API Gateway REST API to all the required AWS accounts. Use the same custom domain name for all the gateway endpoints so that a single SCM webhook can be used for all events from all accounts.","D":"Convert the API Gateway type from REST API to HTTP API.","C":"Grant permission to the central AWS account for EventBridge to access the receiver AWS accounts. Add an EventBridge event bus on the receiver AWS accounts as the targets to the existing EventBridge rule."},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/111295-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-06-06 16:52:00","unix_timestamp":1686063120,"discussion_count":3,"discussion":[{"timestamp":"1701881520.0","poster":"csG13","upvote_count":"19","content":"Selected Answer: C\\nIt\'s C - eventbridge event buses in one (target) account can be a target of another event rule in a source account.\\n\\nFor reference, watch the video in the following link:\\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cross-account.html","comment_id":"916385"},{"comments":[{"poster":"sumanshu","content":"A) Eliminated - This would require modifying the SCM webhook or deploying redundant API Gateway endpoints, which is unnecessary and inefficient.\\n\\nB) Eliminated - This would require multiple webhook configurations in the SCM system, which contradicts the requirement of not changing the SCM setup.\\n\\nD) Eliminated - Changing API Gateway from REST API to HTTP API does not solve the problem of distributing events across multiple AWS accounts.","timestamp":"1739009340.0","comment_id":"1353333","upvote_count":"1"}],"content":"Selected Answer: C\\nThis approach uses EventBridge\'s native cross-account event delivery capabilities, ensuring events are sent to the receiver accounts without modifying the SCM system configuration.","comment_id":"1331907","poster":"sumanshu","timestamp":"1735215900.0","upvote_count":"1"},{"comment_id":"1215961","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1732311060.0","upvote_count":"1","poster":"65703c1"}],"answer_description":"","extracted_at":"2025-12-24T09:15:02.451Z","extraction_method":"api_direct_v1"},{"question_id":"BhLmj52ge3lTiLKPYVDH","question_number":547,"page":110,"question_text":"A company wants to share information with a third party. The third party has an HTTP API endpoint that the company can use to share the information. The company has the required API key to access the HTTP API.\\nThe company needs a way to manage the API key by using code. The integration of the API key with the application code cannot affect application performance.\\nWhich solution will meet these requirements MOST securely?","choices":{"B":"Store the API credentials in a local code variable. Push the code to a secure Git repository. Use the local code variable at runtime to make the API call.","D":"Store the API credentials in an Amazon DynamoDB table. Restrict access to the table by using resource-based policies. Retrieve the API credentials at runtime by using the AWS SDK. Use the credentials to make the API call.","C":"Store the API credentials as an object in a private Amazon S3 bucket. Restrict access to the S3 object by using IAM policies. Retrieve the API credentials at runtime by using the AWS SDK. Use the credentials to make the API call.","A":"Store the API credentials in AWS Secrets Manager. Retrieve the API credentials at runtime by using the AWS SDK. Use the credentials to make the API call."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/103334-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-03-20 07:11:00","unix_timestamp":1679292660,"discussion_count":33,"discussion":[{"upvote_count":"13","content":"Selected Answer: A\\nanswer A","timestamp":"1679895660.0","comment_id":"851760","poster":"Kristijan92"},{"content":"Selected Answer: A\\nWhy B is marked as correct ????","poster":"elfinka9","comments":[{"upvote_count":"1","timestamp":"1722591300.0","content":"Why is developer being a benchod? A, b, c or d?","poster":"ACurryDeveloper","comment_id":"1259799"}],"timestamp":"1690873380.0","upvote_count":"9","comment_id":"968809"},{"content":"Selected Answer: A\\nmost secure approach","poster":"anandkg","comment_id":"1561187","upvote_count":"1","timestamp":"1744823160.0"},{"upvote_count":"1","timestamp":"1744092300.0","comment_id":"1558811","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html","poster":"ocharo"},{"comment_id":"1329540","timestamp":"1734708720.0","poster":"sumanshu","content":"Selected Answer: A\\nAWS Secrets Manager is purpose-built for securely managing sensitive data such as API keys","upvote_count":"3"},{"upvote_count":"2","poster":"trieudo","timestamp":"1733960820.0","content":"Selected Answer: A\\nkeyword: MOST securely\\n\\n==> discard B first: If the code repository is compromised, the API key could be exposed. \\n==> discard C, D after: this requires setting up and managing the DynamoDB table and resource-based policies ==> can make mistake from ppl, then creating issue about security\\n\\nA: AWS Secrets Manager is a specialized service designed to securely store sensitive information like API keys.","comment_id":"1325296"},{"poster":"Bibay","comment_id":"890704","content":"Selected Answer: A\\nThe MOST secure solution to manage the API key while ensuring that the integration of the API key with the application code does not affect application performance is to store the API key in AWS Secrets Manager. The API key can be retrieved at runtime by using the AWS SDK, which does not impact application performance. Therefore, option A is the correct answer.\\n\\nOption B is not secure as it exposes the API key to anyone with access to the code repository, which increases the risk of unauthorized access.\\n\\nOption C and D may work, but they require additional configuration and permissions management. Storing the API key in an S3 bucket or a DynamoDB table could expose the key to unauthorized users if proper IAM policies are not in place. Therefore, option A is the most secure and simple solution to manage the API key while not affecting the application\'s performance.","upvote_count":"2","timestamp":"1727238180.0"},{"comment_id":"1242196","upvote_count":"1","content":"B is certainly a wrong answer because if you read the application development with AWS case study and also the best practices then in it the AWS itself does not encourage the developer to store the sensitive API and license keys in code on the other hand it encourages to use the provided solutions like KMS, Secrets Manager and Parameter Store.","timestamp":"1720112940.0","poster":"nkroker"},{"comment_id":"1230144","poster":"297dfbb","timestamp":"1718324220.0","content":"Selected Answer: A\\nA is correct. B is wrong because you never store credentials in source control.","upvote_count":"1"},{"timestamp":"1718281620.0","upvote_count":"2","comment_id":"1229791","poster":"c949c84","content":"Selected Answer: A\\nMost secure"},{"timestamp":"1716297180.0","comment_id":"1214966","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","poster":"65703c1"},{"upvote_count":"1","poster":"Prosen2522","timestamp":"1715031840.0","comment_id":"1207583","content":"A is it"},{"comment_id":"1188846","timestamp":"1712170200.0","content":"Straight A","poster":"badsati","upvote_count":"1"},{"poster":"bednark","upvote_count":"1","timestamp":"1705845900.0","comment_id":"1127865","content":"Selected Answer: A\\nA is correct"},{"timestamp":"1700091840.0","poster":"leonardoliveros","comment_id":"1072014","upvote_count":"2","content":"Selected Answer: A\\nB isn\'t secury\\nA is the best option for this scenary"},{"comment_id":"1023510","upvote_count":"2","poster":"gullyboy77","timestamp":"1696292520.0","content":"Selected Answer: A\\nSecret Manager is the safest way to store secrets in AWS."},{"timestamp":"1694314320.0","poster":"chvtejaswi","upvote_count":"2","comment_id":"1003641","content":"Selected Answer: A\\nAnswer A"},{"timestamp":"1693234500.0","comment_id":"992314","upvote_count":"1","content":"Selected Answer: A\\nA seems to be the most secure and correct. Always use Secret Manger to store secrets, as the name implies.","poster":"hmdev"},{"content":"Selected Answer: A\\nA is correct","timestamp":"1693141260.0","upvote_count":"1","comment_id":"991463","poster":"Yuxing_Li"},{"content":"Selected Answer: A\\nThe other options (B, C and D) are not as safe or manageable:","upvote_count":"1","timestamp":"1692982920.0","poster":"sivuca1","comment_id":"990252"},{"content":"Selected Answer: A\\nparameter store is secure, so A","upvote_count":"2","timestamp":"1692066900.0","poster":"sp323","comment_id":"981229"},{"comment_id":"978323","timestamp":"1691734500.0","upvote_count":"1","poster":"ssoratroi","content":"Selected Answer: A\\nparameter store is the better solution so A"},{"timestamp":"1691557860.0","poster":"jayvarma","comment_id":"976260","content":"obviously we are not going to store the API credentials in the local code variables. So option B is ruled out\\n\\nComing to Option D, It is not wrong to store the API credentials in the DynamoDB table as long as you encrypt them. But, Considering the extent of human error, there is a chance for the DynamoDB to be given too many permissions. \\n\\nAs Option A, A secrets manager or a parameter store\'s primary purpose is to store a secret, It is ideal to use such kind of service to store the API credentials.","upvote_count":"4"},{"upvote_count":"2","comment_id":"967123","timestamp":"1690722240.0","poster":"Kashan6109","content":"Selected Answer: A\\nCorrect answer is A, option B is not secure at all"},{"upvote_count":"4","timestamp":"1689306000.0","comments":[{"content":"for you to read this comments","poster":"Solovey","timestamp":"1697291160.0","upvote_count":"3","comment_id":"1043496"},{"content":"I had to re-read the question after seeing the answer - whether they had asked for the LEAST favourable option","upvote_count":"1","comment_id":"1138125","timestamp":"1706850900.0","poster":"SD_CS"}],"comment_id":"951179","poster":"tttamtttam","content":"Selected Answer: A\\nWhy it is marked as B???????????????"},{"poster":"MrPie","content":"It\'s A, but at least on react native to retrieve secrets from AWS you need the API key so this option doesn\'t work. You would need to make an HTTP gateway for a lambda function that retrieves the secret.","comment_id":"944913","timestamp":"1688667000.0","upvote_count":"1"},{"poster":"Devon_Fazekas","comment_id":"893254","upvote_count":"3","content":"We all know option A is the most secure and efficient method. Who decided the answer was B?","timestamp":"1683646440.0"},{"timestamp":"1681213140.0","comment_id":"867262","poster":"zk1200","upvote_count":"1","content":"Selected Answer: A\\nsecrets manager seems most likely since it is meant for storing items like API keys."},{"timestamp":"1681183620.0","poster":"hmmm0101","content":"Selected Answer: A\\nAnswer A","comment_id":"866882","upvote_count":"4"},{"poster":"DollyNeekhra","content":"Selected Answer: A\\nnever save secrets in code","timestamp":"1680849300.0","upvote_count":"2","comment_id":"863549"},{"content":"We should not forget performance is not only the factor but most securely. Hence Secrets Manager access at runtime sounds good","comment_id":"844768","timestamp":"1679308800.0","upvote_count":"1","poster":"prabhay786"},{"poster":"prabhay786","comment_id":"844765","content":"It should be A","timestamp":"1679308680.0","upvote_count":"2"},{"timestamp":"1679292660.0","poster":"Warlord_92","comment_id":"844576","upvote_count":"4","content":"Selected Answer: A\\nIt\u2019s not secure to store API keys in git repository. Hence storing it in secret manger is a most secure to way to handle this scenario."}],"answer_description":"","extracted_at":"2025-12-24T09:15:02.451Z","extraction_method":"api_direct_v1"},{"question_id":"wruSoRyrnGbsBQkgDu2u","question_number":548,"page":110,"question_text":"A company moved some of its secure files to a private Amazon S3 bucket that has no public access. The company wants to develop a serverless application that gives its employees the ability to log in and securely share the files with other users.\\n\\nWhich AWS feature should the company use to share and access the files securely?","choices":{"B":"S3 presigned URLs","D":"Amazon Cognito identity pool","A":"Amazon Cognito user pool","C":"S3 bucket policy"},"correct_answer":"B","answer_ET":"B","answers_community":["B (59%)","A (21%)","D (20%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109208-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-14 07:53:00","unix_timestamp":1684043580,"discussion_count":36,"discussion":[{"upvote_count":"25","poster":"Dushank","comment_id":"1003443","timestamp":"1694286360.0","content":"Selected Answer: B\\nEmployees log into the serverless application using an Amazon Cognito User Pool.\\nOnce logged in, the application\'s back-end logic (possibly a Lambda function) generates an S3 pre-signed URL for the requested file.\\nThe pre-signed URL is then given to the authenticated user, allowing them secure, time-limited access to that specific S3 object.\\nSo, while both Amazon Cognito User Pool and S3 Pre-signed URLs would be used in the solution, S3 Pre-signed URLs (Option B) are the specific feature that allows for the secure, temporary sharing of S3 files. \\nTherefore, Option B would be the best answer to the question of how to \\"share and access the files securely.\\""},{"content":"Selected Answer: A\\nthe key words are ability to log in and securely share the files. It is A","comment_id":"897289","timestamp":"1684043580.0","comments":[{"content":"I agree \'log in\' would go user pool.","poster":"jipark","upvote_count":"2","timestamp":"1690984920.0","comment_id":"970258"},{"upvote_count":"3","poster":"rimaSamir","comment_id":"1151793","timestamp":"1708068120.0","content":"But we need to answer a question not task condition"}],"poster":"loctong","upvote_count":"20"},{"upvote_count":"2","comment_id":"1366467","poster":"Shamalka","timestamp":"1741402620.0","content":"Selected Answer: D\\nA presigned URL doesn\'t allow you to share files with others. The last line of the question specifically asks which service would give you the ability not only to access but also to share files too. In that case, CIP seems to be the service to give temporary credentials to AWS resources and perform whatever is specified in the bucket policy"},{"upvote_count":"1","poster":"sumanshu","content":"Selected Answer: B\\nA) Eliminated - While Cognito is useful for managing user authentication, it does not directly provide the capability to securely share files from an S3 bucket.","comment_id":"1331908","timestamp":"1735216020.0"},{"content":"Selected Answer: B\\nI had my doubt on this, but once more they are evaluating if you are reading with attention and not if you have knowldge hehe tricky question, but the punch line question is What feature would be used to share the files securely, ignoring the login part.","comment_id":"1269334","timestamp":"1724148600.0","poster":"wh1t4k3r","upvote_count":"4"},{"comment_id":"1215966","upvote_count":"1","poster":"65703c1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1716406560.0"},{"content":"Selected Answer: B\\nThis option allows secure, temporary access to specific objects in an S3 bucket. By generating presigned URLs, the serverless application can grant users time-limited access to download or upload files without altering the permissions of the S3 bucket or the objects. This method ensures secure access management and is suitable for sharing private files among authenticated users.","upvote_count":"3","poster":"SerialiDr","comment_id":"1160577","timestamp":"1709037000.0"},{"timestamp":"1706955300.0","poster":"SD_CS","comment_id":"1139154","upvote_count":"3","content":"Selected Answer: A\\nin order to log in you need to use cognito user pools"},{"comment_id":"1135763","poster":"rimaSamir","timestamp":"1706617620.0","upvote_count":"4","content":"Actually, the quesion is about \\"what feature will be used by the new serverless application to share and access the files securely\\". Ability to log in is about \\"Amazon Cognito user pool\\". Imagine \\"Lambda function\\" and \\"API Gateway\\" are created as a serverless app to provide some API. When you call API endpoint, it will login to \\"Amazon Cognito user pool\\" and then share files using SDK. How it will share is the next question.\\nMy answer is A"},{"upvote_count":"4","timestamp":"1706598420.0","comment_id":"1135566","content":"Selected Answer: B\\nThe answer must be B. So although in the question it says \\"gives its employees the ability to log in\\" (which is hinting towards Cognito User Pools) the question is actually asking: \\"Which AWS feature should the company use to share and access the files securely?\\"\\n\\nThe question is actually about how to share and access the files securely. Hence it must be the S3 pre-signed URL option. To read up more on S3 pre-signed URLs check here: https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html","poster":"Ashwinvdm22"},{"comment_id":"1127225","upvote_count":"3","timestamp":"1705748880.0","content":"Selected Answer: B\\nWhich AWS feature should the company use to share and access the files securely?\\nSo, It\'s B. S3 Pre-signed URL can used to share S3 object to other people securely.","poster":"peekingpicker"},{"poster":"gqs3119","timestamp":"1704112620.0","upvote_count":"1","comment_id":"1111152","content":"It\'s not A, Cognito user pool is not needed, only employees need ability to log in, they can be provided with IAM accounts."},{"poster":"a_win","timestamp":"1703486460.0","comment_id":"1105063","content":"Selected Answer: D\\nAn Amazon Cognito identity pool provides temporary AWS credentials for users who authenticate via Amazon Cognito. This allows your application users (employees, in this case) to securely authenticate and gain access to AWS services like S3 based on their assigned roles and permissions.\\n\\nThrough Amazon Cognito, you can manage user identities, control user access to resources, and provide temporary, limited-privilege credentials to access the S3 bucket securely.","upvote_count":"4"},{"poster":"KarBiswa","comment_id":"1099742","timestamp":"1702906560.0","upvote_count":"3","content":"Selected Answer: B\\nI will go with B because its purely asking about sharing and no mention about external logins so we should go by default AWS feature which provides this feature,\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html"},{"content":"Selected Answer: B\\nChatGPT: B","upvote_count":"3","timestamp":"1701511200.0","comment_id":"1086030","poster":"tqiu654"},{"comment_id":"1053377","timestamp":"1698198360.0","upvote_count":"1","content":"Login of external to AWS users, we can use Cognito. Identity Pool is specifically for DynamoDB and S3.\\n\\nUse an identity pool when you need to:\\n\\nGive your users access to AWS resources, such as an Amazon Simple Storage Service (Amazon S3) bucket or an Amazon DynamoDB table.\\n\\nhttps://repost.aws/knowledge-center/cognito-user-pools-identity-pools","poster":"didorins"},{"poster":"Rameez1","timestamp":"1697563740.0","comment_id":"1046234","upvote_count":"4","content":"Selected Answer: B\\nActual ask is in the final line \\"Which AWS feature should the company use to share and access the files securely?\\" -> S3 Pre-signed URL provides the most secure feature."},{"content":"Selected Answer: B\\nSecure solution for sharing private s3 resource","poster":"EMPERBACH","upvote_count":"3","timestamp":"1694958900.0","comment_id":"1009837"},{"upvote_count":"6","content":"Selected Answer: B\\nI say \'B\' because:\\nThe question is \\"Which AWS feature should the company use to share and access the files securely?\\"\\nif you look at this part there is no mention about login part. Though there is requirement for the application as a whole, the question targets only about sharing and accessing files securely.","poster":"Iamtany","comment_id":"1005150","timestamp":"1694463300.0"},{"poster":"fossil123","content":"Selected Answer: A\\n\'Login\' points to A","upvote_count":"2","timestamp":"1693355940.0","comment_id":"993605"},{"upvote_count":"2","poster":"Yuxing_Li","content":"Selected Answer: D\\nYou need access to S3","comment_id":"992714","timestamp":"1693273500.0"},{"upvote_count":"2","poster":"breadops","comment_id":"991794","timestamp":"1693197300.0","content":"Selected Answer: B\\nWhich AWS feature should the company use to share and access the files securely?\\nIt\'s B - S3 Presigned URLs."},{"poster":"hmdev","upvote_count":"1","comment_id":"988385","timestamp":"1692799500.0","content":"I think it\'s A cuz we need to log in. The context doesn\'t say anything indicating federated users so doesn\'t look like D. Also, A user needs to log in to create a pre-signed URL."},{"content":"Selected Answer: D\\nhttps://www.techtarget.com/searchcloudcomputing/feature/Cognito-user-pools-vs-identity-pools-what-AWS-users-should-know\\n\\n\\"On the other hand, identity pools are primarily used for authorization. This second Cognito feature, also known as federated identities, has two common use cases -- to provide access to different AWS resources and to create temporary credentials for unauthenticated users\\"\\n\\n\\"User pools alone do not deal with any IAM-level permissions but provide critical information so the enterprise can authorize the users\\"","upvote_count":"3","timestamp":"1692532080.0","poster":"Naj_64","comment_id":"985751"},{"poster":"andrevus","comment_id":"983555","upvote_count":"2","content":"Selected Answer: B\\nquestion is a key. \\nWhich AWS feature should the company use to share and access the files securely?\\nyou cannot share files with cognito!","timestamp":"1692272160.0"},{"content":"Selected Answer: D\\nOption D is correct.\\nhttps://repost.aws/knowledge-center/cognito-user-pools-identity-pools","upvote_count":"3","timestamp":"1691400840.0","comment_id":"974546","poster":"Sbon24"},{"content":"B. S3 presigned URLs\\n\\nExplanation:\\n\\nUsing S3 presigned URLs is the most secure way to give employees the ability to access and share files securely from a private S3 bucket.\\nUsing Amazon Cognito user pool (Option A) and Amazon Cognito identity pool (Option D) can help with user authentication and identity management, but they don\'t directly handle secure sharing and access to files from a private S3 bucket.\\n\\nOption C (S3 bucket policy) is used to control access to the S3 bucket and its objects, but it\'s not recommended to make the bucket public or grant access to unauthorized users. Using S3 presigned URLs is a more secure approach to control access to specific objects for a limited time.","comment_id":"971007","upvote_count":"1","timestamp":"1691059320.0","poster":"bindu545"},{"comment_id":"964102","content":"Option D\\n(Amazon Cognito identity pool) is the correct choice to securely share and access the files in the private S3 bucket, providing a secure and managed way for employees to log in and access the files while controlling access to other users.","timestamp":"1690396140.0","upvote_count":"1","poster":"r3mo"},{"timestamp":"1690271340.0","upvote_count":"3","poster":"bobo777","comment_id":"962476","content":"Selected Answer: D\\nOnly Cognito Identity pool (combined with User pool) allows users from social networks to log in and get access to AWS resources."},{"poster":"jasper_pigeon","upvote_count":"3","comment_id":"961443","timestamp":"1690192740.0","content":"For both ability to log in and securely share the files, Cognito identity pool is the only answer.\\nUsers can log in via public social, OIDC, SAML and Cognito User Pools. S3 presigned URLs are for temporaray usage."},{"upvote_count":"4","comment_id":"955201","poster":"ancomedian","timestamp":"1689673800.0","content":"Selected Answer: D\\nIt is D cause we need to make them sign up, so presigned URL is not the option\\nalso, user pool is for authentication but for authorization, we need identity pool"},{"timestamp":"1688956500.0","content":"Selected Answer: B\\nB is the answer","comment_id":"947679","poster":"HONGGGGGGG","upvote_count":"2"},{"content":"Selected Answer: B\\nB is the answer","timestamp":"1688097780.0","poster":"bakamon","upvote_count":"1","comment_id":"938791"},{"upvote_count":"3","content":"Selected Answer: B\\nPersonally I believe this is a very tricky question and needless to say a bit more context is required. Nonetheless, I vote for B because the question asks for the following:\\n\\n\\"Which AWS feature should the company use to share and access the files securely?\\"\\n\\nThey want to develop an application for their employees to log in **AND** securely share the files with other users. The answer to this last bit is a presigned URL with a meaningful expiry date.\\n\\nCognito services can help to setup a log in system (User pools) and apply specific policies per the request (identity pool), but to me this isn\'t what the question asks about.","timestamp":"1686065400.0","poster":"csG13","comment_id":"916406"},{"timestamp":"1684959300.0","upvote_count":"3","content":"Selected Answer: D\\nRemember User Pool is to verify who you are, Identity Pool is for knowing if you are authorized to do something. \\n-> it\'s D, not A.","comment_id":"906140","poster":"imvb88"},{"upvote_count":"1","comment_id":"902975","timestamp":"1684652220.0","poster":"Bibay","content":"B. S3 presigned URLs"}],"answer_description":"","extracted_at":"2025-12-24T09:15:02.451Z","extraction_method":"api_direct_v1"},{"question_id":"LiztqaSY91qTbESipk5Q","question_number":549,"page":110,"question_text":"A company needs to develop a proof of concept for a web service application. The application will show the weather forecast for one of the company\'s office locations. The application will provide a REST endpoint that clients can call. Where possible, the application should use caching features provided by AWS to limit the number of requests to the backend service. The application backend will receive a small amount of traffic only during testing.\\n\\nWhich approach should the developer take to provide the REST endpoint MOST cost-effectively?","choices":{"D":"Create a microservices application. Deploy the application to AWS Elastic Beanstalk. Expose the AWS Lambda functionality by using an Application Load Balancer.","B":"Create an AWS Lambda function by using the AWS Serverless Application Model (AWS SAM). Expose the Lambda functionality by using Amazon API Gateway.","C":"Create a container image. Deploy the container image by using Amazon Elastic Container Service (Amazon ECS). Expose the functionality by using Amazon API Gateway.","A":"Create a container image. Deploy the container image by using Amazon Elastic Kubernetes Service (Amazon EKS). Expose the functionality by using Amazon API Gateway."},"correct_answer":"B","answer_ET":"B","answers_community":["B (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109210-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-14 07:59:00","unix_timestamp":1684043940,"discussion_count":6,"discussion":[{"upvote_count":"9","timestamp":"1699948740.0","content":"Selected Answer: B\\nAWS Lambda function absolutely ability to do the requirements.","comment_id":"897293","poster":"loctong","comments":[{"content":"Yes, Lambda bery certain great.","upvote_count":"3","poster":"JamalDaBoss","comment_id":"970543","timestamp":"1706913660.0"}]},{"content":"Selected Answer: B\\nA) Eliminated - Amazon EKS is designed for large-scale, containerized applications that require Kubernetes orchestration. For a simple proof of concept with small traffic, it is overkill and introduces unnecessary complexity and cost.\\n\\nC) Eliminated - ECS introduces additional operational overhead compared to a serverless solution like Lambda.\\n\\nD) Elastic Beanstalk is not designed for a lightweight serverless application; it requires provisioning and managing compute resources, which increases cost and complexity.","poster":"sumanshu","upvote_count":"2","comment_id":"1332014","timestamp":"1735232880.0"},{"upvote_count":"1","content":"Selected Answer: B\\nB is the correct answer.","timestamp":"1732311480.0","poster":"65703c1","comment_id":"1215969"},{"comment_id":"1160936","timestamp":"1724780460.0","content":"Selected Answer: B\\nThis solution is cost-effective because AWS Lambda charges are based on the number of requests and the duration of code execution, making it ideal for applications with low to moderate traffic. Amazon API Gateway can efficiently manage the REST endpoint and offers built-in caching capabilities to reduce the number of requests to the backend Lambda function, further optimizing costs. This setup also leverages the serverless model, reducing the operational overhead and cost associated with provisioning and managing servers.","upvote_count":"4","poster":"SerialiDr"},{"content":"Selected Answer: B\\nyes B is correct","poster":"a5fc516","upvote_count":"1","comment_id":"1141977","timestamp":"1722927420.0"},{"comment_id":"988387","upvote_count":"3","content":"Selected Answer: B\\nB is the cost-effective one.","timestamp":"1708704420.0","poster":"hmdev"}],"answer_description":"","extracted_at":"2025-12-24T09:15:02.451Z","extraction_method":"api_direct_v1"},{"question_id":"Um9LhBrrXJGogkujgFe5","question_number":550,"page":110,"question_text":"An e-commerce web application that shares session state on-premises is being migrated to AWS. The application must be fault tolerant, natively highly scalable, and any service interruption should not affect the user experience.\\n\\nWhat is the best option to store the session state?","choices":{"A":"Store the session state in Amazon ElastiCache.","C":"Store the session state in Amazon S3.","B":"Store the session state in Amazon CloudFront.","D":"Enable session stickiness using elastic load balancers."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108741-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 14:02:00","unix_timestamp":1683547320,"discussion_count":7,"discussion":[{"timestamp":"1735233000.0","upvote_count":"1","comment_id":"1332016","poster":"sumanshu","content":"Selected Answer: A\\nB) Eliminated - Amazon CloudFront is a content delivery network (CDN) designed for distributing static and dynamic content globally.\\n\\nC) Eliminated - it is not designed for low-latency use cases like session management.\\n\\nD) Eliminated - it is not highly scalable, as it ties user sessions to specific servers, which can lead to uneven load distribution and scaling issues."},{"comment_id":"1283003","content":"Selected Answer: A\\nA is Correct, the store the session state is a key word","poster":"Saudis","timestamp":"1726202040.0","upvote_count":"1"},{"upvote_count":"2","poster":"65703c1","timestamp":"1716406740.0","comment_id":"1215971","content":"Selected Answer: A\\nA is the correct answer."},{"poster":"SerialiDr","timestamp":"1709063460.0","upvote_count":"4","comment_id":"1160940","content":"Selected Answer: A\\nAmazon ElastiCache is a high-performance, in-memory data store that provides sub-millisecond latency to applications. It supports data structures such as strings, hashes, lists, sets, and sorted sets, making it suitable for storing session state data. ElastiCache offers both Redis and Memcached engines, with Redis providing more advanced data structures and features such as persistence, replication, and transaction support. This solution is fault-tolerant and highly scalable, ensuring that any service interruption does not affect the user experience."},{"content":"Selected Answer: A\\nI vote A\\n\\nhttps://aws.amazon.com/blogs/developer/elasticache-as-an-asp-net-session-store/","comment_id":"933427","poster":"Phongsanth","upvote_count":"4","timestamp":"1687686000.0"},{"poster":"loctong","timestamp":"1684044120.0","comment_id":"897297","upvote_count":"3","content":"Selected Answer: A\\nthe answer came from the discussion at https://www.examtopics.com/discussions/amazon/view/8789-exam-aws-certified-developer-associate-topic-1-question-176/"},{"poster":"zodraz","content":"Selected Answer: A\\nhttps://www.examtopics.com/discussions/amazon/view/8789-exam-aws-certified-developer-associate-topic-1-question-176/","upvote_count":"4","comment_id":"892125","timestamp":"1683547320.0"}],"answer_description":"","extracted_at":"2025-12-24T09:15:02.451Z","extraction_method":"api_direct_v1"},{"question_id":"QSmV7TU7u2ZFifSTbiiC","question_number":551,"page":111,"question_text":"A developer is building an application that uses Amazon DynamoDB. The developer wants to retrieve multiple specific items from the database with a single API call.\\n\\nWhich DynamoDB API call will meet these requirements with the MINIMUM impact on the database?","choices":{"A":"BatchGetItem","B":"GetItem","D":"Query","C":"Scan"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106941-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-21 18:15:00","unix_timestamp":1682093700,"discussion_count":10,"discussion":[{"upvote_count":"12","comment_id":"876693","poster":"MrTee","content":"Selected Answer: A\\nA Is the correct answer with the minimum impact on the database.","timestamp":"1682093700.0"},{"upvote_count":"9","content":"Selected Answer: A\\nhttps://beabetterdev.com/2022/10/12/dynamodb-getitem-vs-query-when-to-use-what/#:~:text=If%20you\'d%20like%20to%20retrieve%20multiple%20items%20at%20once,retrieve%20multiple%20items%20at%20once.","poster":"dan80","comment_id":"883973","comments":[{"poster":"jipark","upvote_count":"15","timestamp":"1691026500.0","comment_id":"970657","content":"tons of thanks.\\n\\nLooking for just a single item on the main table index? Use GetItem\\nLooking for just a single item on a GSI? Use Query.\\nLooking for multiple items with different partition key and sort key combinations at once? Use BatchGetItem\\nLooking for multiple items that share the same partition key? Use Query"}],"timestamp":"1682732340.0"},{"content":"Selected Answer: A\\nB) Eliminated - The GetItem API retrieves only one specific item at a time by its primary key.\\n\\nC) Eliminated - The Scan API retrieves all items in a table or index by sequentially scanning every item.\\n\\nD) Eliminated - The Query API retrieves all items that match a specific partition key and optionally filters them by sort key or other criteria.","poster":"sumanshu","comments":[{"comment_id":"1353494","poster":"sumanshu","upvote_count":"1","timestamp":"1739031540.0","content":"CustomerID OrderID OrderDetails\\n123 A001 Shoes\\n123 A002 Jacket\\n123 A003 Watch\\nIf you need to retrieve all orders for CustomerID = 123, a Query would work well because all the needed items share the same partition key","comments":[{"content":"Suppose you need to retrieve multiple orders, but for different customers:\\nCustomerID OrderID OrderDetails\\n123 A001 Shoes\\n456 B002 Laptop\\n789 C003 Phone\\nHere, the partition keys are different (123, 456, 789).\\nA Query won\'t work because it can only retrieve items for one partition key at a time.\\nBatchGetItem is the best choice because it allows retrieving specific items across multiple partition keys in a single API call.","upvote_count":"1","timestamp":"1739031600.0","comment_id":"1353495","poster":"sumanshu"}]}],"comment_id":"1332018","upvote_count":"1","timestamp":"1735233480.0"},{"timestamp":"1726202340.0","content":"A key word is retrieve multiple specific items","comment_id":"1283006","poster":"Saudis","upvote_count":"1"},{"comment_id":"1215972","content":"Selected Answer: A\\nA is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716406800.0"},{"timestamp":"1712751720.0","content":"Selected Answer: A\\n\u2022 GetItem: recupera um \xfanico item de uma tabela.\\n\u2022 BatchGetItem: retorna at\xe9 100 itens de uma ou mais tabelas limitados a 16MB por chamada.","poster":"Moralles","upvote_count":"1","comment_id":"1192961"},{"poster":"prathameshpathak","upvote_count":"1","comment_id":"1126007","timestamp":"1705592280.0","content":"Selected Answer: A\\n..........................."},{"upvote_count":"1","poster":"marolisa","content":"D.\\n\\"Query\\" allows you to use filter - multiple specific items and is less expensive than the Sacan operation.","timestamp":"1695330900.0","comment_id":"1013396"},{"upvote_count":"1","comment_id":"923368","timestamp":"1686758760.0","content":"Selected Answer: A\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html","poster":"Baba_Eni"},{"timestamp":"1684960020.0","comment_id":"906144","poster":"imvb88","content":"Selected Answer: A\\nNeed specific Item -> cannot be Scan or Query since they are for retrieving items that match conditions. \\nWe need multiple item then A is the option left.","upvote_count":"2"}],"answer_description":"","extracted_at":"2025-12-24T09:15:13.504Z","extraction_method":"api_direct_v1"},{"question_id":"XdwDWRJLt4mulDRmUPiY","question_number":552,"page":111,"question_text":"A developer has written an application that runs on Amazon EC2 instances. The developer is adding functionality for the application to write objects to an Amazon S3 bucket.\\n\\nWhich policy must the developer modify to allow the instances to write these objects?","choices":{"D":"The Amazon VPC endpoint policy","C":"The AWS Key Management Service (AWS KMS) key policy that is attached to the EC2 instance profile role","B":"The session policy that is applied to the EC2 instance role session","A":"The IAM policy that is attached to the EC2 instance profile role"},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/109241-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-14 19:56:00","unix_timestamp":1684086960,"discussion_count":6,"discussion":[{"poster":"Prem28","upvote_count":"6","content":"Selected Answer: A\\na is correct","comment_id":"897799","timestamp":"1684086960.0"},{"upvote_count":"5","content":"Selected Answer: A\\nA: https://repost.aws/knowledge-center/ec2-instance-access-s3-bucket","poster":"Ja13","comment_id":"919477","timestamp":"1686329580.0"},{"comment_id":"1332020","content":"Selected Answer: A\\nEC2 instances assume an IAM role through an instance profile.","poster":"sumanshu","timestamp":"1735233540.0","upvote_count":"1"},{"timestamp":"1726879380.0","poster":"albert_kuo","upvote_count":"1","comment_id":"1287090","content":"Selected Answer: A\\n{\\n \\"Version\\": \\"2012-10-17\\",\\n \\"Statement\\": [\\n {\\n \\"Effect\\": \\"Allow\\",\\n \\"Action\\": [\\n \\"s3:PutObject\\",\\n \\"s3:PutObjectAcl\\"\\n ],\\n \\"Resource\\": \\"arn:aws:s3:::your-bucket-name/*\\"\\n }\\n ]\\n}"},{"upvote_count":"1","comment_id":"1215974","timestamp":"1716406980.0","poster":"65703c1","content":"Selected Answer: A\\nA is the correct answer."},{"content":"B: I Think B is better, because we need to use it on the instance session","poster":"mgonblan","timestamp":"1685461620.0","upvote_count":"1","comment_id":"910394"}],"answer_description":"","extracted_at":"2025-12-24T09:15:13.504Z","extraction_method":"api_direct_v1"},{"question_id":"SF87zoVnDK4DhajvBoLu","question_number":553,"page":111,"question_text":"A developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the developer\'s account. The developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC.\\n\\nWhich logs can the developer use to verify whether the traffic is reaching subnet B?","choices":{"D":"AWS CloudTrail logs","B":"BGP logs","A":"VPN logs","C":"VPC Flow Logs"},"correct_answer":"C","answer_ET":"C","answers_community":["C (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/108742-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-05-08 14:07:00","unix_timestamp":1683547620,"discussion_count":7,"discussion":[{"comment_id":"1003448","upvote_count":"8","timestamp":"1694286900.0","poster":"Dushank","content":"Selected Answer: C\\nVPC Flow Logs capture information about the IP traffic going to and from network interfaces in a VPC. This includes traffic that traverses a VPN connection. VPC Flow Logs can be used to monitor and troubleshoot connectivity issues, including verifying whether traffic is reaching a particular subnet within the VPC."},{"poster":"sumanshu","content":"Selected Answer: C\\nVPC Flow Logs capture detailed information about the traffic flowing to and from network interfaces in a VPC.\\n\\nD) Eliminated - AWS CloudTrail logs record API-level activity in an AWS account, hey do not provide network-level traffic details for verifying traffic reaching specific subnets.","upvote_count":"2","comment_id":"1332321","timestamp":"1735290120.0"},{"poster":"albert_kuo","comment_id":"1287091","content":"Selected Answer: C\\nversion account-id interface-id srcaddr dstaddr srcport dstport protocol packets bytes start end action log-status\\n2 123456789012 eni-abc12345 192.168.1.10 10.0.0.20 443 80 6 10 2048 1620050730 1620050790 ACCEPT OK\\n2 123456789012 eni-abc12345 192.168.1.10 10.0.0.30 22 443 6 5 1024 1620050730 1620050790 REJECT OK","timestamp":"1726879500.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\\nC is the correct answer.","timestamp":"1716407040.0","comment_id":"1215976","poster":"65703c1"},{"timestamp":"1702907880.0","upvote_count":"1","poster":"KarBiswa","content":"Selected Answer: C\\nhttps://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html","comment_id":"1099758"},{"comment_id":"897801","poster":"Prem28","content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/28802-exam-aws-certified-developer-associate-topic-1-question-219/","timestamp":"1684086960.0","upvote_count":"3"},{"poster":"zodraz","comment_id":"892132","content":"Selected Answer: C\\nhttps://www.examtopics.com/discussions/amazon/view/28802-exam-aws-certified-developer-associate-topic-1-question-219/","timestamp":"1683547620.0","upvote_count":"3"}],"answer_description":"","extracted_at":"2025-12-24T09:15:13.504Z","extraction_method":"api_direct_v1"},{"question_id":"7nYRPAdOMAxXXK6TITBE","question_number":554,"page":111,"question_text":"A developer is creating a service that uses an Amazon S3 bucket for image uploads. The service will use an AWS Lambda function to create a thumbnail of each image. Each time an image is uploaded, the service needs to send an email notification and create the thumbnail. The developer needs to configure the image processing and email notifications setup.\\n\\nWhich solution will meet these requirements?","choices":{"A":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an email notification subscription to the SNS topic.","C":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure S3 event notifications with a destination of the SQS queue. Subscribe the Lambda function to the SQS queue. Create an email notification subscription to the SQS queue.","B":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the SQS queue to the SNS topic. Create an email notification subscription to the SQS queue.","D":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Send S3 event notifications to Amazon EventBridge. Create an EventBridge rule that runs the Lambda function when images are uploaded to the S3 bucket. Create an EventBridge rule that sends notifications to the SQS queue. Create an email notification subscription to the SQS queue."},"correct_answer":"A","answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106946-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-21 20:33:00","unix_timestamp":1682101980,"discussion_count":5,"discussion":[{"comment_id":"876759","poster":"MrTee","content":"Selected Answer: A\\nThis solution will allow the developer to receive notifications for each image uploaded to the S3 bucket, and also create a thumbnail using the Lambda function. The SNS topic will serve as a trigger for both the Lambda function and the email notification subscription. When an image is uploaded, S3 will send a notification to the SNS topic, which will trigger the Lambda function to create the thumbnail and also send an email notification to the specified email address.","comments":[{"upvote_count":"5","content":"Thanks. As mentioned Multiple subscription can be added for SNS","comment_id":"1090411","timestamp":"1701963180.0","poster":"payireb682"},{"content":"greate !! send email do not need SQS.","poster":"jipark","comment_id":"970781","timestamp":"1691042520.0","upvote_count":"2"}],"upvote_count":"17","timestamp":"1682101980.0"},{"comment_id":"1332322","upvote_count":"1","timestamp":"1735290900.0","content":"Selected Answer: A\\nB) Eliminated - The SQS queue is not required because SNS can directly notify both the Lambda function and the email service\\n\\nC) Eliminated - SQS cannot send email notifications. Also, The Lambda function would need to poll the SQS queue, adding unnecessary complexity.\\n\\nD) Eliminated - Using EventBridge to forward S3 event notifications introduces unnecessary complexity.","poster":"sumanshu"},{"comment_id":"1250316","timestamp":"1721300880.0","poster":"Tluszczyk","upvote_count":"1","content":"None of these is really an optimal solution to the problem, which is a little annoying really"},{"poster":"65703c1","upvote_count":"1","comment_id":"1215978","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716407160.0"},{"upvote_count":"2","poster":"SerialiDr","timestamp":"1705219080.0","comment_id":"1122367","content":"Selected Answer: A\\nSNS can be used to fan out notifications. When an image is uploaded to the S3 bucket, an event notification is sent to the SNS topic. The Lambda function is subscribed to this topic to create a thumbnail, and an email subscription can also be configured on the same SNS topic to send email notifications. This approach meets all requirements with minimal components."}],"answer_description":"","extracted_at":"2025-12-24T09:15:13.504Z","extraction_method":"api_direct_v1"},{"question_id":"6UsLeLyWWIHbMCdQb3JG","question_number":555,"page":111,"question_text":"A developer has designed an application to store incoming data as JSON files in Amazon S3 objects. Custom business logic in an AWS Lambda function then transforms the objects, and the Lambda function loads the data into an Amazon DynamoDB table. Recently, the workload has experienced sudden and significant changes in traffic. The flow of data to the DynamoDB table is becoming throttled.\\n\\nThe developer needs to implement a solution to eliminate the throttling and load the data into the DynamoDB table more consistently.\\n\\nWhich solution will meet these requirements?","choices":{"D":"Refactor the Lambda function into two functions. Configure one function to store the data in the DynamoDB table. Configure the second function to process the data and update the items after the data is stored in DynamoDB. Create a DynamoDB stream to invoke the second function after the data is stored.","C":"Create an alias for the Lambda function. Configure provisioned concurrency for the application to use.","A":"Refactor the Lambda function into two functions. Configure one function to transform the data and one function to load the data into the DynamoDB table. Create an Amazon Simple Queue Service (Amazon SQS) queue in between the functions to hold the items as messages and to invoke the second function.","B":"Turn on auto scaling for the DynamoDB table. Use Amazon CloudWatch to monitor the table\'s read and write capacity metrics and to track consumed capacity."},"correct_answer":"A","answer_ET":"A","answers_community":["A (61%)","B (26%)","13%"],"topic":"1","exam_id":25,"is_multiple_choice":true,"url":"https://www.examtopics.com/discussions/amazon/view/106947-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_images":[],"timestamp":"2023-04-21 21:02:00","unix_timestamp":1682103720,"discussion_count":31,"discussion":[{"upvote_count":"26","timestamp":"1682759520.0","poster":"ihebchorfi","comment_id":"884186","content":"Selected Answer: A\\nA. Refactor the Lambda function into two functions. Configure one function to transform the data and one function to load the data into the DynamoDB table. Create an Amazon Simple Queue Service (Amazon SQS) queue in between the functions to hold the items as messages and to invoke the second function.\\n\\nBy breaking the Lambda function into two separate functions and using an SQS queue to hold the transformed data as messages, you can decouple the data transformation and loading processes. This allows for more controlled loading of data into the DynamoDB table and helps eliminate throttling issues."},{"timestamp":"1682103720.0","content":"Selected Answer: D\\nThis solution will allow the developer to store the incoming data into the DynamoDB table more consistently without being throttled. By splitting the Lambda function into two functions, the first function can store the data into the DynamoDB table and exit quickly, avoiding any throttling issues. The second function can then process the data and update the items after the data is stored in DynamoDB using a DynamoDB stream to invoke the second function.\\nOption A is also a good option but not the best solution because it introduces additional complexity and cost by using an Amazon SQS queue.","comments":[{"timestamp":"1730533740.0","comment_id":"1306080","poster":"nbxyzd","content":"Read carefully: The flow of data to the DynamoDB table is becoming throttled.\\nSo the bottleneck is the DynamoDB, not the lambda function transforming the data. Option D doesn\'t help because the first function storing data into the DynamoDB will still hit the throttling issue.","upvote_count":"2"},{"timestamp":"1706599980.0","content":"The problem I have with option D is that it is adding more lad on the DynamoDB table. What is the need to insert the item and then update the item later. This is performing two operation on every item just to get it into the correct state. I would go with option A since it is not performing two operations on the DB and hence reducing the load which will help with throttling.","poster":"Ashwinvdm22","comment_id":"1135584","upvote_count":"1"},{"content":"Sorry but when you say \\"the first function can store the data into the DynamoDB table and exit quickly, avoiding any throttling issues\\" I dont understand your point","poster":"robotgeek","comment_id":"912869","upvote_count":"5","timestamp":"1685714340.0"},{"poster":"[Removed]","content":"I disagree... the order of the function with this option makes NO sense. I go with A","comment_id":"1092146","upvote_count":"1","timestamp":"1702164060.0"},{"content":"The issue is between S3 to DynamoDB this is where we need to fix the bottleneck. So configuring two functions to work on the data after it has been uploaded to DynamoDB makes no sense.","timestamp":"1702164300.0","upvote_count":"1","comment_id":"1092148","poster":"[Removed]"}],"poster":"MrTee","upvote_count":"9","comment_id":"876780"},{"content":"Selected Answer: B\\nAdjusting the WCU is enough. no need to implement such complex solutions","comment_id":"1346184","timestamp":"1737735840.0","poster":"mooncake1","upvote_count":"1"},{"comment_id":"1332337","upvote_count":"2","poster":"sumanshu","content":"Selected Answer: A\\nThe SQS queue acts as a buffer, which smooths out sudden traffic spikes by queuing up data. The second Lambda function processes data from the queue at a steady rate, reducing the likelihood of throttling in DynamoDB.\\n\\nB) Eliminated - Auto scaling takes time to adjust, during which throttling may still occur.\\n\\nC) Eliminated - Provisioned concurrency ensures that the Lambda function can handle a predictable number of concurrent requests, but it does not solve the throttling issue at the DynamoDB layer","timestamp":"1735293120.0"},{"comment_id":"1306082","timestamp":"1730533860.0","upvote_count":"1","content":"Selected Answer: A\\nIt\'s hands-down A.","poster":"nbxyzd"},{"content":"Selected Answer: B\\n\\"A\\" would be optimal, but without backoff algorithm the lambda division and SQS won\'t affect the throttling. However Dynamo can autoscale\\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","timestamp":"1721301720.0","comments":[{"content":"Yes, but it asks to \\"load the data into the DynamoDB table more consistently.\\" Therefore, option A will prevent unintentional data load into DynamoDB, it\'s the best option.","upvote_count":"1","comment_id":"1254059","poster":"queekao","timestamp":"1721788500.0"}],"comment_id":"1250326","poster":"Tluszczyk","upvote_count":"1"},{"poster":"65703c1","comment_id":"1215984","content":"Selected Answer: A\\nA is the correct answer.","timestamp":"1716407580.0","upvote_count":"1"},{"comment_id":"1174256","poster":"nder","timestamp":"1710505320.0","upvote_count":"1","content":"Selected Answer: B\\nwe are trying to stop throttling..."},{"poster":"SerialiDr","comment_id":"1160976","upvote_count":"2","timestamp":"1709066760.0","content":"Selected Answer: A\\nThis solution addresses the need to eliminate throttling and ensure consistent data loading into the Amazon DynamoDB table by separating the transformation and loading processes into two different functions. Using an Amazon SQS queue to hold items as messages between the two functions helps manage the flow of data and prevents overloading the DynamoDB table, thereby eliminating throttling issues."},{"comment_id":"1139797","upvote_count":"3","poster":"Brisun","content":"Selected Answer: A\\nA is correct as it requires to write to DynamoDB \\"more consistently\\". Option B can solve the problem too but the writing won\'t be consistent as the traffic will go up and down instantly.\\n\\nIn reality, I will probably do Option B only.","timestamp":"1707022560.0"},{"content":"Selected Answer: B\\nI do not feel refactoring the data transformation and loading would help here as I do not think the number of concurrent calls to the DB would decrease because of this. Autoscaling DynamoDB would seem a more potent option to me.","timestamp":"1706960280.0","upvote_count":"4","comment_id":"1139190","poster":"SD_CS"},{"timestamp":"1705750980.0","upvote_count":"4","content":"Selected Answer: B\\nWhy not B ? \\nDynamoDB can autoscale the RCU and WCU","comment_id":"1127242","poster":"peekingpicker"},{"poster":"SerialiDr","timestamp":"1705231560.0","upvote_count":"3","comment_id":"1122484","content":"Selected Answer: A\\nA. Refactor the Lambda function into two functions, using an Amazon SQS queue to manage the data flow, and/or\\n\\nB. Turn on auto scaling for the DynamoDB table to automatically adjust its write capacity based on traffic patterns.\\n\\nBoth A and B address the core issue of managing write throughput to the DynamoDB table to prevent throttling. Option A provides a way to smooth out data flow and manage write requests more effectively, while option B allows the table to scale its capacity automatically in response to changing traffic, although with potential limitations in response speed to sudden traffic spikes. Combining these approaches could provide an even more robust solution."},{"poster":"KarBiswa","timestamp":"1702909320.0","comment_id":"1099777","content":"Selected Answer: A\\nOff course A & D are options but here after inserting the data further we cannot modify because one extra writing cost will incur rather using queue lambda can poll the transformed data","upvote_count":"3"},{"timestamp":"1697561400.0","content":"Selected Answer: A\\nAnswer : A\\nSQS can be configured to invoke Lambda.\\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-lambda-function-trigger.html","upvote_count":"4","comment_id":"1046213","poster":"Nagasoracle"},{"upvote_count":"1","content":"Selected Answer: B\\nI think B","comment_id":"1046023","timestamp":"1697547900.0","poster":"dexdinh91"},{"timestamp":"1696934940.0","upvote_count":"2","comment_id":"1039394","poster":"jingle4944","content":"Lambda functions can be triggered by SQS: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-lambda-function-trigger.html","comments":[{"upvote_count":"1","poster":"nbxyzd","content":"Correct, and most importantly, it\'s triggered *synchronously* so that there won\'t be throttling issue. Quote:\\nYou can use an AWS Lambda function to process messages in an Amazon SQS queue. Lambda polls the queue and invokes your Lambda function synchronously with an event that contains queue messages.","comment_id":"1306077","timestamp":"1730533500.0"}]},{"upvote_count":"1","poster":"Balliache520505","content":"Selected Answer: B\\nI don\'t believe that option A is correct because an Amazon SQS queue wouldn\'t invoke a Lambda function; in any case, the Lambda function would be configured to retrieve messages from the SQS queue. For that reason, I believe option B would be the correct choice in this case.","timestamp":"1695569040.0","comment_id":"1015949"},{"content":"Selected Answer: A\\nRefactoring the Lambda function into two functions and introducing an Amazon Simple Queue Service (Amazon SQS) queue between them would provide a buffering mechanism. The first Lambda function would transform the data and push it to the SQS queue. The second Lambda function would be triggered by messages in the SQS queue to write the data into DynamoDB. This decouples the two operations and allows for more controlled and consistent data loading into DynamoDB, helping to avoid throttling.","comment_id":"1003451","poster":"Dushank","timestamp":"1694287200.0","upvote_count":"3"},{"content":"Selected Answer: A\\nthe requirement is Lambda function load data to DynamoDB.\\nD is incorrect : \\"DynamoDB stream invoke Lambda\\" - the order is reversed.","upvote_count":"3","poster":"jipark","comment_id":"970793","timestamp":"1691043240.0"},{"comment_id":"958556","timestamp":"1689946500.0","content":"Selected Answer: B\\nThe key point is \\"eliminate the throttling\\"\\nI prefer B than A","upvote_count":"3","poster":"baboopan18"},{"content":"Selected Answer: D\\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-basic-architecture.html\\nThis is the lifecycle for a SQS message. \\nFor my understanding, option A is wrong. SQS cannot invoke function, like is it stated there. \\nSo D it\'s the right answer.","upvote_count":"1","comments":[{"comment_id":"952730","poster":"tttamtttam","content":"Lambda functions can be triggered by messages in a SQS queue.","timestamp":"1689459840.0","upvote_count":"4"}],"poster":"qwan","timestamp":"1688501160.0","comment_id":"943140"},{"timestamp":"1688493960.0","poster":"eberhe900","upvote_count":"7","comment_id":"943062","content":"Selected Answer: B\\nThe developer needs to implement a solution to eliminate the throttling and load the data into the DynamoDB table more consistently. The problem is in DynamoDB does not associate with the lambada. Then the better solution is to auto scale the table of the DynamoDB."},{"upvote_count":"3","timestamp":"1688464260.0","poster":"Phongsanth","content":"Selected Answer: A\\nSQS between Lambda function should deliver the traffic more consistently.","comment_id":"942585"},{"content":"Selected Answer: A\\nThis solution will not meet the requirements because it will not load the data into the DynamoDB table more consistently. By using a DynamoDB stream, you can trigger a Lambda function to process data changes in a DynamoDB table. However, this does not guarantee that all data changes will be processed in order, or that no duplicates will occur. Therefore, this solution may result in inconsistent or incorrect data in your DynamoDB table.\\n\\nThe best solution is A, because it will eliminate the throttling and load the data into the DynamoDB table more consistently.","comment_id":"927758","upvote_count":"3","poster":"gagol14","timestamp":"1687195680.0"},{"comment_id":"912856","upvote_count":"1","poster":"mgonblan","timestamp":"1685712780.0","content":"I vote B, because refactoring the lambdas (A or D) could help, but it doesn\'t help the DynamoDB tables, C would give reserved concurrency to the lambda and improves performance, but it doesn\'t help with DynamoDB layer.\\nSo the best option is B) Because you stablish autoscaling and configure cloudwatch to monitor which RCU and WCU must use for the table."},{"comment_id":"908096","poster":"FunkyFresco","timestamp":"1685203980.0","content":"Selected Answer: D\\nOption D.","upvote_count":"1"},{"upvote_count":"1","poster":"loctong","timestamp":"1684410540.0","content":"Selected Answer: D\\nD is true","comment_id":"901166"},{"upvote_count":"1","timestamp":"1684410300.0","comment_id":"901158","poster":"loctong","content":"Selected Answer: D\\nTo eliminate throttling and load the data into the DynamoDB table more consistently, you can refactor the Lambda function into two functions and utilize DynamoDB streams."},{"timestamp":"1684087380.0","upvote_count":"3","content":"Selected Answer: A\\nOption A suggests refactoring the Lambda function into two functions, one to transform the data and the other to load the data into the DynamoDB table, and adding an Amazon SQS queue in between the functions to hold the items as messages and to invoke the second function. This approach separates the processing and loading stages, allowing the Lambda functions to scale independently and reducing the chance of throttling.","poster":"Prem28","comment_id":"897807"},{"poster":"rlnd2000","comment_id":"897538","comments":[{"comment_id":"898204","timestamp":"1684148940.0","upvote_count":"1","content":"Sorry I change to A, the problem is not in DynamoDB, => ...The flow of data to the DynamoDB table is becoming throttled..., is the flow of data, I go with A.","poster":"rlnd2000"},{"timestamp":"1685455440.0","content":"I\'m also with B. because autoscaling DynamoDB tables and monitoring the reads we can fix the RCU of the DyynamoDB Database. \\nRefactoring the Lambdas would not help very much.","poster":"mgonblan","upvote_count":"1","comment_id":"910302"}],"content":"Selected Answer: B\\nB => I think the problem here is the \\"...sudden and significant changes in traffic...\\" the current write capacity in DynamoDB is not enough to insert all incoming data, Decoupling is good practice but won\'t solve the problem in this case because the question doesn\'t mention that the increase in the traffic is temporary so any solution without increasing the write capacity will create a bottleneck.","upvote_count":"3","timestamp":"1684069440.0"}],"answer_description":"","extracted_at":"2025-12-24T09:15:13.504Z","extraction_method":"api_direct_v1"}],"statistics":{"questions_per_page_avg":5,"topics":["1"],"question_types":{"multiple_choice":555,"other":0},"has_images":{"question_images":9,"answer_images":0},"discussion_stats":{"with_discussion":555,"total_comments":3673}}}')}}]);